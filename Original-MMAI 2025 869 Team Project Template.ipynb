{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"provenance":[{"file_id":"1Qdzbejqt4ypSvL-h8WFMmQFEFZB2GKId","timestamp":1716377771632},{"file_id":"1ER4NDAWpuwaZ43Dn9vYxd_vapYEDeczF","timestamp":1652728119372},{"file_id":"1InS6-7UZYc8qRPKGhEBkGv8nMQ3dl3Qq","timestamp":1631545645387},{"file_id":"1Pp88aji8w35O-WJbctcsHfinGqUhoT1c","timestamp":1622488006439},{"file_id":"1PNmd4hys3w1ZYkMSzqYL7fVV3v72Chxv","timestamp":1614187967149},{"file_id":"1Nv7GmhY_xL7txEJ0nNKNP1WmMiXEHA5U","timestamp":1613739709908},{"file_id":"https://github.com/stepthom/NLP_course/blob/main/document_classification/kiva_classification_simple.ipynb","timestamp":1613482590973}]}},"cells":[{"cell_type":"markdown","metadata":{"id":"HKmorPdno_n_"},"source":["# MMAI 2025 869: Team Project Template\n","*Updated May 3, 2024*\n","\n","This notebook serves as a template for the Team Project. Teams can use this notebook as a starting point, and update it successively with new ideas and techniques to improve their model results.\n","\n","Note that is not required to use this template. Teams may also alter this template in any way they see fit.\n"]},{"cell_type":"markdown","metadata":{"id":"oZFTCX4DqmRO"},"source":["# Preliminaries: Inspect and Set up environment\n","\n","No action is required on your part in this section. These cells print out helpful information about the environment, just in case."]},{"cell_type":"code","metadata":{"id":"xj34Jz-Do_oK"},"source":["import datetime\n","import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mqQ_XOKyXTS6"},"source":["print(datetime.datetime.now())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LfOMt1lErLhZ"},"source":["!which python"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aub2w1-arM5K"},"source":["!python --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E9Y_n_8UrO9i"},"source":["!echo $PYTHONPATH"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-qyD7Jl0Gw1E"},"source":["# TODO: if you need to install any package, do so here. For example:\n","#pip install unidecode"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B_IHoz7f2yIV"},"source":["# 0. Data Loading and Inspection"]},{"cell_type":"markdown","metadata":{"id":"jqm_REd4oouz"},"source":["## 0.1: Load data\n","\n","The file containing the labeled training data is conveniently located on the cloud at the address below. Let's load it up and take a look."]},{"cell_type":"code","metadata":{"id":"X6b_BM0Nz9sF"},"source":["df = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1eYCKuqJda4bpzXBVnqXylg0qQwvpUuum\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 0.1 Simple Exploratory Data Analysis"],"metadata":{"id":"Ys9PPIOlvVzl"}},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"5sQ8ht2_L0cD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's print some descriptive statistics for all the numeric features.\n","\n","df.describe().T"],"metadata":{"id":"GxX8nM24uyzE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# What is the number of unique values in all the categorical features? And what is\n","# the value with the highest frequency?\n","\n","df.describe(include=object).T"],"metadata":{"id":"ELhSsAmiLZxF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# How much missing data is in each feature?\n","\n","df.isna().sum()"],"metadata":{"id":"tBI28r_bgV06"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# For convienience, let's save the names of all numeric features to a list,\n","# and the names of all categorical features to another list.\n","\n","numeric_features = [\n","          \"h1n1_concern\",\n","          \"h1n1_knowledge\",\n","          \"behavioral_antiviral_meds\",\n","          \"behavioral_avoidance\",\n","          \"behavioral_face_mask\",\n","          \"behavioral_wash_hands\",\n","          \"behavioral_large_gatherings\",\n","          \"behavioral_outside_home\",\n","          \"behavioral_touch_face\",\n","          \"doctor_recc_h1n1\",\n","          \"doctor_recc_seasonal\",\n","          \"chronic_med_condition\",\n","          \"child_under_6_months\",\n","          \"health_worker\",\n","          \"health_insurance\",\n","          \"opinion_h1n1_vacc_effective\",\n","          \"opinion_h1n1_risk\",\n","          \"opinion_h1n1_sick_from_vacc\",\n","          \"opinion_seas_vacc_effective\",\n","          \"opinion_seas_risk\",\n","          \"opinion_seas_sick_from_vacc\",\n","          \"household_adults\",\n","          \"household_children\",\n","]\n","\n","categorical_features = [\n","    \"age_group\",\n","    \"education\",\n","    \"race\",\n","    \"sex\",\n","    \"income_poverty\",\n","    \"marital_status\",\n","    \"rent_or_own\",\n","    \"employment_status\",\n","    \"hhs_geo_region\",\n","    \"census_msa\",\n","    \"employment_industry\",\n","    \"employment_occupation\",\n","]\n","\n"],"metadata":{"id":"AC8gMKmad5RF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: Can add more EDA here, as desired"],"metadata":{"id":"u1-yEBsBfieA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1. Train/Test Split\n","\n","Now we randomly split the available data into train and test subsets.\n","\n","The training data will later be used to build and assess the model on various combinations of hyperparaters.\n","\n","The testing data will be used as a \"final estimate\" of a model's performance."],"metadata":{"id":"sbTJkUNdvfsF"}},{"cell_type":"markdown","metadata":{"id":"sdiKKblCo53S"},"source":["# 2. Model 1 (A simple DecisionTree model)\n","\n","As a baseline, we'll do the absolute bare minimum data cleaning and then quickly build a simple Decision Tree."]},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.impute import SimpleImputer\n","from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"HuWoCrg3bQUs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Scikit-learn needs us to put the features in one dataframe, and the label in another.\n","# It's tradition to name these variables X and y, but it doesn't really matter.\n","\n","X = df.drop('h1n1_vaccine', axis=1)\n","y = df['h1n1_vaccine']"],"metadata":{"id":"aUZxa2f6uw3l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.1 Cleaning and FE"],"metadata":{"id":"zqYbbTAejRCD"}},{"cell_type":"code","source":["# We know this dataset has categorical features, and we also know that DTs don't\n","# allow categorical features. For now, we'll just remove (i.e., drop) these\n","# features.\n","#\n","# TODO: do something better, like encode them (as discussed in session 4)\n","\n","X = X.drop(categorical_features, axis=1, errors='ignore')"],"metadata":{"id":"KwfR9_nQftlS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# We know this dataset has some missing data, and we also know that DTs don't\n","# allow missing data. For now, we'll just do simple imputation.\n","#\n","# TODO: consider doing something different/better, like encode them (as\n","# discussed in session 4)\n","\n","imp = SimpleImputer()\n","imp.fit(X)\n","X = imp.transform(X)"],"metadata":{"id":"j4l5INJbdOde"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: Add more data cleaning, as desired."],"metadata":{"id":"LFP31BTzhRrU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.2 Model Creation, Hyperparameter Tuning, and Validation"],"metadata":{"id":"Dm8fR8W4jUrW"}},{"cell_type":"code","metadata":{"id":"mSumAZUAo9O6"},"source":["# Let's create a very simple DecisionTree.\n","\n","clf = DecisionTreeClassifier(max_depth=3, random_state=0)\n","\n","# TODO: Can try different algorithms"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# We use cross_validate to perform K-fold cross validation for us.\n","cv_results = cross_validate(clf, X, y, cv=5, scoring=\"f1_macro\")\n","\n","# TODO: can also add hyperparameter tuning to explore different values of the algorithms\n","# hyperparameters, and see how much those affect results.\n","# See GridSearchCV or RandomizedSearchCV."],"metadata":{"id":"xV_01HAFe4xa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Now that cross validation has completed, we can see what it estimates the peformance\n","# of our model to be.\n","\n","display(cv_results)\n","print(\"The mean CV score is:\")\n","print(np.mean(cv_results['test_score']))"],"metadata":{"id":"HeHuood_f-fh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ihVtYBWg1NM6"},"source":["## 1.4: Create Predictions for Competition Data\n","\n","Once we are happy with the estimated performance of our model, we can move on to the final step.\n","\n","First, we train our model one last time, using all available training data (unlike CV, which always uses a subset). This final training will give our model the best chance as the highest performance.\n","\n","Then, we must load in the (unlabeled) competition data from the cloud and use our model to generate predictions for each instance in that data. We will then output those predictions to a CSV file. We will then send that file to Steve, and he can then tell us how well we did (because he knows the right answers!)."]},{"cell_type":"code","source":["# Our model's \"final form\"\n","\n","clf = clf.fit(X, y)"],"metadata":{"id":"74lBpHWfe5h1"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pu2xugQj1Mci"},"source":["X_comp = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1SmFBoNh7segI1Ky92mfeIe6TpscclMwQ\")\n","\n","# Importantly, we need to perform the same cleaning/transformation steps\n","# on this competition data as you did the training data. Otherwise, we will\n","# get an error and/or unexpected results.\n","\n","X_comp = X_comp.drop(categorical_features, axis=1, errors='ignore')\n","X_comp = imp.transform(X_comp)\n","\n","# Use your model to make predictions\n","pred_comp = clf.predict(X_comp)\n","\n","my_submission = pd.DataFrame({'predicted': pred_comp})\n","\n","# Let's take a peak at the results (as a sanity check)\n","display(my_submission.head(10))\n","\n","# You could use any filename.\n","my_submission.to_csv('my_submission.csv', index=False)\n","\n","# You can now download the above file from Colab (see menu on the left)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model 2 (Your idea Here!)\n","\n","Here, you can do all the above, but try different ideas:\n","\n","- Different ML algorithms (e.g., RandomForestClassifier, LGBM, NN)\n","- Different data cleaning steps (Ordinal encoding, One Hot Encoding, etc.)\n","- Hyperparameter tuning (using, e.g., GridSearchCV or RandomizedSearchCV)\n","- Ensembles\n","- .... anything you can think of!\n","\n","\n","Steve's GitHub page is a great place for ideas:\n","\n","https://github.com/stepthom/869_course"],"metadata":{"id":"1DF6Z8-baL9K"}},{"cell_type":"code","source":["# TODO: Win the competition here!"],"metadata":{"id":"heJMDH4KaN9G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model 3 (Your next idea here!)"],"metadata":{"id":"qquC4XuEiyA5"}},{"cell_type":"code","source":["# TODO: Win the competition here, too!"],"metadata":{"id":"LKrudgbEiyqw"},"execution_count":null,"outputs":[]}]}