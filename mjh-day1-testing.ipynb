{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rllevy/MMAI-Bae/blob/main/day-1-base-line_dropping_health_insurance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKmorPdno_n_"
      },
      "source": [
        "# (MJH - DAY1 TESTING) MMAI 2025 869: Team Project Template\n",
        "*Updated May 3, 2024*\n",
        "\n",
        "This notebook serves as a template for the Team Project. Teams can use this notebook as a starting point, and update it successively with new ideas and techniques to improve their model results.\n",
        "\n",
        "Note that is not required to use this template. Teams may also alter this template in any way they see fit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZFTCX4DqmRO"
      },
      "source": [
        "# Preliminaries: Inspect and Set up environment\n",
        "\n",
        "No action is required on your part in this section. These cells print out helpful information about the environment, just in case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /Users/mhoy/.local/lib/python3.11/site-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /Users/mhoy/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mhoy/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/mhoy/.local/lib/python3.11/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/mhoy/.local/lib/python3.11/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /Users/mhoy/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: numpy in /Users/mhoy/.pyenv/versions/3.11.8/lib/python3.11/site-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /Users/mhoy/.local/lib/python3.11/site-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /Users/mhoy/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /Users/mhoy/.local/lib/python3.11/site-packages (from scikit-learn) (1.13.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Users/mhoy/.local/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/mhoy/.local/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: xgboost in /Users/mhoy/.local/lib/python3.11/site-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /Users/mhoy/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: scipy in /Users/mhoy/.local/lib/python3.11/site-packages (from xgboost) (1.13.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install --user pandas\n",
        "! pip install --user numpy\n",
        "! pip install --user scikit-learn\n",
        "! pip install --user xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xj34Jz-Do_oK"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqQ_XOKyXTS6",
        "outputId": "84ac7f2e-9127-4172-87e1-7a6807ddd4e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-05-21 14:08:29.375318\n"
          ]
        }
      ],
      "source": [
        "print(datetime.datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfOMt1lErLhZ",
        "outputId": "d4c33ee5-50cf-415b-c5aa-c4461de8c087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/mhoy/.pyenv/versions/3.11.8/bin/python\n"
          ]
        }
      ],
      "source": [
        "!which python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aub2w1-arM5K",
        "outputId": "b53966a9-37f7-434e-f793-98c6c80ed0d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.11.8\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9Y_n_8UrO9i",
        "outputId": "df0728a6-6cbc-4ef0-dfdc-ab06efb19a5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "!echo $PYTHONPATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-qyD7Jl0Gw1E"
      },
      "outputs": [],
      "source": [
        "# TODO: if you need to install any package, do so here. For example:\n",
        "#pip install unidecode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_IHoz7f2yIV"
      },
      "source": [
        "# 0. Data Loading and Inspection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqm_REd4oouz"
      },
      "source": [
        "## 0.1: Load data\n",
        "\n",
        "The file containing the labeled training data is conveniently located on the cloud at the address below. Let's load it up and take a look."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "X6b_BM0Nz9sF"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1eYCKuqJda4bpzXBVnqXylg0qQwvpUuum\")\n",
        "# df = pd.read_csv(\"file:///Users/mhoy/ownCloud - mhoy@owncloud-new.markjhoy.com/Smith_MMAI_2025/Courses/MMAI 869 - Intro to AI and ML/cleaned_test2.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys9PPIOlvVzl"
      },
      "source": [
        "## 0.1 Simple Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sQ8ht2_L0cD",
        "outputId": "c337024c-c4f2-48d2-f297-6b8e2d3e5e64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21365 entries, 0 to 21364\n",
            "Data columns (total 36 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   h1n1_concern                 21292 non-null  float64\n",
            " 1   h1n1_knowledge               21274 non-null  float64\n",
            " 2   behavioral_antiviral_meds    21306 non-null  float64\n",
            " 3   behavioral_avoidance         21202 non-null  float64\n",
            " 4   behavioral_face_mask         21351 non-null  float64\n",
            " 5   behavioral_wash_hands        21329 non-null  float64\n",
            " 6   behavioral_large_gatherings  21293 non-null  float64\n",
            " 7   behavioral_outside_home      21306 non-null  float64\n",
            " 8   behavioral_touch_face        21263 non-null  float64\n",
            " 9   doctor_recc_h1n1             19629 non-null  float64\n",
            " 10  doctor_recc_seasonal         19629 non-null  float64\n",
            " 11  chronic_med_condition        20594 non-null  float64\n",
            " 12  child_under_6_months         20710 non-null  float64\n",
            " 13  health_worker                20722 non-null  float64\n",
            " 14  health_insurance             11507 non-null  float64\n",
            " 15  opinion_h1n1_vacc_effective  21047 non-null  float64\n",
            " 16  opinion_h1n1_risk            21054 non-null  float64\n",
            " 17  opinion_h1n1_sick_from_vacc  21044 non-null  float64\n",
            " 18  opinion_seas_vacc_effective  20994 non-null  float64\n",
            " 19  opinion_seas_risk            20955 non-null  float64\n",
            " 20  opinion_seas_sick_from_vacc  20934 non-null  float64\n",
            " 21  age_group                    21365 non-null  object \n",
            " 22  education                    20240 non-null  object \n",
            " 23  race                         21365 non-null  object \n",
            " 24  sex                          21365 non-null  object \n",
            " 25  income_poverty               17851 non-null  object \n",
            " 26  marital_status               20245 non-null  object \n",
            " 27  rent_or_own                  19737 non-null  object \n",
            " 28  employment_status            20203 non-null  object \n",
            " 29  hhs_geo_region               21365 non-null  object \n",
            " 30  census_msa                   21365 non-null  object \n",
            " 31  household_adults             21163 non-null  float64\n",
            " 32  household_children           21163 non-null  float64\n",
            " 33  employment_industry          10738 non-null  object \n",
            " 34  employment_occupation        10629 non-null  object \n",
            " 35  h1n1_vaccine                 21365 non-null  int64  \n",
            "dtypes: float64(23), int64(1), object(12)\n",
            "memory usage: 5.9+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "GxX8nM24uyzE",
        "outputId": "eaf46a77-3a7b-4d90-a82b-e58d1c8883dd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>h1n1_concern</th>\n",
              "      <td>21292.0</td>\n",
              "      <td>1.618026</td>\n",
              "      <td>0.909311</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h1n1_knowledge</th>\n",
              "      <td>21274.0</td>\n",
              "      <td>1.265018</td>\n",
              "      <td>0.617816</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>behavioral_antiviral_meds</th>\n",
              "      <td>21306.0</td>\n",
              "      <td>0.049329</td>\n",
              "      <td>0.216559</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>behavioral_avoidance</th>\n",
              "      <td>21202.0</td>\n",
              "      <td>0.724507</td>\n",
              "      <td>0.446773</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>behavioral_face_mask</th>\n",
              "      <td>21351.0</td>\n",
              "      <td>0.070348</td>\n",
              "      <td>0.255739</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>behavioral_wash_hands</th>\n",
              "      <td>21329.0</td>\n",
              "      <td>0.823574</td>\n",
              "      <td>0.381192</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>behavioral_large_gatherings</th>\n",
              "      <td>21293.0</td>\n",
              "      <td>0.357864</td>\n",
              "      <td>0.479383</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>behavioral_outside_home</th>\n",
              "      <td>21306.0</td>\n",
              "      <td>0.337464</td>\n",
              "      <td>0.472856</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>behavioral_touch_face</th>\n",
              "      <td>21263.0</td>\n",
              "      <td>0.675728</td>\n",
              "      <td>0.468113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doctor_recc_h1n1</th>\n",
              "      <td>19629.0</td>\n",
              "      <td>0.221662</td>\n",
              "      <td>0.415375</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doctor_recc_seasonal</th>\n",
              "      <td>19629.0</td>\n",
              "      <td>0.332467</td>\n",
              "      <td>0.471109</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chronic_med_condition</th>\n",
              "      <td>20594.0</td>\n",
              "      <td>0.284840</td>\n",
              "      <td>0.451349</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>child_under_6_months</th>\n",
              "      <td>20710.0</td>\n",
              "      <td>0.082134</td>\n",
              "      <td>0.274576</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>health_worker</th>\n",
              "      <td>20722.0</td>\n",
              "      <td>0.113840</td>\n",
              "      <td>0.317625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>health_insurance</th>\n",
              "      <td>11507.0</td>\n",
              "      <td>0.879465</td>\n",
              "      <td>0.325601</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>opinion_h1n1_vacc_effective</th>\n",
              "      <td>21047.0</td>\n",
              "      <td>3.848910</td>\n",
              "      <td>1.008976</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>opinion_h1n1_risk</th>\n",
              "      <td>21054.0</td>\n",
              "      <td>2.345730</td>\n",
              "      <td>1.287865</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>opinion_h1n1_sick_from_vacc</th>\n",
              "      <td>21044.0</td>\n",
              "      <td>2.361196</td>\n",
              "      <td>1.362904</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>opinion_seas_vacc_effective</th>\n",
              "      <td>20994.0</td>\n",
              "      <td>4.029532</td>\n",
              "      <td>1.082279</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>opinion_seas_risk</th>\n",
              "      <td>20955.0</td>\n",
              "      <td>2.722023</td>\n",
              "      <td>1.385780</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>opinion_seas_sick_from_vacc</th>\n",
              "      <td>20934.0</td>\n",
              "      <td>2.121286</td>\n",
              "      <td>1.335174</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>household_adults</th>\n",
              "      <td>21163.0</td>\n",
              "      <td>0.888910</td>\n",
              "      <td>0.754466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>household_children</th>\n",
              "      <td>21163.0</td>\n",
              "      <td>0.535888</td>\n",
              "      <td>0.929504</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h1n1_vaccine</th>\n",
              "      <td>21365.0</td>\n",
              "      <td>0.212684</td>\n",
              "      <td>0.409216</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               count      mean       std  min  25%  50%  75%  \\\n",
              "h1n1_concern                 21292.0  1.618026  0.909311  0.0  1.0  2.0  2.0   \n",
              "h1n1_knowledge               21274.0  1.265018  0.617816  0.0  1.0  1.0  2.0   \n",
              "behavioral_antiviral_meds    21306.0  0.049329  0.216559  0.0  0.0  0.0  0.0   \n",
              "behavioral_avoidance         21202.0  0.724507  0.446773  0.0  0.0  1.0  1.0   \n",
              "behavioral_face_mask         21351.0  0.070348  0.255739  0.0  0.0  0.0  0.0   \n",
              "behavioral_wash_hands        21329.0  0.823574  0.381192  0.0  1.0  1.0  1.0   \n",
              "behavioral_large_gatherings  21293.0  0.357864  0.479383  0.0  0.0  0.0  1.0   \n",
              "behavioral_outside_home      21306.0  0.337464  0.472856  0.0  0.0  0.0  1.0   \n",
              "behavioral_touch_face        21263.0  0.675728  0.468113  0.0  0.0  1.0  1.0   \n",
              "doctor_recc_h1n1             19629.0  0.221662  0.415375  0.0  0.0  0.0  0.0   \n",
              "doctor_recc_seasonal         19629.0  0.332467  0.471109  0.0  0.0  0.0  1.0   \n",
              "chronic_med_condition        20594.0  0.284840  0.451349  0.0  0.0  0.0  1.0   \n",
              "child_under_6_months         20710.0  0.082134  0.274576  0.0  0.0  0.0  0.0   \n",
              "health_worker                20722.0  0.113840  0.317625  0.0  0.0  0.0  0.0   \n",
              "health_insurance             11507.0  0.879465  0.325601  0.0  1.0  1.0  1.0   \n",
              "opinion_h1n1_vacc_effective  21047.0  3.848910  1.008976  1.0  3.0  4.0  5.0   \n",
              "opinion_h1n1_risk            21054.0  2.345730  1.287865  1.0  1.0  2.0  4.0   \n",
              "opinion_h1n1_sick_from_vacc  21044.0  2.361196  1.362904  1.0  1.0  2.0  4.0   \n",
              "opinion_seas_vacc_effective  20994.0  4.029532  1.082279  1.0  4.0  4.0  5.0   \n",
              "opinion_seas_risk            20955.0  2.722023  1.385780  1.0  2.0  2.0  4.0   \n",
              "opinion_seas_sick_from_vacc  20934.0  2.121286  1.335174  1.0  1.0  2.0  4.0   \n",
              "household_adults             21163.0  0.888910  0.754466  0.0  0.0  1.0  1.0   \n",
              "household_children           21163.0  0.535888  0.929504  0.0  0.0  0.0  1.0   \n",
              "h1n1_vaccine                 21365.0  0.212684  0.409216  0.0  0.0  0.0  0.0   \n",
              "\n",
              "                             max  \n",
              "h1n1_concern                 3.0  \n",
              "h1n1_knowledge               2.0  \n",
              "behavioral_antiviral_meds    1.0  \n",
              "behavioral_avoidance         1.0  \n",
              "behavioral_face_mask         1.0  \n",
              "behavioral_wash_hands        1.0  \n",
              "behavioral_large_gatherings  1.0  \n",
              "behavioral_outside_home      1.0  \n",
              "behavioral_touch_face        1.0  \n",
              "doctor_recc_h1n1             1.0  \n",
              "doctor_recc_seasonal         1.0  \n",
              "chronic_med_condition        1.0  \n",
              "child_under_6_months         1.0  \n",
              "health_worker                1.0  \n",
              "health_insurance             1.0  \n",
              "opinion_h1n1_vacc_effective  5.0  \n",
              "opinion_h1n1_risk            5.0  \n",
              "opinion_h1n1_sick_from_vacc  5.0  \n",
              "opinion_seas_vacc_effective  5.0  \n",
              "opinion_seas_risk            5.0  \n",
              "opinion_seas_sick_from_vacc  5.0  \n",
              "household_adults             3.0  \n",
              "household_children           3.0  \n",
              "h1n1_vaccine                 1.0  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's print some descriptive statistics for all the numeric features.\n",
        "\n",
        "df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "ELhSsAmiLZxF",
        "outputId": "c4917882-f2d0-4f89-e8eb-4f69082a27e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age_group</th>\n",
              "      <td>21365</td>\n",
              "      <td>5</td>\n",
              "      <td>65+ Years</td>\n",
              "      <td>5454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>education</th>\n",
              "      <td>20240</td>\n",
              "      <td>4</td>\n",
              "      <td>College Graduate</td>\n",
              "      <td>8063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>race</th>\n",
              "      <td>21365</td>\n",
              "      <td>4</td>\n",
              "      <td>White</td>\n",
              "      <td>16974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex</th>\n",
              "      <td>21365</td>\n",
              "      <td>2</td>\n",
              "      <td>Female</td>\n",
              "      <td>12748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>income_poverty</th>\n",
              "      <td>17851</td>\n",
              "      <td>3</td>\n",
              "      <td>&lt;= $75,000, Above Poverty</td>\n",
              "      <td>10301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>marital_status</th>\n",
              "      <td>20245</td>\n",
              "      <td>2</td>\n",
              "      <td>Married</td>\n",
              "      <td>10880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rent_or_own</th>\n",
              "      <td>19737</td>\n",
              "      <td>2</td>\n",
              "      <td>Own</td>\n",
              "      <td>15012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>employment_status</th>\n",
              "      <td>20203</td>\n",
              "      <td>3</td>\n",
              "      <td>Employed</td>\n",
              "      <td>10886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hhs_geo_region</th>\n",
              "      <td>21365</td>\n",
              "      <td>10</td>\n",
              "      <td>lzgpxyit</td>\n",
              "      <td>3406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>census_msa</th>\n",
              "      <td>21365</td>\n",
              "      <td>3</td>\n",
              "      <td>MSA, Not Principle  City</td>\n",
              "      <td>9268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>employment_industry</th>\n",
              "      <td>10738</td>\n",
              "      <td>21</td>\n",
              "      <td>fcxhlnwr</td>\n",
              "      <td>2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>employment_occupation</th>\n",
              "      <td>10629</td>\n",
              "      <td>23</td>\n",
              "      <td>xtkaffoo</td>\n",
              "      <td>1406</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       count unique                        top   freq\n",
              "age_group              21365      5                  65+ Years   5454\n",
              "education              20240      4           College Graduate   8063\n",
              "race                   21365      4                      White  16974\n",
              "sex                    21365      2                     Female  12748\n",
              "income_poverty         17851      3  <= $75,000, Above Poverty  10301\n",
              "marital_status         20245      2                    Married  10880\n",
              "rent_or_own            19737      2                        Own  15012\n",
              "employment_status      20203      3                   Employed  10886\n",
              "hhs_geo_region         21365     10                   lzgpxyit   3406\n",
              "census_msa             21365      3   MSA, Not Principle  City   9268\n",
              "employment_industry    10738     21                   fcxhlnwr   2009\n",
              "employment_occupation  10629     23                   xtkaffoo   1406"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# What is the number of unique values in all the categorical features? And what is\n",
        "# the value with the highest frequency?\n",
        "\n",
        "df.describe(include=object).T\n",
        "# df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBI28r_bgV06",
        "outputId": "d51b2884-a747-4025-82f2-93484340bda1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "h1n1_concern                      73\n",
              "h1n1_knowledge                    91\n",
              "behavioral_antiviral_meds         59\n",
              "behavioral_avoidance             163\n",
              "behavioral_face_mask              14\n",
              "behavioral_wash_hands             36\n",
              "behavioral_large_gatherings       72\n",
              "behavioral_outside_home           59\n",
              "behavioral_touch_face            102\n",
              "doctor_recc_h1n1                1736\n",
              "doctor_recc_seasonal            1736\n",
              "chronic_med_condition            771\n",
              "child_under_6_months             655\n",
              "health_worker                    643\n",
              "health_insurance                9858\n",
              "opinion_h1n1_vacc_effective      318\n",
              "opinion_h1n1_risk                311\n",
              "opinion_h1n1_sick_from_vacc      321\n",
              "opinion_seas_vacc_effective      371\n",
              "opinion_seas_risk                410\n",
              "opinion_seas_sick_from_vacc      431\n",
              "age_group                          0\n",
              "education                       1125\n",
              "race                               0\n",
              "sex                                0\n",
              "income_poverty                  3514\n",
              "marital_status                  1120\n",
              "rent_or_own                     1628\n",
              "employment_status               1162\n",
              "hhs_geo_region                     0\n",
              "census_msa                         0\n",
              "household_adults                 202\n",
              "household_children               202\n",
              "employment_industry            10627\n",
              "employment_occupation          10736\n",
              "h1n1_vaccine                       0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# How much missing data is in each feature?\n",
        "\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AC8gMKmad5RF"
      },
      "outputs": [],
      "source": [
        "# For convienience, let's save the names of all numeric features to a list,\n",
        "# and the names of all categorical features to another list.\n",
        "\n",
        "numeric_features = [\n",
        "          \"h1n1_concern\",\n",
        "          \"h1n1_knowledge\",\n",
        "          \"behavioral_antiviral_meds\",\n",
        "          \"behavioral_avoidance\",\n",
        "          \"behavioral_face_mask\",\n",
        "          \"behavioral_wash_hands\",\n",
        "          \"behavioral_large_gatherings\",\n",
        "          \"behavioral_outside_home\",\n",
        "          \"behavioral_touch_face\",\n",
        "          \"doctor_recc_h1n1\",\n",
        "          \"doctor_recc_seasonal\",\n",
        "          \"chronic_med_condition\",\n",
        "          \"child_under_6_months\",\n",
        "          \"health_worker\",\n",
        "          \"health_insurance\",\n",
        "          \"opinion_h1n1_vacc_effective\",\n",
        "          \"opinion_h1n1_risk\",\n",
        "          \"opinion_h1n1_sick_from_vacc\",\n",
        "          \"opinion_seas_vacc_effective\",\n",
        "          \"opinion_seas_risk\",\n",
        "          \"opinion_seas_sick_from_vacc\",\n",
        "          \"household_adults\",\n",
        "          \"household_children\",\n",
        "]\n",
        "\n",
        "categorical_features = [\n",
        "    \"age_group\",\n",
        "    \"education\",\n",
        "    \"race\",\n",
        "    \"sex\",\n",
        "    \"income_poverty\",\n",
        "    \"marital_status\",\n",
        "    \"rent_or_own\",\n",
        "    \"employment_status\",\n",
        "    \"hhs_geo_region\",\n",
        "    \"census_msa\",\n",
        "    \"employment_industry\",\n",
        "    \"employment_occupation\",\n",
        "]\n",
        "\n",
        "cols_to_drop = [\n",
        "#    \"employment_industry\",\n",
        "#    \"employment_occupation\",\n",
        "#    \"health_insurance\",\n",
        "]\n",
        "\n",
        "categorical_features = [x for x in categorical_features if x not in cols_to_drop]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "u1-yEBsBfieA"
      },
      "outputs": [],
      "source": [
        "# TODO: Can add more EDA here, as desired"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbTJkUNdvfsF"
      },
      "source": [
        "# 1. Train/Test Split\n",
        "\n",
        "Now we randomly split the available data into train and test subsets.\n",
        "\n",
        "The training data will later be used to build and assess the model on various combinations of hyperparaters.\n",
        "\n",
        "The testing data will be used as a \"final estimate\" of a model's performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdiKKblCo53S"
      },
      "source": [
        "# 2. Model 1 (A simple DecisionTree model)\n",
        "\n",
        "As a baseline, we'll do the absolute bare minimum data cleaning and then quickly build a simple Decision Tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HuWoCrg3bQUs"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "aUZxa2f6uw3l"
      },
      "outputs": [],
      "source": [
        "# Scikit-learn needs us to put the features in one dataframe, and the label in another.\n",
        "# It's tradition to name these variables X and y, but it doesn't really matter.\n",
        "\n",
        "X = df.drop('h1n1_vaccine', axis=1)\n",
        "y = df['h1n1_vaccine']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqYbbTAejRCD"
      },
      "source": [
        "## 1.1 Cleaning and FE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KwfR9_nQftlS"
      },
      "outputs": [],
      "source": [
        "# instead of dropping all categorical items (as we'll 1-hot encode these later),\n",
        "# we drop only specific columns\n",
        "#\n",
        "# for now - this is empty (see above)\n",
        "\n",
        "def drop_bad_columns(df):\n",
        "    return df.drop(cols_to_drop, axis=1, errors='ignore')\n",
        "\n",
        "def drop_categorical_columns(df):\n",
        "    return df.drop(categorical_features, axis=1, errors='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# perform one hot encoding of categorical data\n",
        "\n",
        "def one_hot_encode_categories(df):\n",
        "    return pd.get_dummies(df, columns = categorical_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "j4l5INJbdOde"
      },
      "outputs": [],
      "source": [
        "# impute the missing data from the rest of the dataset\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "def impute_missing_values(df):\n",
        "    # imputer = IterativeImputer(random_state=100, max_iter=6, verbose=2)\n",
        "    # ^^ DOES NOT HELP MORE THAN SIMPLE IMPUTATION! and takes longer...\n",
        "\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    imputer.fit(df)\n",
        "    imputed_df = imputer.transform(df)\n",
        "    return pd.DataFrame(imputed_df, columns=df.columns)\n",
        "#     return pd.DataFrame(imputer.fit_transform(imputed_x), columns=df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# here, we normalize the data to ensure all values are \n",
        "# in the 0.0 to 1.0 range. This makes it better for some\n",
        "# of the algorithms to run and typically yields better results\n",
        "\n",
        "def normalize_dataframe(df):\n",
        "    return df.apply(lambda iterator: ((iterator.max() - iterator)/(iterator.max() - iterator.min())))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LFP31BTzhRrU"
      },
      "outputs": [],
      "source": [
        "# This (currently unused) method selects the best k features\n",
        "# from our dataset and returns a DataFrame that only uses those\n",
        "#\n",
        "# Through experimentation, this seems to perform slightly worse\n",
        "# so, the method is not used at the moment\n",
        "\n",
        "from sklearn.feature_selection import chi2, SelectKBest\n",
        "\n",
        "def select_best_features(df, kvalue = 20):\n",
        "    selector = SelectKBest(score_func=chi2,k=kvalue)\n",
        "    ret_val = selector.fit_transform(df, y)\n",
        "    cols_idxs = selector.get_support(indices=True)\n",
        "    feature_columns = list(df.iloc[:,cols_idxs].columns)\n",
        "    return pd.DataFrame(ret_val, columns=feature_columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Our model cleaning process.\n",
        "#\n",
        "# through experimentation, I've observed overall so far:\n",
        "#  - 1-hot encoding to keep the categorical columns is good.\n",
        "#  - imputataion is necessary\n",
        "#  - normalization helps\n",
        "#  - selecting best features only provides slightly worse results\n",
        "\n",
        "import re\n",
        "\n",
        "def model_cleaning(df):\n",
        "    # simple cleaning\n",
        "    ret = drop_bad_columns(df)\n",
        "    # ret = drop_categorical_columns(ret)\n",
        "\n",
        "    # encoding\n",
        "    ret = one_hot_encode_categories(ret)\n",
        "\n",
        "    # imputation\n",
        "    ret = impute_missing_values(ret)\n",
        "    \n",
        "    # normalization\n",
        "    ret = normalize_dataframe(ret)\n",
        "\n",
        "    # feature reduction\n",
        "    # ret = select_best_features(ret) # does not help\n",
        "\n",
        "    # rename some columns to get rid of bad characters\n",
        "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
        "    ret.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in ret.columns.values]\n",
        "\n",
        "    return ret\n",
        "\n",
        "cleaned_data = model_cleaning(X)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dm8fR8W4jUrW"
      },
      "source": [
        "## 1.2 Model Creation, Hyperparameter Tuning, and Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier\n",
            "depth: 1 -- The mean CV score is: 0.6959383371869742\n",
            "depth: 2 -- The mean CV score is: 0.6689248144736056\n",
            "depth: 3 -- The mean CV score is: 0.6439743444016648\n",
            "depth: 4 -- The mean CV score is: 0.7049483195810098\n",
            "depth: 5 -- The mean CV score is: 0.7262965153012413\n",
            "depth: 6 -- The mean CV score is: 0.7194319711678351\n",
            "depth: 7 -- The mean CV score is: 0.7272765843219517\n",
            "depth: 8 -- The mean CV score is: 0.716825215256117\n",
            "depth: 9 -- The mean CV score is: 0.7207166619789527\n",
            "depth: 10 -- The mean CV score is: 0.717628084783215\n"
          ]
        }
      ],
      "source": [
        "def run_decision_tree(data, depth):\n",
        "    clf = DecisionTreeClassifier(max_depth=depth, random_state=0).fit(data, y)\n",
        "    cv_results = cross_validate(clf, data, y, cv=5, scoring=\"f1_macro\")\n",
        "    print(f\"depth: {depth} -- The mean CV score is: {np.mean(cv_results['test_score'])}\")\n",
        "\n",
        "print(\"DecisionTreeClassifier\")\n",
        "\n",
        "for n in range(0,10):\n",
        "    run_decision_tree(cleaned_data, n+1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Testing MLPClassifier (neural network)\n",
        "\n",
        "This is commented out at the moment as it's slow, and the best score achvied with this was around 0.7153903853823627"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# test_model = MLPClassifier(random_state=1, max_iter=1000).fit(cleaned_data, y)\n",
        "# grid_search_params = {\n",
        "#     \"hidden_layer_sizes\": [(25,), (50,), (100,), (150,)]\n",
        "# }\n",
        "# print(grid_search_params)\n",
        "# grid_search = GridSearchCV(test_model, grid_search_params, cv=5, scoring=\"f1_macro\")\n",
        "# grid_search.fit(cleaned_data, y)\n",
        "# display(grid_search.best_score_)\n",
        "# display(grid_search.best_params_)\n",
        "\n",
        "# layer_size = len(list(cleaned_data.columns))\n",
        "# display(f\"layer size: {layer_size}\")\n",
        "# clf = MLPClassifier(hidden_layer_sizes=(layer_size,), random_state=1, max_iter=4096).fit(cleaned_data,y)\n",
        "# cv_results = cross_validate(clf, cleaned_data, y, cv=5, scoring=\"f1_macro\")\n",
        "# print(f\"The mean CV score is: {np.mean(cv_results['test_score'])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The mean CV score is: 0.6147344123238534\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "layer_size = len(list(cleaned_data.columns))\n",
        "clf = KNeighborsClassifier(n_neighbors=5).fit(cleaned_data,y)\n",
        "cv_results = cross_validate(clf, cleaned_data, y, cv=5, scoring=\"f1_macro\")\n",
        "print(f\"The mean CV score is: {np.mean(cv_results['test_score'])}\")\n",
        "\n",
        "# test_model = KNeighborsClassifier().fit(cleaned_data, y)\n",
        "# grid_search_params = {\n",
        "#     \"n_neighbors\": list(range(1, 8)),\n",
        "#     \"p\": list(np.linspace(1, 4, num=6))\n",
        "# }\n",
        "# print(grid_search_params)\n",
        "# grid_search = GridSearchCV(test_model, grid_search_params, cv=5, scoring=\"f1_macro\")\n",
        "# grid_search.fit(cleaned_data, y)\n",
        "# display(grid_search.best_score_)\n",
        "# display(grid_search.best_params_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The mean CV score is: 0.7236249769651738\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier(random_state=1).fit(cleaned_data,y)\n",
        "cv_results = cross_validate(clf, cleaned_data, y, cv=5, scoring=\"f1_macro\")\n",
        "print(f\"The mean CV score is: {np.mean(cv_results['test_score'])}\")\n",
        "\n",
        "# test_model = RandomForestClassifier(random_state=1).fit(cleaned_data, y)\n",
        "# grid_search_params = {\n",
        "#     \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
        "#     \"max_leaf_nodes\": [10, 20, 30, 40, None],\n",
        "\n",
        "# }\n",
        "# print(grid_search_params)\n",
        "# grid_search = GridSearchCV(test_model, grid_search_params, cv=5, scoring=\"f1_macro\")\n",
        "# grid_search.fit(cleaned_data, y)\n",
        "# display(grid_search.best_score_)\n",
        "# display(grid_search.best_params_)\n",
        "# {'criterion': 'entropy', 'max_leaf_nodes': None}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GradientBoostingClassifier\n",
            "learning_rate: 0.1 -- The mean CV score is: 0.7536670551779296\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def run_gradient_boost(data, learning_rate):\n",
        "    # clf = GradientBoostingClassifier(loss='log_loss', max_depth=3, learning_rate=learning_rate, random_state=1).fit(data, y)\n",
        "    clf = HistGradientBoostingClassifier(learning_rate=learning_rate, random_state=1).fit(data, y)\n",
        "    cv_results = cross_validate(clf, data, y, cv=5, scoring=\"f1_macro\")\n",
        "    print(f\"learning_rate: {learning_rate} -- The mean CV score is: {np.mean(cv_results['test_score'])}\")\n",
        "\n",
        "print(\"GradientBoostingClassifier\")\n",
        "min_rate = 0.1\n",
        "max_rate = 0.6\n",
        "# cleaned_data_all_features = cleaned_data # model_cleaning(X)\n",
        "# print(\"-- with all features categories:\")\n",
        "\n",
        "#for learning_rate in np.linspace(min_rate, max_rate, num=10):\n",
        "#    run_gradient_boost(cleaned_data, learning_rate)    \n",
        "run_gradient_boost(cleaned_data, 0.1)    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test_model = HistGradientBoostingClassifier(random_state=1).fit(cleaned_data, y)\n",
        "# grid_search_params = {\n",
        "#     \"learning_rate\": list(np.linspace(min_rate, max_rate, num=15)),\n",
        "#     \"max_leaf_nodes\": [10, 20, 30, 40, None],\n",
        "\n",
        "# }\n",
        "# print(grid_search_params)\n",
        "# grid_search = GridSearchCV(test_model, grid_search_params, cv=5, scoring=\"f1_macro\")\n",
        "# grid_search.fit(cleaned_data, y)\n",
        "# display(grid_search.best_score_)\n",
        "# display(grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-- The mean CV score is: 0.7127663225531284\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(random_state=1, max_iter=512).fit(cleaned_data, y)\n",
        "cv_results = cross_validate(clf, cleaned_data, y, cv=5, scoring=\"f1_macro\")\n",
        "print(f\"-- The mean CV score is: {np.mean(cv_results['test_score'])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost\n",
            "{'objective': ['binary:logistic'], 'learning_rate': [0.11], 'subsample': [0.4888888888888889], 'max_depth': [6], 'booster': ['gbtree'], 'n_estimators': [100]}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7602104399043436"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'booster': 'gbtree',\n",
              " 'learning_rate': 0.11,\n",
              " 'max_depth': 6,\n",
              " 'n_estimators': 100,\n",
              " 'objective': 'binary:logistic',\n",
              " 'subsample': 0.4888888888888889}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "def run_xgboost_boost(data, learning_rate, subsample):\n",
        "   params = {\"objective\": \"binary:logitraw\", \n",
        "             \"eta\": learning_rate, \n",
        "             \"sampling_method\": \"uniform\",\n",
        "             \"subsample\": 0.95,\n",
        "             \"booster\": \"gbtree\" }\n",
        "   params = {\"eta\": learning_rate, \n",
        "             \"sampling_method\": \"uniform\",\n",
        "             \"subsample\": subsample,\n",
        "             \"booster\": \"gbtree\" }\n",
        "   dtrain_reg = xgb.DMatrix(data.values, y.values)\n",
        "   clf = xgb.XGBClassifier(objective=\"binary:hinge\", **params).fit(data.to_numpy(), y.to_numpy())\n",
        "   # model = xgb.train(\n",
        "   #    params=params,\n",
        "   #    dtrain=dtrain_reg,\n",
        "   #    num_boost_round=n,\n",
        "   # )\n",
        "   # clf = model.get_booster()\n",
        "   cv_results = cross_validate(clf, cleaned_data, y, cv=5, scoring=\"f1_macro\")\n",
        "   # cv_results = xgb.cv(params, dtrain_reg, 5, nfold=5, metrics={\"auc\"}, seed=0)\n",
        "   # print(cv_results)\n",
        "   # print(f\"learning_rate: {learning_rate} -- The mean CV score is: {np.mean(cv_results['test-auc-mean'])}\")\n",
        "   print(f\"learning_rate: {learning_rate}, subsample: {subsample} -- The mean CV score is: {np.mean(cv_results['test_score'])}\")\n",
        "\n",
        "print(\"XGBoost\")\n",
        "# min_rate = 1\n",
        "# max_rate = 10\n",
        "# min_subsample = 95\n",
        "# max_subsample = 100\n",
        "# for learning_rate in range(min_rate, max_rate):\n",
        "#    for subsample in range(min_subsample, max_subsample)\n",
        "#   run_xgboost_boost(cleaned_data, learning_rate*0.05, subsample=1)\n",
        "\n",
        "test_model = xgb.XGBClassifier(random_state=1).fit(cleaned_data.to_numpy(), y.to_numpy())\n",
        "grid_search_params = {\n",
        "    \"objective\": [\"binary:logistic\"],\n",
        "    \"learning_rate\": [0.11],\n",
        "    \"subsample\": [0.4888888888888889], # list(np.linspace(0.48, 0.49, num=50)), # [0.4888888888888889],\n",
        "    \"max_depth\": [6],\n",
        "    \"booster\": ['gbtree'],\n",
        "    \"n_estimators\": [100],\n",
        "    \"eval_metric\": ['rmse', 'rmsle', 'mae', 'mape', 'mphe', 'error']\n",
        "}\n",
        "print(grid_search_params)\n",
        "grid_search = GridSearchCV(test_model, grid_search_params, cv=5, scoring=\"f1_macro\")\n",
        "grid_search.fit(cleaned_data, y)\n",
        "display(grid_search.best_score_)\n",
        "display(grid_search.best_params_)\n",
        "\n",
        "# {'learning_rate': 0.11,\n",
        "# 'objective': 'binary:logistic',\n",
        "# 'subsample': 0.4888888888888889\n",
        "# }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomForestClassifier\n",
            "var_smoothing: 0.0 -- The mean CV score is: 0.6072375462125044\n",
            "var_smoothing: 0.1 -- The mean CV score is: 0.6734576349055209\n",
            "var_smoothing: 0.2 -- The mean CV score is: 0.6902031874263501\n",
            "var_smoothing: 0.30000000000000004 -- The mean CV score is: 0.6984086514933967\n",
            "var_smoothing: 0.4 -- The mean CV score is: 0.7008396652419232\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "def run_naive_bayes(data, smoothing):\n",
        "    clf = GaussianNB(var_smoothing=smoothing).fit(data, y)\n",
        "    cv_results = cross_validate(clf, data, y, cv=5, scoring=\"f1_macro\")\n",
        "    print(f\"var_smoothing: {smoothing} -- The mean CV score is: {np.mean(cv_results['test_score'])}\")\n",
        "\n",
        "print(\"RandomForestClassifier\")\n",
        "for n in range(0, 5):\n",
        "    run_naive_bayes(cleaned_data, n*0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SVM Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.svm import SVC\n",
        "\n",
        "# test_model = SVC(random_state=1).fit(cleaned_data.to_numpy(), y.to_numpy())\n",
        "# grid_search_params = {\n",
        "#     \"C\": list(np.linspace(0.5, 2.0, num=10)),\n",
        "# }\n",
        "# print(grid_search_params)\n",
        "# grid_search = GridSearchCV(test_model, grid_search_params, cv=5, scoring=\"f1_macro\")\n",
        "# grid_search.fit(cleaned_data, y)\n",
        "# display(grid_search.best_score_)\n",
        "# display(grid_search.best_params_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Selection Tests\n",
        "\n",
        "**bottom line: does not help! use all the available features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature K: 10 - 0.735319208061668\n",
            "Feature K: 30 - 0.7502488646501894\n",
            "Feature K: 50 - 0.7543781829222638\n",
            "Feature K: 70 - 0.7568676719239618\n",
            "Feature K: 90 - 0.7564772301591769\n",
            "Feature K: 100 - 0.7554416014886319\n",
            "Feature K: 101 - 0.7563581217023747\n",
            "Feature K: 102 - 0.753964013088962\n",
            "Feature K: 103 - 0.754355559591985\n",
            "Feature K: 104 - 0.7602104399043436\n",
            "Feature K: 105 - 0.7602104399043436\n"
          ]
        }
      ],
      "source": [
        "def run_feature_selection(data, k):\n",
        "    df = select_best_features(data, kvalue = k)\n",
        "    # display(list(df.columns))\n",
        "    clf = xgb.XGBClassifier(random_state=1, objective=\"binary:logistic\", learning_rate=0.11, subsample=0.4888888888888889, max_depth=6).fit(df.to_numpy(), y.to_numpy())\n",
        "    cv_results = cross_validate(clf, df, y, cv=5, scoring=\"f1_macro\")\n",
        "    print(f\"Feature K: {k} - {np.mean(cv_results['test_score'])}\")\n",
        "\n",
        "for n in range(10, 100, 20):\n",
        "    run_feature_selection(cleaned_data, n)\n",
        "\n",
        "for n in range(100, len(cleaned_data.columns)+1):\n",
        "    run_feature_selection(cleaned_data, n)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## day 1 baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6439743444016648\n"
          ]
        }
      ],
      "source": [
        "clf = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
        "cv_results = cross_validate(clf, cleaned_data, y, cv=5, scoring=\"f1_macro\")\n",
        "print(np.mean(cv_results['test_score']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Train Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "mSumAZUAo9O6"
      },
      "outputs": [],
      "source": [
        "# The best algorithm found so far has been HistGradientBoostingClassifier with 0.3 learning rate\n",
        "# clf = HistGradientBoostingClassifier(learning_rate=0.1, max_leaf_nodes=30, random_state=1).fit(cleaned_data, y)\n",
        "# clf = GradientBoostingClassifier(loss='log_loss', max_depth=3, learning_rate=0.11, random_state=1).fit(cleaned_data, y)\n",
        "\n",
        "clf = xgb.XGBClassifier(random_state=1, objective=\"binary:logistic\", learning_rate=0.11, subsample=0.4888888888888889, max_depth=6).fit(cleaned_data.to_numpy(), y.to_numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "xV_01HAFe4xa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7602104399043436\n"
          ]
        }
      ],
      "source": [
        "# We use cross_validate to perform K-fold cross validation for us.\n",
        "\n",
        "# baseline\n",
        "cv_results = cross_validate(clf, cleaned_data, y, cv=5, scoring=\"f1_macro\")\n",
        "print(np.mean(cv_results['test_score']))\n",
        "\n",
        "# TODO: can also add hyperparameter tuning to explore different values of the algorithms\n",
        "# hyperparameters, and see how much those affect results.\n",
        "# See GridSearchCV or RandomizedSearchCV.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "HeHuood_f-fh",
        "outputId": "bac11d9f-67c8-4e7e-ccaf-55c7aa79a83c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'fit_time': array([0.17403483, 0.17582321, 0.16091108, 0.14946914, 0.20155978]),\n",
              " 'score_time': array([0.00780106, 0.01023889, 0.00797486, 0.00858307, 0.00877404]),\n",
              " 'test_score': array([0.74823176, 0.76650626, 0.77260423, 0.75474824, 0.75896171])}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The mean CV score is:\n",
            "0.7602104399043436\n"
          ]
        }
      ],
      "source": [
        "# Now that cross validation has completed, we can see what it estimates the peformance\n",
        "# of our model to be.\n",
        "display(cv_results)\n",
        "print(\"The mean CV score is:\")\n",
        "print(np.mean(cv_results['test_score']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihVtYBWg1NM6"
      },
      "source": [
        "## 1.4: Create Predictions for Competition Data\n",
        "\n",
        "Once we are happy with the estimated performance of our model, we can move on to the final step.\n",
        "\n",
        "First, we train our model one last time, using all available training data (unlike CV, which always uses a subset). This final training will give our model the best chance as the highest performance.\n",
        "\n",
        "Then, we must load in the (unlabeled) competition data from the cloud and use our model to generate predictions for each instance in that data. We will then output those predictions to a CSV file. We will then send that file to Steve, and he can then tell us how well we did (because he knows the right answers!)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "74lBpHWfe5h1"
      },
      "outputs": [],
      "source": [
        "# Our model's \"final form\"\n",
        "clf = clf.fit(cleaned_data, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Pu2xugQj1Mci",
        "outputId": "2ac38bca-9bab-4c75-8336-3ce1ba5f56b2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   predicted\n",
              "0          0\n",
              "1          0\n",
              "2          0\n",
              "3          0\n",
              "4          0\n",
              "5          1\n",
              "6          0\n",
              "7          0\n",
              "8          0\n",
              "9          1"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "X_comp = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1SmFBoNh7segI1Ky92mfeIe6TpscclMwQ\")\n",
        "\n",
        "# Importantly, we need to perform the same cleaning/transformation steps\n",
        "# on this competition data as you did the training data. Otherwise, we will\n",
        "# get an error and/or unexpected results.\n",
        "\n",
        "X_comp = model_cleaning(X_comp)\n",
        "\n",
        "# Use your model to make predictions\n",
        "pred_comp = clf.predict(X_comp)\n",
        "\n",
        "my_submission = pd.DataFrame({'predicted': pred_comp})\n",
        "\n",
        "# Let's take a peak at the results (as a sanity check)\n",
        "display(my_submission.head(10))\n",
        "\n",
        "# You could use any filename.\n",
        "my_submission.to_csv('my_submission.csv', index=False)\n",
        "\n",
        "# You can now download the above file from Colab (see menu on the left)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DF6Z8-baL9K"
      },
      "source": [
        "# Model 2 (Your idea Here!)\n",
        "\n",
        "Here, you can do all the above, but try different ideas:\n",
        "\n",
        "- Different ML algorithms (e.g., RandomForestClassifier, LGBM, NN)\n",
        "- Different data cleaning steps (Ordinal encoding, One Hot Encoding, etc.)\n",
        "- Hyperparameter tuning (using, e.g., GridSearchCV or RandomizedSearchCV)\n",
        "- Ensembles\n",
        "- .... anything you can think of!\n",
        "\n",
        "\n",
        "Steve's GitHub page is a great place for ideas:\n",
        "\n",
        "https://github.com/stepthom/869_course"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "heJMDH4KaN9G"
      },
      "outputs": [],
      "source": [
        "# TODO: Win the competition here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qquC4XuEiyA5"
      },
      "source": [
        "# Model 3 (Your next idea here!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "LKrudgbEiyqw"
      },
      "outputs": [],
      "source": [
        "# TODO: Win the competition here, too!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
