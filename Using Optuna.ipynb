{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKmorPdno_n_"
   },
   "source": [
    "# MMAI 2025 869: Team Project Template\n",
    "*Updated May 3, 2024*\n",
    "\n",
    "This notebook serves as a template for the Team Project. Teams can use this notebook as a starting point, and update it successively with new ideas and techniques to improve their model results.\n",
    "\n",
    "Note that is not required to use this template. Teams may also alter this template in any way they see fit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZFTCX4DqmRO"
   },
   "source": [
    "# Preliminaries: Inspect and Set up environment\n",
    "\n",
    "No action is required on your part in this section. These cells print out helpful information about the environment, just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xj34Jz-Do_oK"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mqQ_XOKyXTS6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-29 16:50:40.841182\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LfOMt1lErLhZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'which' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aub2w1-arM5K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.7\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "E9Y_n_8UrO9i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$PYTHONPATH\n"
     ]
    }
   ],
   "source": [
    "!echo $PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-qyD7Jl0Gw1E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\俊俊\\appdata\\roaming\\python\\python311\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\ana\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\ana\\lib\\site-packages (from xgboost) (1.11.4)\n",
      "Requirement already satisfied: fancyimpute in c:\\users\\俊俊\\appdata\\roaming\\python\\python311\\site-packages (0.7.0)\n",
      "Requirement already satisfied: knnimpute>=0.1.0 in c:\\users\\俊俊\\appdata\\roaming\\python\\python311\\site-packages (from fancyimpute) (0.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24.2 in c:\\ana\\lib\\site-packages (from fancyimpute) (1.2.2)\n",
      "Requirement already satisfied: cvxpy in c:\\users\\俊俊\\appdata\\roaming\\python\\python311\\site-packages (from fancyimpute) (1.5.1)\n",
      "Requirement already satisfied: cvxopt in c:\\users\\俊俊\\appdata\\roaming\\python\\python311\\site-packages (from fancyimpute) (1.3.2)\n",
      "Requirement already satisfied: pytest in c:\\ana\\lib\\site-packages (from fancyimpute) (7.4.0)\n",
      "Requirement already satisfied: nose in c:\\users\\俊俊\\appdata\\roaming\\python\\python311\\site-packages (from fancyimpute) (1.3.7)\n",
      "Requirement already satisfied: six in c:\\ana\\lib\\site-packages (from knnimpute>=0.1.0->fancyimpute) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.10 in c:\\ana\\lib\\site-packages (from knnimpute>=0.1.0->fancyimpute) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\ana\\lib\\site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\ana\\lib\\site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\ana\\lib\\site-packages (from scikit-learn>=0.24.2->fancyimpute) (2.2.0)\n",
      "Requirement already satisfied: osqp>=0.6.2 in c:\\users\\俊俊\\appdata\\roaming\\python\\python311\\site-packages (from cvxpy->fancyimpute) (0.6.7)\n",
      "Requirement already satisfied: ecos>=2 in c:\\users\\俊俊\\appdata\\roaming\\python\\python311\\site-packages (from cvxpy->fancyimpute) (2.0.13)\n",
      "Requirement already satisfied: clarabel>=0.5.0 in c:\\users\\俊俊\\appdata\\roaming\\python\\python311\\site-packages (from cvxpy->fancyimpute) (0.8.1)\n",
      "Requirement already satisfied: scs>=3.2.4.post1 in c:\\users\\俊俊\\appdata\\roaming\\python\\python311\\site-packages (from cvxpy->fancyimpute) (3.2.4.post1)\n",
      "Requirement already satisfied: iniconfig in c:\\ana\\lib\\site-packages (from pytest->fancyimpute) (1.1.1)\n",
      "Requirement already satisfied: packaging in c:\\ana\\lib\\site-packages (from pytest->fancyimpute) (23.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in c:\\ana\\lib\\site-packages (from pytest->fancyimpute) (1.0.0)\n",
      "Requirement already satisfied: colorama in c:\\ana\\lib\\site-packages (from pytest->fancyimpute) (0.4.6)\n",
      "Requirement already satisfied: qdldl in c:\\users\\俊俊\\appdata\\roaming\\python\\python311\\site-packages (from osqp>=0.6.2->cvxpy->fancyimpute) (0.1.7.post2)\n",
      "Requirement already satisfied: sklearn-genetic in c:\\users\\俊俊\\appdata\\roaming\\python\\python311\\site-packages (0.6.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in c:\\ana\\lib\\site-packages (from sklearn-genetic) (1.2.2)\n",
      "Requirement already satisfied: deap>=1.0.2 in c:\\users\\俊俊\\appdata\\roaming\\python\\python311\\site-packages (from sklearn-genetic) (1.4.1)\n",
      "Requirement already satisfied: numpy in c:\\ana\\lib\\site-packages (from sklearn-genetic) (1.26.4)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\俊俊\\appdata\\roaming\\python\\python311\\site-packages (from sklearn-genetic) (0.70.16)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\ana\\lib\\site-packages (from scikit-learn>=1.0->sklearn-genetic) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\ana\\lib\\site-packages (from scikit-learn>=1.0->sklearn-genetic) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\ana\\lib\\site-packages (from scikit-learn>=1.0->sklearn-genetic) (2.2.0)\n",
      "Requirement already satisfied: dill>=0.3.8 in c:\\users\\俊俊\\appdata\\roaming\\python\\python311\\site-packages (from multiprocess->sklearn-genetic) (0.3.8)\n",
      "Requirement already satisfied: ipywidgets in c:\\ana\\lib\\site-packages (7.6.5)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\ana\\lib\\site-packages (from ipywidgets) (6.28.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\ana\\lib\\site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\ana\\lib\\site-packages (from ipywidgets) (5.7.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\ana\\lib\\site-packages (from ipywidgets) (5.9.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\ana\\lib\\site-packages (from ipywidgets) (3.5.2)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\ana\\lib\\site-packages (from ipywidgets) (8.20.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\ana\\lib\\site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\ana\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\ana\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\ana\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.9)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\ana\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (5.5.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\ana\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\ana\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\ana\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (23.1)\n",
      "Requirement already satisfied: psutil in c:\\ana\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\ana\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (24.0.1)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\ana\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.3)\n",
      "Requirement already satisfied: decorator in c:\\ana\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\ana\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\ana\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\ana\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\ana\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\ana\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: fastjsonschema in c:\\ana\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\ana\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (4.19.2)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\ana\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.5.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\ana\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\ana\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\ana\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\ana\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\ana\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (0.10.6)\n",
      "Requirement already satisfied: entrypoints in c:\\ana\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\ana\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\ana\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\ana\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (305.1)\n",
      "Requirement already satisfied: jinja2 in c:\\ana\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.1.3)\n",
      "Requirement already satisfied: argon2-cffi in c:\\ana\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: nbconvert>=5 in c:\\ana\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (7.10.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in c:\\ana\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\ana\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.17.1)\n",
      "Requirement already satisfied: prometheus-client in c:\\ana\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.14.1)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in c:\\ana\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: wcwidth in c:\\ana\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in c:\\ana\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\ana\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\ana\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in c:\\ana\\lib\\site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2.3 in c:\\ana\\lib\\site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.1.3)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in c:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\ana\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in c:\\ana\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.10)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\ana\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: webencodings in c:\\ana\\lib\\site-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\ana\\lib\\site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.2.0)\n",
      "Requirement already satisfied: jupyter-events>=0.6.0 in c:\\ana\\lib\\site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in c:\\ana\\lib\\site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: overrides in c:\\ana\\lib\\site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (7.4.0)\n",
      "Requirement already satisfied: websocket-client in c:\\ana\\lib\\site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.58.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\ana\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\ana\\lib\\site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.5)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\ana\\lib\\site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\ana\\lib\\site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.3.0)\n",
      "Requirement already satisfied: pycparser in c:\\ana\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.21)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\ana\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\ana\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\ana\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\ana\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.1)\n",
      "Requirement already satisfied: fqdn in c:\\users\\俊俊\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\俊俊\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\ana\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.1)\n",
      "Requirement already satisfied: uri-template in c:\\users\\俊俊\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in c:\\users\\俊俊\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.13)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\ana\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.2.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install --user xgboost\n",
    "! pip install --user fancyimpute\n",
    "! pip install --user sklearn-genetic\n",
    "! pip install --user ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_IHoz7f2yIV"
   },
   "source": [
    "# 0. Data Loading and Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqm_REd4oouz"
   },
   "source": [
    "## 0.1: Load data\n",
    "\n",
    "The file containing the labeled training data is conveniently located on the cloud at the address below. Let's load it up and take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "X6b_BM0Nz9sF"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1eYCKuqJda4bpzXBVnqXylg0qQwvpUuum\")\n",
    "target_feature = 'h1n1_vaccine'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ys9PPIOlvVzl"
   },
   "source": [
    "## 0.1 Simple Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5sQ8ht2_L0cD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21365 entries, 0 to 21364\n",
      "Data columns (total 36 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   h1n1_concern                 21292 non-null  float64\n",
      " 1   h1n1_knowledge               21274 non-null  float64\n",
      " 2   behavioral_antiviral_meds    21306 non-null  float64\n",
      " 3   behavioral_avoidance         21202 non-null  float64\n",
      " 4   behavioral_face_mask         21351 non-null  float64\n",
      " 5   behavioral_wash_hands        21329 non-null  float64\n",
      " 6   behavioral_large_gatherings  21293 non-null  float64\n",
      " 7   behavioral_outside_home      21306 non-null  float64\n",
      " 8   behavioral_touch_face        21263 non-null  float64\n",
      " 9   doctor_recc_h1n1             19629 non-null  float64\n",
      " 10  doctor_recc_seasonal         19629 non-null  float64\n",
      " 11  chronic_med_condition        20594 non-null  float64\n",
      " 12  child_under_6_months         20710 non-null  float64\n",
      " 13  health_worker                20722 non-null  float64\n",
      " 14  health_insurance             11507 non-null  float64\n",
      " 15  opinion_h1n1_vacc_effective  21047 non-null  float64\n",
      " 16  opinion_h1n1_risk            21054 non-null  float64\n",
      " 17  opinion_h1n1_sick_from_vacc  21044 non-null  float64\n",
      " 18  opinion_seas_vacc_effective  20994 non-null  float64\n",
      " 19  opinion_seas_risk            20955 non-null  float64\n",
      " 20  opinion_seas_sick_from_vacc  20934 non-null  float64\n",
      " 21  age_group                    21365 non-null  object \n",
      " 22  education                    20240 non-null  object \n",
      " 23  race                         21365 non-null  object \n",
      " 24  sex                          21365 non-null  object \n",
      " 25  income_poverty               17851 non-null  object \n",
      " 26  marital_status               20245 non-null  object \n",
      " 27  rent_or_own                  19737 non-null  object \n",
      " 28  employment_status            20203 non-null  object \n",
      " 29  hhs_geo_region               21365 non-null  object \n",
      " 30  census_msa                   21365 non-null  object \n",
      " 31  household_adults             21163 non-null  float64\n",
      " 32  household_children           21163 non-null  float64\n",
      " 33  employment_industry          10738 non-null  object \n",
      " 34  employment_occupation        10629 non-null  object \n",
      " 35  h1n1_vaccine                 21365 non-null  int64  \n",
      "dtypes: float64(23), int64(1), object(12)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GxX8nM24uyzE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>h1n1_concern</th>\n",
       "      <td>21292.0</td>\n",
       "      <td>1.618026</td>\n",
       "      <td>0.909311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <td>21274.0</td>\n",
       "      <td>1.265018</td>\n",
       "      <td>0.617816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <td>21306.0</td>\n",
       "      <td>0.049329</td>\n",
       "      <td>0.216559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <td>21202.0</td>\n",
       "      <td>0.724507</td>\n",
       "      <td>0.446773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <td>21351.0</td>\n",
       "      <td>0.070348</td>\n",
       "      <td>0.255739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <td>21329.0</td>\n",
       "      <td>0.823574</td>\n",
       "      <td>0.381192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <td>21293.0</td>\n",
       "      <td>0.357864</td>\n",
       "      <td>0.479383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <td>21306.0</td>\n",
       "      <td>0.337464</td>\n",
       "      <td>0.472856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <td>21263.0</td>\n",
       "      <td>0.675728</td>\n",
       "      <td>0.468113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doctor_recc_h1n1</th>\n",
       "      <td>19629.0</td>\n",
       "      <td>0.221662</td>\n",
       "      <td>0.415375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doctor_recc_seasonal</th>\n",
       "      <td>19629.0</td>\n",
       "      <td>0.332467</td>\n",
       "      <td>0.471109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chronic_med_condition</th>\n",
       "      <td>20594.0</td>\n",
       "      <td>0.284840</td>\n",
       "      <td>0.451349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>child_under_6_months</th>\n",
       "      <td>20710.0</td>\n",
       "      <td>0.082134</td>\n",
       "      <td>0.274576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_worker</th>\n",
       "      <td>20722.0</td>\n",
       "      <td>0.113840</td>\n",
       "      <td>0.317625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_insurance</th>\n",
       "      <td>11507.0</td>\n",
       "      <td>0.879465</td>\n",
       "      <td>0.325601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion_h1n1_vacc_effective</th>\n",
       "      <td>21047.0</td>\n",
       "      <td>3.848910</td>\n",
       "      <td>1.008976</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion_h1n1_risk</th>\n",
       "      <td>21054.0</td>\n",
       "      <td>2.345730</td>\n",
       "      <td>1.287865</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion_h1n1_sick_from_vacc</th>\n",
       "      <td>21044.0</td>\n",
       "      <td>2.361196</td>\n",
       "      <td>1.362904</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion_seas_vacc_effective</th>\n",
       "      <td>20994.0</td>\n",
       "      <td>4.029532</td>\n",
       "      <td>1.082279</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion_seas_risk</th>\n",
       "      <td>20955.0</td>\n",
       "      <td>2.722023</td>\n",
       "      <td>1.385780</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion_seas_sick_from_vacc</th>\n",
       "      <td>20934.0</td>\n",
       "      <td>2.121286</td>\n",
       "      <td>1.335174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>household_adults</th>\n",
       "      <td>21163.0</td>\n",
       "      <td>0.888910</td>\n",
       "      <td>0.754466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>household_children</th>\n",
       "      <td>21163.0</td>\n",
       "      <td>0.535888</td>\n",
       "      <td>0.929504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h1n1_vaccine</th>\n",
       "      <td>21365.0</td>\n",
       "      <td>0.212684</td>\n",
       "      <td>0.409216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count      mean       std  min  25%  50%  75%  \\\n",
       "h1n1_concern                 21292.0  1.618026  0.909311  0.0  1.0  2.0  2.0   \n",
       "h1n1_knowledge               21274.0  1.265018  0.617816  0.0  1.0  1.0  2.0   \n",
       "behavioral_antiviral_meds    21306.0  0.049329  0.216559  0.0  0.0  0.0  0.0   \n",
       "behavioral_avoidance         21202.0  0.724507  0.446773  0.0  0.0  1.0  1.0   \n",
       "behavioral_face_mask         21351.0  0.070348  0.255739  0.0  0.0  0.0  0.0   \n",
       "behavioral_wash_hands        21329.0  0.823574  0.381192  0.0  1.0  1.0  1.0   \n",
       "behavioral_large_gatherings  21293.0  0.357864  0.479383  0.0  0.0  0.0  1.0   \n",
       "behavioral_outside_home      21306.0  0.337464  0.472856  0.0  0.0  0.0  1.0   \n",
       "behavioral_touch_face        21263.0  0.675728  0.468113  0.0  0.0  1.0  1.0   \n",
       "doctor_recc_h1n1             19629.0  0.221662  0.415375  0.0  0.0  0.0  0.0   \n",
       "doctor_recc_seasonal         19629.0  0.332467  0.471109  0.0  0.0  0.0  1.0   \n",
       "chronic_med_condition        20594.0  0.284840  0.451349  0.0  0.0  0.0  1.0   \n",
       "child_under_6_months         20710.0  0.082134  0.274576  0.0  0.0  0.0  0.0   \n",
       "health_worker                20722.0  0.113840  0.317625  0.0  0.0  0.0  0.0   \n",
       "health_insurance             11507.0  0.879465  0.325601  0.0  1.0  1.0  1.0   \n",
       "opinion_h1n1_vacc_effective  21047.0  3.848910  1.008976  1.0  3.0  4.0  5.0   \n",
       "opinion_h1n1_risk            21054.0  2.345730  1.287865  1.0  1.0  2.0  4.0   \n",
       "opinion_h1n1_sick_from_vacc  21044.0  2.361196  1.362904  1.0  1.0  2.0  4.0   \n",
       "opinion_seas_vacc_effective  20994.0  4.029532  1.082279  1.0  4.0  4.0  5.0   \n",
       "opinion_seas_risk            20955.0  2.722023  1.385780  1.0  2.0  2.0  4.0   \n",
       "opinion_seas_sick_from_vacc  20934.0  2.121286  1.335174  1.0  1.0  2.0  4.0   \n",
       "household_adults             21163.0  0.888910  0.754466  0.0  0.0  1.0  1.0   \n",
       "household_children           21163.0  0.535888  0.929504  0.0  0.0  0.0  1.0   \n",
       "h1n1_vaccine                 21365.0  0.212684  0.409216  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                             max  \n",
       "h1n1_concern                 3.0  \n",
       "h1n1_knowledge               2.0  \n",
       "behavioral_antiviral_meds    1.0  \n",
       "behavioral_avoidance         1.0  \n",
       "behavioral_face_mask         1.0  \n",
       "behavioral_wash_hands        1.0  \n",
       "behavioral_large_gatherings  1.0  \n",
       "behavioral_outside_home      1.0  \n",
       "behavioral_touch_face        1.0  \n",
       "doctor_recc_h1n1             1.0  \n",
       "doctor_recc_seasonal         1.0  \n",
       "chronic_med_condition        1.0  \n",
       "child_under_6_months         1.0  \n",
       "health_worker                1.0  \n",
       "health_insurance             1.0  \n",
       "opinion_h1n1_vacc_effective  5.0  \n",
       "opinion_h1n1_risk            5.0  \n",
       "opinion_h1n1_sick_from_vacc  5.0  \n",
       "opinion_seas_vacc_effective  5.0  \n",
       "opinion_seas_risk            5.0  \n",
       "opinion_seas_sick_from_vacc  5.0  \n",
       "household_adults             3.0  \n",
       "household_children           3.0  \n",
       "h1n1_vaccine                 1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's print some descriptive statistics for all the numeric features.\n",
    "\n",
    "df.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ELhSsAmiLZxF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age_group</th>\n",
       "      <td>21365</td>\n",
       "      <td>5</td>\n",
       "      <td>65+ Years</td>\n",
       "      <td>5454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>20240</td>\n",
       "      <td>4</td>\n",
       "      <td>College Graduate</td>\n",
       "      <td>8063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>21365</td>\n",
       "      <td>4</td>\n",
       "      <td>White</td>\n",
       "      <td>16974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>21365</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>12748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income_poverty</th>\n",
       "      <td>17851</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>10301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital_status</th>\n",
       "      <td>20245</td>\n",
       "      <td>2</td>\n",
       "      <td>Married</td>\n",
       "      <td>10880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rent_or_own</th>\n",
       "      <td>19737</td>\n",
       "      <td>2</td>\n",
       "      <td>Own</td>\n",
       "      <td>15012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employment_status</th>\n",
       "      <td>20203</td>\n",
       "      <td>3</td>\n",
       "      <td>Employed</td>\n",
       "      <td>10886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <td>21365</td>\n",
       "      <td>10</td>\n",
       "      <td>lzgpxyit</td>\n",
       "      <td>3406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>census_msa</th>\n",
       "      <td>21365</td>\n",
       "      <td>3</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>9268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employment_industry</th>\n",
       "      <td>10738</td>\n",
       "      <td>21</td>\n",
       "      <td>fcxhlnwr</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employment_occupation</th>\n",
       "      <td>10629</td>\n",
       "      <td>23</td>\n",
       "      <td>xtkaffoo</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count unique                        top   freq\n",
       "age_group              21365      5                  65+ Years   5454\n",
       "education              20240      4           College Graduate   8063\n",
       "race                   21365      4                      White  16974\n",
       "sex                    21365      2                     Female  12748\n",
       "income_poverty         17851      3  <= $75,000, Above Poverty  10301\n",
       "marital_status         20245      2                    Married  10880\n",
       "rent_or_own            19737      2                        Own  15012\n",
       "employment_status      20203      3                   Employed  10886\n",
       "hhs_geo_region         21365     10                   lzgpxyit   3406\n",
       "census_msa             21365      3   MSA, Not Principle  City   9268\n",
       "employment_industry    10738     21                   fcxhlnwr   2009\n",
       "employment_occupation  10629     23                   xtkaffoo   1406"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the number of unique values in all the categorical features? And what is\n",
    "# the value with the highest frequency?\n",
    "\n",
    "df.describe(include=object).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tBI28r_bgV06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h1n1_concern                      73\n",
       "h1n1_knowledge                    91\n",
       "behavioral_antiviral_meds         59\n",
       "behavioral_avoidance             163\n",
       "behavioral_face_mask              14\n",
       "behavioral_wash_hands             36\n",
       "behavioral_large_gatherings       72\n",
       "behavioral_outside_home           59\n",
       "behavioral_touch_face            102\n",
       "doctor_recc_h1n1                1736\n",
       "doctor_recc_seasonal            1736\n",
       "chronic_med_condition            771\n",
       "child_under_6_months             655\n",
       "health_worker                    643\n",
       "health_insurance                9858\n",
       "opinion_h1n1_vacc_effective      318\n",
       "opinion_h1n1_risk                311\n",
       "opinion_h1n1_sick_from_vacc      321\n",
       "opinion_seas_vacc_effective      371\n",
       "opinion_seas_risk                410\n",
       "opinion_seas_sick_from_vacc      431\n",
       "age_group                          0\n",
       "education                       1125\n",
       "race                               0\n",
       "sex                                0\n",
       "income_poverty                  3514\n",
       "marital_status                  1120\n",
       "rent_or_own                     1628\n",
       "employment_status               1162\n",
       "hhs_geo_region                     0\n",
       "census_msa                         0\n",
       "household_adults                 202\n",
       "household_children               202\n",
       "employment_industry            10627\n",
       "employment_occupation          10736\n",
       "h1n1_vaccine                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How much missing data is in each feature?\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking a look at the class imbalance of our target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No vaccine: 16821\n",
      "Has vaccine: 4544\n",
      "training_data_pos_scale_weight: 3.7018045774647885\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder,OrdinalEncoder\n",
    "\n",
    "def get_target_skew_rate(data_target):\n",
    "    target_df = pd.DataFrame(data_target)\n",
    "    sns.countplot(x=target_feature, data=target_df)\n",
    "\n",
    "    no_vaccine_count = len(target_df[target_df[target_feature]==0])\n",
    "    yes_vaccine_count = len(target_df[target_df[target_feature]==1])\n",
    "    print(f\"No vaccine: {no_vaccine_count}\")\n",
    "    print(f\"Has vaccine: {yes_vaccine_count}\")\n",
    "\n",
    "    # save this for later...\n",
    "    training_data_pos_scale_weight = (no_vaccine_count / yes_vaccine_count)\n",
    "    print(f\"training_data_pos_scale_weight: {training_data_pos_scale_weight}\")\n",
    "    return training_data_pos_scale_weight\n",
    "\n",
    "training_data_pos_scale_weight = get_target_skew_rate(df[target_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "AC8gMKmad5RF"
   },
   "outputs": [],
   "source": [
    "# For convienience, let's save the names of all numeric features to a list,\n",
    "# and the names of all categorical features to another list.\n",
    "\n",
    "numeric_features = [\n",
    "          \"h1n1_concern\",\n",
    "          \"h1n1_knowledge\",\n",
    "          \"behavioral_antiviral_meds\",\n",
    "          \"behavioral_avoidance\",\n",
    "          \"behavioral_face_mask\",\n",
    "          \"behavioral_wash_hands\",\n",
    "          \"behavioral_large_gatherings\",\n",
    "          \"behavioral_outside_home\",\n",
    "          \"behavioral_touch_face\",\n",
    "          \"doctor_recc_h1n1\",\n",
    "          \"doctor_recc_seasonal\",\n",
    "          \"chronic_med_condition\",\n",
    "          \"child_under_6_months\",\n",
    "          \"health_worker\",\n",
    "          \"health_insurance\",\n",
    "          \"opinion_h1n1_vacc_effective\",\n",
    "          \"opinion_h1n1_risk\",\n",
    "          \"opinion_h1n1_sick_from_vacc\",\n",
    "          \"opinion_seas_vacc_effective\",\n",
    "          \"opinion_seas_risk\",\n",
    "          \"opinion_seas_sick_from_vacc\",\n",
    "          \"household_adults\",\n",
    "          \"household_children\",\n",
    "]\n",
    "\n",
    "behavioural_features = list(x for x in numeric_features if 'behavioral' in x)\n",
    "\n",
    "categorical_features = [\n",
    "    \"age_group\",\n",
    "    \"education\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"income_poverty\",\n",
    "    \"marital_status\",\n",
    "    \"rent_or_own\",\n",
    "    \"employment_status\",\n",
    "    \"hhs_geo_region\",\n",
    "    \"census_msa\",\n",
    "    \"employment_industry\",\n",
    "    \"employment_occupation\",\n",
    "]\n",
    "\n",
    "all_features = numeric_features + categorical_features\n",
    "\n",
    "all_cat_features = categorical_features\n",
    "\n",
    "continuous_features = [\n",
    "    'opinion_h1n1_vacc_effective',\n",
    "    'opinion_h1n1_risk',\n",
    "    'opinion_h1n1_sick_from_vacc',\n",
    "    'opinion_seas_vacc_effective',\n",
    "    'opinion_seas_risk',\n",
    "    'opinion_seas_sick_from_vacc',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper method for getting the least correlated items to the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_low_correlations_for_target(data, show_plot = False):\n",
    "    corr = data.corr()\n",
    "\n",
    "    threshold = 0.01\n",
    "    tf_corr = corr[(abs(corr[target_feature]) <= threshold)]\n",
    "    display(tf_corr)\n",
    "\n",
    "    if show_plot:\n",
    "        g = sns.heatmap(corr,  vmax=.3, center=0,\n",
    "                    square=True, linewidths=1, \n",
    "                    cbar_kws={\"shrink\": .5}, annot=True, \n",
    "                    fmt='.2f', cmap='coolwarm')\n",
    "        sns.despine()\n",
    "        g.figure.set_size_inches(30,25)\n",
    "        plt.show()\n",
    "\n",
    "    return list(tf_corr.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do each of the behavioural features correlate to the target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [behavioral_antiviral_meds, behavioral_avoidance, behavioral_face_mask, behavioral_wash_hands, behavioral_large_gatherings, behavioral_outside_home, behavioral_touch_face, h1n1_vaccine]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x2500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_bv_target = pd.concat((df[behavioural_features], df[target_feature]), axis=1)\n",
    "df_bv_target.hist()\n",
    "get_low_correlations_for_target(df_bv_target, show_plot=True)\n",
    "\n",
    "# separate these by skewedness in correlation with the target\n",
    "# so when we FE combine these, it makes sense\n",
    "behavioural_features_neg = [\n",
    "          \"behavioral_avoidance\",\n",
    "          \"behavioral_wash_hands\",\n",
    "          \"behavioral_outside_home\",\n",
    "          \"behavioral_touch_face\",\n",
    "]\n",
    "\n",
    "behavioural_features_pos = [x for x in behavioural_features if x not in behavioural_features_neg]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbTJkUNdvfsF"
   },
   "source": [
    "# 1. Train/Test Split\n",
    "\n",
    "Now we randomly split the available data into train and test subsets.\n",
    "\n",
    "The training data will later be used to build and assess the model on various combinations of hyperparaters.\n",
    "\n",
    "The testing data will be used as a \"final estimate\" of a model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdiKKblCo53S"
   },
   "source": [
    "# 2. Model 1 (A simple DecisionTree model)\n",
    "\n",
    "As a baseline, we'll do the absolute bare minimum data cleaning and then quickly build a simple Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HuWoCrg3bQUs"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_validate\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "aUZxa2f6uw3l"
   },
   "outputs": [],
   "source": [
    "# Scikit-learn needs us to put the features in one dataframe, and the label in another.\n",
    "# It's tradition to name these variables X and y, but it doesn't really matter.\n",
    "\n",
    "X = df.drop(target_feature, axis=1)\n",
    "y = df[target_feature]\n",
    "\n",
    "# X[continuous_features].hist()\n",
    "# X[behavioural_features].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqYbbTAejRCD"
   },
   "source": [
    "## 1.1 Cleaning and FE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Encoding / Label Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "KwfR9_nQftlS"
   },
   "outputs": [],
   "source": [
    "label_mapping = {}\n",
    "\n",
    "def apply_label_mapping_fxn(row):\n",
    "    global label_mapping\n",
    "    for feature in all_cat_features:\n",
    "        feature_mapping = label_mapping[feature]\n",
    "        enc_value = feature_mapping[row[feature]]\n",
    "        row[feature] = enc_value\n",
    "    return row\n",
    "\n",
    "def apply_label_mapping(data):\n",
    "    return data.apply(apply_label_mapping_fxn, axis=1)\n",
    "\n",
    "def update_row_mappings(row):\n",
    "    global label_mapping\n",
    "    for feature in all_cat_features:\n",
    "        if not feature in label_mapping:\n",
    "            label_mapping[feature] = {}\n",
    "        enc_feature_name = f\"{feature}_enc\"\n",
    "        orig_value = row[feature]\n",
    "        enc_value = row[enc_feature_name]\n",
    "        label_mapping[feature][orig_value] = enc_value\n",
    "\n",
    "    return row\n",
    "\n",
    "def set_label_mapping(orig_data, encoded_data):\n",
    "    global label_mapping\n",
    "    map_df = pd.DataFrame()\n",
    "    for feature in all_cat_features:\n",
    "        map_df[feature] = orig_data[feature]\n",
    "        map_df[f\"{feature}_enc\"] = encoded_data[feature]\n",
    "    map_df.apply(update_row_mappings, axis=1)\n",
    "\n",
    "def label_encoding(data):\n",
    "    global labeled_columns\n",
    "\n",
    "    import category_encoders as ce\n",
    "    encoder = ce.JamesSteinEncoder(cols=all_cat_features)\n",
    "    labeled = encoder.fit_transform(data, y)\n",
    "    labeled_columns = list(encoder.get_feature_names_out())\n",
    "\n",
    "    set_label_mapping(data, labeled)\n",
    "\n",
    "    return labeled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "j4l5INJbdOde"
   },
   "outputs": [],
   "source": [
    "from fancyimpute import SoftImpute\n",
    "\n",
    "def impute_data(data):\n",
    "    return pd.DataFrame(SoftImpute(verbose=False).fit_transform(data), columns=data.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale our skewed features (using Box-Cox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>opinion_h1n1_vacc_effective</th>\n",
       "      <td>21047.0</td>\n",
       "      <td>3.848910</td>\n",
       "      <td>1.008976</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion_h1n1_risk</th>\n",
       "      <td>21054.0</td>\n",
       "      <td>2.345730</td>\n",
       "      <td>1.287865</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion_h1n1_sick_from_vacc</th>\n",
       "      <td>21044.0</td>\n",
       "      <td>2.361196</td>\n",
       "      <td>1.362904</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion_seas_vacc_effective</th>\n",
       "      <td>20994.0</td>\n",
       "      <td>4.029532</td>\n",
       "      <td>1.082279</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion_seas_risk</th>\n",
       "      <td>20955.0</td>\n",
       "      <td>2.722023</td>\n",
       "      <td>1.385780</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion_seas_sick_from_vacc</th>\n",
       "      <td>20934.0</td>\n",
       "      <td>2.121286</td>\n",
       "      <td>1.335174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count      mean       std  min  25%  50%  75%  \\\n",
       "opinion_h1n1_vacc_effective  21047.0  3.848910  1.008976  1.0  3.0  4.0  5.0   \n",
       "opinion_h1n1_risk            21054.0  2.345730  1.287865  1.0  1.0  2.0  4.0   \n",
       "opinion_h1n1_sick_from_vacc  21044.0  2.361196  1.362904  1.0  1.0  2.0  4.0   \n",
       "opinion_seas_vacc_effective  20994.0  4.029532  1.082279  1.0  4.0  4.0  5.0   \n",
       "opinion_seas_risk            20955.0  2.722023  1.385780  1.0  2.0  2.0  4.0   \n",
       "opinion_seas_sick_from_vacc  20934.0  2.121286  1.335174  1.0  1.0  2.0  4.0   \n",
       "\n",
       "                             max  \n",
       "opinion_h1n1_vacc_effective  5.0  \n",
       "opinion_h1n1_risk            5.0  \n",
       "opinion_h1n1_sick_from_vacc  5.0  \n",
       "opinion_seas_vacc_effective  5.0  \n",
       "opinion_seas_risk            5.0  \n",
       "opinion_seas_sick_from_vacc  5.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "display(X[continuous_features].describe().T)\n",
    "\n",
    "def set_non_zero(row):\n",
    "    for feature in continuous_features:\n",
    "        if row[feature] == 0.0:\n",
    "            row[feature] = 0.00000001\n",
    "    return row\n",
    "\n",
    "def set_continuous_features(data):\n",
    "    # data[continuous_features] = data[continuous_features].apply(set_non_zero, axis=1)\n",
    "\n",
    "    display(data[continuous_features].describe().T)\n",
    "\n",
    "    scaler = PowerTransformer(method='yeo-johnson')\n",
    "    scaler.fit(data[continuous_features])\n",
    "    data[continuous_features] = scaler.transform(data[continuous_features])\n",
    "    # data[continuous_features].hist()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data):\n",
    "    data['insured_family_size'] = data['household_adults'] + data['health_insurance'] + data['household_children']\n",
    "    data['at_risk_patient'] = data['doctor_recc_h1n1'] + data['doctor_recc_seasonal'] + data['chronic_med_condition']\n",
    "\n",
    "    data['behavioral_risk_neg'] = data[behavioural_features_neg].sum(axis=1)\n",
    "    data['behavioral_risk_pos'] = data[behavioural_features_pos].sum(axis=1)\n",
    "    # data = data.drop(behavioural_features, axis=1)\n",
    "\n",
    "    data['opinion_seas_risk'] = data['opinion_seas_risk'] + data['opinion_seas_sick_from_vacc']\n",
    "    data['opinion_h1n1'] = data['opinion_h1n1_vacc_effective'] + data['h1n1_concern']\n",
    "    data['poverty_vs_insurance'] = data['income_poverty'] + data['health_insurance']\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation mapping...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>doctor_recc_h1n1</th>\n",
       "      <th>...</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>employment_industry</th>\n",
       "      <th>employment_occupation</th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>opinion_seas_sick_from_vacc</th>\n",
       "      <td>0.222891</td>\n",
       "      <td>-0.064476</td>\n",
       "      <td>0.084385</td>\n",
       "      <td>0.078971</td>\n",
       "      <td>0.101353</td>\n",
       "      <td>0.092033</td>\n",
       "      <td>0.135759</td>\n",
       "      <td>0.137775</td>\n",
       "      <td>0.092923</td>\n",
       "      <td>0.055074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028392</td>\n",
       "      <td>-0.089694</td>\n",
       "      <td>-0.040087</td>\n",
       "      <td>-0.030540</td>\n",
       "      <td>-0.004128</td>\n",
       "      <td>0.019630</td>\n",
       "      <td>0.054649</td>\n",
       "      <td>-0.008723</td>\n",
       "      <td>-0.021985</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>census_msa</th>\n",
       "      <td>-0.004295</td>\n",
       "      <td>0.052737</td>\n",
       "      <td>0.008361</td>\n",
       "      <td>0.007260</td>\n",
       "      <td>0.018310</td>\n",
       "      <td>0.004913</td>\n",
       "      <td>-0.052667</td>\n",
       "      <td>-0.041904</td>\n",
       "      <td>-0.022556</td>\n",
       "      <td>0.013221</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052605</td>\n",
       "      <td>-0.082343</td>\n",
       "      <td>-0.029317</td>\n",
       "      <td>-0.051005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002273</td>\n",
       "      <td>0.018309</td>\n",
       "      <td>0.011184</td>\n",
       "      <td>0.018651</td>\n",
       "      <td>0.005751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>household_children</th>\n",
       "      <td>0.048426</td>\n",
       "      <td>0.050386</td>\n",
       "      <td>0.087459</td>\n",
       "      <td>0.038914</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.049134</td>\n",
       "      <td>-0.012202</td>\n",
       "      <td>-0.014424</td>\n",
       "      <td>0.020550</td>\n",
       "      <td>0.033586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162315</td>\n",
       "      <td>-0.033011</td>\n",
       "      <td>-0.076230</td>\n",
       "      <td>0.015233</td>\n",
       "      <td>0.018309</td>\n",
       "      <td>0.187856</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017251</td>\n",
       "      <td>0.018737</td>\n",
       "      <td>-0.005867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             h1n1_concern  h1n1_knowledge  \\\n",
       "opinion_seas_sick_from_vacc      0.222891       -0.064476   \n",
       "census_msa                      -0.004295        0.052737   \n",
       "household_children               0.048426        0.050386   \n",
       "\n",
       "                             behavioral_antiviral_meds  behavioral_avoidance  \\\n",
       "opinion_seas_sick_from_vacc                   0.084385              0.078971   \n",
       "census_msa                                    0.008361              0.007260   \n",
       "household_children                            0.087459              0.038914   \n",
       "\n",
       "                             behavioral_face_mask  behavioral_wash_hands  \\\n",
       "opinion_seas_sick_from_vacc              0.101353               0.092033   \n",
       "census_msa                               0.018310               0.004913   \n",
       "household_children                       0.007088               0.049134   \n",
       "\n",
       "                             behavioral_large_gatherings  \\\n",
       "opinion_seas_sick_from_vacc                     0.135759   \n",
       "census_msa                                     -0.052667   \n",
       "household_children                             -0.012202   \n",
       "\n",
       "                             behavioral_outside_home  behavioral_touch_face  \\\n",
       "opinion_seas_sick_from_vacc                 0.137775               0.092923   \n",
       "census_msa                                 -0.041904              -0.022556   \n",
       "household_children                         -0.014424               0.020550   \n",
       "\n",
       "                             doctor_recc_h1n1  ...  marital_status  \\\n",
       "opinion_seas_sick_from_vacc          0.055074  ...       -0.028392   \n",
       "census_msa                           0.013221  ...       -0.052605   \n",
       "household_children                   0.033586  ...        0.162315   \n",
       "\n",
       "                             rent_or_own  employment_status  hhs_geo_region  \\\n",
       "opinion_seas_sick_from_vacc    -0.089694          -0.040087       -0.030540   \n",
       "census_msa                     -0.082343          -0.029317       -0.051005   \n",
       "household_children             -0.033011          -0.076230        0.015233   \n",
       "\n",
       "                             census_msa  household_adults  household_children  \\\n",
       "opinion_seas_sick_from_vacc   -0.004128          0.019630            0.054649   \n",
       "census_msa                     1.000000         -0.002273            0.018309   \n",
       "household_children             0.018309          0.187856            1.000000   \n",
       "\n",
       "                             employment_industry  employment_occupation  \\\n",
       "opinion_seas_sick_from_vacc            -0.008723              -0.021985   \n",
       "census_msa                              0.011184               0.018651   \n",
       "household_children                      0.017251               0.018737   \n",
       "\n",
       "                             h1n1_vaccine  \n",
       "opinion_seas_sick_from_vacc      0.000225  \n",
       "census_msa                       0.005751  \n",
       "household_children              -0.005867  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap_data = pd.concat([label_encoding(X), y], axis=1)\n",
    "low_correlation_features = get_low_correlations_for_target(heatmap_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our primary data cleaning / preprocessing pipeline method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>opinion_h1n1_vacc_effective</th>\n",
       "      <td>21365.0</td>\n",
       "      <td>3.824442</td>\n",
       "      <td>1.024825</td>\n",
       "      <td>0.560828</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion_h1n1_risk</th>\n",
       "      <td>21365.0</td>\n",
       "      <td>2.330693</td>\n",
       "      <td>1.285729</td>\n",
       "      <td>0.213785</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion_h1n1_sick_from_vacc</th>\n",
       "      <td>21365.0</td>\n",
       "      <td>2.346082</td>\n",
       "      <td>1.359361</td>\n",
       "      <td>0.245398</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion_seas_vacc_effective</th>\n",
       "      <td>21365.0</td>\n",
       "      <td>4.000288</td>\n",
       "      <td>1.099648</td>\n",
       "      <td>0.585813</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion_seas_risk</th>\n",
       "      <td>21365.0</td>\n",
       "      <td>2.701037</td>\n",
       "      <td>1.383165</td>\n",
       "      <td>0.258922</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion_seas_sick_from_vacc</th>\n",
       "      <td>21365.0</td>\n",
       "      <td>2.104664</td>\n",
       "      <td>1.328436</td>\n",
       "      <td>0.269741</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.664399</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count      mean       std       min  25%  50%  \\\n",
       "opinion_h1n1_vacc_effective  21365.0  3.824442  1.024825  0.560828  3.0  4.0   \n",
       "opinion_h1n1_risk            21365.0  2.330693  1.285729  0.213785  1.0  2.0   \n",
       "opinion_h1n1_sick_from_vacc  21365.0  2.346082  1.359361  0.245398  1.0  2.0   \n",
       "opinion_seas_vacc_effective  21365.0  4.000288  1.099648  0.585813  4.0  4.0   \n",
       "opinion_seas_risk            21365.0  2.701037  1.383165  0.258922  2.0  2.0   \n",
       "opinion_seas_sick_from_vacc  21365.0  2.104664  1.328436  0.269741  1.0  2.0   \n",
       "\n",
       "                                  75%  max  \n",
       "opinion_h1n1_vacc_effective  5.000000  5.0  \n",
       "opinion_h1n1_risk            4.000000  5.0  \n",
       "opinion_h1n1_sick_from_vacc  4.000000  5.0  \n",
       "opinion_seas_vacc_effective  5.000000  5.0  \n",
       "opinion_seas_risk            4.000000  5.0  \n",
       "opinion_seas_sick_from_vacc  2.664399  5.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clean_data(data, use_fe=False):\n",
    "    ret = data\n",
    "    \n",
    "    ret = apply_label_mapping(ret)\n",
    "\n",
    "    ret = impute_data(ret)\n",
    "    ret = set_continuous_features(ret)\n",
    "\n",
    "    if use_fe:\n",
    "        ret = feature_engineering(ret)\n",
    "\n",
    "    # ret = drop_not_used_ga_features(ret)\n",
    "\n",
    "    # use our full training set to get the correlation data\n",
    "    # ret = ret.drop(low_correlation_features, axis=1)\n",
    "\n",
    "    return ret\n",
    "\n",
    "cleaned_data = clean_data(X, use_fe=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>doctor_recc_h1n1</th>\n",
       "      <th>...</th>\n",
       "      <th>income_poverty</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>employment_industry</th>\n",
       "      <th>employment_occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189323</td>\n",
       "      <td>0.234283</td>\n",
       "      <td>0.185397</td>\n",
       "      <td>0.166259</td>\n",
       "      <td>0.191116</td>\n",
       "      <td>0.213315</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209662</td>\n",
       "      <td>0.210373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247746</td>\n",
       "      <td>0.191351</td>\n",
       "      <td>0.223421</td>\n",
       "      <td>0.215797</td>\n",
       "      <td>0.191116</td>\n",
       "      <td>0.213315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230139</td>\n",
       "      <td>0.225453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188381</td>\n",
       "      <td>0.234283</td>\n",
       "      <td>0.192875</td>\n",
       "      <td>0.215797</td>\n",
       "      <td>0.221840</td>\n",
       "      <td>0.213315</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.154844</td>\n",
       "      <td>0.207180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188381</td>\n",
       "      <td>0.191351</td>\n",
       "      <td>0.223421</td>\n",
       "      <td>0.215797</td>\n",
       "      <td>0.240960</td>\n",
       "      <td>0.209042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183499</td>\n",
       "      <td>0.206045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206938</td>\n",
       "      <td>0.191351</td>\n",
       "      <td>0.223421</td>\n",
       "      <td>0.218575</td>\n",
       "      <td>0.223350</td>\n",
       "      <td>0.215127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.209662</td>\n",
       "      <td>0.210373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21360</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247746</td>\n",
       "      <td>0.191351</td>\n",
       "      <td>0.223421</td>\n",
       "      <td>0.218575</td>\n",
       "      <td>0.221840</td>\n",
       "      <td>0.215127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209662</td>\n",
       "      <td>0.210373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21361</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.136308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206938</td>\n",
       "      <td>0.191351</td>\n",
       "      <td>0.223421</td>\n",
       "      <td>0.166259</td>\n",
       "      <td>0.223350</td>\n",
       "      <td>0.215127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209662</td>\n",
       "      <td>0.210373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21362</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206938</td>\n",
       "      <td>0.234283</td>\n",
       "      <td>0.223421</td>\n",
       "      <td>0.215797</td>\n",
       "      <td>0.221840</td>\n",
       "      <td>0.209042</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158773</td>\n",
       "      <td>0.166187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21363</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247746</td>\n",
       "      <td>0.234283</td>\n",
       "      <td>0.223421</td>\n",
       "      <td>0.215797</td>\n",
       "      <td>0.205361</td>\n",
       "      <td>0.215127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300026</td>\n",
       "      <td>0.329988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21364</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206938</td>\n",
       "      <td>0.191351</td>\n",
       "      <td>0.185397</td>\n",
       "      <td>0.215797</td>\n",
       "      <td>0.204482</td>\n",
       "      <td>0.213315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.163376</td>\n",
       "      <td>0.148388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21365 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
       "0               2.0             1.0                        0.0   \n",
       "1               2.0             1.0                        1.0   \n",
       "2               0.0             1.0                        0.0   \n",
       "3               1.0             1.0                        0.0   \n",
       "4               1.0             0.0                        0.0   \n",
       "...             ...             ...                        ...   \n",
       "21360           2.0             1.0                        0.0   \n",
       "21361           1.0             1.0                        0.0   \n",
       "21362           2.0             1.0                        0.0   \n",
       "21363           2.0             1.0                        0.0   \n",
       "21364           3.0             1.0                        0.0   \n",
       "\n",
       "       behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n",
       "0                       1.0                   0.0                    1.0   \n",
       "1                       1.0                   1.0                    1.0   \n",
       "2                       0.0                   0.0                    1.0   \n",
       "3                       0.0                   0.0                    0.0   \n",
       "4                       0.0                   0.0                    1.0   \n",
       "...                     ...                   ...                    ...   \n",
       "21360                   0.0                   0.0                    1.0   \n",
       "21361                   0.0                   0.0                    1.0   \n",
       "21362                   1.0                   0.0                    0.0   \n",
       "21363                   1.0                   0.0                    1.0   \n",
       "21364                   0.0                   0.0                    1.0   \n",
       "\n",
       "       behavioral_large_gatherings  behavioral_outside_home  \\\n",
       "0                              0.0                      1.0   \n",
       "1                              1.0                      1.0   \n",
       "2                              0.0                      1.0   \n",
       "3                              0.0                      0.0   \n",
       "4                              0.0                      0.0   \n",
       "...                            ...                      ...   \n",
       "21360                          0.0                      0.0   \n",
       "21361                          0.0                      0.0   \n",
       "21362                          0.0                      0.0   \n",
       "21363                          0.0                      0.0   \n",
       "21364                          0.0                      1.0   \n",
       "\n",
       "       behavioral_touch_face  doctor_recc_h1n1  ...  income_poverty  \\\n",
       "0                        1.0          0.000000  ...        0.189323   \n",
       "1                        1.0          0.000000  ...        0.247746   \n",
       "2                        0.0          0.000000  ...        0.188381   \n",
       "3                        0.0          0.000000  ...        0.188381   \n",
       "4                        0.0          0.000000  ...        0.206938   \n",
       "...                      ...               ...  ...             ...   \n",
       "21360                    1.0          0.000000  ...        0.247746   \n",
       "21361                    1.0          0.136308  ...        0.206938   \n",
       "21362                    1.0          0.000000  ...        0.206938   \n",
       "21363                    1.0          1.000000  ...        0.247746   \n",
       "21364                    1.0          0.000000  ...        0.206938   \n",
       "\n",
       "       marital_status  rent_or_own  employment_status  hhs_geo_region  \\\n",
       "0            0.234283     0.185397           0.166259        0.191116   \n",
       "1            0.191351     0.223421           0.215797        0.191116   \n",
       "2            0.234283     0.192875           0.215797        0.221840   \n",
       "3            0.191351     0.223421           0.215797        0.240960   \n",
       "4            0.191351     0.223421           0.218575        0.223350   \n",
       "...               ...          ...                ...             ...   \n",
       "21360        0.191351     0.223421           0.218575        0.221840   \n",
       "21361        0.191351     0.223421           0.166259        0.223350   \n",
       "21362        0.234283     0.223421           0.215797        0.221840   \n",
       "21363        0.234283     0.223421           0.215797        0.205361   \n",
       "21364        0.191351     0.185397           0.215797        0.204482   \n",
       "\n",
       "       census_msa  household_adults  household_children  employment_industry  \\\n",
       "0        0.213315               1.0                 0.0             0.209662   \n",
       "1        0.213315               0.0                 0.0             0.230139   \n",
       "2        0.213315               1.0                 1.0             0.154844   \n",
       "3        0.209042               0.0                 0.0             0.183499   \n",
       "4        0.215127               1.0                 1.0             0.209662   \n",
       "...           ...               ...                 ...                  ...   \n",
       "21360    0.215127               0.0                 0.0             0.209662   \n",
       "21361    0.215127               0.0                 0.0             0.209662   \n",
       "21362    0.209042               1.0                 0.0             0.158773   \n",
       "21363    0.215127               1.0                 0.0             0.300026   \n",
       "21364    0.213315               0.0                 0.0             0.163376   \n",
       "\n",
       "       employment_occupation  \n",
       "0                   0.210373  \n",
       "1                   0.225453  \n",
       "2                   0.207180  \n",
       "3                   0.206045  \n",
       "4                   0.210373  \n",
       "...                      ...  \n",
       "21360               0.210373  \n",
       "21361               0.210373  \n",
       "21362               0.166187  \n",
       "21363               0.329988  \n",
       "21364               0.148388  \n",
       "\n",
       "[21365 rows x 35 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(cleaned_data,y,test_size=0.30,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>doctor_recc_h1n1</th>\n",
       "      <th>...</th>\n",
       "      <th>income_poverty</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>employment_industry</th>\n",
       "      <th>employment_occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16270</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188381</td>\n",
       "      <td>0.181250</td>\n",
       "      <td>0.192875</td>\n",
       "      <td>0.187195</td>\n",
       "      <td>0.191116</td>\n",
       "      <td>0.213315</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209662</td>\n",
       "      <td>0.210373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17234</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206938</td>\n",
       "      <td>0.191351</td>\n",
       "      <td>0.223421</td>\n",
       "      <td>0.215797</td>\n",
       "      <td>0.213557</td>\n",
       "      <td>0.209042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183499</td>\n",
       "      <td>0.206045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9625</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206938</td>\n",
       "      <td>0.234283</td>\n",
       "      <td>0.185397</td>\n",
       "      <td>0.218575</td>\n",
       "      <td>0.204482</td>\n",
       "      <td>0.215127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209662</td>\n",
       "      <td>0.210373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10408</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206938</td>\n",
       "      <td>0.191351</td>\n",
       "      <td>0.185397</td>\n",
       "      <td>0.215797</td>\n",
       "      <td>0.223350</td>\n",
       "      <td>0.209042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.163376</td>\n",
       "      <td>0.168261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.17233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188381</td>\n",
       "      <td>0.181250</td>\n",
       "      <td>0.192875</td>\n",
       "      <td>0.187195</td>\n",
       "      <td>0.240960</td>\n",
       "      <td>0.213315</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.209662</td>\n",
       "      <td>0.210373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247746</td>\n",
       "      <td>0.234283</td>\n",
       "      <td>0.223421</td>\n",
       "      <td>0.218575</td>\n",
       "      <td>0.191116</td>\n",
       "      <td>0.213315</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.209662</td>\n",
       "      <td>0.210373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188381</td>\n",
       "      <td>0.181250</td>\n",
       "      <td>0.192875</td>\n",
       "      <td>0.187195</td>\n",
       "      <td>0.191116</td>\n",
       "      <td>0.215127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209662</td>\n",
       "      <td>0.210373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206938</td>\n",
       "      <td>0.234283</td>\n",
       "      <td>0.223421</td>\n",
       "      <td>0.166259</td>\n",
       "      <td>0.191116</td>\n",
       "      <td>0.209042</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.209662</td>\n",
       "      <td>0.210373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206938</td>\n",
       "      <td>0.191351</td>\n",
       "      <td>0.223421</td>\n",
       "      <td>0.218575</td>\n",
       "      <td>0.221695</td>\n",
       "      <td>0.215127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209662</td>\n",
       "      <td>0.210373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188381</td>\n",
       "      <td>0.191351</td>\n",
       "      <td>0.192875</td>\n",
       "      <td>0.218575</td>\n",
       "      <td>0.205361</td>\n",
       "      <td>0.215127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209662</td>\n",
       "      <td>0.210373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14955 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
       "16270           2.0             0.0                        0.0   \n",
       "17234           1.0             1.0                        0.0   \n",
       "9625            2.0             2.0                        0.0   \n",
       "10408           0.0             1.0                        0.0   \n",
       "2299            2.0             1.0                        0.0   \n",
       "...             ...             ...                        ...   \n",
       "11284           3.0             1.0                        0.0   \n",
       "11964           1.0             1.0                        0.0   \n",
       "5390            1.0             2.0                        0.0   \n",
       "860             2.0             2.0                        0.0   \n",
       "15795           3.0             0.0                        0.0   \n",
       "\n",
       "       behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n",
       "16270                   0.0                   0.0                    1.0   \n",
       "17234                   0.0                   0.0                    1.0   \n",
       "9625                    1.0                   0.0                    1.0   \n",
       "10408                   0.0                   0.0                    1.0   \n",
       "2299                    1.0                   0.0                    1.0   \n",
       "...                     ...                   ...                    ...   \n",
       "11284                   1.0                   0.0                    1.0   \n",
       "11964                   0.0                   0.0                    0.0   \n",
       "5390                    1.0                   0.0                    1.0   \n",
       "860                     1.0                   0.0                    1.0   \n",
       "15795                   0.0                   1.0                    1.0   \n",
       "\n",
       "       behavioral_large_gatherings  behavioral_outside_home  \\\n",
       "16270                          1.0                      1.0   \n",
       "17234                          0.0                      0.0   \n",
       "9625                           0.0                      0.0   \n",
       "10408                          0.0                      0.0   \n",
       "2299                           0.0                      0.0   \n",
       "...                            ...                      ...   \n",
       "11284                          0.0                      1.0   \n",
       "11964                          0.0                      0.0   \n",
       "5390                           0.0                      0.0   \n",
       "860                            1.0                      1.0   \n",
       "15795                          0.0                      0.0   \n",
       "\n",
       "       behavioral_touch_face  doctor_recc_h1n1  ...  income_poverty  \\\n",
       "16270                    1.0           0.00000  ...        0.188381   \n",
       "17234                    0.0           0.00000  ...        0.206938   \n",
       "9625                     1.0           1.00000  ...        0.206938   \n",
       "10408                    0.0           0.00000  ...        0.206938   \n",
       "2299                     1.0           0.17233  ...        0.188381   \n",
       "...                      ...               ...  ...             ...   \n",
       "11284                    1.0           0.00000  ...        0.247746   \n",
       "11964                    1.0           0.00000  ...        0.188381   \n",
       "5390                     1.0           0.00000  ...        0.206938   \n",
       "860                      1.0           0.00000  ...        0.206938   \n",
       "15795                    0.0           0.00000  ...        0.188381   \n",
       "\n",
       "       marital_status  rent_or_own  employment_status  hhs_geo_region  \\\n",
       "16270        0.181250     0.192875           0.187195        0.191116   \n",
       "17234        0.191351     0.223421           0.215797        0.213557   \n",
       "9625         0.234283     0.185397           0.218575        0.204482   \n",
       "10408        0.191351     0.185397           0.215797        0.223350   \n",
       "2299         0.181250     0.192875           0.187195        0.240960   \n",
       "...               ...          ...                ...             ...   \n",
       "11284        0.234283     0.223421           0.218575        0.191116   \n",
       "11964        0.181250     0.192875           0.187195        0.191116   \n",
       "5390         0.234283     0.223421           0.166259        0.191116   \n",
       "860          0.191351     0.223421           0.218575        0.221695   \n",
       "15795        0.191351     0.192875           0.218575        0.205361   \n",
       "\n",
       "       census_msa  household_adults  household_children  employment_industry  \\\n",
       "16270    0.213315               1.0                 0.0             0.209662   \n",
       "17234    0.209042               0.0                 0.0             0.183499   \n",
       "9625     0.215127               1.0                 0.0             0.209662   \n",
       "10408    0.209042               0.0                 0.0             0.163376   \n",
       "2299     0.213315               1.0                 2.0             0.209662   \n",
       "...           ...               ...                 ...                  ...   \n",
       "11284    0.213315               1.0                 3.0             0.209662   \n",
       "11964    0.215127               0.0                 0.0             0.209662   \n",
       "5390     0.209042               2.0                 1.0             0.209662   \n",
       "860      0.215127               0.0                 0.0             0.209662   \n",
       "15795    0.215127               0.0                 0.0             0.209662   \n",
       "\n",
       "       employment_occupation  \n",
       "16270               0.210373  \n",
       "17234               0.206045  \n",
       "9625                0.210373  \n",
       "10408               0.168261  \n",
       "2299                0.210373  \n",
       "...                      ...  \n",
       "11284               0.210373  \n",
       "11964               0.210373  \n",
       "5390                0.210373  \n",
       "860                 0.210373  \n",
       "15795               0.210373  \n",
       "\n",
       "[14955 rows x 35 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:   46.6s finished\n",
      "\n",
      "[2024-05-29 17:10:57] Features: 1/35 -- score: 0.7948512203276497[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:   59.9s finished\n",
      "\n",
      "[2024-05-29 17:11:56] Features: 2/35 -- score: 0.8143095954530258[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:  1.0min finished\n",
      "\n",
      "[2024-05-29 17:12:59] Features: 3/35 -- score: 0.8203276496155132[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:  1.5min finished\n",
      "\n",
      "[2024-05-29 17:14:29] Features: 4/35 -- score: 0.8205951186894016[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:  1.5min finished\n",
      "\n",
      "[2024-05-29 17:15:57] Features: 5/35 -- score: 0.8210631895687059[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.6min finished\n",
      "\n",
      "[2024-05-29 17:17:34] Features: 6/35 -- score: 0.8212637913741224[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:  1.6min finished\n",
      "\n",
      "[2024-05-29 17:19:10] Features: 7/35 -- score: 0.8207957204948177[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  1.6min finished\n",
      "\n",
      "[2024-05-29 17:20:44] Features: 8/35 -- score: 0.8209294550317618[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  1.9min finished\n",
      "\n",
      "[2024-05-29 17:22:39] Features: 9/35 -- score: 0.829822801738549[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:  2.3min finished\n",
      "\n",
      "[2024-05-29 17:24:59] Features: 10/35 -- score: 0.8320962888665997[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  2.2min finished\n",
      "\n",
      "[2024-05-29 17:27:12] Features: 11/35 -- score: 0.8344366432631227[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  2.2min finished\n",
      "\n",
      "[2024-05-29 17:29:22] Features: 12/35 -- score: 0.837178201270478[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:  2.1min finished\n",
      "\n",
      "[2024-05-29 17:31:27] Features: 13/35 -- score: 0.8390504847876965[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:  2.0min finished\n",
      "\n",
      "[2024-05-29 17:33:29] Features: 14/35 -- score: 0.8397860247408893[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:  1.9min finished\n",
      "\n",
      "[2024-05-29 17:35:24] Features: 15/35 -- score: 0.8404546974256102[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  2.1min finished\n",
      "\n",
      "[2024-05-29 17:37:28] Features: 16/35 -- score: 0.8415245737211634[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:  2.0min finished\n",
      "\n",
      "[2024-05-29 17:39:26] Features: 17/35 -- score: 0.8437980608492144[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  1.9min finished\n",
      "\n",
      "[2024-05-29 17:41:18] Features: 18/35 -- score: 0.8439986626546305[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:  1.7min finished\n",
      "\n",
      "[2024-05-29 17:43:02] Features: 19/35 -- score: 0.8447342026078234[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:  1.6min finished\n",
      "\n",
      "[2024-05-29 17:44:39] Features: 20/35 -- score: 0.8462721497826815[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  1.5min finished\n",
      "\n",
      "[2024-05-29 17:46:10] Features: 21/35 -- score: 0.8467402206619858[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:  1.4min finished\n",
      "\n",
      "[2024-05-29 17:47:35] Features: 22/35 -- score: 0.8476094951521229[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:  1.3min finished\n",
      "\n",
      "[2024-05-29 17:48:54] Features: 23/35 -- score: 0.8490137077900368[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  1.2min finished\n",
      "\n",
      "[2024-05-29 17:50:06] Features: 24/35 -- score: 0.8490137077900368[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:  1.2min finished\n",
      "\n",
      "[2024-05-29 17:51:19] Features: 25/35 -- score: 0.8493480441323971[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.1min finished\n",
      "\n",
      "[2024-05-29 17:52:25] Features: 26/35 -- score: 0.8480106987629557[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   59.0s finished\n",
      "\n",
      "[2024-05-29 17:53:24] Features: 27/35 -- score: 0.8502173186225344[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   52.4s finished\n",
      "\n",
      "[2024-05-29 17:54:16] Features: 28/35 -- score: 0.8499498495486459[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   45.6s finished\n",
      "\n",
      "[2024-05-29 17:55:02] Features: 29/35 -- score: 0.8488799732530925[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   40.3s finished\n",
      "\n",
      "[2024-05-29 17:55:42] Features: 30/35 -- score: 0.8490805750585089[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   33.0s finished\n",
      "\n",
      "[2024-05-29 17:56:15] Features: 31/35 -- score: 0.8490137077900368[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   26.2s finished\n",
      "\n",
      "[2024-05-29 17:56:42] Features: 32/35 -- score: 0.8497492477432298[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   19.5s finished\n",
      "\n",
      "[2024-05-29 17:57:01] Features: 33/35 -- score: 0.8476763624205951[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   12.9s finished\n",
      "\n",
      "[2024-05-29 17:57:14] Features: 34/35 -- score: 0.849147442326981[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.3s finished\n",
      "\n",
      "[2024-05-29 17:57:21] Features: 35/35 -- score: 0.8486125041792043"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SequentialFeatureSelector(estimator=RandomForestClassifier(),\n",
       "                          k_features=(1, 35), scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SequentialFeatureSelector</label><div class=\"sk-toggleable__content\"><pre>SequentialFeatureSelector(estimator=RandomForestClassifier(),\n",
       "                          k_features=(1, 35), scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SequentialFeatureSelector(estimator=RandomForestClassifier(),\n",
       "                          k_features=(1, 35), scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "from catboost import CatBoostClassifier\n",
    "sfs = SequentialFeatureSelector(rf,k_features=(1,x_train.shape[1]),forward=True,verbose = 2,scoring='accuracy')\n",
    "sfs.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_idx</th>\n",
       "      <th>cv_scores</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>feature_names</th>\n",
       "      <th>ci_bound</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>std_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(9,)</td>\n",
       "      <td>[0.7997325309261116, 0.8030758943497158, 0.789...</td>\n",
       "      <td>0.794851</td>\n",
       "      <td>(doctor_recc_h1n1,)</td>\n",
       "      <td>0.007101</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.002762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(9, 15)</td>\n",
       "      <td>[0.8154463390170511, 0.8184553660982948, 0.815...</td>\n",
       "      <td>0.81431</td>\n",
       "      <td>(doctor_recc_h1n1, opinion_h1n1_vacc_effective)</td>\n",
       "      <td>0.004912</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>0.001911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(9, 15, 34)</td>\n",
       "      <td>[0.8238047475760615, 0.8207957204948177, 0.819...</td>\n",
       "      <td>0.820328</td>\n",
       "      <td>(doctor_recc_h1n1, opinion_h1n1_vacc_effective...</td>\n",
       "      <td>0.005218</td>\n",
       "      <td>0.00406</td>\n",
       "      <td>0.00203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(5, 9, 15, 34)</td>\n",
       "      <td>[0.8268137746573052, 0.8214643931795386, 0.815...</td>\n",
       "      <td>0.820595</td>\n",
       "      <td>(behavioral_wash_hands, doctor_recc_h1n1, opin...</td>\n",
       "      <td>0.007311</td>\n",
       "      <td>0.005688</td>\n",
       "      <td>0.002844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(5, 9, 15, 18, 34)</td>\n",
       "      <td>[0.8268137746573052, 0.8251420929455032, 0.817...</td>\n",
       "      <td>0.821063</td>\n",
       "      <td>(behavioral_wash_hands, doctor_recc_h1n1, opin...</td>\n",
       "      <td>0.007524</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>0.002927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(4, 5, 9, 15, 18, 34)</td>\n",
       "      <td>[0.8244734202607823, 0.8241390839184219, 0.819...</td>\n",
       "      <td>0.821264</td>\n",
       "      <td>(behavioral_face_mask, behavioral_wash_hands, ...</td>\n",
       "      <td>0.005958</td>\n",
       "      <td>0.004636</td>\n",
       "      <td>0.002318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(2, 4, 5, 9, 15, 18, 34)</td>\n",
       "      <td>[0.8248077566031428, 0.8254764292878636, 0.816...</td>\n",
       "      <td>0.820796</td>\n",
       "      <td>(behavioral_antiviral_meds, behavioral_face_ma...</td>\n",
       "      <td>0.005483</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.002133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(2, 4, 5, 9, 15, 16, 18, 34)</td>\n",
       "      <td>[0.8294884653961886, 0.8221330658642595, 0.818...</td>\n",
       "      <td>0.820929</td>\n",
       "      <td>(behavioral_antiviral_meds, behavioral_face_ma...</td>\n",
       "      <td>0.007973</td>\n",
       "      <td>0.006203</td>\n",
       "      <td>0.003102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2, 4, 5, 9, 14, 15, 16, 18, 34)</td>\n",
       "      <td>[0.843530591775326, 0.8207957204948177, 0.8298...</td>\n",
       "      <td>0.829823</td>\n",
       "      <td>(behavioral_antiviral_meds, behavioral_face_ma...</td>\n",
       "      <td>0.010162</td>\n",
       "      <td>0.007906</td>\n",
       "      <td>0.003953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(2, 4, 5, 9, 14, 15, 16, 18, 33, 34)</td>\n",
       "      <td>[0.8438649281176864, 0.8261451019725844, 0.834...</td>\n",
       "      <td>0.832096</td>\n",
       "      <td>(behavioral_antiviral_meds, behavioral_face_ma...</td>\n",
       "      <td>0.008933</td>\n",
       "      <td>0.00695</td>\n",
       "      <td>0.003475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(2, 4, 5, 9, 14, 15, 16, 18, 22, 33, 34)</td>\n",
       "      <td>[0.8448679371447676, 0.8271481109996657, 0.831...</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>(behavioral_antiviral_meds, behavioral_face_ma...</td>\n",
       "      <td>0.008046</td>\n",
       "      <td>0.00626</td>\n",
       "      <td>0.00313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(2, 4, 5, 9, 14, 15, 16, 17, 18, 22, 33, 34)</td>\n",
       "      <td>[0.8455366098294884, 0.8365095285857572, 0.837...</td>\n",
       "      <td>0.837178</td>\n",
       "      <td>(behavioral_antiviral_meds, behavioral_face_ma...</td>\n",
       "      <td>0.006816</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>0.002652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(2, 4, 5, 9, 14, 15, 16, 17, 18, 22, 31, 33, 34)</td>\n",
       "      <td>[0.8518890003343363, 0.8328318288197927, 0.835...</td>\n",
       "      <td>0.83905</td>\n",
       "      <td>(behavioral_antiviral_meds, behavioral_face_ma...</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.006649</td>\n",
       "      <td>0.003324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(2, 4, 5, 9, 13, 14, 15, 16, 17, 18, 22, 31, 3...</td>\n",
       "      <td>[0.8492143095954531, 0.8401872283517219, 0.838...</td>\n",
       "      <td>0.839786</td>\n",
       "      <td>(behavioral_antiviral_meds, behavioral_face_ma...</td>\n",
       "      <td>0.006775</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.002636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(0, 2, 4, 5, 9, 13, 14, 15, 16, 17, 18, 22, 31...</td>\n",
       "      <td>[0.8495486459378134, 0.8375125376128385, 0.842...</td>\n",
       "      <td>0.840455</td>\n",
       "      <td>(h1n1_concern, behavioral_antiviral_meds, beha...</td>\n",
       "      <td>0.006491</td>\n",
       "      <td>0.00505</td>\n",
       "      <td>0.002525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(0, 2, 4, 5, 9, 13, 14, 15, 16, 17, 18, 19, 22...</td>\n",
       "      <td>[0.8495486459378134, 0.8381812102975593, 0.838...</td>\n",
       "      <td>0.841525</td>\n",
       "      <td>(h1n1_concern, behavioral_antiviral_meds, beha...</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.004208</td>\n",
       "      <td>0.002104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(0, 2, 4, 5, 9, 13, 14, 15, 16, 17, 18, 19, 22...</td>\n",
       "      <td>[0.8515546639919759, 0.8415245737211635, 0.846...</td>\n",
       "      <td>0.843798</td>\n",
       "      <td>(h1n1_concern, behavioral_antiviral_meds, beha...</td>\n",
       "      <td>0.006306</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>0.002453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(0, 2, 3, 4, 5, 9, 13, 14, 15, 16, 17, 18, 19,...</td>\n",
       "      <td>[0.8528920093614176, 0.8391842193246406, 0.845...</td>\n",
       "      <td>0.843999</td>\n",
       "      <td>(h1n1_concern, behavioral_antiviral_meds, beha...</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.002426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(0, 2, 3, 4, 5, 9, 13, 14, 15, 16, 17, 18, 19,...</td>\n",
       "      <td>[0.8512203276496155, 0.8448679371447676, 0.841...</td>\n",
       "      <td>0.844734</td>\n",
       "      <td>(h1n1_concern, behavioral_antiviral_meds, beha...</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.003548</td>\n",
       "      <td>0.001774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(0, 2, 3, 4, 5, 9, 13, 14, 15, 16, 17, 18, 19,...</td>\n",
       "      <td>[0.8492143095954531, 0.8522233366766968, 0.844...</td>\n",
       "      <td>0.846272</td>\n",
       "      <td>(h1n1_concern, behavioral_antiviral_meds, beha...</td>\n",
       "      <td>0.005926</td>\n",
       "      <td>0.00461</td>\n",
       "      <td>0.002305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 9, 13, 14, 15, 16, 17, 18, ...</td>\n",
       "      <td>[0.8535606820461384, 0.8452022734871281, 0.847...</td>\n",
       "      <td>0.84674</td>\n",
       "      <td>(h1n1_concern, h1n1_knowledge, behavioral_anti...</td>\n",
       "      <td>0.006754</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.002627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 9, 13, 14, 15, 16, 17, 18, ...</td>\n",
       "      <td>[0.8555667001003009, 0.8492143095954531, 0.851...</td>\n",
       "      <td>0.847609</td>\n",
       "      <td>(h1n1_concern, h1n1_knowledge, behavioral_anti...</td>\n",
       "      <td>0.007789</td>\n",
       "      <td>0.00606</td>\n",
       "      <td>0.00303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 7, 9, 13, 14, 15, 16, 17, 1...</td>\n",
       "      <td>[0.853226345703778, 0.8488799732530926, 0.8532...</td>\n",
       "      <td>0.849014</td>\n",
       "      <td>(h1n1_concern, h1n1_knowledge, behavioral_anti...</td>\n",
       "      <td>0.006857</td>\n",
       "      <td>0.005335</td>\n",
       "      <td>0.002668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 7, 9, 13, 14, 15, 16, 17, 1...</td>\n",
       "      <td>[0.8505516549648947, 0.8515546639919759, 0.851...</td>\n",
       "      <td>0.849014</td>\n",
       "      <td>(h1n1_concern, h1n1_knowledge, behavioral_anti...</td>\n",
       "      <td>0.005692</td>\n",
       "      <td>0.004428</td>\n",
       "      <td>0.002214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 9, 13, 14, 15, 16, 17...</td>\n",
       "      <td>[0.8508859913072551, 0.8528920093614176, 0.850...</td>\n",
       "      <td>0.849348</td>\n",
       "      <td>(h1n1_concern, h1n1_knowledge, behavioral_anti...</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>0.001787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 13, 14, 15, 16...</td>\n",
       "      <td>[0.8492143095954531, 0.8512203276496155, 0.851...</td>\n",
       "      <td>0.848011</td>\n",
       "      <td>(h1n1_concern, h1n1_knowledge, behavioral_anti...</td>\n",
       "      <td>0.007038</td>\n",
       "      <td>0.005476</td>\n",
       "      <td>0.002738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 13, 14, 15, 16...</td>\n",
       "      <td>[0.8562353727850217, 0.8538950183884988, 0.852...</td>\n",
       "      <td>0.850217</td>\n",
       "      <td>(h1n1_concern, h1n1_knowledge, behavioral_anti...</td>\n",
       "      <td>0.00901</td>\n",
       "      <td>0.00701</td>\n",
       "      <td>0.003505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15,...</td>\n",
       "      <td>[0.8538950183884988, 0.8488799732530926, 0.851...</td>\n",
       "      <td>0.84995</td>\n",
       "      <td>(h1n1_concern, h1n1_knowledge, behavioral_anti...</td>\n",
       "      <td>0.007047</td>\n",
       "      <td>0.005483</td>\n",
       "      <td>0.002742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15,...</td>\n",
       "      <td>[0.8559010364426614, 0.8462052825142093, 0.852...</td>\n",
       "      <td>0.84888</td>\n",
       "      <td>(h1n1_concern, h1n1_knowledge, behavioral_anti...</td>\n",
       "      <td>0.008144</td>\n",
       "      <td>0.006337</td>\n",
       "      <td>0.003168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15,...</td>\n",
       "      <td>[0.8559010364426614, 0.8485456369107321, 0.848...</td>\n",
       "      <td>0.849081</td>\n",
       "      <td>(h1n1_concern, h1n1_knowledge, behavioral_anti...</td>\n",
       "      <td>0.005627</td>\n",
       "      <td>0.004378</td>\n",
       "      <td>0.002189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14,...</td>\n",
       "      <td>[0.8559010364426614, 0.8502173186225342, 0.852...</td>\n",
       "      <td>0.849014</td>\n",
       "      <td>(h1n1_concern, h1n1_knowledge, behavioral_anti...</td>\n",
       "      <td>0.007356</td>\n",
       "      <td>0.005723</td>\n",
       "      <td>0.002862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14,...</td>\n",
       "      <td>[0.8569040454697425, 0.8512203276496155, 0.847...</td>\n",
       "      <td>0.849749</td>\n",
       "      <td>(h1n1_concern, h1n1_knowledge, behavioral_anti...</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.005589</td>\n",
       "      <td>0.002794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[0.8548980274155801, 0.847542627883651, 0.8498...</td>\n",
       "      <td>0.847676</td>\n",
       "      <td>(h1n1_concern, h1n1_knowledge, behavioral_anti...</td>\n",
       "      <td>0.007466</td>\n",
       "      <td>0.005809</td>\n",
       "      <td>0.002904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[0.8589100635239051, 0.8462052825142093, 0.851...</td>\n",
       "      <td>0.849147</td>\n",
       "      <td>(h1n1_concern, h1n1_knowledge, behavioral_anti...</td>\n",
       "      <td>0.00877</td>\n",
       "      <td>0.006824</td>\n",
       "      <td>0.003412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[0.8565697091273822, 0.8455366098294884, 0.850...</td>\n",
       "      <td>0.848613</td>\n",
       "      <td>(h1n1_concern, h1n1_knowledge, behavioral_anti...</td>\n",
       "      <td>0.006764</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.002631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          feature_idx  \\\n",
       "1                                                (9,)   \n",
       "2                                             (9, 15)   \n",
       "3                                         (9, 15, 34)   \n",
       "4                                      (5, 9, 15, 34)   \n",
       "5                                  (5, 9, 15, 18, 34)   \n",
       "6                               (4, 5, 9, 15, 18, 34)   \n",
       "7                            (2, 4, 5, 9, 15, 18, 34)   \n",
       "8                        (2, 4, 5, 9, 15, 16, 18, 34)   \n",
       "9                    (2, 4, 5, 9, 14, 15, 16, 18, 34)   \n",
       "10               (2, 4, 5, 9, 14, 15, 16, 18, 33, 34)   \n",
       "11           (2, 4, 5, 9, 14, 15, 16, 18, 22, 33, 34)   \n",
       "12       (2, 4, 5, 9, 14, 15, 16, 17, 18, 22, 33, 34)   \n",
       "13   (2, 4, 5, 9, 14, 15, 16, 17, 18, 22, 31, 33, 34)   \n",
       "14  (2, 4, 5, 9, 13, 14, 15, 16, 17, 18, 22, 31, 3...   \n",
       "15  (0, 2, 4, 5, 9, 13, 14, 15, 16, 17, 18, 22, 31...   \n",
       "16  (0, 2, 4, 5, 9, 13, 14, 15, 16, 17, 18, 19, 22...   \n",
       "17  (0, 2, 4, 5, 9, 13, 14, 15, 16, 17, 18, 19, 22...   \n",
       "18  (0, 2, 3, 4, 5, 9, 13, 14, 15, 16, 17, 18, 19,...   \n",
       "19  (0, 2, 3, 4, 5, 9, 13, 14, 15, 16, 17, 18, 19,...   \n",
       "20  (0, 2, 3, 4, 5, 9, 13, 14, 15, 16, 17, 18, 19,...   \n",
       "21  (0, 1, 2, 3, 4, 5, 9, 13, 14, 15, 16, 17, 18, ...   \n",
       "22  (0, 1, 2, 3, 4, 5, 9, 13, 14, 15, 16, 17, 18, ...   \n",
       "23  (0, 1, 2, 3, 4, 5, 7, 9, 13, 14, 15, 16, 17, 1...   \n",
       "24  (0, 1, 2, 3, 4, 5, 7, 9, 13, 14, 15, 16, 17, 1...   \n",
       "25  (0, 1, 2, 3, 4, 5, 6, 7, 9, 13, 14, 15, 16, 17...   \n",
       "26  (0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 13, 14, 15, 16...   \n",
       "27  (0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 13, 14, 15, 16...   \n",
       "28  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15,...   \n",
       "29  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15,...   \n",
       "30  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15,...   \n",
       "31  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14,...   \n",
       "32  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14,...   \n",
       "33  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "34  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "35  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "\n",
       "                                            cv_scores avg_score  \\\n",
       "1   [0.7997325309261116, 0.8030758943497158, 0.789...  0.794851   \n",
       "2   [0.8154463390170511, 0.8184553660982948, 0.815...   0.81431   \n",
       "3   [0.8238047475760615, 0.8207957204948177, 0.819...  0.820328   \n",
       "4   [0.8268137746573052, 0.8214643931795386, 0.815...  0.820595   \n",
       "5   [0.8268137746573052, 0.8251420929455032, 0.817...  0.821063   \n",
       "6   [0.8244734202607823, 0.8241390839184219, 0.819...  0.821264   \n",
       "7   [0.8248077566031428, 0.8254764292878636, 0.816...  0.820796   \n",
       "8   [0.8294884653961886, 0.8221330658642595, 0.818...  0.820929   \n",
       "9   [0.843530591775326, 0.8207957204948177, 0.8298...  0.829823   \n",
       "10  [0.8438649281176864, 0.8261451019725844, 0.834...  0.832096   \n",
       "11  [0.8448679371447676, 0.8271481109996657, 0.831...  0.834437   \n",
       "12  [0.8455366098294884, 0.8365095285857572, 0.837...  0.837178   \n",
       "13  [0.8518890003343363, 0.8328318288197927, 0.835...   0.83905   \n",
       "14  [0.8492143095954531, 0.8401872283517219, 0.838...  0.839786   \n",
       "15  [0.8495486459378134, 0.8375125376128385, 0.842...  0.840455   \n",
       "16  [0.8495486459378134, 0.8381812102975593, 0.838...  0.841525   \n",
       "17  [0.8515546639919759, 0.8415245737211635, 0.846...  0.843798   \n",
       "18  [0.8528920093614176, 0.8391842193246406, 0.845...  0.843999   \n",
       "19  [0.8512203276496155, 0.8448679371447676, 0.841...  0.844734   \n",
       "20  [0.8492143095954531, 0.8522233366766968, 0.844...  0.846272   \n",
       "21  [0.8535606820461384, 0.8452022734871281, 0.847...   0.84674   \n",
       "22  [0.8555667001003009, 0.8492143095954531, 0.851...  0.847609   \n",
       "23  [0.853226345703778, 0.8488799732530926, 0.8532...  0.849014   \n",
       "24  [0.8505516549648947, 0.8515546639919759, 0.851...  0.849014   \n",
       "25  [0.8508859913072551, 0.8528920093614176, 0.850...  0.849348   \n",
       "26  [0.8492143095954531, 0.8512203276496155, 0.851...  0.848011   \n",
       "27  [0.8562353727850217, 0.8538950183884988, 0.852...  0.850217   \n",
       "28  [0.8538950183884988, 0.8488799732530926, 0.851...   0.84995   \n",
       "29  [0.8559010364426614, 0.8462052825142093, 0.852...   0.84888   \n",
       "30  [0.8559010364426614, 0.8485456369107321, 0.848...  0.849081   \n",
       "31  [0.8559010364426614, 0.8502173186225342, 0.852...  0.849014   \n",
       "32  [0.8569040454697425, 0.8512203276496155, 0.847...  0.849749   \n",
       "33  [0.8548980274155801, 0.847542627883651, 0.8498...  0.847676   \n",
       "34  [0.8589100635239051, 0.8462052825142093, 0.851...  0.849147   \n",
       "35  [0.8565697091273822, 0.8455366098294884, 0.850...  0.848613   \n",
       "\n",
       "                                        feature_names  ci_bound   std_dev  \\\n",
       "1                                 (doctor_recc_h1n1,)  0.007101  0.005525   \n",
       "2     (doctor_recc_h1n1, opinion_h1n1_vacc_effective)  0.004912  0.003821   \n",
       "3   (doctor_recc_h1n1, opinion_h1n1_vacc_effective...  0.005218   0.00406   \n",
       "4   (behavioral_wash_hands, doctor_recc_h1n1, opin...  0.007311  0.005688   \n",
       "5   (behavioral_wash_hands, doctor_recc_h1n1, opin...  0.007524  0.005854   \n",
       "6   (behavioral_face_mask, behavioral_wash_hands, ...  0.005958  0.004636   \n",
       "7   (behavioral_antiviral_meds, behavioral_face_ma...  0.005483  0.004266   \n",
       "8   (behavioral_antiviral_meds, behavioral_face_ma...  0.007973  0.006203   \n",
       "9   (behavioral_antiviral_meds, behavioral_face_ma...  0.010162  0.007906   \n",
       "10  (behavioral_antiviral_meds, behavioral_face_ma...  0.008933   0.00695   \n",
       "11  (behavioral_antiviral_meds, behavioral_face_ma...  0.008046   0.00626   \n",
       "12  (behavioral_antiviral_meds, behavioral_face_ma...  0.006816  0.005303   \n",
       "13  (behavioral_antiviral_meds, behavioral_face_ma...  0.008545  0.006649   \n",
       "14  (behavioral_antiviral_meds, behavioral_face_ma...  0.006775  0.005271   \n",
       "15  (h1n1_concern, behavioral_antiviral_meds, beha...  0.006491   0.00505   \n",
       "16  (h1n1_concern, behavioral_antiviral_meds, beha...  0.005408  0.004208   \n",
       "17  (h1n1_concern, behavioral_antiviral_meds, beha...  0.006306  0.004906   \n",
       "18  (h1n1_concern, behavioral_antiviral_meds, beha...  0.006237  0.004852   \n",
       "19  (h1n1_concern, behavioral_antiviral_meds, beha...  0.004561  0.003548   \n",
       "20  (h1n1_concern, behavioral_antiviral_meds, beha...  0.005926   0.00461   \n",
       "21  (h1n1_concern, h1n1_knowledge, behavioral_anti...  0.006754  0.005255   \n",
       "22  (h1n1_concern, h1n1_knowledge, behavioral_anti...  0.007789   0.00606   \n",
       "23  (h1n1_concern, h1n1_knowledge, behavioral_anti...  0.006857  0.005335   \n",
       "24  (h1n1_concern, h1n1_knowledge, behavioral_anti...  0.005692  0.004428   \n",
       "25  (h1n1_concern, h1n1_knowledge, behavioral_anti...  0.004593  0.003573   \n",
       "26  (h1n1_concern, h1n1_knowledge, behavioral_anti...  0.007038  0.005476   \n",
       "27  (h1n1_concern, h1n1_knowledge, behavioral_anti...   0.00901   0.00701   \n",
       "28  (h1n1_concern, h1n1_knowledge, behavioral_anti...  0.007047  0.005483   \n",
       "29  (h1n1_concern, h1n1_knowledge, behavioral_anti...  0.008144  0.006337   \n",
       "30  (h1n1_concern, h1n1_knowledge, behavioral_anti...  0.005627  0.004378   \n",
       "31  (h1n1_concern, h1n1_knowledge, behavioral_anti...  0.007356  0.005723   \n",
       "32  (h1n1_concern, h1n1_knowledge, behavioral_anti...  0.007183  0.005589   \n",
       "33  (h1n1_concern, h1n1_knowledge, behavioral_anti...  0.007466  0.005809   \n",
       "34  (h1n1_concern, h1n1_knowledge, behavioral_anti...   0.00877  0.006824   \n",
       "35  (h1n1_concern, h1n1_knowledge, behavioral_anti...  0.006764  0.005263   \n",
       "\n",
       "     std_err  \n",
       "1   0.002762  \n",
       "2   0.001911  \n",
       "3    0.00203  \n",
       "4   0.002844  \n",
       "5   0.002927  \n",
       "6   0.002318  \n",
       "7   0.002133  \n",
       "8   0.003102  \n",
       "9   0.003953  \n",
       "10  0.003475  \n",
       "11   0.00313  \n",
       "12  0.002652  \n",
       "13  0.003324  \n",
       "14  0.002636  \n",
       "15  0.002525  \n",
       "16  0.002104  \n",
       "17  0.002453  \n",
       "18  0.002426  \n",
       "19  0.001774  \n",
       "20  0.002305  \n",
       "21  0.002627  \n",
       "22   0.00303  \n",
       "23  0.002668  \n",
       "24  0.002214  \n",
       "25  0.001787  \n",
       "26  0.002738  \n",
       "27  0.003505  \n",
       "28  0.002742  \n",
       "29  0.003168  \n",
       "30  0.002189  \n",
       "31  0.002862  \n",
       "32  0.002794  \n",
       "33  0.002904  \n",
       "34  0.003412  \n",
       "35  0.002631  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1 = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8502173186225344"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs.k_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('h1n1_concern',\n",
       " 'h1n1_knowledge',\n",
       " 'behavioral_antiviral_meds',\n",
       " 'behavioral_avoidance',\n",
       " 'behavioral_face_mask',\n",
       " 'behavioral_wash_hands',\n",
       " 'behavioral_large_gatherings',\n",
       " 'behavioral_outside_home',\n",
       " 'doctor_recc_h1n1',\n",
       " 'doctor_recc_seasonal',\n",
       " 'health_worker',\n",
       " 'health_insurance',\n",
       " 'opinion_h1n1_vacc_effective',\n",
       " 'opinion_h1n1_risk',\n",
       " 'opinion_h1n1_sick_from_vacc',\n",
       " 'opinion_seas_vacc_effective',\n",
       " 'opinion_seas_risk',\n",
       " 'opinion_seas_sick_from_vacc',\n",
       " 'education',\n",
       " 'race',\n",
       " 'marital_status',\n",
       " 'rent_or_own',\n",
       " 'hhs_geo_region',\n",
       " 'household_adults',\n",
       " 'household_children',\n",
       " 'employment_industry',\n",
       " 'employment_occupation')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 1500x600 with 1 Axes>,\n",
       " <Axes: xlabel='Number of Features', ylabel='Performance'>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "plot_sfs(sfs.get_metric_dict(), kind='std_err', figsize=(15,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_cv(classifier, data, truth):\n",
    "    classifier.fit(data, truth)\n",
    "    predicted = classifier.predict(data)\n",
    "\n",
    "    # We use cross_validate to perform K-fold cross validation for us.\n",
    "    cv_results = cross_validate(classifier, data, truth, cv=5, scoring=\"f1_macro\")\n",
    "    f1_score = np.mean(cv_results['test_score'])\n",
    "    display(f\"results f1: {f1_score}\")\n",
    "\n",
    "    print(classification_report(truth, predicted))\n",
    "    print(f\"auc: {roc_auc_score(truth, predicted)}\")\n",
    "\n",
    "    confusion_matrix = metrics.confusion_matrix(truth, predicted)\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1])\n",
    "    cm_display.plot()\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.iloc[:,list(sfs.k_feature_idx_)]\n",
    "x_test = x_test.iloc[:,list(sfs.k_feature_idx_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>doctor_recc_h1n1</th>\n",
       "      <th>doctor_recc_seasonal</th>\n",
       "      <th>...</th>\n",
       "      <th>opinion_seas_sick_from_vacc</th>\n",
       "      <th>education</th>\n",
       "      <th>race</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>employment_industry</th>\n",
       "      <th>employment_occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16270</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364841</td>\n",
       "      <td>0.190783</td>\n",
       "      <td>0.211317</td>\n",
       "      <td>0.181250</td>\n",
       "      <td>0.192875</td>\n",
       "      <td>0.191116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209662</td>\n",
       "      <td>0.210373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17234</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000654</td>\n",
       "      <td>0.237200</td>\n",
       "      <td>0.218508</td>\n",
       "      <td>0.191351</td>\n",
       "      <td>0.223421</td>\n",
       "      <td>0.213557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183499</td>\n",
       "      <td>0.206045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9625</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.352926</td>\n",
       "      <td>0.237200</td>\n",
       "      <td>0.211317</td>\n",
       "      <td>0.234283</td>\n",
       "      <td>0.185397</td>\n",
       "      <td>0.204482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209662</td>\n",
       "      <td>0.210373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10408</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000654</td>\n",
       "      <td>0.237200</td>\n",
       "      <td>0.218508</td>\n",
       "      <td>0.191351</td>\n",
       "      <td>0.185397</td>\n",
       "      <td>0.223350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.163376</td>\n",
       "      <td>0.168261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17233</td>\n",
       "      <td>0.241367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363238</td>\n",
       "      <td>0.190783</td>\n",
       "      <td>0.218508</td>\n",
       "      <td>0.181250</td>\n",
       "      <td>0.192875</td>\n",
       "      <td>0.240960</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.209662</td>\n",
       "      <td>0.210373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363238</td>\n",
       "      <td>0.190441</td>\n",
       "      <td>0.211317</td>\n",
       "      <td>0.234283</td>\n",
       "      <td>0.223421</td>\n",
       "      <td>0.191116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.209662</td>\n",
       "      <td>0.210373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000654</td>\n",
       "      <td>0.190783</td>\n",
       "      <td>0.160954</td>\n",
       "      <td>0.181250</td>\n",
       "      <td>0.192875</td>\n",
       "      <td>0.191116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209662</td>\n",
       "      <td>0.210373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.581371</td>\n",
       "      <td>0.211880</td>\n",
       "      <td>0.218508</td>\n",
       "      <td>0.234283</td>\n",
       "      <td>0.223421</td>\n",
       "      <td>0.191116</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.209662</td>\n",
       "      <td>0.210373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000654</td>\n",
       "      <td>0.190441</td>\n",
       "      <td>0.218508</td>\n",
       "      <td>0.191351</td>\n",
       "      <td>0.223421</td>\n",
       "      <td>0.221695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209662</td>\n",
       "      <td>0.210373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363238</td>\n",
       "      <td>0.173457</td>\n",
       "      <td>0.218508</td>\n",
       "      <td>0.191351</td>\n",
       "      <td>0.192875</td>\n",
       "      <td>0.205361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209662</td>\n",
       "      <td>0.210373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14955 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
       "16270           2.0             0.0                        0.0   \n",
       "17234           1.0             1.0                        0.0   \n",
       "9625            2.0             2.0                        0.0   \n",
       "10408           0.0             1.0                        0.0   \n",
       "2299            2.0             1.0                        0.0   \n",
       "...             ...             ...                        ...   \n",
       "11284           3.0             1.0                        0.0   \n",
       "11964           1.0             1.0                        0.0   \n",
       "5390            1.0             2.0                        0.0   \n",
       "860             2.0             2.0                        0.0   \n",
       "15795           3.0             0.0                        0.0   \n",
       "\n",
       "       behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n",
       "16270                   0.0                   0.0                    1.0   \n",
       "17234                   0.0                   0.0                    1.0   \n",
       "9625                    1.0                   0.0                    1.0   \n",
       "10408                   0.0                   0.0                    1.0   \n",
       "2299                    1.0                   0.0                    1.0   \n",
       "...                     ...                   ...                    ...   \n",
       "11284                   1.0                   0.0                    1.0   \n",
       "11964                   0.0                   0.0                    0.0   \n",
       "5390                    1.0                   0.0                    1.0   \n",
       "860                     1.0                   0.0                    1.0   \n",
       "15795                   0.0                   1.0                    1.0   \n",
       "\n",
       "       behavioral_large_gatherings  behavioral_outside_home  doctor_recc_h1n1  \\\n",
       "16270                          1.0                      1.0           0.00000   \n",
       "17234                          0.0                      0.0           0.00000   \n",
       "9625                           0.0                      0.0           1.00000   \n",
       "10408                          0.0                      0.0           0.00000   \n",
       "2299                           0.0                      0.0           0.17233   \n",
       "...                            ...                      ...               ...   \n",
       "11284                          0.0                      1.0           0.00000   \n",
       "11964                          0.0                      0.0           0.00000   \n",
       "5390                           0.0                      0.0           0.00000   \n",
       "860                            1.0                      1.0           0.00000   \n",
       "15795                          0.0                      0.0           0.00000   \n",
       "\n",
       "       doctor_recc_seasonal  ...  opinion_seas_sick_from_vacc  education  \\\n",
       "16270              0.000000  ...                     0.364841   0.190783   \n",
       "17234              0.000000  ...                    -1.000654   0.237200   \n",
       "9625               1.000000  ...                     1.352926   0.237200   \n",
       "10408              0.000000  ...                    -1.000654   0.237200   \n",
       "2299               0.241367  ...                     0.363238   0.190783   \n",
       "...                     ...  ...                          ...        ...   \n",
       "11284              0.000000  ...                     0.363238   0.190441   \n",
       "11964              0.000000  ...                    -1.000654   0.190783   \n",
       "5390               1.000000  ...                     1.581371   0.211880   \n",
       "860                1.000000  ...                    -1.000654   0.190441   \n",
       "15795              0.000000  ...                     0.363238   0.173457   \n",
       "\n",
       "           race  marital_status  rent_or_own  hhs_geo_region  \\\n",
       "16270  0.211317        0.181250     0.192875        0.191116   \n",
       "17234  0.218508        0.191351     0.223421        0.213557   \n",
       "9625   0.211317        0.234283     0.185397        0.204482   \n",
       "10408  0.218508        0.191351     0.185397        0.223350   \n",
       "2299   0.218508        0.181250     0.192875        0.240960   \n",
       "...         ...             ...          ...             ...   \n",
       "11284  0.211317        0.234283     0.223421        0.191116   \n",
       "11964  0.160954        0.181250     0.192875        0.191116   \n",
       "5390   0.218508        0.234283     0.223421        0.191116   \n",
       "860    0.218508        0.191351     0.223421        0.221695   \n",
       "15795  0.218508        0.191351     0.192875        0.205361   \n",
       "\n",
       "       household_adults  household_children  employment_industry  \\\n",
       "16270               1.0                 0.0             0.209662   \n",
       "17234               0.0                 0.0             0.183499   \n",
       "9625                1.0                 0.0             0.209662   \n",
       "10408               0.0                 0.0             0.163376   \n",
       "2299                1.0                 2.0             0.209662   \n",
       "...                 ...                 ...                  ...   \n",
       "11284               1.0                 3.0             0.209662   \n",
       "11964               0.0                 0.0             0.209662   \n",
       "5390                2.0                 1.0             0.209662   \n",
       "860                 0.0                 0.0             0.209662   \n",
       "15795               0.0                 0.0             0.209662   \n",
       "\n",
       "       employment_occupation  \n",
       "16270               0.210373  \n",
       "17234               0.206045  \n",
       "9625                0.210373  \n",
       "10408               0.168261  \n",
       "2299                0.210373  \n",
       "...                      ...  \n",
       "11284               0.210373  \n",
       "11964               0.210373  \n",
       "5390                0.210373  \n",
       "860                 0.210373  \n",
       "15795               0.210373  \n",
       "\n",
       "[14955 rows x 27 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train,y_train)\n",
    "rf.score(x_test,y_test)\n",
    "rf.score(x_train,y_train)\n",
    "y_pred = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------RandomForest Classifier---------------------------------\n",
      "For Y variable\n",
      "---------------------------------------------------------------------\n",
      "the Accuracy score for H1N1 vaccine : 0.8500780031201248\n",
      "---------------------------------------------------------------------\n",
      "the classification report for H1N1 vaccine :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      5024\n",
      "           1       0.73      0.48      0.58      1386\n",
      "\n",
      "    accuracy                           0.85      6410\n",
      "   macro avg       0.80      0.72      0.74      6410\n",
      "weighted avg       0.84      0.85      0.84      6410\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "the confusion matrix for H1N1 vaccine : [[4784  240]\n",
      " [ 721  665]]\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"------------------RandomForest Classifier---------------------------------\")\n",
    "print(\"For Y variable\")\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(f'the Accuracy score for H1N1 vaccine : {accuracy_score(y_test,y_pred)}')\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(f'the classification report for H1N1 vaccine : {classification_report(y_test,y_pred)}')\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(f'the confusion matrix for H1N1 vaccine : {confusion_matrix(y_test,y_pred)}')\n",
    "print(\"---------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xg = XGBClassifier()\n",
    "xg.fit(x_train,y_train)\n",
    "xg.score(x_train,y_train)\n",
    "xg.score(x_test,y_test)\n",
    "y_pred = xg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------XGB Classifier---------------------------------\n",
      "For Y variable\n",
      "---------------------------------------------------------------------\n",
      "the Accuracy score for H1N1 vaccine : 0.8472698907956319\n",
      "---------------------------------------------------------------------\n",
      "the classification report for H1N1 vaccine :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      5024\n",
      "           1       0.70      0.52      0.60      1386\n",
      "\n",
      "    accuracy                           0.85      6410\n",
      "   macro avg       0.79      0.73      0.75      6410\n",
      "weighted avg       0.84      0.85      0.84      6410\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "the confusion matrix for H1N1 vaccine : [[4711  313]\n",
      " [ 666  720]]\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------XGB Classifier---------------------------------\")\n",
    "print(\"For Y variable\")\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(f'the Accuracy score for H1N1 vaccine : {accuracy_score(y_test,y_pred)}')\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(f'the classification report for H1N1 vaccine : {classification_report(y_test,y_pred)}')\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(f'the confusion matrix for H1N1 vaccine : {confusion_matrix(y_test,y_pred)}')\n",
    "print(\"---------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-29 20:00:33,301] A new study created in memory with name: no-name-e41e915f-e45a-49a2-86e9-6c5e9d2bc7bf\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:34,074] Trial 0 finished with value: 0.844177596111478 and parameters: {'n_estimators': 900, 'learning_rate': 0.2268970688293367, 'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.8799490561528163, 'colsample_bytree': 0.5430722444645497, 'gamma': 0.30799715429092, 'reg_alpha': 0.0033881039119612044, 'reg_lambda': 0.0009580222220017596}. Best is trial 0 with value: 0.844177596111478.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:34,674] Trial 1 finished with value: 0.8461266156940538 and parameters: {'n_estimators': 1000, 'learning_rate': 0.1123079592531485, 'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.7353082418797627, 'colsample_bytree': 0.8922017622600307, 'gamma': 0.47743111686293865, 'reg_alpha': 0.08846999248839588, 'reg_lambda': 2.4959707478828257e-07}. Best is trial 1 with value: 0.8461266156940538.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:35,004] Trial 2 finished with value: 0.8486561531276378 and parameters: {'n_estimators': 600, 'learning_rate': 0.28744214697901666, 'max_depth': 6, 'min_child_weight': 9, 'subsample': 0.8030394640627406, 'colsample_bytree': 0.7226851624258538, 'gamma': 0.48145016654679557, 'reg_alpha': 0.014443916985601237, 'reg_lambda': 0.22915506551388923}. Best is trial 2 with value: 0.8486561531276378.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:35,343] Trial 3 finished with value: 0.8412009678705834 and parameters: {'n_estimators': 300, 'learning_rate': 0.21927757219125812, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.7289602552169347, 'colsample_bytree': 0.979593137503102, 'gamma': 0.36669031316860334, 'reg_alpha': 0.007595190853519722, 'reg_lambda': 4.1025143291544314e-08}. Best is trial 2 with value: 0.8486561531276378.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:35,719] Trial 4 finished with value: 0.8455748501070526 and parameters: {'n_estimators': 700, 'learning_rate': 0.24933534096271362, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.5014356283394057, 'colsample_bytree': 0.7105265050941588, 'gamma': 0.13319846315759198, 'reg_alpha': 6.161949220891752e-06, 'reg_lambda': 3.4624799836556037}. Best is trial 2 with value: 0.8486561531276378.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:36,706] Trial 5 finished with value: 0.8450078161233151 and parameters: {'n_estimators': 600, 'learning_rate': 0.1788562481667654, 'max_depth': 2, 'min_child_weight': 9, 'subsample': 0.7928240430107556, 'colsample_bytree': 0.8131206471324854, 'gamma': 0.3661774992952898, 'reg_alpha': 8.881432371812031e-08, 'reg_lambda': 8.653337525864347e-05}. Best is trial 2 with value: 0.8486561531276378.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:37,199] Trial 6 finished with value: 0.8467516144441447 and parameters: {'n_estimators': 300, 'learning_rate': 0.13035826681461332, 'max_depth': 9, 'min_child_weight': 10, 'subsample': 0.6938921131651805, 'colsample_bytree': 0.9097996825256516, 'gamma': 0.4300771391892971, 'reg_alpha': 0.0019182390537394519, 'reg_lambda': 0.005073365160879506}. Best is trial 2 with value: 0.8486561531276378.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:37,577] Trial 7 finished with value: 0.8436202675145756 and parameters: {'n_estimators': 500, 'learning_rate': 0.25889352965248347, 'max_depth': 8, 'min_child_weight': 7, 'subsample': 0.6717758213174008, 'colsample_bytree': 0.7562957749729979, 'gamma': 0.27552706307349195, 'reg_alpha': 2.514980190271103e-07, 'reg_lambda': 8.108740012656656e-06}. Best is trial 2 with value: 0.8486561531276378.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:37,922] Trial 8 finished with value: 0.8469309296525729 and parameters: {'n_estimators': 1000, 'learning_rate': 0.2440149344513049, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.5279028176335177, 'colsample_bytree': 0.7147879917971978, 'gamma': 0.17143957259252995, 'reg_alpha': 4.758177233523851e-08, 'reg_lambda': 1.3655372301620162e-05}. Best is trial 2 with value: 0.8486561531276378.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:38,475] Trial 9 finished with value: 0.8461652817012121 and parameters: {'n_estimators': 600, 'learning_rate': 0.267445718388475, 'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.540137264701246, 'colsample_bytree': 0.9632549141237425, 'gamma': 0.11487664707159823, 'reg_alpha': 0.035296867428266106, 'reg_lambda': 0.01853397890167118}. Best is trial 2 with value: 0.8486561531276378.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:39,439] Trial 10 finished with value: 0.8456344432776407 and parameters: {'n_estimators': 200, 'learning_rate': 0.058178803041135985, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.9879988716736067, 'colsample_bytree': 0.5780877415013725, 'gamma': 0.009439339513234613, 'reg_alpha': 7.500531970380306, 'reg_lambda': 5.491872985731324}. Best is trial 2 with value: 0.8486561531276378.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:39,812] Trial 11 finished with value: 0.8371352276952749 and parameters: {'n_estimators': 800, 'learning_rate': 0.2921669799570573, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.6310958692454958, 'colsample_bytree': 0.6521482902518707, 'gamma': 0.1823810266054907, 'reg_alpha': 2.652892422613314e-05, 'reg_lambda': 0.07697467952352888}. Best is trial 2 with value: 0.8486561531276378.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:40,286] Trial 12 finished with value: 0.8449889048351785 and parameters: {'n_estimators': 1000, 'learning_rate': 0.19261876945645215, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.8315310361912066, 'colsample_bytree': 0.6544481902135157, 'gamma': 0.23143420379654142, 'reg_alpha': 4.0790765588939996e-05, 'reg_lambda': 5.825079185105185e-06}. Best is trial 2 with value: 0.8486561531276378.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:42,225] Trial 13 finished with value: 0.8461320663876677 and parameters: {'n_estimators': 400, 'learning_rate': 0.014234109551944735, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.5899669668451892, 'colsample_bytree': 0.7913910582689441, 'gamma': 0.034107385399228474, 'reg_alpha': 0.9499630021914887, 'reg_lambda': 0.3926757021403866}. Best is trial 2 with value: 0.8486561531276378.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:42,630] Trial 14 finished with value: 0.8421505222206911 and parameters: {'n_estimators': 100, 'learning_rate': 0.29238621042587376, 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.929072838535695, 'colsample_bytree': 0.6803372752889241, 'gamma': 0.19988071488567383, 'reg_alpha': 1.0861454566178672e-08, 'reg_lambda': 0.00010244176172399207}. Best is trial 2 with value: 0.8486561531276378.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:43,055] Trial 15 finished with value: 0.8437926748703449 and parameters: {'n_estimators': 800, 'learning_rate': 0.2051395713674116, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.8270928265970052, 'colsample_bytree': 0.8400660901120514, 'gamma': 0.09991446274323634, 'reg_alpha': 0.00020848234649866306, 'reg_lambda': 1.403618270367471e-06}. Best is trial 2 with value: 0.8486561531276378.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:43,548] Trial 16 finished with value: 0.8457121640790884 and parameters: {'n_estimators': 800, 'learning_rate': 0.14052532905622767, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.622123635480486, 'colsample_bytree': 0.5941330635600878, 'gamma': 0.4909087615045392, 'reg_alpha': 3.6491862002780167e-07, 'reg_lambda': 0.000853926690397699}. Best is trial 2 with value: 0.8486561531276378.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:44,017] Trial 17 finished with value: 0.8481741319022561 and parameters: {'n_estimators': 500, 'learning_rate': 0.1686823764065381, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.7857685270182211, 'colsample_bytree': 0.7408994359514456, 'gamma': 0.32675813731128917, 'reg_alpha': 2.0153176131991902e-06, 'reg_lambda': 2.418338684523151e-05}. Best is trial 2 with value: 0.8486561531276378.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:44,584] Trial 18 finished with value: 0.8456559447094633 and parameters: {'n_estimators': 500, 'learning_rate': 0.09181821609087265, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.795881965238012, 'colsample_bytree': 0.7480719177979276, 'gamma': 0.4050480108355517, 'reg_alpha': 4.753637881374098e-06, 'reg_lambda': 0.31225433437852135}. Best is trial 2 with value: 0.8486561531276378.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:45,026] Trial 19 finished with value: 0.8449300267722144 and parameters: {'n_estimators': 400, 'learning_rate': 0.167519918552494, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.9163826762798256, 'colsample_bytree': 0.8669463589163899, 'gamma': 0.31611393427747125, 'reg_alpha': 0.0001900793234227242, 'reg_lambda': 0.004998310539415205}. Best is trial 2 with value: 0.8486561531276378.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:45,770] Trial 20 finished with value: 0.8477564471385818 and parameters: {'n_estimators': 700, 'learning_rate': 0.06700661028080603, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.7709574892190965, 'colsample_bytree': 0.6219655547184167, 'gamma': 0.4398646819773332, 'reg_alpha': 0.3546988793171281, 'reg_lambda': 5.658418721303061e-07}. Best is trial 2 with value: 0.8486561531276378.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:46,685] Trial 21 finished with value: 0.8482204231562704 and parameters: {'n_estimators': 700, 'learning_rate': 0.06471710731322516, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.7693671783215681, 'colsample_bytree': 0.6338206085782867, 'gamma': 0.43231474880891196, 'reg_alpha': 0.28747954200463705, 'reg_lambda': 2.1478405369633874e-08}. Best is trial 2 with value: 0.8486561531276378.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:48,592] Trial 22 finished with value: 0.8489092083351555 and parameters: {'n_estimators': 700, 'learning_rate': 0.06462428637635938, 'max_depth': 9, 'min_child_weight': 9, 'subsample': 0.8518410735632522, 'colsample_bytree': 0.7743622855367843, 'gamma': 0.375254512095637, 'reg_alpha': 8.458722932836862, 'reg_lambda': 2.5546760868317333e-08}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:51,193] Trial 23 finished with value: 0.8422809273416069 and parameters: {'n_estimators': 700, 'learning_rate': 0.010586823521614087, 'max_depth': 9, 'min_child_weight': 9, 'subsample': 0.856717342402527, 'colsample_bytree': 0.5095713551288165, 'gamma': 0.3903160740650756, 'reg_alpha': 9.321073215610205, 'reg_lambda': 1.0122653355322441e-08}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:52,144] Trial 24 finished with value: 0.8473246792089758 and parameters: {'n_estimators': 600, 'learning_rate': 0.04853237879151434, 'max_depth': 9, 'min_child_weight': 9, 'subsample': 0.8967064587100166, 'colsample_bytree': 0.7965264035984768, 'gamma': 0.45589277341214063, 'reg_alpha': 1.4609130371603645, 'reg_lambda': 8.761689387801936e-08}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:52,773] Trial 25 finished with value: 0.8457717573759741 and parameters: {'n_estimators': 700, 'learning_rate': 0.09786546989585987, 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.9480866951942981, 'colsample_bytree': 0.6907281341578712, 'gamma': 0.4158361193195013, 'reg_alpha': 0.07684858952885153, 'reg_lambda': 1.785894911553022e-08}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:53,928] Trial 26 finished with value: 0.8466557840466933 and parameters: {'n_estimators': 900, 'learning_rate': 0.0346187176207812, 'max_depth': 8, 'min_child_weight': 10, 'subsample': 0.82819714262019, 'colsample_bytree': 0.6443491914419764, 'gamma': 0.49350350315630737, 'reg_alpha': 0.017235119407502688, 'reg_lambda': 1.3555332742181324e-07}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:54,528] Trial 27 finished with value: 0.8430816436231335 and parameters: {'n_estimators': 600, 'learning_rate': 0.09748771218201203, 'max_depth': 9, 'min_child_weight': 7, 'subsample': 0.7114074567136833, 'colsample_bytree': 0.5975937048352475, 'gamma': 0.3822729678876754, 'reg_alpha': 0.5133308643578088, 'reg_lambda': 1.6642863107918062e-06}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:55,284] Trial 28 finished with value: 0.8476772186443343 and parameters: {'n_estimators': 800, 'learning_rate': 0.07400296570764416, 'max_depth': 10, 'min_child_weight': 9, 'subsample': 0.8585146318855672, 'colsample_bytree': 0.7774231828715167, 'gamma': 0.3515735118115693, 'reg_alpha': 2.4915139924977536, 'reg_lambda': 3.9319708089418545e-08}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:56,547] Trial 29 finished with value: 0.8475978972793592 and parameters: {'n_estimators': 900, 'learning_rate': 0.03422091024083058, 'max_depth': 6, 'min_child_weight': 10, 'subsample': 0.7498279756487183, 'colsample_bytree': 0.8290957130228226, 'gamma': 0.27333001917307015, 'reg_alpha': 0.0028043683220258433, 'reg_lambda': 0.0005675334878083211}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:57,050] Trial 30 finished with value: 0.8472247617890085 and parameters: {'n_estimators': 900, 'learning_rate': 0.122029285418884, 'max_depth': 8, 'min_child_weight': 8, 'subsample': 0.8825158662730063, 'colsample_bytree': 0.5623018061448334, 'gamma': 0.44003376621972223, 'reg_alpha': 0.2113606715727835, 'reg_lambda': 0.9009672138479792}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:57,535] Trial 31 finished with value: 0.8424589943996541 and parameters: {'n_estimators': 500, 'learning_rate': 0.15152999545247925, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.7831613417079166, 'colsample_bytree': 0.7295528312035199, 'gamma': 0.3267143425377866, 'reg_alpha': 0.0004936082901727645, 'reg_lambda': 0.00012849359736030549}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:57,924] Trial 32 finished with value: 0.8461461884580362 and parameters: {'n_estimators': 400, 'learning_rate': 0.23088265920880857, 'max_depth': 9, 'min_child_weight': 9, 'subsample': 0.7582436590177851, 'colsample_bytree': 0.7566191023819737, 'gamma': 0.3436130443199593, 'reg_alpha': 0.12134530682185572, 'reg_lambda': 2.9877074904162197e-07}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:58,623] Trial 33 finished with value: 0.8472461179630368 and parameters: {'n_estimators': 500, 'learning_rate': 0.07931691731928672, 'max_depth': 6, 'min_child_weight': 8, 'subsample': 0.8228235021975849, 'colsample_bytree': 0.6798421588858568, 'gamma': 0.4628009589201442, 'reg_alpha': 0.014851694889638114, 'reg_lambda': 2.500696194789498e-05}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:59,380] Trial 34 finished with value: 0.8453579371031501 and parameters: {'n_estimators': 700, 'learning_rate': 0.20952137360350873, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.7295188013148014, 'colsample_bytree': 0.7314658293166781, 'gamma': 0.29856508798736603, 'reg_alpha': 3.9051029049170496, 'reg_lambda': 0.004190776012084136}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:00:59,940] Trial 35 finished with value: 0.8464600358117266 and parameters: {'n_estimators': 600, 'learning_rate': 0.11713268732249132, 'max_depth': 8, 'min_child_weight': 6, 'subsample': 0.7979143064322086, 'colsample_bytree': 0.7006759382565775, 'gamma': 0.4013364546556113, 'reg_alpha': 0.0011485554967109908, 'reg_lambda': 9.107685076231851e-07}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:00,413] Trial 36 finished with value: 0.8472218733086144 and parameters: {'n_estimators': 300, 'learning_rate': 0.18256843835514514, 'max_depth': 10, 'min_child_weight': 9, 'subsample': 0.8708097740902154, 'colsample_bytree': 0.7753891399361481, 'gamma': 0.4657661839562469, 'reg_alpha': 0.006255704110469452, 'reg_lambda': 3.325084449452415e-06}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:00,867] Trial 37 finished with value: 0.8487248259114546 and parameters: {'n_estimators': 700, 'learning_rate': 0.16264104678914054, 'max_depth': 7, 'min_child_weight': 10, 'subsample': 0.6810152165706947, 'colsample_bytree': 0.8579062048194704, 'gamma': 0.37920079767356285, 'reg_alpha': 3.082024498035799e-06, 'reg_lambda': 5.486617795652275e-08}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:01,922] Trial 38 finished with value: 0.847618780189336 and parameters: {'n_estimators': 700, 'learning_rate': 0.041166493500020246, 'max_depth': 9, 'min_child_weight': 10, 'subsample': 0.647227192641584, 'colsample_bytree': 0.8778054195317291, 'gamma': 0.363278086841948, 'reg_alpha': 0.052003803355575064, 'reg_lambda': 5.976810111438322e-08}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:02,259] Trial 39 finished with value: 0.8469893706730963 and parameters: {'n_estimators': 800, 'learning_rate': 0.27456434304988375, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.6956621913179705, 'colsample_bytree': 0.9210925833045198, 'gamma': 0.4265000548460038, 'reg_alpha': 0.9251142019435339, 'reg_lambda': 2.6210202168737515e-08}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:02,712] Trial 40 finished with value: 0.8474389763418259 and parameters: {'n_estimators': 600, 'learning_rate': 0.13799671947771844, 'max_depth': 8, 'min_child_weight': 9, 'subsample': 0.6644718690968362, 'colsample_bytree': 0.8440172729429273, 'gamma': 0.38407918523804674, 'reg_alpha': 8.084223193172917e-07, 'reg_lambda': 1.9145332162386268e-07}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:03,132] Trial 41 finished with value: 0.8435539228979755 and parameters: {'n_estimators': 700, 'learning_rate': 0.16427031560546188, 'max_depth': 7, 'min_child_weight': 9, 'subsample': 0.7343028026415671, 'colsample_bytree': 0.9395088966362821, 'gamma': 0.2912174238924262, 'reg_alpha': 7.695824650787596e-07, 'reg_lambda': 3.835576175157517e-07}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:03,495] Trial 42 finished with value: 0.8457532536261912 and parameters: {'n_estimators': 500, 'learning_rate': 0.23285670305810727, 'max_depth': 6, 'min_child_weight': 10, 'subsample': 0.7068808933017489, 'colsample_bytree': 0.8106495353576504, 'gamma': 0.3385549616113153, 'reg_alpha': 3.363968534510352e-06, 'reg_lambda': 2.7530642345384554e-05}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:04,055] Trial 43 finished with value: 0.847656083654913 and parameters: {'n_estimators': 600, 'learning_rate': 0.10953185583171238, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.8149131036818194, 'colsample_bytree': 0.7222133779445447, 'gamma': 0.2520586808721055, 'reg_alpha': 8.595282168712079e-05, 'reg_lambda': 1.8794648315549268e-08}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:04,514] Trial 44 finished with value: 0.8440839052932405 and parameters: {'n_estimators': 600, 'learning_rate': 0.1518120555278709, 'max_depth': 6, 'min_child_weight': 10, 'subsample': 0.7556711658054913, 'colsample_bytree': 0.6273230512076831, 'gamma': 0.3772987808255694, 'reg_alpha': 1.3947190358933823e-06, 'reg_lambda': 1.0253459370986712e-07}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:04,982] Trial 45 finished with value: 0.8418833773390413 and parameters: {'n_estimators': 700, 'learning_rate': 0.17241990669976312, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.8530103544867431, 'colsample_bytree': 0.7607152612640533, 'gamma': 0.41714041927923207, 'reg_alpha': 1.8881069161331285e-05, 'reg_lambda': 0.03935075801077319}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:05,425] Trial 46 finished with value: 0.8458485715594024 and parameters: {'n_estimators': 400, 'learning_rate': 0.19082200144439523, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.6817910476121124, 'colsample_bytree': 0.8563305310181535, 'gamma': 0.4557849544428096, 'reg_alpha': 1.2912161796802625e-07, 'reg_lambda': 1.0345144603076142e-08}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:05,808] Trial 47 finished with value: 0.8479451331222444 and parameters: {'n_estimators': 800, 'learning_rate': 0.2455991581785513, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.7748031249297885, 'colsample_bytree': 0.8915356686143179, 'gamma': 0.47964177262692653, 'reg_alpha': 4.094586750092964e-08, 'reg_lambda': 1.5717205848104756}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:06,165] Trial 48 finished with value: 0.8467876766507922 and parameters: {'n_estimators': 500, 'learning_rate': 0.27857433734531956, 'max_depth': 7, 'min_child_weight': 9, 'subsample': 0.5841657507458722, 'colsample_bytree': 0.995543693272579, 'gamma': 0.36489988598401074, 'reg_alpha': 0.0219168373985117, 'reg_lambda': 4.684437426635017e-06}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:06,575] Trial 49 finished with value: 0.844888761930274 and parameters: {'n_estimators': 300, 'learning_rate': 0.21418546280043432, 'max_depth': 6, 'min_child_weight': 8, 'subsample': 0.8024435808828542, 'colsample_bytree': 0.673583409143609, 'gamma': 0.4449763245682587, 'reg_alpha': 3.628595426157358, 'reg_lambda': 0.002334418362483117}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:08,563] Trial 50 finished with value: 0.8482068075233518 and parameters: {'n_estimators': 700, 'learning_rate': 0.02180635079068189, 'max_depth': 10, 'min_child_weight': 10, 'subsample': 0.8456863487320669, 'colsample_bytree': 0.8268870810815586, 'gamma': 0.3240669483740694, 'reg_alpha': 0.0007444860910292312, 'reg_lambda': 0.01548444123891588}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:10,334] Trial 51 finished with value: 0.8482428762881219 and parameters: {'n_estimators': 700, 'learning_rate': 0.02492357454658597, 'max_depth': 10, 'min_child_weight': 10, 'subsample': 0.8450456247825726, 'colsample_bytree': 0.8267700122957757, 'gamma': 0.3344488591908732, 'reg_alpha': 0.001145179655714837, 'reg_lambda': 0.10238008221960353}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:12,049] Trial 52 finished with value: 0.8477768916246072 and parameters: {'n_estimators': 700, 'learning_rate': 0.024853526534513268, 'max_depth': 10, 'min_child_weight': 10, 'subsample': 0.8948582881652398, 'colsample_bytree': 0.818298476957412, 'gamma': 0.2646754691615899, 'reg_alpha': 0.0008181673424389494, 'reg_lambda': 0.08945737274890293}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:13,035] Trial 53 finished with value: 0.8472796851271559 and parameters: {'n_estimators': 800, 'learning_rate': 0.05502055409668179, 'max_depth': 10, 'min_child_weight': 10, 'subsample': 0.8438904139600037, 'colsample_bytree': 0.7965921724527175, 'gamma': 0.30252311284436517, 'reg_alpha': 0.0072050601171755055, 'reg_lambda': 0.024495394444577826}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:14,925] Trial 54 finished with value: 0.8464401354588519 and parameters: {'n_estimators': 700, 'learning_rate': 0.019476810385536864, 'max_depth': 9, 'min_child_weight': 10, 'subsample': 0.9652419267269706, 'colsample_bytree': 0.8922531325161909, 'gamma': 0.23447388185264023, 'reg_alpha': 0.0023583705218302954, 'reg_lambda': 0.1884588385265104}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:15,856] Trial 55 finished with value: 0.8461652817012121 and parameters: {'n_estimators': 900, 'learning_rate': 0.05799835969929575, 'max_depth': 10, 'min_child_weight': 9, 'subsample': 0.9130427534449428, 'colsample_bytree': 0.8496733697983472, 'gamma': 0.39445365679611205, 'reg_alpha': 6.506449484871008e-05, 'reg_lambda': 1.036159606812858}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:17,599] Trial 56 finished with value: 0.8477564471385818 and parameters: {'n_estimators': 800, 'learning_rate': 0.02668544866325489, 'max_depth': 10, 'min_child_weight': 10, 'subsample': 0.8119499825652297, 'colsample_bytree': 0.8271936753867466, 'gamma': 0.34864887913415843, 'reg_alpha': 0.00021081359035721525, 'reg_lambda': 5.003721318863098}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:18,470] Trial 57 finished with value: 0.8437565319902844 and parameters: {'n_estimators': 600, 'learning_rate': 0.08647523985704232, 'max_depth': 9, 'min_child_weight': 9, 'subsample': 0.8437583261031023, 'colsample_bytree': 0.522480624458082, 'gamma': 0.4161477759677442, 'reg_alpha': 1.3286962092288533e-05, 'reg_lambda': 9.421223868293236}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:19,332] Trial 58 finished with value: 0.8477720790135685 and parameters: {'n_estimators': 700, 'learning_rate': 0.06694871612211169, 'max_depth': 9, 'min_child_weight': 10, 'subsample': 0.8774627276719258, 'colsample_bytree': 0.7768325210655129, 'gamma': 0.3156952271637534, 'reg_alpha': 0.0004548221474461169, 'reg_lambda': 0.012167064349679485}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:20,264] Trial 59 finished with value: 0.8467144557997432 and parameters: {'n_estimators': 600, 'learning_rate': 0.049488952019749996, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.6024995234654117, 'colsample_bytree': 0.8013924414083594, 'gamma': 0.4943330014397081, 'reg_alpha': 0.004492600897129019, 'reg_lambda': 0.08986597786016853}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:21,505] Trial 60 finished with value: 0.8478075358541174 and parameters: {'n_estimators': 800, 'learning_rate': 0.03956670096448073, 'max_depth': 9, 'min_child_weight': 10, 'subsample': 0.7610333735278874, 'colsample_bytree': 0.8674387887710667, 'gamma': 0.28794509828398807, 'reg_alpha': 0.0013203674087296589, 'reg_lambda': 0.21731850335774167}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:24,928] Trial 61 finished with value: 0.8484026257294051 and parameters: {'n_estimators': 700, 'learning_rate': 0.011051290901155565, 'max_depth': 10, 'min_child_weight': 9, 'subsample': 0.7918916124288482, 'colsample_bytree': 0.7076124407941099, 'gamma': 0.3205624542980829, 'reg_alpha': 0.2612702060815929, 'reg_lambda': 0.000210382068723398}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:28,436] Trial 62 finished with value: 0.8474019829949458 and parameters: {'n_estimators': 700, 'learning_rate': 0.010953695043737296, 'max_depth': 10, 'min_child_weight': 9, 'subsample': 0.7912206318760646, 'colsample_bytree': 0.7134834231227358, 'gamma': 0.32794166289004323, 'reg_alpha': 0.15482980680834135, 'reg_lambda': 0.0002876303722561119}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:30,016] Trial 63 finished with value: 0.8463394966588745 and parameters: {'n_estimators': 800, 'learning_rate': 0.02938276291282129, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.8431975726802116, 'colsample_bytree': 0.6641121805917812, 'gamma': 0.36651664841696324, 'reg_alpha': 0.3538331846507511, 'reg_lambda': 0.009533489135446055}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:31,094] Trial 64 finished with value: 0.8471870416801405 and parameters: {'n_estimators': 700, 'learning_rate': 0.04604805904915585, 'max_depth': 10, 'min_child_weight': 9, 'subsample': 0.7461257284942229, 'colsample_bytree': 0.7411029056817511, 'gamma': 0.06752875871571468, 'reg_alpha': 0.02798181210815824, 'reg_lambda': 0.035074577356515375}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:33,267] Trial 65 finished with value: 0.8482863868478715 and parameters: {'n_estimators': 600, 'learning_rate': 0.01934442583559544, 'max_depth': 9, 'min_child_weight': 10, 'subsample': 0.8120723629019881, 'colsample_bytree': 0.6956490265229833, 'gamma': 0.4320001765646575, 'reg_alpha': 0.009796901163550609, 'reg_lambda': 0.6624558942913062}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:33,967] Trial 66 finished with value: 0.8442807468966601 and parameters: {'n_estimators': 600, 'learning_rate': 0.07034096170333005, 'max_depth': 9, 'min_child_weight': 8, 'subsample': 0.8169049396831238, 'colsample_bytree': 0.6964820587357394, 'gamma': 0.4746002288634568, 'reg_alpha': 0.010449100186999988, 'reg_lambda': 4.100815154864486e-08}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:34,393] Trial 67 finished with value: 0.8477937162824172 and parameters: {'n_estimators': 600, 'learning_rate': 0.2555151887571715, 'max_depth': 9, 'min_child_weight': 9, 'subsample': 0.7755470514508889, 'colsample_bytree': 0.6278937158332678, 'gamma': 0.40619353300257943, 'reg_alpha': 0.07037030692218778, 'reg_lambda': 2.143364330087851}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:35,017] Trial 68 finished with value: 0.8472262832790103 and parameters: {'n_estimators': 700, 'learning_rate': 0.1077729024224043, 'max_depth': 8, 'min_child_weight': 9, 'subsample': 0.7164198433601192, 'colsample_bytree': 0.6058286894125773, 'gamma': 0.43283450675967, 'reg_alpha': 0.9876184843288067, 'reg_lambda': 0.7264119403520956}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:37,102] Trial 69 finished with value: 0.8451376554286264 and parameters: {'n_estimators': 600, 'learning_rate': 0.01678115695217801, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.8029322738752314, 'colsample_bytree': 0.7026324203555366, 'gamma': 0.4502207343524899, 'reg_alpha': 6.065929876766027, 'reg_lambda': 0.6199538688270704}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:37,748] Trial 70 finished with value: 0.8437220814421994 and parameters: {'n_estimators': 800, 'learning_rate': 0.08163033401238126, 'max_depth': 8, 'min_child_weight': 8, 'subsample': 0.8349104811475234, 'colsample_bytree': 0.6500173949626059, 'gamma': 0.4278155839381298, 'reg_alpha': 0.4026189344053057, 'reg_lambda': 0.0014034266879917419}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:39,908] Trial 71 finished with value: 0.8454375683345353 and parameters: {'n_estimators': 700, 'learning_rate': 0.018996167192284513, 'max_depth': 10, 'min_child_weight': 10, 'subsample': 0.8740171076606984, 'colsample_bytree': 0.7654556433856654, 'gamma': 0.357245547981285, 'reg_alpha': 0.003746252498671768, 'reg_lambda': 0.13455342822504002}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:40,338] Trial 72 finished with value: 0.8433644206416084 and parameters: {'n_estimators': 700, 'learning_rate': 0.2996286765522209, 'max_depth': 10, 'min_child_weight': 10, 'subsample': 0.856989257800861, 'colsample_bytree': 0.7848157013183539, 'gamma': 0.3824180360647542, 'reg_alpha': 0.000817870237944109, 'reg_lambda': 0.5130682866138967}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:41,787] Trial 73 finished with value: 0.8482204231562704 and parameters: {'n_estimators': 700, 'learning_rate': 0.03760540470472506, 'max_depth': 9, 'min_child_weight': 9, 'subsample': 0.8297886965694932, 'colsample_bytree': 0.8318506603191377, 'gamma': 0.3330502920523205, 'reg_alpha': 1.7269307162608694, 'reg_lambda': 2.3602848069790263}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:43,505] Trial 74 finished with value: 0.8478731961113153 and parameters: {'n_estimators': 600, 'learning_rate': 0.03199964002120405, 'max_depth': 9, 'min_child_weight': 9, 'subsample': 0.8255827196719491, 'colsample_bytree': 0.6860596080278689, 'gamma': 0.3387331958428908, 'reg_alpha': 1.9425870490838668, 'reg_lambda': 2.3493522336323256}. Best is trial 22 with value: 0.8489092083351555.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:44,409] Trial 75 finished with value: 0.8492877968356741 and parameters: {'n_estimators': 500, 'learning_rate': 0.05853677397055986, 'max_depth': 9, 'min_child_weight': 9, 'subsample': 0.7864773290198578, 'colsample_bytree': 0.7497746343514877, 'gamma': 0.3115464001764693, 'reg_alpha': 0.04368002699194678, 'reg_lambda': 4.402476744615238}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:45,505] Trial 76 finished with value: 0.8479346296395269 and parameters: {'n_estimators': 500, 'learning_rate': 0.046629071852899134, 'max_depth': 9, 'min_child_weight': 9, 'subsample': 0.7852065677830457, 'colsample_bytree': 0.7327356758873126, 'gamma': 0.4799487807638092, 'reg_alpha': 0.0456676183839731, 'reg_lambda': 7.818490606247249}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:46,347] Trial 77 finished with value: 0.8457121640790884 and parameters: {'n_estimators': 400, 'learning_rate': 0.06091113159403159, 'max_depth': 8, 'min_child_weight': 7, 'subsample': 0.7674589909872467, 'colsample_bytree': 0.7493839315620289, 'gamma': 0.40709395520880715, 'reg_alpha': 0.24503154885348857, 'reg_lambda': 0.34640338770956847}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:46,982] Trial 78 finished with value: 0.8450259155591496 and parameters: {'n_estimators': 500, 'learning_rate': 0.09342689396778135, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.7472519276585281, 'colsample_bytree': 0.7170567014367498, 'gamma': 0.3775141047330573, 'reg_alpha': 0.014976919667627459, 'reg_lambda': 7.045880788984941e-08}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:48,324] Trial 79 finished with value: 0.8481511929446098 and parameters: {'n_estimators': 600, 'learning_rate': 0.06301867238803346, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.7225864273760256, 'colsample_bytree': 0.5766324783518078, 'gamma': 0.31442273125736514, 'reg_alpha': 0.1051467811177094, 'reg_lambda': 1.4110742301268542e-07}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:49,043] Trial 80 finished with value: 0.8451033792930965 and parameters: {'n_estimators': 600, 'learning_rate': 0.07721094185228092, 'max_depth': 9, 'min_child_weight': 9, 'subsample': 0.8039947690655299, 'colsample_bytree': 0.6666967171647091, 'gamma': 0.39533932540547706, 'reg_alpha': 0.8133192399585869, 'reg_lambda': 2.5566101533378256e-08}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:50,768] Trial 81 finished with value: 0.8475395846992785 and parameters: {'n_estimators': 700, 'learning_rate': 0.03827822211601706, 'max_depth': 9, 'min_child_weight': 9, 'subsample': 0.782523194610359, 'colsample_bytree': 0.7665059938690558, 'gamma': 0.2779677032054747, 'reg_alpha': 4.441736420487597, 'reg_lambda': 3.60437719983808}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:51,362] Trial 82 finished with value: 0.8452615749137414 and parameters: {'n_estimators': 100, 'learning_rate': 0.05160924491760337, 'max_depth': 9, 'min_child_weight': 9, 'subsample': 0.8326375510057565, 'colsample_bytree': 0.8079581083636496, 'gamma': 0.2094905757385699, 'reg_alpha': 1.5250060927525204, 'reg_lambda': 1.4257359839494101}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:55,004] Trial 83 finished with value: 0.8473246792089758 and parameters: {'n_estimators': 700, 'learning_rate': 0.010451660624715281, 'max_depth': 9, 'min_child_weight': 8, 'subsample': 0.865409430144524, 'colsample_bytree': 0.8380294645226194, 'gamma': 0.15741405153078322, 'reg_alpha': 0.6125838162127871, 'reg_lambda': 2.7894541690754653}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:56,912] Trial 84 finished with value: 0.8465776108206431 and parameters: {'n_estimators': 800, 'learning_rate': 0.03239920768232087, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.887410154207267, 'colsample_bytree': 0.6386087224686705, 'gamma': 0.352622356031342, 'reg_alpha': 0.036783857605923745, 'reg_lambda': 5.559991833190418}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:01:58,468] Trial 85 finished with value: 0.8467144557997432 and parameters: {'n_estimators': 700, 'learning_rate': 0.042196602315894984, 'max_depth': 6, 'min_child_weight': 10, 'subsample': 0.8067414370907015, 'colsample_bytree': 0.8636595164110807, 'gamma': 0.33951622596894526, 'reg_alpha': 2.8726910020213023, 'reg_lambda': 4.4471156260121794e-05}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:02:00,323] Trial 86 finished with value: 0.8491849478100896 and parameters: {'n_estimators': 500, 'learning_rate': 0.02324045187366966, 'max_depth': 10, 'min_child_weight': 9, 'subsample': 0.7379250650555584, 'colsample_bytree': 0.7306789812570308, 'gamma': 0.3719203837635027, 'reg_alpha': 0.19213101352591128, 'reg_lambda': 1.3940573729969535e-08}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:02:02,336] Trial 87 finished with value: 0.8480108939594617 and parameters: {'n_estimators': 500, 'learning_rate': 0.02551466070547759, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.741283120239035, 'colsample_bytree': 0.7288866895354955, 'gamma': 0.3046291683950334, 'reg_alpha': 0.08457526314680715, 'reg_lambda': 1.681501137374066e-08}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:02:02,802] Trial 88 finished with value: 0.8427924145173269 and parameters: {'n_estimators': 500, 'learning_rate': 0.20295506169380087, 'max_depth': 10, 'min_child_weight': 10, 'subsample': 0.7005867086652354, 'colsample_bytree': 0.7461286361200089, 'gamma': 0.4657613422797705, 'reg_alpha': 0.010166252630392237, 'reg_lambda': 5.479831030125275e-07}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:02:03,414] Trial 89 finished with value: 0.848082762201416 and parameters: {'n_estimators': 400, 'learning_rate': 0.1297554321158013, 'max_depth': 7, 'min_child_weight': 10, 'subsample': 0.6846645104913278, 'colsample_bytree': 0.7103079104591586, 'gamma': 0.37252505765531496, 'reg_alpha': 0.19603816939760751, 'reg_lambda': 1.152449120352098e-08}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:02:04,149] Trial 90 finished with value: 0.844845750765576 and parameters: {'n_estimators': 500, 'learning_rate': 0.10356925235896171, 'max_depth': 10, 'min_child_weight': 9, 'subsample': 0.7677764629309426, 'colsample_bytree': 0.6900177493016709, 'gamma': 0.43581340116498946, 'reg_alpha': 0.0247351166871077, 'reg_lambda': 1.0680621808800175e-05}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:02:05,226] Trial 91 finished with value: 0.8466922695768136 and parameters: {'n_estimators': 600, 'learning_rate': 0.03603190530016353, 'max_depth': 10, 'min_child_weight': 9, 'subsample': 0.6404865783782954, 'colsample_bytree': 0.7917217895912823, 'gamma': 0.3599674584992759, 'reg_alpha': 0.05577017951091497, 'reg_lambda': 5.3608897789544825e-08}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:02:07,788] Trial 92 finished with value: 0.8449561378100106 and parameters: {'n_estimators': 600, 'learning_rate': 0.016969067991367215, 'max_depth': 9, 'min_child_weight': 9, 'subsample': 0.8211026767674984, 'colsample_bytree': 0.8816689930747458, 'gamma': 0.3286775537615324, 'reg_alpha': 8.457261164245436, 'reg_lambda': 2.695960445582362e-08}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:02:09,548] Trial 93 finished with value: 0.8480108939594617 and parameters: {'n_estimators': 700, 'learning_rate': 0.026642171983093516, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.7918110976538677, 'colsample_bytree': 0.75595678870061, 'gamma': 0.3862401969525913, 'reg_alpha': 0.24792934420118062, 'reg_lambda': 1.1124560044057603}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:02:10,334] Trial 94 finished with value: 0.846479927745546 and parameters: {'n_estimators': 600, 'learning_rate': 0.05728766577117354, 'max_depth': 8, 'min_child_weight': 9, 'subsample': 0.7790112831035104, 'colsample_bytree': 0.8158340657641471, 'gamma': 0.4171069674751363, 'reg_alpha': 0.11537663870267278, 'reg_lambda': 0.2321557974526566}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:02:10,741] Trial 95 finished with value: 0.8454552750660389 and parameters: {'n_estimators': 800, 'learning_rate': 0.22377417876098477, 'max_depth': 9, 'min_child_weight': 10, 'subsample': 0.7602420511193512, 'colsample_bytree': 0.705806707303432, 'gamma': 0.3443313355001809, 'reg_alpha': 0.0019717118491404595, 'reg_lambda': 0.058321521394597}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:02:11,950] Trial 96 finished with value: 0.8466353615917679 and parameters: {'n_estimators': 500, 'learning_rate': 0.04336296194764751, 'max_depth': 10, 'min_child_weight': 9, 'subsample': 0.8161502677730077, 'colsample_bytree': 0.7225966150391193, 'gamma': 0.2970204430777173, 'reg_alpha': 1.2080127828021232, 'reg_lambda': 2.069447855650046e-07}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:02:12,705] Trial 97 finished with value: 0.8487138324632248 and parameters: {'n_estimators': 700, 'learning_rate': 0.0712319264706562, 'max_depth': 9, 'min_child_weight': 8, 'subsample': 0.5105967087065494, 'colsample_bytree': 0.737372651435642, 'gamma': 0.2634576367596715, 'reg_alpha': 0.005338943879658039, 'reg_lambda': 1.6424156832253925e-06}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:02:13,479] Trial 98 finished with value: 0.8472262832790103 and parameters: {'n_estimators': 600, 'learning_rate': 0.06769922766667746, 'max_depth': 7, 'min_child_weight': 7, 'subsample': 0.587632523057786, 'colsample_bytree': 0.7361877224042307, 'gamma': 0.25370655556284044, 'reg_alpha': 0.004222422418995624, 'reg_lambda': 1.3550418933130233e-06}. Best is trial 75 with value: 0.8492877968356741.\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2289967975.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2024-05-29 20:02:14,236] Trial 99 finished with value: 0.8482778571197889 and parameters: {'n_estimators': 700, 'learning_rate': 0.08159288344696955, 'max_depth': 9, 'min_child_weight': 8, 'subsample': 0.5463863373943646, 'colsample_bytree': 0.7698198215726149, 'gamma': 0.23188977714335499, 'reg_alpha': 0.00616131132065059, 'reg_lambda': 0.00032462144589062405}. Best is trial 75 with value: 0.8492877968356741.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'n_estimators': 500, 'learning_rate': 0.05853677397055986, 'max_depth': 9, 'min_child_weight': 9, 'subsample': 0.7864773290198578, 'colsample_bytree': 0.7497746343514877, 'gamma': 0.3115464001764693, 'reg_alpha': 0.04368002699194678, 'reg_lambda': 4.402476744615238}\n",
      "Best F1 Score:  0.8492877968356741\n",
      "[0]\tvalidation_0-logloss:0.51050\n",
      "[1]\tvalidation_0-logloss:0.49794\n",
      "[2]\tvalidation_0-logloss:0.48691\n",
      "[3]\tvalidation_0-logloss:0.47483\n",
      "[4]\tvalidation_0-logloss:0.46640\n",
      "[5]\tvalidation_0-logloss:0.45714\n",
      "[6]\tvalidation_0-logloss:0.44823\n",
      "[7]\tvalidation_0-logloss:0.44032\n",
      "[8]\tvalidation_0-logloss:0.43419\n",
      "[9]\tvalidation_0-logloss:0.42869\n",
      "[10]\tvalidation_0-logloss:0.42507\n",
      "[11]\tvalidation_0-logloss:0.41911\n",
      "[12]\tvalidation_0-logloss:0.41405\n",
      "[13]\tvalidation_0-logloss:0.41103\n",
      "[14]\tvalidation_0-logloss:0.40620\n",
      "[15]\tvalidation_0-logloss:0.40233\n",
      "[16]\tvalidation_0-logloss:0.39888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\俊俊\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17]\tvalidation_0-logloss:0.39506\n",
      "[18]\tvalidation_0-logloss:0.39300\n",
      "[19]\tvalidation_0-logloss:0.38955\n",
      "[20]\tvalidation_0-logloss:0.38704\n",
      "[21]\tvalidation_0-logloss:0.38420\n",
      "[22]\tvalidation_0-logloss:0.38149\n",
      "[23]\tvalidation_0-logloss:0.37898\n",
      "[24]\tvalidation_0-logloss:0.37714\n",
      "[25]\tvalidation_0-logloss:0.37539\n",
      "[26]\tvalidation_0-logloss:0.37323\n",
      "[27]\tvalidation_0-logloss:0.37164\n",
      "[28]\tvalidation_0-logloss:0.36991\n",
      "[29]\tvalidation_0-logloss:0.36871\n",
      "[30]\tvalidation_0-logloss:0.36727\n",
      "[31]\tvalidation_0-logloss:0.36597\n",
      "[32]\tvalidation_0-logloss:0.36486\n",
      "[33]\tvalidation_0-logloss:0.36350\n",
      "[34]\tvalidation_0-logloss:0.36214\n",
      "[35]\tvalidation_0-logloss:0.36104\n",
      "[36]\tvalidation_0-logloss:0.36016\n",
      "[37]\tvalidation_0-logloss:0.35935\n",
      "[38]\tvalidation_0-logloss:0.35889\n",
      "[39]\tvalidation_0-logloss:0.35807\n",
      "[40]\tvalidation_0-logloss:0.35728\n",
      "[41]\tvalidation_0-logloss:0.35643\n",
      "[42]\tvalidation_0-logloss:0.35558\n",
      "[43]\tvalidation_0-logloss:0.35494\n",
      "[44]\tvalidation_0-logloss:0.35437\n",
      "[45]\tvalidation_0-logloss:0.35380\n",
      "[46]\tvalidation_0-logloss:0.35329\n",
      "[47]\tvalidation_0-logloss:0.35256\n",
      "[48]\tvalidation_0-logloss:0.35188\n",
      "[49]\tvalidation_0-logloss:0.35149\n",
      "[50]\tvalidation_0-logloss:0.35077\n",
      "[51]\tvalidation_0-logloss:0.35026\n",
      "[52]\tvalidation_0-logloss:0.34975\n",
      "[53]\tvalidation_0-logloss:0.34924\n",
      "[54]\tvalidation_0-logloss:0.34885\n",
      "[55]\tvalidation_0-logloss:0.34849\n",
      "[56]\tvalidation_0-logloss:0.34806\n",
      "[57]\tvalidation_0-logloss:0.34775\n",
      "[58]\tvalidation_0-logloss:0.34732\n",
      "[59]\tvalidation_0-logloss:0.34709\n",
      "[60]\tvalidation_0-logloss:0.34678\n",
      "[61]\tvalidation_0-logloss:0.34638\n",
      "[62]\tvalidation_0-logloss:0.34612\n",
      "[63]\tvalidation_0-logloss:0.34589\n",
      "[64]\tvalidation_0-logloss:0.34575\n",
      "[65]\tvalidation_0-logloss:0.34547\n",
      "[66]\tvalidation_0-logloss:0.34513\n",
      "[67]\tvalidation_0-logloss:0.34499\n",
      "[68]\tvalidation_0-logloss:0.34478\n",
      "[69]\tvalidation_0-logloss:0.34467\n",
      "[70]\tvalidation_0-logloss:0.34436\n",
      "[71]\tvalidation_0-logloss:0.34417\n",
      "[72]\tvalidation_0-logloss:0.34398\n",
      "[73]\tvalidation_0-logloss:0.34381\n",
      "[74]\tvalidation_0-logloss:0.34360\n",
      "[75]\tvalidation_0-logloss:0.34326\n",
      "[76]\tvalidation_0-logloss:0.34313\n",
      "[77]\tvalidation_0-logloss:0.34300\n",
      "[78]\tvalidation_0-logloss:0.34279\n",
      "[79]\tvalidation_0-logloss:0.34275\n",
      "[80]\tvalidation_0-logloss:0.34278\n",
      "[81]\tvalidation_0-logloss:0.34257\n",
      "[82]\tvalidation_0-logloss:0.34253\n",
      "[83]\tvalidation_0-logloss:0.34243\n",
      "[84]\tvalidation_0-logloss:0.34234\n",
      "[85]\tvalidation_0-logloss:0.34223\n",
      "[86]\tvalidation_0-logloss:0.34196\n",
      "[87]\tvalidation_0-logloss:0.34170\n",
      "[88]\tvalidation_0-logloss:0.34174\n",
      "[89]\tvalidation_0-logloss:0.34176\n",
      "[90]\tvalidation_0-logloss:0.34167\n",
      "[91]\tvalidation_0-logloss:0.34158\n",
      "[92]\tvalidation_0-logloss:0.34153\n",
      "[93]\tvalidation_0-logloss:0.34139\n",
      "[94]\tvalidation_0-logloss:0.34140\n",
      "[95]\tvalidation_0-logloss:0.34130\n",
      "[96]\tvalidation_0-logloss:0.34121\n",
      "[97]\tvalidation_0-logloss:0.34119\n",
      "[98]\tvalidation_0-logloss:0.34098\n",
      "[99]\tvalidation_0-logloss:0.34084\n",
      "[100]\tvalidation_0-logloss:0.34075\n",
      "[101]\tvalidation_0-logloss:0.34073\n",
      "[102]\tvalidation_0-logloss:0.34067\n",
      "[103]\tvalidation_0-logloss:0.34068\n",
      "[104]\tvalidation_0-logloss:0.34051\n",
      "[105]\tvalidation_0-logloss:0.34030\n",
      "[106]\tvalidation_0-logloss:0.34021\n",
      "[107]\tvalidation_0-logloss:0.34016\n",
      "[108]\tvalidation_0-logloss:0.34026\n",
      "[109]\tvalidation_0-logloss:0.34017\n",
      "[110]\tvalidation_0-logloss:0.34004\n",
      "[111]\tvalidation_0-logloss:0.33997\n",
      "[112]\tvalidation_0-logloss:0.33983\n",
      "[113]\tvalidation_0-logloss:0.33974\n",
      "[114]\tvalidation_0-logloss:0.33968\n",
      "[115]\tvalidation_0-logloss:0.33959\n",
      "[116]\tvalidation_0-logloss:0.33947\n",
      "[117]\tvalidation_0-logloss:0.33939\n",
      "[118]\tvalidation_0-logloss:0.33934\n",
      "[119]\tvalidation_0-logloss:0.33917\n",
      "[120]\tvalidation_0-logloss:0.33904\n",
      "[121]\tvalidation_0-logloss:0.33892\n",
      "[122]\tvalidation_0-logloss:0.33884\n",
      "[123]\tvalidation_0-logloss:0.33889\n",
      "[124]\tvalidation_0-logloss:0.33891\n",
      "[125]\tvalidation_0-logloss:0.33882\n",
      "[126]\tvalidation_0-logloss:0.33874\n",
      "[127]\tvalidation_0-logloss:0.33849\n",
      "[128]\tvalidation_0-logloss:0.33866\n",
      "[129]\tvalidation_0-logloss:0.33867\n",
      "[130]\tvalidation_0-logloss:0.33871\n",
      "[131]\tvalidation_0-logloss:0.33858\n",
      "[132]\tvalidation_0-logloss:0.33850\n",
      "[133]\tvalidation_0-logloss:0.33844\n",
      "[134]\tvalidation_0-logloss:0.33852\n",
      "[135]\tvalidation_0-logloss:0.33846\n",
      "[136]\tvalidation_0-logloss:0.33857\n",
      "[137]\tvalidation_0-logloss:0.33857\n",
      "[138]\tvalidation_0-logloss:0.33879\n",
      "[139]\tvalidation_0-logloss:0.33885\n",
      "[140]\tvalidation_0-logloss:0.33894\n",
      "[141]\tvalidation_0-logloss:0.33900\n",
      "[142]\tvalidation_0-logloss:0.33902\n",
      "[143]\tvalidation_0-logloss:0.33912\n",
      "[144]\tvalidation_0-logloss:0.33913\n",
      "[145]\tvalidation_0-logloss:0.33918\n",
      "[146]\tvalidation_0-logloss:0.33934\n",
      "[147]\tvalidation_0-logloss:0.33939\n",
      "[148]\tvalidation_0-logloss:0.33935\n",
      "[149]\tvalidation_0-logloss:0.33935\n",
      "[150]\tvalidation_0-logloss:0.33941\n",
      "[151]\tvalidation_0-logloss:0.33937\n",
      "[152]\tvalidation_0-logloss:0.33937\n",
      "[153]\tvalidation_0-logloss:0.33930\n",
      "[154]\tvalidation_0-logloss:0.33937\n",
      "[155]\tvalidation_0-logloss:0.33935\n",
      "[156]\tvalidation_0-logloss:0.33938\n",
      "[157]\tvalidation_0-logloss:0.33942\n",
      "[158]\tvalidation_0-logloss:0.33956\n",
      "[159]\tvalidation_0-logloss:0.33951\n",
      "[160]\tvalidation_0-logloss:0.33952\n",
      "[161]\tvalidation_0-logloss:0.33958\n",
      "[162]\tvalidation_0-logloss:0.33956\n",
      "[163]\tvalidation_0-logloss:0.33952\n",
      "[164]\tvalidation_0-logloss:0.33949\n",
      "[165]\tvalidation_0-logloss:0.33945\n",
      "[166]\tvalidation_0-logloss:0.33942\n",
      "[167]\tvalidation_0-logloss:0.33945\n",
      "[168]\tvalidation_0-logloss:0.33953\n",
      "[169]\tvalidation_0-logloss:0.33954\n",
      "[170]\tvalidation_0-logloss:0.33970\n",
      "[171]\tvalidation_0-logloss:0.33969\n",
      "[172]\tvalidation_0-logloss:0.33973\n",
      "[173]\tvalidation_0-logloss:0.33979\n",
      "[174]\tvalidation_0-logloss:0.33986\n",
      "[175]\tvalidation_0-logloss:0.33986\n",
      "[176]\tvalidation_0-logloss:0.33990\n",
      "[177]\tvalidation_0-logloss:0.33996\n",
      "[178]\tvalidation_0-logloss:0.34000\n",
      "[179]\tvalidation_0-logloss:0.34006\n",
      "[180]\tvalidation_0-logloss:0.34007\n",
      "[181]\tvalidation_0-logloss:0.34007\n",
      "[182]\tvalidation_0-logloss:0.34011\n",
      "Final F1 Score on Test Set:  0.8492877968356741\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        'min_child_weight': trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        'subsample': trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float(\"gamma\", 0.0, 0.5),\n",
    "        'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
    "        'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
    "    }\n",
    "    model = XGBClassifier(**param, use_label_encoder=False, eval_metric='logloss')\n",
    "    model.fit(x_train, y_train, early_stopping_rounds=50, eval_set=[(x_test, y_test)], verbose=False)\n",
    "    y_pred = model.predict(x_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted') \n",
    "    return f1\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters: \", best_params)\n",
    "print(\"Best F1 Score: \", study.best_value)\n",
    "\n",
    "\n",
    "best_model_XGB = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss')\n",
    "best_model_XGB.fit(x_train, y_train, early_stopping_rounds=50, eval_set=[(x_test, y_test)], verbose=True)\n",
    "\n",
    "\n",
    "y_pred = best_model_XGB.predict(x_test)\n",
    "final_f1 = f1_score(y_test, y_pred, average='weighted') \n",
    "print(\"Final F1 Score on Test Set: \", final_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500,\n",
       " 'learning_rate': 0.05853677397055986,\n",
       " 'max_depth': 9,\n",
       " 'min_child_weight': 9,\n",
       " 'subsample': 0.7864773290198578,\n",
       " 'colsample_bytree': 0.7497746343514877,\n",
       " 'gamma': 0.3115464001764693,\n",
       " 'reg_alpha': 0.04368002699194678,\n",
       " 'reg_lambda': 4.402476744615238}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results f1: 0.7573443623663275'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     16821\n",
      "           1       0.94      0.79      0.86      4544\n",
      "\n",
      "    accuracy                           0.94     21365\n",
      "   macro avg       0.94      0.89      0.91     21365\n",
      "weighted avg       0.94      0.94      0.94     21365\n",
      "\n",
      "auc: 0.888454641969587\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAGwCAYAAAAqpFaiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABK8ElEQVR4nO3de1xUdf4/8NfIZUBkRi4CTqJiIqKQEhqilboaaCKa3yIXm3QjrCxZVtS2dS1tV0grteKbmrnh18tav0y7E1ipkXeUCmUxiwSSEcxxEOQ6c35/uJw6gjnDGeRyXs/H4zwezTnvc+ZzJmTevD+XoxIEQQARERHRDXRr7wYQERFR58CkgYiIiKzCpIGIiIiswqSBiIiIrMKkgYiIiKzCpIGIiIiswqSBiIiIrOLY3g2Qw2Kx4Ny5c3B3d4dKpWrv5hARkY0EQcDly5eh0+nQrVvb/R1bW1uL+vp62ddxdnaGi4uLHVrUOXXqpOHcuXPw9/dv72YQEZFMJSUl6NOnT5tcu7a2FgH9esBQbpZ9LT8/PxQVFSk2cejUSYO7uzsA4Ozx/tD0YE8LdU33DQpt7yYQtZlGNCAHn4i/z9tCfX09DOVmnM3tD417678rKi9b0C/8J9TX1zNp6IyauiQ0PbrJ+kEg6sgcVU7t3QSitvPfBxncjC7mHu4q9HBv/ftYwG7wTp00EBERWcssWGCW8bQls2CxX2M6KSYNRESkCBYIsKD1WYOcc7sK1vSJiIjIKqw0EBGRIlhggZwOBnlndw1MGoiISBHMggCz0PouBjnndhXsniAiIiKrMGkgIiJFaBoIKWezxf79+zF16lTodDqoVCrs3r27WUxBQQFiY2Oh1Wrh7u6OUaNGobi4WDxeV1eH+fPnw9vbG25uboiNjUVpaankGkajEXq9HlqtFlqtFnq9HpcuXZLEFBcXY+rUqXBzc4O3tzeSkpJatUImkwYiIlIECwSYZWy2Jg3V1dUYNmwY0tPTWzz+ww8/4M4778TgwYOxd+9efPPNN1i6dKlk4ajk5GTs2rULO3bsQE5ODqqqqhATEwOz+dfVLePj45GXl4fMzExkZmYiLy8Per1ePG42mzFlyhRUV1cjJycHO3bswM6dO5GSkmLjJwioBKHzdtJUVlZCq9XCeHoAF3eiLitaN7y9m0DUZhqFBuzF+zCZTNBoNG3yHk3fFUX/6Q13Gd8Vly9bEDC4rFVtValU2LVrF6ZPny7umzlzJpycnLBly5YWzzGZTOjVqxe2bNmCBx98EMCvj0/45JNPEB0djYKCAgwZMgSHDh1CREQEAODQoUOIjIzEf/7zHwQFBeHTTz9FTEwMSkpKoNPpAAA7duzAnDlzUF5ebtO98JuWiIgUwV7dE5WVlZKtrq7O9rZYLPj4448xaNAgREdHw8fHBxEREZIujNzcXDQ0NCAqKkrcp9PpEBISggMHDgAADh48CK1WKyYMADBq1ChotVpJTEhIiJgwAEB0dDTq6uqQm5trU7uZNBARkSI0zZ6QswGAv7+/OH5Aq9UiLS3N5raUl5ejqqoKL7zwAiZNmoSsrCzcd999mDFjBvbt2wcAMBgMcHZ2hoeHh+RcX19fGAwGMcbHx6fZ9X18fCQxvr6+kuMeHh5wdnYWY6zFKZdEREQ2KCkpkZT01Wq1zdewWK6u+TBt2jT85S9/AQAMHz4cBw4cwPr16zF27NjrnisIguRZHS09t6M1MdZgpYGIiBTBYocNADQajWRrTdLg7e0NR0dHDBkyRLI/ODhYnD3h5+eH+vp6GI1GSUx5eblYOfDz88P58+ebXb+iokISc21FwWg0oqGhoVkF4kaYNBARkSLImTnRtNmLs7MzRo4cicLCQsn+06dPo1+/fgCA8PBwODk5ITs7WzxeVlaG/Px8jB49GgAQGRkJk8mEI0eOiDGHDx+GyWSSxOTn56OsrEyMycrKglqtRnh4uE3tZvcEEREpglmAzKdc2hZfVVWFM2fOiK+LioqQl5cHT09P9O3bF4sWLcKDDz6Iu+++G+PHj0dmZiY+/PBD7N27FwCg1WqRkJCAlJQUeHl5wdPTEwsXLkRoaCgmTpwI4GplYtKkSUhMTMSGDRsAAHPnzkVMTAyCgoIAAFFRURgyZAj0ej1efPFFXLx4EQsXLkRiYqLNs0BYaSAiImoDx44dQ1hYGMLCwgAACxYsQFhYGJ599lkAwH333Yf169dj1apVCA0NxZtvvomdO3fizjvvFK+xZs0aTJ8+HXFxcRgzZgy6d++ODz/8EA4ODmLMtm3bEBoaiqioKERFReG2226TTON0cHDAxx9/DBcXF4wZMwZxcXGYPn06XnrpJZvvies0EHVwXKeBurKbuU5D3ikf2es0DB9S3qZt7ejYPUFERIpggQpm2DZb4NrzlY5/nhMREZFVWGkgIiJFsAhXNznnKx2TBiIiUgSzzO4JOed2FeyeICIiIquw0kBERIrASoN8TBqIiEgRLIIKFkHG7AkZ53YV7J4gIiIiq7DSQEREisDuCfmYNBARkSKY0Q1mGQV2sx3b0lkxaSAiIkUQZI5pEDimgWMaiIiIyDqsNBARkSJwTIN8TBqIiEgRzEI3mAUZYxq4jDS7J4iIiMg6rDQQEZEiWKCCRcbfyhaw1MCkgYiIFIFjGuRj9wQRERFZhZUGIiJSBPkDIdk9waSBiIgU4eqYBhkPrGL3BLsniIiIyDqsNBARkSJYZD57grMnmDQQEZFCcEyDfEwaiIhIESzoxnUaZOKYBiIiIrIKKw1ERKQIZkEFs4zHW8s5t6tg0kBERIpgljkQ0szuCXZPEBERkXVYaSAiIkWwCN1gkTF7wsLZE0waiIhIGdg9IR+7J4iIiMgqrDQQEZEiWCBvBoTFfk3ptJg0EBGRIshf3InFeX4CREREZBVWGoiISBHkP3uCf2fzEyAiIkWwQCV7s8X+/fsxdepU6HQ6qFQq7N69+7qxjz32GFQqFdauXSvZX1dXh/nz58Pb2xtubm6IjY1FaWmpJMZoNEKv10Or1UKr1UKv1+PSpUuSmOLiYkydOhVubm7w9vZGUlIS6uvrbbofgEkDEREpRFOlQc5mi+rqagwbNgzp6em/G7d7924cPnwYOp2u2bHk5GTs2rULO3bsQE5ODqqqqhATEwOz2SzGxMfHIy8vD5mZmcjMzEReXh70ev2v9202Y8qUKaiurkZOTg527NiBnTt3IiUlxab7Adg9QUREZJPKykrJa7VaDbVa3Sxu8uTJmDx58u9e6+eff8ZTTz2Fzz77DFOmTJEcM5lM2LRpE7Zs2YKJEycCALZu3Qp/f3/s2bMH0dHRKCgoQGZmJg4dOoSIiAgAwMaNGxEZGYnCwkIEBQUhKysLp06dQklJiZiYvPzyy5gzZw5WrFgBjUZj9b2z0kBERIrQtLiTnA0A/P39xa4ArVaLtLS0VrXHYrFAr9dj0aJFGDp0aLPjubm5aGhoQFRUlLhPp9MhJCQEBw4cAAAcPHgQWq1WTBgAYNSoUdBqtZKYkJAQSSUjOjoadXV1yM3NtanNrDQQEZEiWAQVLHLWafjvuSUlJZK/zluqMlhj5cqVcHR0RFJSUovHDQYDnJ2d4eHhIdnv6+sLg8Egxvj4+DQ718fHRxLj6+srOe7h4QFnZ2cxxlpMGoiIiGyg0WhsKum3JDc3F6+88gqOHz8Olcq2REYQBMk5LZ3fmhhrsHuCiIgUwSKza8Keizt99dVXKC8vR9++feHo6AhHR0ecPXsWKSkp6N+/PwDAz88P9fX1MBqNknPLy8vFyoGfnx/Onz/f7PoVFRWSmGsrCkajEQ0NDc0qEDfCpIGIiBSh6SmXcjZ70ev1+Pbbb5GXlyduOp0OixYtwmeffQYACA8Ph5OTE7Kzs8XzysrKkJ+fj9GjRwMAIiMjYTKZcOTIETHm8OHDMJlMkpj8/HyUlZWJMVlZWVCr1QgPD7ep3eyeICIiagNVVVU4c+aM+LqoqAh5eXnw9PRE37594eXlJYl3cnKCn58fgoKCAABarRYJCQlISUmBl5cXPD09sXDhQoSGhoqzKYKDgzFp0iQkJiZiw4YNAIC5c+ciJiZGvE5UVBSGDBkCvV6PF198ERcvXsTChQuRmJhoczcLkwYiIlIEM1Qw27hA07Xn2+LYsWMYP368+HrBggUAgNmzZyMjI8Oqa6xZswaOjo6Ii4tDTU0NJkyYgIyMDDg4OIgx27ZtQ1JSkjjLIjY2VrI2hIODAz7++GPMmzcPY8aMgaurK+Lj4/HSSy/ZdD8AoBIEodM+ILyyshJarRbG0wOgcWdPC3VN0brh7d0EojbTKDRgL96HyWSSPbjwepq+K5YfngiXHq3/W7m2qhHPRexp07Z2dPymJSIiIquwe4KIiBTBDNu7GK49X+mYNBARkSLInQFhz9kTnRWTBiIiUgQ+Gls+fgJERERkFVYaiIhIEQSoYJExpkGQcW5XwaSBiIgUgd0T8vETICIiIquw0kBERIpgr0djKxmTBiIiUoSmp1XKOV/p+AkQERGRVVhpICIiRWD3hHxMGoiISBEs6AaLjAK7nHO7Cn4CREREZBVWGoiISBHMggpmGV0Mcs7tKpg0EBGRInBMg3xMGoiISBEEmU+5FLgiJMc0EBERkXVYaSAiIkUwQwWzjIdOyTm3q2DSQEREimAR5I1LsAh2bEwnxe4JIiIisgorDV3cd4fc8P9e98H333XHxfNOeG5TEUZPNkliir9XY9M/dfj2UA8IFqBfUC2WrP8JPn0aAACL/mcgvj3YQ3LO2Fgj/rb+LADgmwM9sPj+gS2+/6ufFCJoeI1kX+VFBzxxTxAulDljZ8F36KE12+t2iZp58KnzGHOvCf4D61Bf2w2njnXHphW9UfqDS4vxSStLMEV/Eeuf1WHXm70AAL596vF/RwpajP/n3H746qOebdV8siOLzIGQcs7tKpg0dHG1V7phwNAaRM28iH88GtDs+LmfnLFgeiAmzfwF+oUGuGnMKP7eBc4u0jrc5FkX8PAig/ha7WIR/3vIiGr8Oy9fEr95VW+c+KoHBg2TJgwAsDqlLwKCa3GhzFnu7RHd0G2R1fgwwxun87rDwVHAnKfLkPrvH5E4Ngh1NQ6S2MhJJgy+/QoulEl/NVacc8LMYUMk++596Bc8MK8CR79wb/N7IPuwQAWLjHEJcs7tKto9bXr99dcREBAAFxcXhIeH46uvvmrvJnUpI/9wGXOeNuDOe00tHs94oTfu+EMlHl1ahoGhNejdrx4REyvR07tREqd2FeDp0yhubppfkwYnZ+kxjUcjDmVpED3zIlTX/Bv7cLMXqisdcP/j5Xa/V6KWLJk1ANnveOLsaRf8eMoVL/+lL3z7NCDwNmlC6+XXgCf/+TNWPtkPjY3SH1yLRQVjhZNkGz3ZhH0f9ETtFWniQdSVtWvS8PbbbyM5ORlLlizBiRMncNddd2Hy5MkoLi5uz2YphsUCHPlcg1sG1OFvfxyAuNChSJoSiAOfapvFfvmeBx4YGoLEcUF4Y7kOV6qu/6NzMEuLyouOuCfuomT/2dNqbF/jh0WvnIWq3dNVUio3zdXusMuXfv2yV6kELH61GO+u64Wzp1vutvitgaFXMDCkFp/927PN2kn217QipJxN6dr1V/fq1auRkJCARx99FMHBwVi7di38/f2xbt269myWYly64Iiaage8ne6DEeMvI+3fP2LMJBOef7Q/vj3oJsaNn3ERf339J7y48wxmJZ9HzidaPJ/QvKujyWf/9kL4uMvwuaVB3Fdfp0LavP54dOk5cawE0c0nYO6yc8g/7Iazha7i3rgny2E2A7s3eVt1lUl/vIizp9U4dcztxsHUYTSNaZCzKV27jWmor69Hbm4u/vrXv0r2R0VF4cCBAy2eU1dXh7q6OvF1ZWVlm7axqxP+28MQGV2JGXMrAAC3htTg1DE3fPx/3rgtshoAcO+sXysG/QfX4pYBdXhqUhC+/9a1WYm34pwTcve6428bfpLsfyutN/oOrMWE/zG23Q0R3cCTqT8jILgGKdN/Hbg7MPQKpj96AU9GDwKs6LN2drFg/H1GbF/r24YtJeqY2i1puHDhAsxmM3x9pf/wfH19YTAYWjwnLS0Ny5cvvxnNUwSNpxkOjgL6DaqV7PcPrMXJI9f/C2pgaA0cnSz4uUjdLGnIetsT7h6NiIySjqHIy3HHT/9xwWT/nld3/Hec5QMhIfhj0nnJIEuitjDvn6WIjKpEyn23SgbhhkZUo6d3I7YePSXuc3AEEp87h+mJFZgdIR0AedeUS1C7Ctjz/9g10dlYIPPZExwI2f6zJ1TXjJQTBKHZvibPPPMMFixYIL6urKyEv79/m7avK3NyFjBo2BWU/qCW7P/5R/XvdiGcLXRBY0M3ePlKYwThatIw8X4jHJ2k5yx9swj1tb+W9grzumP1gr54edf30PWvl38zRNcl4MkVP2P0JBMW3T8Q50ukP+97dnrg+FfSKcWp23/E5zs9kPV288Qg+o8XcShLA9PFdv/1STYSZM6eEJg0tF/S4O3tDQcHh2ZVhfLy8mbVhyZqtRpqtbrFY9SymupuOFf062dmKHHGD/mucO/ZCJ8+DXhgXjlSH++HkFFVGDa6Cse+1OBQthYvvnsGwNUpmV+854E7JlRC42lG8Wk13lh+CwaGXMGQkdWS98rL6QFDsRqT4n9p1o5rE4OmX7h9A+u4TgO1qadSf8b4+4xY9qcA1FR1g0evq8lu9WUH1Nd2w2WjIy4bpb8KGxtVMJY7NVvLQde/DqGjqrH0oeuP6aGOi0+5lK/dkgZnZ2eEh4cjOzsb9913n7g/Ozsb06ZNa69mdTmnv+kuWXhpw7JbAAD3xF3EwrXFGDPZhKQXSrEj3RfrlvZBnwF1WLqxCCERVxMCRycBeTnu2L2pF2qru8Fb14CICZWYtcAAh2tmmmX+2wtDRlShb2AdiDqKqXOuJrEvvfeDZP9Lyf7Ifse2LobomRfxi8EJufu4NgMpk0oQhHZbTfvtt9+GXq/H+vXrERkZiTfeeAMbN27EyZMn0a9fvxueX1lZCa1WC+PpAdC4c1QrdU3RuuHt3QSiNtMoNGAv3ofJZIJGo2mT92j6rrgv+09wcmv9onIN1fXYdc9bbdrWjq5dO+UefPBB/PLLL3j++edRVlaGkJAQfPLJJ1YlDERERLZg94R87T6SZ968eZg3b157N4OIiIhugDV9IiJShKZnT8jZbLF//35MnToVOp0OKpUKu3fvFo81NDTg6aefRmhoKNzc3KDT6fDwww/j3LlzkmvU1dVh/vz58Pb2hpubG2JjY1FaWiqJMRqN0Ov10Gq10Gq10Ov1uHTpkiSmuLgYU6dOhZubG7y9vZGUlIT6ettnrjFpICIiRWjqnpCz2aK6uhrDhg1Denp6s2NXrlzB8ePHsXTpUhw/fhzvvfceTp8+jdjYWElccnIydu3ahR07diAnJwdVVVWIiYmB2fzrrLP4+Hjk5eUhMzMTmZmZyMvLg16vF4+bzWZMmTIF1dXVyMnJwY4dO7Bz506kpKTY+Al2gO4JIiKirmjy5MmYPHlyi8e0Wi2ys7Ml+1577TXccccdKC4uRt++fWEymbBp0yZs2bIFEydOBABs3boV/v7+2LNnD6Kjo1FQUIDMzEwcOnQIERERAICNGzciMjIShYWFCAoKQlZWFk6dOoWSkhLodDoAwMsvv4w5c+ZgxYoVNg3qZKWBiIgUwV6VhsrKSsn228cbyGEymaBSqdCzZ08AQG5uLhoaGhAVFSXG6HQ6hISEiI9bOHjwILRarZgwAMCoUaOg1WolMSEhIWLCAADR0dGoq6tDbm6uTW1k0kBERIpgr6TB399fHD+g1WqRlpYmu221tbX461//ivj4ePEvf4PBAGdnZ3h4eEhif/u4BYPBAB8fn2bX8/HxkcRcu2iih4cHnJ2dr/vYhuth9wQREZENSkpKJCV9uSsVNzQ0YObMmbBYLHj99ddvGH/t4xZaevRCa2KswUoDEREpgr0qDRqNRrLJSRoaGhoQFxeHoqIiZGdnS5IRPz8/1NfXw2iUPh34t49b8PPzw/nz55tdt6KiQhJzbUXBaDSioaHhuo9tuB4mDUREpAgC5E27tPfyyU0Jw/fff489e/bAy8tLcjw8PBxOTk6SAZNlZWXIz8/H6NGjAQCRkZEwmUw4cuSIGHP48GGYTCZJTH5+PsrKysSYrKwsqNVqhIeH29Rmdk8QEZEi3OwVIauqqnDmzBnxdVFREfLy8uDp6QmdTof7778fx48fx0cffQSz2SxWAzw9PeHs7AytVouEhASkpKTAy8sLnp6eWLhwIUJDQ8XZFMHBwZg0aRISExOxYcMGAMDcuXMRExODoKAgAEBUVBSGDBkCvV6PF198ERcvXsTChQuRmJho83LYTBqIiIjawLFjxzB+/Hjx9YIFCwAAs2fPxrJly/DBBx8AAIYPHy4578svv8S4ceMAAGvWrIGjoyPi4uJQU1ODCRMmICMjAw6/eWLgtm3bkJSUJM6yiI2NlawN4eDggI8//hjz5s3DmDFj4Orqivj4eLz00ks231O7PrBKLj6wipSAD6yiruxmPrBq3EdPwNGt9eMPGqvrsDdmHR9YRURE1NXxgVXy8c9zIiIisgorDUREpAisNMjHpIGIiBRBEFQQZHzxyzm3q2D3BBEREVmFlQYiIlKEpkWa5JyvdEwaiIhIETimQT52TxAREZFVWGkgIiJF4EBI+Zg0EBGRIrB7Qj4mDUREpAisNMjHMQ1ERERkFVYaiIhIEQSZ3ROsNDBpICIihRAAyHmuc6d9JLQdsXuCiIiIrMJKAxERKYIFKqi4IqQsTBqIiEgROHtCPnZPEBERkVVYaSAiIkWwCCqouLiTLEwaiIhIEQRB5uwJTp9g9wQRERFZh5UGIiJSBA6ElI9JAxERKQKTBvmYNBARkSJwIKR8HNNAREREVmGlgYiIFIGzJ+Rj0kBERIpwNWmQM6bBjo3ppNg9QURERFZhpYGIiBSBsyfkY9JARESKIPx3k3O+0rF7goiIiKzCSgMRESkCuyfkY9JARETKwP4J2Zg0EBGRMsisNICVBo5pICIiagv79+/H1KlTodPpoFKpsHv3bslxQRCwbNky6HQ6uLq6Yty4cTh58qQkpq6uDvPnz4e3tzfc3NwQGxuL0tJSSYzRaIRer4dWq4VWq4Ver8elS5ckMcXFxZg6dSrc3Nzg7e2NpKQk1NfX23xPTBqIiEgRmlaElLPZorq6GsOGDUN6enqLx1etWoXVq1cjPT0dR48ehZ+fH+655x5cvnxZjElOTsauXbuwY8cO5OTkoKqqCjExMTCbzWJMfHw88vLykJmZiczMTOTl5UGv14vHzWYzpkyZgurqauTk5GDHjh3YuXMnUlJSbLshsHuCiIgU4mYPhJw8eTImT558nWsJWLt2LZYsWYIZM2YAADZv3gxfX19s374djz32GEwmEzZt2oQtW7Zg4sSJAICtW7fC398fe/bsQXR0NAoKCpCZmYlDhw4hIiICALBx40ZERkaisLAQQUFByMrKwqlTp1BSUgKdTgcAePnllzFnzhysWLECGo3G6ntipYGIiMgGlZWVkq2urs7maxQVFcFgMCAqKkrcp1arMXbsWBw4cAAAkJubi4aGBkmMTqdDSEiIGHPw4EFotVoxYQCAUaNGQavVSmJCQkLEhAEAoqOjUVdXh9zcXJvazaSBiIiUQVDJ3wD4+/uL4we0Wi3S0tJsborBYAAA+Pr6Svb7+vqKxwwGA5ydneHh4fG7MT4+Ps2u7+PjI4m59n08PDzg7OwsxliL3RNERKQI9nrKZUlJiaSkr1arW31NlUra5SEIQrN9zdshjWkpvjUx1mClgYiIyAYajUaytSZp8PPzA4Bmf+mXl5eLVQE/Pz/U19fDaDT+bsz58+ebXb+iokISc+37GI1GNDQ0NKtA3AiTBiIiUgbBDpudBAQEwM/PD9nZ2eK++vp67Nu3D6NHjwYAhIeHw8nJSRJTVlaG/Px8MSYyMhImkwlHjhwRYw4fPgyTySSJyc/PR1lZmRiTlZUFtVqN8PBwm9rN7gkiIlKEmz17oqqqCmfOnBFfFxUVIS8vD56enujbty+Sk5ORmpqKwMBABAYGIjU1Fd27d0d8fDwAQKvVIiEhASkpKfDy8oKnpycWLlyI0NBQcTZFcHAwJk2ahMTERGzYsAEAMHfuXMTExCAoKAgAEBUVhSFDhkCv1+PFF1/ExYsXsXDhQiQmJto0cwKwMml49dVXrb5gUlKSTQ0gIiLqio4dO4bx48eLrxcsWAAAmD17NjIyMrB48WLU1NRg3rx5MBqNiIiIQFZWFtzd3cVz1qxZA0dHR8TFxaGmpgYTJkxARkYGHBwcxJht27YhKSlJnGURGxsrWRvCwcEBH3/8MebNm4cxY8bA1dUV8fHxeOmll2y+J5Ug3HhYSEBAgHUXU6nw448/2tyI1qqsrIRWq4Xx9ABo3NnTQl1TtG54ezeBqM00Cg3Yi/dhMpls/qvXWk3fFX3feBbdXF1afR1LTS2K5z7fpm3t6KyqNBQVFbV1O4iIiNoUn3IpX6v/PK+vr0dhYSEaGxvt2R4iIqK20YEGQnZWNicNV65cQUJCArp3746hQ4eiuLgYwNWxDC+88ILdG0hEREQdg81JwzPPPINvvvkGe/fuhYvLr31DEydOxNtvv23XxhEREdmPyg6bstk85XL37t14++23MWrUKMlKUkOGDMEPP/xg18YRERHZjdwuBnZP2F5pqKioaHGd6+rqapuXoyQiIqLOw+akYeTIkfj444/F102JQtOjOImIiDokDoSUzebuibS0NEyaNAmnTp1CY2MjXnnlFZw8eRIHDx7Evn372qKNRERE8v3mSZWtPl/hbK40jB49Gl9//TWuXLmCW2+9FVlZWfD19cXBgwdtXsOaiIiIOo9WPXsiNDQUmzdvtndbiIiI2oy9Ho2tZK1KGsxmM3bt2oWCggKoVCoEBwdj2rRpcHTk86+IiKiD4uwJ2Wz+ls/Pz8e0adNgMBjEJ2idPn0avXr1wgcffIDQ0FC7N5KIiIjan81jGh599FEMHToUpaWlOH78OI4fP46SkhLcdtttmDt3blu0kYiISL6mgZByNoWzudLwzTff4NixY/Dw8BD3eXh4YMWKFRg5cqRdG0dERGQvKuHqJud8pbO50hAUFITz5883219eXo6BAwfapVFERER2x3UaZLMqaaisrBS31NRUJCUl4d1330VpaSlKS0vx7rvvIjk5GStXrmzr9hIREVE7sap7omfPnpIlogVBQFxcnLhP+O88lKlTp8JsNrdBM4mIiGTi4k6yWZU0fPnll23dDiIiorbFKZeyWZU0jB07tq3bQURERB1cq1djunLlCoqLi1FfXy/Zf9ttt8luFBERkd2x0iCbzUlDRUUF/vSnP+HTTz9t8TjHNBARUYfEpEE2m6dcJicnw2g04tChQ3B1dUVmZiY2b96MwMBAfPDBB23RRiIiIuoAbK40fPHFF3j//fcxcuRIdOvWDf369cM999wDjUaDtLQ0TJkypS3aSUREJA9nT8hmc6WhuroaPj4+AABPT09UVFQAuPrky+PHj9u3dURERHbStCKknE3pWrUiZGFhIQBg+PDh2LBhA37++WesX78evXv3tnsDiYiIqGOwuXsiOTkZZWVlAIDnnnsO0dHR2LZtG5ydnZGRkWHv9hEREdkHB0LKZnPSMGvWLPG/w8LC8NNPP+E///kP+vbtC29vb7s2joiIiDqOVq/T0KR79+64/fbb7dEWIiKiNqOCzKdc2q0lnZdVScOCBQusvuDq1atb3RgiIiLquKxKGk6cOGHVxX77UKub6f4Ro+Gocm6X9yZqa40TAtu7CURtprGxFtj7/s15M065lI0PrCIiImXgQEjZbJ5ySURERMokeyAkERFRp8BKg2xMGoiISBHkrurIFSHZPUFERERWYtJARETKINhhs0FjYyP+/ve/IyAgAK6urhgwYACef/55WCyWX5skCFi2bBl0Oh1cXV0xbtw4nDx5UnKduro6zJ8/H97e3nBzc0NsbCxKS0slMUajEXq9HlqtFlqtFnq9HpcuXbKtwVZoVdKwZcsWjBkzBjqdDmfPngUArF27Fu+/f5OmzRAREdnqJicNK1euxPr165Geno6CggKsWrUKL774Il577TUxZtWqVVi9ejXS09Nx9OhR+Pn54Z577sHly5fFmOTkZOzatQs7duxATk4OqqqqEBMTA7PZLMbEx8cjLy8PmZmZyMzMRF5eHvR6vc0f0Y3YnDSsW7cOCxYswL333otLly6Jje7ZsyfWrl1r7/YRERF1KJWVlZKtrq6uxbiDBw9i2rRpmDJlCvr374/7778fUVFROHbsGICrVYa1a9diyZIlmDFjBkJCQrB582ZcuXIF27dvBwCYTCZs2rQJL7/8MiZOnIiwsDBs3boV3333Hfbs2QMAKCgoQGZmJt58801ERkYiMjISGzduxEcffSQ+YNJebE4aXnvtNWzcuBFLliyBg4ODuH/EiBH47rvv7No4IiIie7HXo7H9/f3FbgCtVou0tLQW3+/OO+/E559/jtOnTwMAvvnmG+Tk5ODee+8FABQVFcFgMCAqKko8R61WY+zYsThw4AAAIDc3Fw0NDZIYnU6HkJAQMebgwYPQarWIiIgQY0aNGgWtVivG2IvNsyeKiooQFhbWbL9arUZ1dbVdGkVERGR3dloRsqSkBBqNRtytVqtbDH/66adhMpkwePBgODg4wGw2Y8WKFfjjH/8IADAYDAAAX19fyXm+vr5i17/BYICzszM8PDyaxTSdbzAY4OPj0+z9fXx8xBh7sTlpCAgIQF5eHvr16yfZ/+mnn2LIkCF2axgREZFd2WmdBo1GI0karuftt9/G1q1bsX37dgwdOhR5eXlITk6GTqfD7NmzxbhrH8EgCMINH8twbUxL8dZcx1Y2Jw2LFi3Ck08+idraWgiCgCNHjuDf//430tLS8Oabb9q1cURERJ3VokWL8Ne//hUzZ84EAISGhuLs2bNIS0vD7Nmz4efnB+BqpaB3797ieeXl5WL1wc/PD/X19TAajZJqQ3l5OUaPHi3GnD9/vtn7V1RUNKtiyGXzmIY//elPeO6557B48WJcuXIF8fHxWL9+PV555RXxgyEiIupo7DWmwVpXrlxBt27Sr1kHBwdxymVAQAD8/PyQnZ0tHq+vr8e+ffvEhCA8PBxOTk6SmLKyMuTn54sxkZGRMJlMOHLkiBhz+PBhmEwmMcZeWrUiZGJiIhITE3HhwgVYLJYW+1KIiIg6lJu8jPTUqVOxYsUK9O3bF0OHDsWJEyewevVqPPLIIwCudikkJycjNTUVgYGBCAwMRGpqKrp37474+HgAgFarRUJCAlJSUuDl5QVPT08sXLgQoaGhmDhxIgAgODgYkyZNQmJiIjZs2AAAmDt3LmJiYhAUFCTjhpuTtYy0t7e3vdpBRETUpbz22mtYunQp5s2bh/Lycuh0Ojz22GN49tlnxZjFixejpqYG8+bNg9FoREREBLKysuDu7i7GrFmzBo6OjoiLi0NNTQ0mTJiAjIwMyQzGbdu2ISkpSZxlERsbi/T0dLvfk0oQBJtyp4CAgN8dWPHjjz/KbpS1KisrodVqMUHzEBxVzjftfYluprqRge3dBKI209hYi5y9y2EymawaXNgaTd8VA5amwsHFpdXXMdfW4sd//K1N29rR2VxpSE5OlrxuaGjAiRMnkJmZiUWLFtmrXURERPbFp1zKZnPS8Oc//7nF/f/7v/8rrnJFREREXY/dHlg1efJk7Ny5016XIyIisq+b/OyJrkjWQMjfevfdd+Hp6WmvyxEREdlVa6ZNXnu+0tmcNISFhUkGQgqCAIPBgIqKCrz++ut2bRwRERF1HDYnDdOnT5e87tatG3r16oVx48Zh8ODB9moXERERdTA2JQ2NjY3o378/oqOjxeUviYiIOgXOnpDNpoGQjo6OeOKJJ6777HAiIqKO6mYvI90V2Tx7IiIiAidOnGiLthAREVEHZvOYhnnz5iElJQWlpaUIDw+Hm5ub5Phtt91mt8YRERHZFasFslidNDzyyCNYu3YtHnzwQQBAUlKSeEylUonP7TabzfZvJRERkVwc0yCb1UnD5s2b8cILL6CoqKgt20NEREQdlNVJQ9Nzrfr169dmjSEiImorXNxJPpvGNPze0y2JiIg6NHZPyGZT0jBo0KAbJg4XL16U1SAiIiLqmGxKGpYvXw6tVttWbSEiImoz7J6Qz6akYebMmfDx8WmrthAREbUddk/IZvXiThzPQEREpGw2z54gIiLqlFhpkM3qpMFisbRlO4iIiNoUxzTIZ/My0kRERJ0SKw2y2fzAKiIiIlImVhqIiEgZWGmQjUkDEREpAsc0yMfuCSIiIrIKKw1ERKQM7J6QjUkDEREpArsn5GP3BBEREVmFlQYiIlIGdk/IxqSBiIiUgUmDbOyeICIiIquw0kBERIqg+u8m53ylY9JARETKwO4J2Zg0EBGRInDKpXwc00BERNRGfv75Zzz00EPw8vJC9+7dMXz4cOTm5orHBUHAsmXLoNPp4OrqinHjxuHkyZOSa9TV1WH+/Pnw9vaGm5sbYmNjUVpaKokxGo3Q6/XQarXQarXQ6/W4dOmS3e+HSQMRESmDYIfNBkajEWPGjIGTkxM+/fRTnDp1Ci+//DJ69uwpxqxatQqrV69Geno6jh49Cj8/P9xzzz24fPmyGJOcnIxdu3Zhx44dyMnJQVVVFWJiYmA2m8WY+Ph45OXlITMzE5mZmcjLy4Ner7f1E7ohdk8QEZFy2KGLobKyUvJarVZDrVY3i1u5ciX8/f3x1ltvifv69+//a1MEAWvXrsWSJUswY8YMAMDmzZvh6+uL7du347HHHoPJZMKmTZuwZcsWTJw4EQCwdetW+Pv7Y8+ePYiOjkZBQQEyMzNx6NAhREREAAA2btyIyMhIFBYWIigoSP5N/xcrDURERDbw9/cXuwG0Wi3S0tJajPvggw8wYsQIPPDAA/Dx8UFYWBg2btwoHi8qKoLBYEBUVJS4T61WY+zYsThw4AAAIDc3Fw0NDZIYnU6HkJAQMebgwYPQarViwgAAo0aNglarFWPshZUGIiJSBHsNhCwpKYFGoxH3t1RlAIAff/wR69atw4IFC/C3v/0NR44cQVJSEtRqNR5++GEYDAYAgK+vr+Q8X19fnD17FgBgMBjg7OwMDw+PZjFN5xsMBvj4+DR7fx8fHzHGXpg0EBGRMthpyqVGo5EkDddjsVgwYsQIpKamAgDCwsJw8uRJrFu3Dg8//LAYp1JJV4AQBKHZvmZNuSampXhrrmMrdk8QERG1gd69e2PIkCGSfcHBwSguLgYA+Pn5AUCzakB5eblYffDz80N9fT2MRuPvxpw/f77Z+1dUVDSrYsjFpIGIiBShqXtCzmaLMWPGoLCwULLv9OnT6NevHwAgICAAfn5+yM7OFo/X19dj3759GD16NAAgPDwcTk5OkpiysjLk5+eLMZGRkTCZTDhy5IgYc/jwYZhMJjHGXtg9QUREynCTV4T8y1/+gtGjRyM1NRVxcXE4cuQI3njjDbzxxhsArnYpJCcnIzU1FYGBgQgMDERqaiq6d++O+Ph4AIBWq0VCQgJSUlLg5eUFT09PLFy4EKGhoeJsiuDgYEyaNAmJiYnYsGEDAGDu3LmIiYmx68wJgEkDERFRmxg5ciR27dqFZ555Bs8//zwCAgKwdu1azJo1S4xZvHgxampqMG/ePBiNRkRERCArKwvu7u5izJo1a+Do6Ii4uDjU1NRgwoQJyMjIgIODgxizbds2JCUlibMsYmNjkZ6ebvd7UgmC0GkXxqysrIRWq8UEzUNwVDm3d3OI2kTdyMD2bgJRm2lsrEXO3uUwmUxWDS5sjabvitseSYWDs0urr2Our8W3//pbm7a1o2OlgYiIlIEPrJKNSQMRESkDkwbZOHuCiIiIrMJKAxERKQIfjS0fkwYiIlIGdk/Ixu4JIiIisgorDUREpAgqQYBKxioDcs7tKpg0EBGRMrB7QjZ2TxAREZFVWGkgIiJF4OwJ+Zg0EBGRMrB7QjZ2TxAREZFVWGkgIiJFYPeEfEwaiIhIGdg9IRuTBiIiUgRWGuTjmAYiIiKyCisNRESkDOyekI1JAxERKQa7GORh9wQRERFZhZUGIiJSBkG4usk5X+GYNBARkSJw9oR87J4gIiIiq7DSQEREysDZE7IxaSAiIkVQWa5ucs5XOnZPEBERkVVYaSC4ujVCn3QWoyf+Aq1XA34ocMOGFbfi+3z3ZrFPLf8e9z5owIbUAXj//24BAPjcUouMz4+2eO3UPw9Gzme92rT9RL81dUIBYv/wH/j2qgIAnC3tiS27h+PIt/4AgMVz9yP6rjOSc06d6YX5y6eKr3v7VOLxPx5ByKByODmZcfTbW5D+f5EwVroCAIYNLsPqJZ+2+P7znp2KwiL+zHdI7J6QjUkD4c//+B79Aq/gpaeD8Eu5M/4QW47Ut77D41PC8Uu5WoyLnHABQbddxoXzzpLzL5SpMevOCMm+SXFluD+hFMe+8rwp90DU5MJFN2x8ZwTOndcAAKLu/B7P/+VzPPb3aTj7swcA4Mg3t2DVxrvEcxobHcT/dlE3YNXiz/BDsScWpk0CAPzp/uP454JsPLV8KgRBhZPf++D+p2ZK3vdP/3Mct4ecQ2GRd1vfIrUSZ0/I167dE/v378fUqVOh0+mgUqmwe/fu9myOIjmrzRgTdQH/eikA+ce0KCt2xbb0fjCUumDKH8vEOC+fOjyx9Ae8uCgI5kaV5BoWiwrGC86SbfTEX7D/016oveJw7VsStamDJ/riyDf+KDVoUWrQ4l/vjkBNrSOGDKwQYxoaHWA0dRe3y9W/JsdDA8vh26sKq964C0Wlnigq9cSqN+7C4FsvIGzIOQBAo1l6fmWVC0bfXozMfYMAqK5tEnUUTes0yNkUrl2ThurqagwbNgzp6ent2QxFc3AU4OAI1NdJf9HV13XDkPBKAIBKJWDhqkLs3NQHxWfcbnjNgUMv49Yh1cja6dcmbSayVjeVBeNH/QgXdSNOff9rl8GwwQa8+7/bsXnVu1jwSA56amrEY85OZkC4mlg0qW9wgNmiQsig8y2+z+iwYmjc6/DZVwPb7maIOoB27Z6YPHkyJk+ebHV8XV0d6urqxNeVlZVt0SxFqal2xKkT7vjjvBKU/Ngdly44Y+yUCgTddhnnzl7tv30gsRRmswrvb9FZdc2o/zmP4jOuKDihacumE11XQJ+LeO25j+DsZEZNrROee2UCzp5r6prog32HA3D+lx7o3esy5vzPcbz0zKd4Yuk0NDQ64NSZXqipc0Tig0ex6f+NgEolIPHBY3DoJsCrZ02L7zd53Gkc++4WVFzscTNvk2zE7gn5OtXsibS0NGi1WnHz9/dv7yZ1CS8tDoJKJWDr/iN4/9scxOp/xt6PesFivlo1iNX/jNXPWFd2dVabMS6mHJ+xykDtqKRMi7lLpuOp5VPxwReD8fTcr9BPZwQA7D08AIe/8cdPpR44eKIvnnkxCn38KhExvAQAYLrsiudf+wMiw0rw0cb/wwcbtsLNtR6ni7xgtjT/N+DtUY0RoT/j072Dbuo9UisIdtgUrlMNhHzmmWewYMEC8XVlZSUTBzswlLjiaf0wqF3N6N7DDGOFM/66ugCGUhcMDa9ET68GbP7iiBjv4Ag8+vSPmD77Z/xpwh2Sa90ZfQFqFws+3+1zs2+DSNRodsC58quVrtNF3ggKqMCM6FNY89aYZrEXTd1x/kIP9PH9tXKZm38L9AsfgKZHLcwWFaqvqPH/Xvs3DBXNZxRNuvt7VFapceBE37a7IaIOolMlDWq1Gmq1+saB1Cp1NQ6oq3FAD00Dbr/TiH+9FICvs7yRd7CnJO4fb+bji/d9kL3Lt9k1ou4/j8NfeqLS6NzsGFF7UakAJydzi8c0PWrh41mNXy65NjtWWeUCABg+5Bx6ampw4Pi1iYGA6LtPIztnIMzmTlW4VSR2T8jXqZIGahu332mECgJKi7pD168Gjywqws9F3ZH9ni/Mjd1w+ZKTJN7ceHW2xM9F3SX7e/etQcgIE56bO/RmNp9IIuGBYzjyTR+UX3RDd5cGjB/1I4YFG/DMi1FwUTdg9owT+Opof/xyyRV+3lVIiMuFqUqNnNz+4jWi7zqN4nM9cemyC4YOLMeTDx3GzsyhKDVoJe8VNqQMOp8qfLqPXROdAp9yKRtTY4Jbj0bMe/YHvPHpMaS8UIhTxzVYkhACc6NtPx5R/3Mev5x3xvGvPdqopUQ35qGtwV8f34+MVTvx4jOZGHxrBZ55MQq5+bfAYlEhoI8Rz/9lDza/uBNPP7YfpQYN5i+PQU3tr8mxf28Tnk/+HG+tfA/66XnY9sEwrP/3Hc3ea/LY08g/7YPicz1v4h1SZ5SWlgaVSoXk5GRxnyAIWLZsGXQ6HVxdXTFu3DicPHlScl5dXR3mz58Pb29vuLm5ITY2FqWlpZIYo9EIvV4vjvfT6/W4dOlSm9yHShDaL3WqqqrCmTNXV2YLCwvD6tWrMX78eHh6eqJv3xv3D1ZWVkKr1WKC5iE4qlgOp66pbmRgezeBqM00NtYiZ+9ymEwmaDRtM+Oq6bsicvLzcHRyafV1GhtqcfDTZ21u69GjRxEXFweNRoPx48dj7dq1AICVK1dixYoVyMjIwKBBg/DPf/4T+/fvR2FhIdzdr46feeKJJ/Dhhx8iIyMDXl5eSElJwcWLF5GbmwsHh6vTgidPnozS0lK88cYbAIC5c+eif//++PDDD1t9r9fTrpWGY8eOISwsDGFhYQCABQsWICwsDM8++2x7NouIiLqidpg9UVVVhVmzZmHjxo3w8Pi1CisIAtauXYslS5ZgxowZCAkJwebNm3HlyhVs374dAGAymbBp0ya8/PLLmDhxIsLCwrB161Z899132LNnDwCgoKAAmZmZePPNNxEZGYnIyEhs3LgRH330EQoLC1v1Mf2edk0axo0bB0EQmm0ZGRnt2SwiIqLrqqyslGy/XT/oWk8++SSmTJmCiRMnSvYXFRXBYDAgKipK3KdWqzF27FgcOHAAAJCbm4uGhgZJjE6nQ0hIiBhz8OBBaLVaRET8upT/qFGjoNVqxRh74pgGIiJShKbZE3I2APD395esGZSWltbi++3YsQPHjx9v8bjBYAAA+PpKZ6H5+vqKxwwGA5ydnSUVipZifHyaT3H38fERY+yJsyeIiEgZLMLVTc75AEpKSiRjGlpaCqCkpAR//vOfkZWVBReX64+jUKmkC4YJgtBs37WujWkp3prrtAYrDUREpAx2GtOg0WgkW0tJQ25uLsrLyxEeHg5HR0c4Ojpi3759ePXVV+Ho6ChWGK6tBpSXl4vH/Pz8UF9fD6PR+Lsx5883fyZKRUVFsyqGPTBpICIisrMJEybgu+++Q15enriNGDECs2bNQl5eHgYMGAA/Pz9kZ2eL59TX12Pfvn0YPXo0ACA8PBxOTk6SmLKyMuTn54sxkZGRMJlMOHLk11V7Dx8+DJPJJMbYE7sniIhIEVSQuSKkDbHu7u4ICQmR7HNzc4OXl5e4Pzk5GampqQgMDERgYCBSU1PRvXt3xMfHAwC0Wi0SEhKQkpICLy8veHp6YuHChQgNDRUHVgYHB2PSpElITEzEhg0bAFydchkTE4OgoKDW3+x1MGkgIiJl6GArQi5evBg1NTWYN28ejEYjIiIikJWVJa7RAABr1qyBo6Mj4uLiUFNTgwkTJiAjI0NcowEAtm3bhqSkJHGWRWxsLNLT0+3a1ibturiTXFzciZSAiztRV3YzF3caM2EZHB1lLO7UWIuvP1/Wpm3t6FhpICIiReADq+Rj0kBERMrQylUdJecrHGdPEBERkVVYaSAiIkVQCQJUMobxyTm3q2DSQEREymD57ybnfIVj9wQRERFZhZUGIiJSBHZPyMekgYiIlIGzJ2Rj0kBERMrQwVaE7Iw4poGIiIiswkoDEREpAleElI9JAxERKQO7J2Rj9wQRERFZhZUGIiJSBJXl6ibnfKVj0kBERMrA7gnZ2D1BREREVmGlgYiIlIGLO8nGpIGIiBSBy0jLx+4JIiIisgorDUREpAwcCCkbkwYiIlIGAYCcaZPMGZg0EBGRMnBMg3wc00BERERWYaWBiIiUQYDMMQ12a0mnxaSBiIiUgQMhZWP3BBEREVmFlQYiIlIGCwCVzPMVjkkDEREpAmdPyMfuCSIiIrIKKw1ERKQMHAgpG5MGIiJSBiYNsrF7goiIiKzCSgMRESkDKw2yMWkgIiJl4JRL2dg9QUREitA05VLOZou0tDSMHDkS7u7u8PHxwfTp01FYWCiJEQQBy5Ytg06ng6urK8aNG4eTJ09KYurq6jB//nx4e3vDzc0NsbGxKC0tlcQYjUbo9XpotVpotVro9XpcunSpVZ/T72HSQERE1Ab27duHJ598EocOHUJ2djYaGxsRFRWF6upqMWbVqlVYvXo10tPTcfToUfj5+eGee+7B5cuXxZjk5GTs2rULO3bsQE5ODqqqqhATEwOz2SzGxMfHIy8vD5mZmcjMzEReXh70er3d74ndE0REpAw3eUxDZmam5PVbb70FHx8f5Obm4u6774YgCFi7di2WLFmCGTNmAAA2b94MX19fbN++HY899hhMJhM2bdqELVu2YOLEiQCArVu3wt/fH3v27EF0dDQKCgqQmZmJQ4cOISIiAgCwceNGREZGorCwEEFBQa2/52uw0kBERMpgEeRvACorKyVbXV2dVW9vMpkAAJ6engCAoqIiGAwGREVFiTFqtRpjx47FgQMHAAC5ubloaGiQxOh0OoSEhIgxBw8ehFarFRMGABg1ahS0Wq0YYy9MGoiIiGzg7+8vjh3QarVIS0u74TmCIGDBggW48847ERISAgAwGAwAAF9fX0msr6+veMxgMMDZ2RkeHh6/G+Pj49PsPX18fMQYe2H3BBERKYOduidKSkqg0WjE3Wq1+oanPvXUU/j222+Rk5PT7JhKJZ3SIQhCs33NmyKNaSnemuvYipUGIiJSCOHXxKE1G64mDRqNRrLdKGmYP38+PvjgA3z55Zfo06ePuN/Pzw8AmlUDysvLxeqDn58f6uvrYTQafzfm/Pnzzd63oqKiWRVDLiYNREREbUAQBDz11FN477338MUXXyAgIEByPCAgAH5+fsjOzhb31dfXY9++fRg9ejQAIDw8HE5OTpKYsrIy5OfnizGRkZEwmUw4cuSIGHP48GGYTCYxxl7YPUFERMpwk2dPPPnkk9i+fTvef/99uLu7ixUFrVYLV1dXqFQqJCcnIzU1FYGBgQgMDERqaiq6d++O+Ph4MTYhIQEpKSnw8vKCp6cnFi5ciNDQUHE2RXBwMCZNmoTExERs2LABADB37lzExMTYdeYEwKSBiIiUwvJrF0Prz7feunXrAADjxo2T7H/rrbcwZ84cAMDixYtRU1ODefPmwWg0IiIiAllZWXB3dxfj16xZA0dHR8TFxaGmpgYTJkxARkYGHBwcxJht27YhKSlJnGURGxuL9PT0Vtzk71MJQuddTLuyshJarRYTNA/BUeXc3s0hahN1IwPbuwlEbaaxsRY5e5fDZDJJBhfaU9N3xcR+T8Gx240HLV5Po6UOe86mt2lbOzpWGoiISBkEy9VNzvkKx6SBiIiUgU+5lI1JAxERKcNNHtPQFXHKJREREVmFlQYiIlIGdk/IxqSBiIiUQYDMpMFuLem02D1BREREVmGlgYiIlIHdE7IxaSAiImWwWADIWGvBwnUa2D1BREREVmGlgYiIlIHdE7IxaSAiImVg0iAbuyeIiIjIKqw0EBGRMnAZadmYNBARkSIIggWCjCdVyjm3q2DSQEREyiAI8qoFHNPAMQ1ERERkHVYaiIhIGQSZYxpYaWDSQERECmGxACoZ4xI4poHdE0RERGQdVhqIiEgZ2D0hG5MGIiJSBMFigSCje4JTLtk9QURERFZipYGIiJSB3ROyMWkgIiJlsAiAikmDHOyeICIiIquw0kBERMogCADkrNPASgOTBiIiUgTBIkCQ0T0hMGlg0kBERAohWCCv0sAplxzTQERERFZhpYGIiBSB3RPyMWkgIiJlYPeEbJ06aWjK+hqF+nZuCVHbaWysbe8mELWZxsY6ADfnr/hGNMha26kRDfZrTCfVqZOGy5cvAwD2XX6nnVtC1Ib2tncDiNre5cuXodVq2+Tazs7O8PPzQ47hE9nX8vPzg7Ozsx1a1TmphE7cSWOxWHDu3Dm4u7tDpVK1d3MUobKyEv7+/igpKYFGo2nv5hDZFX++bz5BEHD58mXodDp069Z2Y/Nra2tRXy+/Ku3s7AwXFxc7tKhz6tSVhm7duqFPnz7t3QxF0mg0/KVKXRZ/vm+utqow/JaLi4uiv+zthVMuiYiIyCpMGoiIiMgqTBrIJmq1Gs899xzUanV7N4XI7vjzTfT7OvVASCIiIrp5WGkgIiIiqzBpICIiIqswaSAiIiKrMGkgIiIiqzBpIKu9/vrrCAgIgIuLC8LDw/HVV1+1d5OI7GL//v2YOnUqdDodVCoVdu/e3d5NIuqQmDSQVd5++20kJydjyZIlOHHiBO666y5MnjwZxcXF7d00Itmqq6sxbNgwpKent3dTiDo0Trkkq0REROD222/HunXrxH3BwcGYPn060tLS2rFlRPalUqmwa9cuTJ8+vb2bQtThsNJAN1RfX4/c3FxERUVJ9kdFReHAgQPt1CoiIrrZmDTQDV24cAFmsxm+vr6S/b6+vjAYDO3UKiIiutmYNJDVrn38uCAIfCQ5EZGCMGmgG/L29oaDg0OzqkJ5eXmz6gMREXVdTBrohpydnREeHo7s7GzJ/uzsbIwePbqdWkVERDebY3s3gDqHBQsWQK/XY8SIEYiMjMQbb7yB4uJiPP744+3dNCLZqqqqcObMGfF1UVER8vLy4Onpib59+7Zjy4g6Fk65JKu9/vrrWLVqFcrKyhASEoI1a9bg7rvvbu9mEcm2d+9ejB8/vtn+2bNnIyMj4+Y3iKiDYtJAREREVuGYBiIiIrIKkwYiIiKyCpMGIiIisgqTBiIiIrIKkwYiIiKyCpMGIiIisgqTBiIiIrIKkwYiIiKyCpMGIpmWLVuG4cOHi6/nzJmD6dOn3/R2/PTTT1CpVMjLy7tuTP/+/bF27Vqrr5mRkYGePXvKbptKpcLu3btlX4eI2heTBuqS5syZA5VKBZVKBScnJwwYMAALFy5EdXV1m7/3K6+8YvXSw9Z80RMRdRR8YBV1WZMmTcJbb72FhoYGfPXVV3j00UdRXV2NdevWNYttaGiAk5OTXd5Xq9Xa5TpERB0NKw3UZanVavj5+cHf3x/x8fGYNWuWWCJv6lL417/+hQEDBkCtVkMQBJhMJsydOxc+Pj7QaDT4wx/+gG+++UZy3RdeeAG+vr5wd3dHQkICamtrJcev7Z6wWCxYuXIlBg4cCLVajb59+2LFihUAgICAAABAWFgYVCoVxo0bJ5731ltvITg4GC4uLhg8eDBef/11yfscOXIEYWFhcHFxwYgRI3DixAmbP6PVq1cjNDQUbm5u8Pf3x7x581BVVdUsbvfu3Rg0aBBcXFxwzz33oKSkRHL8ww8/RHh4OFxcXDBgwAAsX74cjY2NNreHiDo2Jg2kGK6urmhoaBBfnzlzBu+88w527twpdg9MmTIFBoMBn3zyCXJzc3H77bdjwoQJuHjxIgDgnXfewXPPPYcVK1bg2LFj6N27d7Mv82s988wzWLlyJZYuXYpTp05h+/bt8PX1BXD1ix8A9uzZg7KyMrz33nsAgI0bN2LJkiVYsWIFCgoKkJqaiqVLl2Lz5s0AgOrqasTExCAoKAi5ublYtmwZFi5caPNn0q1bN7z66qvIz8/H5s2b8cUXX2Dx4sWSmCtXrmDFihXYvHkzvv76a1RWVmLmzJni8c8++wwPPfQQkpKScOrUKWzYsAEZGRliYkREXYhA1AXNnj1bmDZtmvj68OHDgpeXlxAXFycIgiA899xzgpOTk1BeXi7GfP7554JGoxFqa2sl17r11luFDRs2CIIgCJGRkcLjjz8uOR4RESEMGzasxfeurKwU1Gq1sHHjxhbbWVRUJAAQTpw4Idnv7+8vbN++XbLvH//4hxAZGSkIgiBs2LBB8PT0FKqrq8Xj69ata/Fav9WvXz9hzZo11z3+zjvvCF5eXuLrt956SwAgHDp0SNxXUFAgABAOHz4sCIIg3HXXXUJqaqrkOlu2bBF69+4tvgYg7Nq167rvS0SdA8c0UJf10UcfoUePHmhsbERDQwOmTZuG1157TTzer18/9OrVS3ydm5uLqqoqeHl5Sa5TU1ODH374AQBQUFCAxx9/XHI8MjISX375ZYttKCgoQF1dHSZMmGB1uysqKlBSUoKEhAQkJiaK+xsbG8XxEgUFBRg2bBi6d+8uaYetvvzyS6SmpuLUqVOorKxEY2MjamtrUV1dDTc3NwCAo6MjRowYIZ4zePBg9OzZEwUFBbjjjjuQm5uLo0ePSioLZrMZtbW1uHLliqSNRNS5MWmgLmv8+PFYt24dnJycoNPpmg10bPpSbGKxWNC7d2/s3bu32bVaO+3Q1dXV5nMsFguAq10UERERkmMODg4AAEEQWtWe3zp79izuvfdePP744/jHP/4BT09P5OTkICEhQdKNA1ydMnmtpn0WiwXLly/HjBkzmsW4uLjIbicRdRxMGqjLcnNzw8CBA62Ov/3222EwGODo6Ij+/fu3GBMcHIxDhw7h4YcfFvcdOnToutcMDAyEq6srPv/8czz66KPNjjs7OwO4+pd5E19fX9xyyy348ccfMWvWrBavO2TIEGzZsgU1NTViYvJ77WjJsWPH0NjYiJdffhndul0d3vTOO+80i2tsbMSxY8dwxx13AAAKCwtx6dIlDB48GMDVz62wsNCmz5qIOicmDUT/NXHiRERGRmL69OlYuXIlgoKCcO7cOXzyySeYPn06RowYgT//+c+YPXs2RowYgTvvvBPbtm3DyZMnMWDAgBav6eLigqeffhqLFy+Gs7MzxowZg4qKCpw8eRIJCQnw8fGBq6srMjMz0adPH7i4uECr1WLZsmVISkqCRqPB5MmTUVdXh2PHjsFoNGLBggWIj4/HkiVLkJCQgL///e/46aef8NJLL9l0v7feeisaGxvx2muvYerUqfj666+xfv36ZnFOTk6YP38+Xn31VTg5OeGpp57CqFGjxCTi2WefRUxMDPz9/fHAAw+gW7du+Pbbb/Hdd9/hn//8p+3/I4iow+LsCaL/UqlU+OSTT3D33XfjkUcewaBBgzBz5kz89NNP4myHBx98EM8++yyefvpphIeH4+zZs3jiiSd+97pLly5FSkoKnn32WQQHB+PBBx9EeXk5gKvjBV599VVs2LABOp0O06ZNAwA8+uijePPNN5GRkYHQ0FCMHTsWGRkZ4hTNHj164MMPP8SpU6cQFhaGJUuWYOXKlTbd7/Dhw7F69WqsXLkSISEh2LZtG9LS0prFde/eHU8//TTi4+MRGRkJV1dX7NixQzweHR2Njz76CNnZ2Rg5ciRGjRqF1atXo1+/fja1h4g6PpVgj85RIiIi6vJYaSAiIiKrMGkgIiIiqzBpICIiIqswaSAiIiKrMGkgIiIiqzBpICIiIqswaSAiIiKrMGkgIiIiqzBpICIiIqswaSAiIiKrMGkgIiIiq/x/EfOBY0EStLAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params\n",
    "display_cv(best_model_XGB,cleaned_data , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.032702\n",
      "0:\tlearn: 0.6696002\ttotal: 155ms\tremaining: 2m 34s\n",
      "1:\tlearn: 0.6477958\ttotal: 160ms\tremaining: 1m 20s\n",
      "2:\tlearn: 0.6261034\ttotal: 166ms\tremaining: 55.1s\n",
      "3:\tlearn: 0.6065678\ttotal: 171ms\tremaining: 42.6s\n",
      "4:\tlearn: 0.5882760\ttotal: 177ms\tremaining: 35.2s\n",
      "5:\tlearn: 0.5717004\ttotal: 182ms\tremaining: 30.2s\n",
      "6:\tlearn: 0.5586073\ttotal: 188ms\tremaining: 26.6s\n",
      "7:\tlearn: 0.5450499\ttotal: 193ms\tremaining: 24s\n",
      "8:\tlearn: 0.5322933\ttotal: 199ms\tremaining: 21.9s\n",
      "9:\tlearn: 0.5208610\ttotal: 204ms\tremaining: 20.2s\n",
      "10:\tlearn: 0.5089577\ttotal: 211ms\tremaining: 18.9s\n",
      "11:\tlearn: 0.4984601\ttotal: 218ms\tremaining: 18s\n",
      "12:\tlearn: 0.4887901\ttotal: 225ms\tremaining: 17.1s\n",
      "13:\tlearn: 0.4804599\ttotal: 231ms\tremaining: 16.3s\n",
      "14:\tlearn: 0.4731180\ttotal: 237ms\tremaining: 15.6s\n",
      "15:\tlearn: 0.4662764\ttotal: 242ms\tremaining: 14.9s\n",
      "16:\tlearn: 0.4598359\ttotal: 248ms\tremaining: 14.3s\n",
      "17:\tlearn: 0.4530180\ttotal: 253ms\tremaining: 13.8s\n",
      "18:\tlearn: 0.4470459\ttotal: 259ms\tremaining: 13.4s\n",
      "19:\tlearn: 0.4420148\ttotal: 264ms\tremaining: 12.9s\n",
      "20:\tlearn: 0.4367089\ttotal: 269ms\tremaining: 12.5s\n",
      "21:\tlearn: 0.4321223\ttotal: 274ms\tremaining: 12.2s\n",
      "22:\tlearn: 0.4277835\ttotal: 280ms\tremaining: 11.9s\n",
      "23:\tlearn: 0.4235960\ttotal: 285ms\tremaining: 11.6s\n",
      "24:\tlearn: 0.4201645\ttotal: 290ms\tremaining: 11.3s\n",
      "25:\tlearn: 0.4163754\ttotal: 296ms\tremaining: 11.1s\n",
      "26:\tlearn: 0.4129319\ttotal: 301ms\tremaining: 10.8s\n",
      "27:\tlearn: 0.4098340\ttotal: 306ms\tremaining: 10.6s\n",
      "28:\tlearn: 0.4067465\ttotal: 312ms\tremaining: 10.4s\n",
      "29:\tlearn: 0.4043889\ttotal: 317ms\tremaining: 10.3s\n",
      "30:\tlearn: 0.4019581\ttotal: 323ms\tremaining: 10.1s\n",
      "31:\tlearn: 0.4001108\ttotal: 329ms\tremaining: 9.96s\n",
      "32:\tlearn: 0.3977967\ttotal: 336ms\tremaining: 9.85s\n",
      "33:\tlearn: 0.3957489\ttotal: 342ms\tremaining: 9.72s\n",
      "34:\tlearn: 0.3937160\ttotal: 349ms\tremaining: 9.61s\n",
      "35:\tlearn: 0.3920165\ttotal: 356ms\tremaining: 9.52s\n",
      "36:\tlearn: 0.3900744\ttotal: 362ms\tremaining: 9.43s\n",
      "37:\tlearn: 0.3882896\ttotal: 369ms\tremaining: 9.33s\n",
      "38:\tlearn: 0.3870599\ttotal: 375ms\tremaining: 9.24s\n",
      "39:\tlearn: 0.3856433\ttotal: 382ms\tremaining: 9.16s\n",
      "40:\tlearn: 0.3843830\ttotal: 387ms\tremaining: 9.05s\n",
      "41:\tlearn: 0.3832240\ttotal: 392ms\tremaining: 8.94s\n",
      "42:\tlearn: 0.3822243\ttotal: 398ms\tremaining: 8.85s\n",
      "43:\tlearn: 0.3809764\ttotal: 403ms\tremaining: 8.75s\n",
      "44:\tlearn: 0.3796500\ttotal: 408ms\tremaining: 8.66s\n",
      "45:\tlearn: 0.3783759\ttotal: 415ms\tremaining: 8.6s\n",
      "46:\tlearn: 0.3772225\ttotal: 421ms\tremaining: 8.54s\n",
      "47:\tlearn: 0.3762011\ttotal: 428ms\tremaining: 8.48s\n",
      "48:\tlearn: 0.3750683\ttotal: 433ms\tremaining: 8.41s\n",
      "49:\tlearn: 0.3742183\ttotal: 439ms\tremaining: 8.34s\n",
      "50:\tlearn: 0.3730835\ttotal: 445ms\tremaining: 8.28s\n",
      "51:\tlearn: 0.3723398\ttotal: 451ms\tremaining: 8.22s\n",
      "52:\tlearn: 0.3715044\ttotal: 456ms\tremaining: 8.15s\n",
      "53:\tlearn: 0.3707628\ttotal: 462ms\tremaining: 8.09s\n",
      "54:\tlearn: 0.3700164\ttotal: 467ms\tremaining: 8.02s\n",
      "55:\tlearn: 0.3693015\ttotal: 473ms\tremaining: 7.97s\n",
      "56:\tlearn: 0.3685829\ttotal: 479ms\tremaining: 7.92s\n",
      "57:\tlearn: 0.3678890\ttotal: 484ms\tremaining: 7.86s\n",
      "58:\tlearn: 0.3670811\ttotal: 490ms\tremaining: 7.81s\n",
      "59:\tlearn: 0.3664829\ttotal: 495ms\tremaining: 7.75s\n",
      "60:\tlearn: 0.3657904\ttotal: 500ms\tremaining: 7.7s\n",
      "61:\tlearn: 0.3651891\ttotal: 506ms\tremaining: 7.66s\n",
      "62:\tlearn: 0.3646277\ttotal: 511ms\tremaining: 7.61s\n",
      "63:\tlearn: 0.3640327\ttotal: 517ms\tremaining: 7.56s\n",
      "64:\tlearn: 0.3634250\ttotal: 523ms\tremaining: 7.52s\n",
      "65:\tlearn: 0.3628486\ttotal: 528ms\tremaining: 7.47s\n",
      "66:\tlearn: 0.3623882\ttotal: 533ms\tremaining: 7.42s\n",
      "67:\tlearn: 0.3618802\ttotal: 539ms\tremaining: 7.38s\n",
      "68:\tlearn: 0.3614342\ttotal: 544ms\tremaining: 7.34s\n",
      "69:\tlearn: 0.3608825\ttotal: 549ms\tremaining: 7.3s\n",
      "70:\tlearn: 0.3605388\ttotal: 555ms\tremaining: 7.26s\n",
      "71:\tlearn: 0.3600200\ttotal: 560ms\tremaining: 7.21s\n",
      "72:\tlearn: 0.3596056\ttotal: 565ms\tremaining: 7.17s\n",
      "73:\tlearn: 0.3591538\ttotal: 570ms\tremaining: 7.13s\n",
      "74:\tlearn: 0.3586070\ttotal: 575ms\tremaining: 7.09s\n",
      "75:\tlearn: 0.3582325\ttotal: 581ms\tremaining: 7.06s\n",
      "76:\tlearn: 0.3578137\ttotal: 586ms\tremaining: 7.02s\n",
      "77:\tlearn: 0.3574837\ttotal: 591ms\tremaining: 6.99s\n",
      "78:\tlearn: 0.3570918\ttotal: 597ms\tremaining: 6.96s\n",
      "79:\tlearn: 0.3567663\ttotal: 602ms\tremaining: 6.92s\n",
      "80:\tlearn: 0.3564230\ttotal: 607ms\tremaining: 6.89s\n",
      "81:\tlearn: 0.3560918\ttotal: 613ms\tremaining: 6.86s\n",
      "82:\tlearn: 0.3557308\ttotal: 621ms\tremaining: 6.86s\n",
      "83:\tlearn: 0.3552506\ttotal: 628ms\tremaining: 6.84s\n",
      "84:\tlearn: 0.3549082\ttotal: 633ms\tremaining: 6.81s\n",
      "85:\tlearn: 0.3545258\ttotal: 639ms\tremaining: 6.79s\n",
      "86:\tlearn: 0.3541843\ttotal: 644ms\tremaining: 6.76s\n",
      "87:\tlearn: 0.3539200\ttotal: 649ms\tremaining: 6.73s\n",
      "88:\tlearn: 0.3535885\ttotal: 654ms\tremaining: 6.7s\n",
      "89:\tlearn: 0.3532116\ttotal: 661ms\tremaining: 6.68s\n",
      "90:\tlearn: 0.3530107\ttotal: 666ms\tremaining: 6.66s\n",
      "91:\tlearn: 0.3527089\ttotal: 672ms\tremaining: 6.63s\n",
      "92:\tlearn: 0.3523680\ttotal: 678ms\tremaining: 6.61s\n",
      "93:\tlearn: 0.3520550\ttotal: 683ms\tremaining: 6.58s\n",
      "94:\tlearn: 0.3518044\ttotal: 688ms\tremaining: 6.55s\n",
      "95:\tlearn: 0.3515233\ttotal: 693ms\tremaining: 6.53s\n",
      "96:\tlearn: 0.3512801\ttotal: 699ms\tremaining: 6.5s\n",
      "97:\tlearn: 0.3510744\ttotal: 704ms\tremaining: 6.48s\n",
      "98:\tlearn: 0.3508416\ttotal: 709ms\tremaining: 6.45s\n",
      "99:\tlearn: 0.3506734\ttotal: 714ms\tremaining: 6.43s\n",
      "100:\tlearn: 0.3504473\ttotal: 719ms\tremaining: 6.4s\n",
      "101:\tlearn: 0.3501403\ttotal: 725ms\tremaining: 6.38s\n",
      "102:\tlearn: 0.3497909\ttotal: 730ms\tremaining: 6.36s\n",
      "103:\tlearn: 0.3494448\ttotal: 735ms\tremaining: 6.33s\n",
      "104:\tlearn: 0.3492375\ttotal: 741ms\tremaining: 6.31s\n",
      "105:\tlearn: 0.3490473\ttotal: 746ms\tremaining: 6.29s\n",
      "106:\tlearn: 0.3487712\ttotal: 751ms\tremaining: 6.27s\n",
      "107:\tlearn: 0.3485247\ttotal: 757ms\tremaining: 6.25s\n",
      "108:\tlearn: 0.3482679\ttotal: 762ms\tremaining: 6.23s\n",
      "109:\tlearn: 0.3480456\ttotal: 767ms\tremaining: 6.21s\n",
      "110:\tlearn: 0.3478603\ttotal: 772ms\tremaining: 6.18s\n",
      "111:\tlearn: 0.3476629\ttotal: 778ms\tremaining: 6.17s\n",
      "112:\tlearn: 0.3474160\ttotal: 783ms\tremaining: 6.15s\n",
      "113:\tlearn: 0.3472380\ttotal: 789ms\tremaining: 6.13s\n",
      "114:\tlearn: 0.3470652\ttotal: 795ms\tremaining: 6.12s\n",
      "115:\tlearn: 0.3468028\ttotal: 802ms\tremaining: 6.11s\n",
      "116:\tlearn: 0.3465270\ttotal: 808ms\tremaining: 6.1s\n",
      "117:\tlearn: 0.3463207\ttotal: 813ms\tremaining: 6.08s\n",
      "118:\tlearn: 0.3461235\ttotal: 820ms\tremaining: 6.07s\n",
      "119:\tlearn: 0.3458381\ttotal: 827ms\tremaining: 6.06s\n",
      "120:\tlearn: 0.3455957\ttotal: 834ms\tremaining: 6.06s\n",
      "121:\tlearn: 0.3453244\ttotal: 841ms\tremaining: 6.05s\n",
      "122:\tlearn: 0.3451258\ttotal: 852ms\tremaining: 6.08s\n",
      "123:\tlearn: 0.3448967\ttotal: 859ms\tremaining: 6.07s\n",
      "124:\tlearn: 0.3447065\ttotal: 866ms\tremaining: 6.06s\n",
      "125:\tlearn: 0.3445245\ttotal: 872ms\tremaining: 6.05s\n",
      "126:\tlearn: 0.3443511\ttotal: 879ms\tremaining: 6.04s\n",
      "127:\tlearn: 0.3441255\ttotal: 885ms\tremaining: 6.03s\n",
      "128:\tlearn: 0.3439134\ttotal: 891ms\tremaining: 6.02s\n",
      "129:\tlearn: 0.3437078\ttotal: 897ms\tremaining: 6s\n",
      "130:\tlearn: 0.3434466\ttotal: 902ms\tremaining: 5.98s\n",
      "131:\tlearn: 0.3431919\ttotal: 907ms\tremaining: 5.96s\n",
      "132:\tlearn: 0.3429701\ttotal: 913ms\tremaining: 5.95s\n",
      "133:\tlearn: 0.3427551\ttotal: 918ms\tremaining: 5.93s\n",
      "134:\tlearn: 0.3426637\ttotal: 924ms\tremaining: 5.92s\n",
      "135:\tlearn: 0.3424940\ttotal: 930ms\tremaining: 5.91s\n",
      "136:\tlearn: 0.3423057\ttotal: 936ms\tremaining: 5.89s\n",
      "137:\tlearn: 0.3420722\ttotal: 941ms\tremaining: 5.88s\n",
      "138:\tlearn: 0.3418436\ttotal: 947ms\tremaining: 5.87s\n",
      "139:\tlearn: 0.3416353\ttotal: 953ms\tremaining: 5.86s\n",
      "140:\tlearn: 0.3414220\ttotal: 960ms\tremaining: 5.85s\n",
      "141:\tlearn: 0.3412827\ttotal: 968ms\tremaining: 5.85s\n",
      "142:\tlearn: 0.3410881\ttotal: 975ms\tremaining: 5.84s\n",
      "143:\tlearn: 0.3408740\ttotal: 982ms\tremaining: 5.84s\n",
      "144:\tlearn: 0.3406202\ttotal: 989ms\tremaining: 5.83s\n",
      "145:\tlearn: 0.3403692\ttotal: 996ms\tremaining: 5.82s\n",
      "146:\tlearn: 0.3402263\ttotal: 1s\tremaining: 5.82s\n",
      "147:\tlearn: 0.3399836\ttotal: 1.01s\tremaining: 5.81s\n",
      "148:\tlearn: 0.3397857\ttotal: 1.01s\tremaining: 5.8s\n",
      "149:\tlearn: 0.3395563\ttotal: 1.02s\tremaining: 5.79s\n",
      "150:\tlearn: 0.3394105\ttotal: 1.03s\tremaining: 5.78s\n",
      "151:\tlearn: 0.3392087\ttotal: 1.03s\tremaining: 5.78s\n",
      "152:\tlearn: 0.3390330\ttotal: 1.04s\tremaining: 5.77s\n",
      "153:\tlearn: 0.3388784\ttotal: 1.05s\tremaining: 5.76s\n",
      "154:\tlearn: 0.3386684\ttotal: 1.05s\tremaining: 5.76s\n",
      "155:\tlearn: 0.3385298\ttotal: 1.06s\tremaining: 5.75s\n",
      "156:\tlearn: 0.3384055\ttotal: 1.07s\tremaining: 5.74s\n",
      "157:\tlearn: 0.3382347\ttotal: 1.07s\tremaining: 5.73s\n",
      "158:\tlearn: 0.3381171\ttotal: 1.08s\tremaining: 5.72s\n",
      "159:\tlearn: 0.3379732\ttotal: 1.09s\tremaining: 5.71s\n",
      "160:\tlearn: 0.3377676\ttotal: 1.09s\tremaining: 5.7s\n",
      "161:\tlearn: 0.3375817\ttotal: 1.1s\tremaining: 5.69s\n",
      "162:\tlearn: 0.3374269\ttotal: 1.11s\tremaining: 5.68s\n",
      "163:\tlearn: 0.3373202\ttotal: 1.11s\tremaining: 5.67s\n",
      "164:\tlearn: 0.3371485\ttotal: 1.12s\tremaining: 5.67s\n",
      "165:\tlearn: 0.3370140\ttotal: 1.13s\tremaining: 5.65s\n",
      "166:\tlearn: 0.3368070\ttotal: 1.13s\tremaining: 5.64s\n",
      "167:\tlearn: 0.3366023\ttotal: 1.14s\tremaining: 5.63s\n",
      "168:\tlearn: 0.3363448\ttotal: 1.14s\tremaining: 5.61s\n",
      "169:\tlearn: 0.3361444\ttotal: 1.15s\tremaining: 5.6s\n",
      "170:\tlearn: 0.3359980\ttotal: 1.15s\tremaining: 5.59s\n",
      "171:\tlearn: 0.3357934\ttotal: 1.16s\tremaining: 5.58s\n",
      "172:\tlearn: 0.3355873\ttotal: 1.17s\tremaining: 5.57s\n",
      "173:\tlearn: 0.3354277\ttotal: 1.17s\tremaining: 5.56s\n",
      "174:\tlearn: 0.3352756\ttotal: 1.18s\tremaining: 5.54s\n",
      "175:\tlearn: 0.3350969\ttotal: 1.18s\tremaining: 5.53s\n",
      "176:\tlearn: 0.3349713\ttotal: 1.19s\tremaining: 5.52s\n",
      "177:\tlearn: 0.3348654\ttotal: 1.19s\tremaining: 5.5s\n",
      "178:\tlearn: 0.3347044\ttotal: 1.2s\tremaining: 5.49s\n",
      "179:\tlearn: 0.3345379\ttotal: 1.2s\tremaining: 5.48s\n",
      "180:\tlearn: 0.3343979\ttotal: 1.21s\tremaining: 5.47s\n",
      "181:\tlearn: 0.3342873\ttotal: 1.21s\tremaining: 5.45s\n",
      "182:\tlearn: 0.3341286\ttotal: 1.22s\tremaining: 5.44s\n",
      "183:\tlearn: 0.3339707\ttotal: 1.22s\tremaining: 5.43s\n",
      "184:\tlearn: 0.3337297\ttotal: 1.23s\tremaining: 5.42s\n",
      "185:\tlearn: 0.3335972\ttotal: 1.24s\tremaining: 5.41s\n",
      "186:\tlearn: 0.3334537\ttotal: 1.24s\tremaining: 5.4s\n",
      "187:\tlearn: 0.3333460\ttotal: 1.25s\tremaining: 5.39s\n",
      "188:\tlearn: 0.3331962\ttotal: 1.25s\tremaining: 5.38s\n",
      "189:\tlearn: 0.3330148\ttotal: 1.26s\tremaining: 5.37s\n",
      "190:\tlearn: 0.3328877\ttotal: 1.26s\tremaining: 5.36s\n",
      "191:\tlearn: 0.3327623\ttotal: 1.27s\tremaining: 5.35s\n",
      "192:\tlearn: 0.3326797\ttotal: 1.27s\tremaining: 5.33s\n",
      "193:\tlearn: 0.3325520\ttotal: 1.28s\tremaining: 5.32s\n",
      "194:\tlearn: 0.3324165\ttotal: 1.29s\tremaining: 5.31s\n",
      "195:\tlearn: 0.3322440\ttotal: 1.29s\tremaining: 5.3s\n",
      "196:\tlearn: 0.3321156\ttotal: 1.3s\tremaining: 5.29s\n",
      "197:\tlearn: 0.3319015\ttotal: 1.3s\tremaining: 5.28s\n",
      "198:\tlearn: 0.3317041\ttotal: 1.31s\tremaining: 5.27s\n",
      "199:\tlearn: 0.3315640\ttotal: 1.32s\tremaining: 5.26s\n",
      "200:\tlearn: 0.3314861\ttotal: 1.32s\tremaining: 5.26s\n",
      "201:\tlearn: 0.3313617\ttotal: 1.33s\tremaining: 5.25s\n",
      "202:\tlearn: 0.3312488\ttotal: 1.34s\tremaining: 5.25s\n",
      "203:\tlearn: 0.3310653\ttotal: 1.34s\tremaining: 5.24s\n",
      "204:\tlearn: 0.3309650\ttotal: 1.35s\tremaining: 5.23s\n",
      "205:\tlearn: 0.3307965\ttotal: 1.35s\tremaining: 5.22s\n",
      "206:\tlearn: 0.3306683\ttotal: 1.36s\tremaining: 5.21s\n",
      "207:\tlearn: 0.3305267\ttotal: 1.36s\tremaining: 5.2s\n",
      "208:\tlearn: 0.3304016\ttotal: 1.37s\tremaining: 5.19s\n",
      "209:\tlearn: 0.3302060\ttotal: 1.38s\tremaining: 5.18s\n",
      "210:\tlearn: 0.3300669\ttotal: 1.38s\tremaining: 5.17s\n",
      "211:\tlearn: 0.3298819\ttotal: 1.39s\tremaining: 5.16s\n",
      "212:\tlearn: 0.3297856\ttotal: 1.39s\tremaining: 5.14s\n",
      "213:\tlearn: 0.3296331\ttotal: 1.4s\tremaining: 5.13s\n",
      "214:\tlearn: 0.3295146\ttotal: 1.4s\tremaining: 5.12s\n",
      "215:\tlearn: 0.3293583\ttotal: 1.41s\tremaining: 5.11s\n",
      "216:\tlearn: 0.3291900\ttotal: 1.41s\tremaining: 5.1s\n",
      "217:\tlearn: 0.3290221\ttotal: 1.42s\tremaining: 5.09s\n",
      "218:\tlearn: 0.3288879\ttotal: 1.43s\tremaining: 5.08s\n",
      "219:\tlearn: 0.3287564\ttotal: 1.43s\tremaining: 5.07s\n",
      "220:\tlearn: 0.3286106\ttotal: 1.44s\tremaining: 5.07s\n",
      "221:\tlearn: 0.3284895\ttotal: 1.45s\tremaining: 5.08s\n",
      "222:\tlearn: 0.3283667\ttotal: 1.46s\tremaining: 5.07s\n",
      "223:\tlearn: 0.3282049\ttotal: 1.46s\tremaining: 5.07s\n",
      "224:\tlearn: 0.3280254\ttotal: 1.47s\tremaining: 5.06s\n",
      "225:\tlearn: 0.3278800\ttotal: 1.47s\tremaining: 5.04s\n",
      "226:\tlearn: 0.3277173\ttotal: 1.48s\tremaining: 5.03s\n",
      "227:\tlearn: 0.3275943\ttotal: 1.48s\tremaining: 5.02s\n",
      "228:\tlearn: 0.3274938\ttotal: 1.49s\tremaining: 5.01s\n",
      "229:\tlearn: 0.3273215\ttotal: 1.49s\tremaining: 5s\n",
      "230:\tlearn: 0.3272333\ttotal: 1.5s\tremaining: 4.99s\n",
      "231:\tlearn: 0.3270457\ttotal: 1.5s\tremaining: 4.98s\n",
      "232:\tlearn: 0.3268662\ttotal: 1.51s\tremaining: 4.97s\n",
      "233:\tlearn: 0.3268103\ttotal: 1.51s\tremaining: 4.96s\n",
      "234:\tlearn: 0.3266397\ttotal: 1.52s\tremaining: 4.94s\n",
      "235:\tlearn: 0.3264804\ttotal: 1.52s\tremaining: 4.93s\n",
      "236:\tlearn: 0.3263440\ttotal: 1.53s\tremaining: 4.92s\n",
      "237:\tlearn: 0.3262174\ttotal: 1.53s\tremaining: 4.91s\n",
      "238:\tlearn: 0.3261015\ttotal: 1.54s\tremaining: 4.9s\n",
      "239:\tlearn: 0.3259513\ttotal: 1.54s\tremaining: 4.89s\n",
      "240:\tlearn: 0.3258062\ttotal: 1.55s\tremaining: 4.88s\n",
      "241:\tlearn: 0.3256164\ttotal: 1.55s\tremaining: 4.87s\n",
      "242:\tlearn: 0.3255079\ttotal: 1.56s\tremaining: 4.86s\n",
      "243:\tlearn: 0.3253365\ttotal: 1.56s\tremaining: 4.85s\n",
      "244:\tlearn: 0.3252049\ttotal: 1.57s\tremaining: 4.84s\n",
      "245:\tlearn: 0.3250573\ttotal: 1.57s\tremaining: 4.83s\n",
      "246:\tlearn: 0.3249479\ttotal: 1.58s\tremaining: 4.82s\n",
      "247:\tlearn: 0.3248181\ttotal: 1.58s\tremaining: 4.81s\n",
      "248:\tlearn: 0.3246947\ttotal: 1.59s\tremaining: 4.8s\n",
      "249:\tlearn: 0.3245171\ttotal: 1.6s\tremaining: 4.79s\n",
      "250:\tlearn: 0.3243874\ttotal: 1.6s\tremaining: 4.78s\n",
      "251:\tlearn: 0.3242901\ttotal: 1.61s\tremaining: 4.77s\n",
      "252:\tlearn: 0.3241659\ttotal: 1.61s\tremaining: 4.76s\n",
      "253:\tlearn: 0.3239981\ttotal: 1.62s\tremaining: 4.75s\n",
      "254:\tlearn: 0.3238159\ttotal: 1.62s\tremaining: 4.75s\n",
      "255:\tlearn: 0.3236441\ttotal: 1.63s\tremaining: 4.74s\n",
      "256:\tlearn: 0.3235015\ttotal: 1.64s\tremaining: 4.73s\n",
      "257:\tlearn: 0.3234218\ttotal: 1.64s\tremaining: 4.72s\n",
      "258:\tlearn: 0.3232932\ttotal: 1.65s\tremaining: 4.71s\n",
      "259:\tlearn: 0.3231608\ttotal: 1.65s\tremaining: 4.71s\n",
      "260:\tlearn: 0.3230752\ttotal: 1.66s\tremaining: 4.7s\n",
      "261:\tlearn: 0.3229712\ttotal: 1.67s\tremaining: 4.7s\n",
      "262:\tlearn: 0.3227749\ttotal: 1.67s\tremaining: 4.69s\n",
      "263:\tlearn: 0.3226082\ttotal: 1.68s\tremaining: 4.68s\n",
      "264:\tlearn: 0.3224783\ttotal: 1.69s\tremaining: 4.67s\n",
      "265:\tlearn: 0.3223944\ttotal: 1.69s\tremaining: 4.67s\n",
      "266:\tlearn: 0.3222200\ttotal: 1.7s\tremaining: 4.66s\n",
      "267:\tlearn: 0.3220435\ttotal: 1.7s\tremaining: 4.65s\n",
      "268:\tlearn: 0.3219379\ttotal: 1.71s\tremaining: 4.64s\n",
      "269:\tlearn: 0.3218021\ttotal: 1.71s\tremaining: 4.63s\n",
      "270:\tlearn: 0.3217286\ttotal: 1.72s\tremaining: 4.62s\n",
      "271:\tlearn: 0.3216062\ttotal: 1.72s\tremaining: 4.61s\n",
      "272:\tlearn: 0.3214814\ttotal: 1.73s\tremaining: 4.6s\n",
      "273:\tlearn: 0.3213325\ttotal: 1.73s\tremaining: 4.59s\n",
      "274:\tlearn: 0.3211614\ttotal: 1.74s\tremaining: 4.58s\n",
      "275:\tlearn: 0.3210619\ttotal: 1.74s\tremaining: 4.58s\n",
      "276:\tlearn: 0.3209648\ttotal: 1.75s\tremaining: 4.57s\n",
      "277:\tlearn: 0.3208234\ttotal: 1.75s\tremaining: 4.56s\n",
      "278:\tlearn: 0.3206959\ttotal: 1.76s\tremaining: 4.55s\n",
      "279:\tlearn: 0.3205628\ttotal: 1.76s\tremaining: 4.54s\n",
      "280:\tlearn: 0.3204402\ttotal: 1.77s\tremaining: 4.53s\n",
      "281:\tlearn: 0.3202675\ttotal: 1.78s\tremaining: 4.52s\n",
      "282:\tlearn: 0.3201467\ttotal: 1.78s\tremaining: 4.51s\n",
      "283:\tlearn: 0.3200135\ttotal: 1.79s\tremaining: 4.5s\n",
      "284:\tlearn: 0.3198287\ttotal: 1.79s\tremaining: 4.5s\n",
      "285:\tlearn: 0.3197861\ttotal: 1.8s\tremaining: 4.49s\n",
      "286:\tlearn: 0.3196398\ttotal: 1.8s\tremaining: 4.49s\n",
      "287:\tlearn: 0.3194621\ttotal: 1.81s\tremaining: 4.48s\n",
      "288:\tlearn: 0.3193386\ttotal: 1.82s\tremaining: 4.47s\n",
      "289:\tlearn: 0.3191864\ttotal: 1.83s\tremaining: 4.47s\n",
      "290:\tlearn: 0.3190928\ttotal: 1.83s\tremaining: 4.46s\n",
      "291:\tlearn: 0.3189983\ttotal: 1.84s\tremaining: 4.46s\n",
      "292:\tlearn: 0.3188007\ttotal: 1.84s\tremaining: 4.45s\n",
      "293:\tlearn: 0.3186416\ttotal: 1.85s\tremaining: 4.44s\n",
      "294:\tlearn: 0.3185208\ttotal: 1.86s\tremaining: 4.44s\n",
      "295:\tlearn: 0.3183720\ttotal: 1.86s\tremaining: 4.43s\n",
      "296:\tlearn: 0.3181863\ttotal: 1.87s\tremaining: 4.43s\n",
      "297:\tlearn: 0.3180316\ttotal: 1.88s\tremaining: 4.42s\n",
      "298:\tlearn: 0.3178807\ttotal: 1.88s\tremaining: 4.41s\n",
      "299:\tlearn: 0.3177827\ttotal: 1.89s\tremaining: 4.4s\n",
      "300:\tlearn: 0.3176133\ttotal: 1.89s\tremaining: 4.39s\n",
      "301:\tlearn: 0.3174943\ttotal: 1.9s\tremaining: 4.38s\n",
      "302:\tlearn: 0.3173647\ttotal: 1.9s\tremaining: 4.37s\n",
      "303:\tlearn: 0.3172586\ttotal: 1.91s\tremaining: 4.36s\n",
      "304:\tlearn: 0.3171232\ttotal: 1.91s\tremaining: 4.36s\n",
      "305:\tlearn: 0.3169739\ttotal: 1.92s\tremaining: 4.35s\n",
      "306:\tlearn: 0.3168060\ttotal: 1.92s\tremaining: 4.34s\n",
      "307:\tlearn: 0.3166603\ttotal: 1.93s\tremaining: 4.33s\n",
      "308:\tlearn: 0.3165363\ttotal: 1.93s\tremaining: 4.32s\n",
      "309:\tlearn: 0.3164220\ttotal: 1.94s\tremaining: 4.31s\n",
      "310:\tlearn: 0.3163156\ttotal: 1.94s\tremaining: 4.3s\n",
      "311:\tlearn: 0.3161932\ttotal: 1.95s\tremaining: 4.3s\n",
      "312:\tlearn: 0.3160308\ttotal: 1.95s\tremaining: 4.29s\n",
      "313:\tlearn: 0.3158986\ttotal: 1.96s\tremaining: 4.28s\n",
      "314:\tlearn: 0.3157537\ttotal: 1.96s\tremaining: 4.27s\n",
      "315:\tlearn: 0.3155872\ttotal: 1.97s\tremaining: 4.26s\n",
      "316:\tlearn: 0.3154461\ttotal: 1.97s\tremaining: 4.25s\n",
      "317:\tlearn: 0.3152440\ttotal: 1.98s\tremaining: 4.24s\n",
      "318:\tlearn: 0.3151418\ttotal: 1.98s\tremaining: 4.24s\n",
      "319:\tlearn: 0.3150332\ttotal: 1.99s\tremaining: 4.23s\n",
      "320:\tlearn: 0.3148845\ttotal: 1.99s\tremaining: 4.22s\n",
      "321:\tlearn: 0.3147420\ttotal: 2s\tremaining: 4.21s\n",
      "322:\tlearn: 0.3146084\ttotal: 2s\tremaining: 4.2s\n",
      "323:\tlearn: 0.3144872\ttotal: 2.01s\tremaining: 4.19s\n",
      "324:\tlearn: 0.3143708\ttotal: 2.01s\tremaining: 4.18s\n",
      "325:\tlearn: 0.3142619\ttotal: 2.02s\tremaining: 4.17s\n",
      "326:\tlearn: 0.3140778\ttotal: 2.02s\tremaining: 4.17s\n",
      "327:\tlearn: 0.3138624\ttotal: 2.03s\tremaining: 4.16s\n",
      "328:\tlearn: 0.3137468\ttotal: 2.03s\tremaining: 4.15s\n",
      "329:\tlearn: 0.3135875\ttotal: 2.04s\tremaining: 4.14s\n",
      "330:\tlearn: 0.3134652\ttotal: 2.04s\tremaining: 4.13s\n",
      "331:\tlearn: 0.3133086\ttotal: 2.05s\tremaining: 4.12s\n",
      "332:\tlearn: 0.3131943\ttotal: 2.05s\tremaining: 4.12s\n",
      "333:\tlearn: 0.3130993\ttotal: 2.06s\tremaining: 4.11s\n",
      "334:\tlearn: 0.3129375\ttotal: 2.06s\tremaining: 4.1s\n",
      "335:\tlearn: 0.3127743\ttotal: 2.07s\tremaining: 4.09s\n",
      "336:\tlearn: 0.3126639\ttotal: 2.08s\tremaining: 4.09s\n",
      "337:\tlearn: 0.3125736\ttotal: 2.08s\tremaining: 4.08s\n",
      "338:\tlearn: 0.3125037\ttotal: 2.09s\tremaining: 4.07s\n",
      "339:\tlearn: 0.3123958\ttotal: 2.09s\tremaining: 4.06s\n",
      "340:\tlearn: 0.3122913\ttotal: 2.1s\tremaining: 4.06s\n",
      "341:\tlearn: 0.3121457\ttotal: 2.1s\tremaining: 4.05s\n",
      "342:\tlearn: 0.3120182\ttotal: 2.11s\tremaining: 4.04s\n",
      "343:\tlearn: 0.3119089\ttotal: 2.11s\tremaining: 4.03s\n",
      "344:\tlearn: 0.3117942\ttotal: 2.12s\tremaining: 4.02s\n",
      "345:\tlearn: 0.3116973\ttotal: 2.13s\tremaining: 4.02s\n",
      "346:\tlearn: 0.3115248\ttotal: 2.13s\tremaining: 4.01s\n",
      "347:\tlearn: 0.3114293\ttotal: 2.13s\tremaining: 4s\n",
      "348:\tlearn: 0.3113059\ttotal: 2.14s\tremaining: 3.99s\n",
      "349:\tlearn: 0.3112211\ttotal: 2.15s\tremaining: 3.99s\n",
      "350:\tlearn: 0.3111199\ttotal: 2.15s\tremaining: 3.98s\n",
      "351:\tlearn: 0.3110398\ttotal: 2.16s\tremaining: 3.97s\n",
      "352:\tlearn: 0.3109526\ttotal: 2.16s\tremaining: 3.96s\n",
      "353:\tlearn: 0.3107779\ttotal: 2.17s\tremaining: 3.96s\n",
      "354:\tlearn: 0.3107021\ttotal: 2.17s\tremaining: 3.95s\n",
      "355:\tlearn: 0.3105951\ttotal: 2.18s\tremaining: 3.94s\n",
      "356:\tlearn: 0.3105196\ttotal: 2.18s\tremaining: 3.93s\n",
      "357:\tlearn: 0.3104280\ttotal: 2.19s\tremaining: 3.93s\n",
      "358:\tlearn: 0.3103232\ttotal: 2.19s\tremaining: 3.92s\n",
      "359:\tlearn: 0.3102320\ttotal: 2.2s\tremaining: 3.91s\n",
      "360:\tlearn: 0.3100927\ttotal: 2.21s\tremaining: 3.9s\n",
      "361:\tlearn: 0.3099411\ttotal: 2.21s\tremaining: 3.9s\n",
      "362:\tlearn: 0.3098438\ttotal: 2.22s\tremaining: 3.89s\n",
      "363:\tlearn: 0.3097136\ttotal: 2.22s\tremaining: 3.88s\n",
      "364:\tlearn: 0.3096229\ttotal: 2.23s\tremaining: 3.88s\n",
      "365:\tlearn: 0.3094905\ttotal: 2.23s\tremaining: 3.87s\n",
      "366:\tlearn: 0.3093600\ttotal: 2.24s\tremaining: 3.86s\n",
      "367:\tlearn: 0.3092308\ttotal: 2.24s\tremaining: 3.85s\n",
      "368:\tlearn: 0.3090599\ttotal: 2.25s\tremaining: 3.85s\n",
      "369:\tlearn: 0.3089411\ttotal: 2.26s\tremaining: 3.84s\n",
      "370:\tlearn: 0.3087949\ttotal: 2.26s\tremaining: 3.83s\n",
      "371:\tlearn: 0.3086670\ttotal: 2.27s\tremaining: 3.83s\n",
      "372:\tlearn: 0.3085981\ttotal: 2.27s\tremaining: 3.82s\n",
      "373:\tlearn: 0.3084246\ttotal: 2.28s\tremaining: 3.81s\n",
      "374:\tlearn: 0.3083276\ttotal: 2.29s\tremaining: 3.81s\n",
      "375:\tlearn: 0.3081918\ttotal: 2.29s\tremaining: 3.8s\n",
      "376:\tlearn: 0.3080727\ttotal: 2.3s\tremaining: 3.8s\n",
      "377:\tlearn: 0.3079415\ttotal: 2.31s\tremaining: 3.8s\n",
      "378:\tlearn: 0.3078316\ttotal: 2.31s\tremaining: 3.79s\n",
      "379:\tlearn: 0.3077421\ttotal: 2.32s\tremaining: 3.79s\n",
      "380:\tlearn: 0.3076545\ttotal: 2.33s\tremaining: 3.79s\n",
      "381:\tlearn: 0.3074901\ttotal: 2.34s\tremaining: 3.78s\n",
      "382:\tlearn: 0.3073802\ttotal: 2.34s\tremaining: 3.77s\n",
      "383:\tlearn: 0.3072895\ttotal: 2.35s\tremaining: 3.77s\n",
      "384:\tlearn: 0.3071488\ttotal: 2.36s\tremaining: 3.76s\n",
      "385:\tlearn: 0.3070473\ttotal: 2.36s\tremaining: 3.76s\n",
      "386:\tlearn: 0.3068847\ttotal: 2.37s\tremaining: 3.75s\n",
      "387:\tlearn: 0.3067128\ttotal: 2.37s\tremaining: 3.75s\n",
      "388:\tlearn: 0.3066266\ttotal: 2.38s\tremaining: 3.74s\n",
      "389:\tlearn: 0.3065216\ttotal: 2.38s\tremaining: 3.73s\n",
      "390:\tlearn: 0.3064250\ttotal: 2.39s\tremaining: 3.72s\n",
      "391:\tlearn: 0.3063449\ttotal: 2.4s\tremaining: 3.72s\n",
      "392:\tlearn: 0.3062465\ttotal: 2.4s\tremaining: 3.71s\n",
      "393:\tlearn: 0.3060871\ttotal: 2.41s\tremaining: 3.7s\n",
      "394:\tlearn: 0.3059946\ttotal: 2.41s\tremaining: 3.7s\n",
      "395:\tlearn: 0.3059091\ttotal: 2.42s\tremaining: 3.69s\n",
      "396:\tlearn: 0.3057772\ttotal: 2.42s\tremaining: 3.68s\n",
      "397:\tlearn: 0.3056979\ttotal: 2.43s\tremaining: 3.68s\n",
      "398:\tlearn: 0.3056366\ttotal: 2.44s\tremaining: 3.67s\n",
      "399:\tlearn: 0.3055355\ttotal: 2.44s\tremaining: 3.66s\n",
      "400:\tlearn: 0.3054484\ttotal: 2.45s\tremaining: 3.65s\n",
      "401:\tlearn: 0.3053476\ttotal: 2.45s\tremaining: 3.65s\n",
      "402:\tlearn: 0.3052795\ttotal: 2.46s\tremaining: 3.64s\n",
      "403:\tlearn: 0.3051744\ttotal: 2.46s\tremaining: 3.63s\n",
      "404:\tlearn: 0.3049965\ttotal: 2.47s\tremaining: 3.63s\n",
      "405:\tlearn: 0.3049249\ttotal: 2.48s\tremaining: 3.64s\n",
      "406:\tlearn: 0.3047972\ttotal: 2.49s\tremaining: 3.63s\n",
      "407:\tlearn: 0.3046765\ttotal: 2.5s\tremaining: 3.62s\n",
      "408:\tlearn: 0.3046067\ttotal: 2.5s\tremaining: 3.62s\n",
      "409:\tlearn: 0.3044923\ttotal: 2.51s\tremaining: 3.61s\n",
      "410:\tlearn: 0.3044481\ttotal: 2.52s\tremaining: 3.6s\n",
      "411:\tlearn: 0.3043348\ttotal: 2.52s\tremaining: 3.6s\n",
      "412:\tlearn: 0.3042046\ttotal: 2.53s\tremaining: 3.59s\n",
      "413:\tlearn: 0.3041309\ttotal: 2.53s\tremaining: 3.58s\n",
      "414:\tlearn: 0.3040375\ttotal: 2.54s\tremaining: 3.58s\n",
      "415:\tlearn: 0.3039616\ttotal: 2.54s\tremaining: 3.57s\n",
      "416:\tlearn: 0.3038166\ttotal: 2.55s\tremaining: 3.56s\n",
      "417:\tlearn: 0.3037132\ttotal: 2.55s\tremaining: 3.55s\n",
      "418:\tlearn: 0.3036428\ttotal: 2.56s\tremaining: 3.55s\n",
      "419:\tlearn: 0.3035106\ttotal: 2.56s\tremaining: 3.54s\n",
      "420:\tlearn: 0.3034351\ttotal: 2.57s\tremaining: 3.53s\n",
      "421:\tlearn: 0.3033263\ttotal: 2.57s\tremaining: 3.53s\n",
      "422:\tlearn: 0.3032338\ttotal: 2.58s\tremaining: 3.52s\n",
      "423:\tlearn: 0.3031127\ttotal: 2.58s\tremaining: 3.51s\n",
      "424:\tlearn: 0.3029967\ttotal: 2.59s\tremaining: 3.5s\n",
      "425:\tlearn: 0.3028434\ttotal: 2.6s\tremaining: 3.5s\n",
      "426:\tlearn: 0.3027629\ttotal: 2.6s\tremaining: 3.49s\n",
      "427:\tlearn: 0.3027271\ttotal: 2.61s\tremaining: 3.48s\n",
      "428:\tlearn: 0.3026469\ttotal: 2.61s\tremaining: 3.48s\n",
      "429:\tlearn: 0.3025492\ttotal: 2.62s\tremaining: 3.47s\n",
      "430:\tlearn: 0.3024451\ttotal: 2.62s\tremaining: 3.46s\n",
      "431:\tlearn: 0.3022967\ttotal: 2.63s\tremaining: 3.46s\n",
      "432:\tlearn: 0.3021987\ttotal: 2.63s\tremaining: 3.45s\n",
      "433:\tlearn: 0.3021238\ttotal: 2.64s\tremaining: 3.44s\n",
      "434:\tlearn: 0.3019483\ttotal: 2.64s\tremaining: 3.44s\n",
      "435:\tlearn: 0.3018644\ttotal: 2.65s\tremaining: 3.43s\n",
      "436:\tlearn: 0.3017889\ttotal: 2.65s\tremaining: 3.42s\n",
      "437:\tlearn: 0.3016429\ttotal: 2.66s\tremaining: 3.41s\n",
      "438:\tlearn: 0.3015107\ttotal: 2.67s\tremaining: 3.41s\n",
      "439:\tlearn: 0.3014248\ttotal: 2.67s\tremaining: 3.4s\n",
      "440:\tlearn: 0.3013725\ttotal: 2.68s\tremaining: 3.39s\n",
      "441:\tlearn: 0.3012498\ttotal: 2.68s\tremaining: 3.38s\n",
      "442:\tlearn: 0.3011297\ttotal: 2.69s\tremaining: 3.38s\n",
      "443:\tlearn: 0.3010739\ttotal: 2.69s\tremaining: 3.37s\n",
      "444:\tlearn: 0.3009711\ttotal: 2.7s\tremaining: 3.36s\n",
      "445:\tlearn: 0.3009192\ttotal: 2.7s\tremaining: 3.36s\n",
      "446:\tlearn: 0.3008424\ttotal: 2.71s\tremaining: 3.35s\n",
      "447:\tlearn: 0.3006800\ttotal: 2.71s\tremaining: 3.35s\n",
      "448:\tlearn: 0.3005998\ttotal: 2.72s\tremaining: 3.34s\n",
      "449:\tlearn: 0.3004241\ttotal: 2.73s\tremaining: 3.33s\n",
      "450:\tlearn: 0.3002529\ttotal: 2.73s\tremaining: 3.32s\n",
      "451:\tlearn: 0.3001825\ttotal: 2.74s\tremaining: 3.32s\n",
      "452:\tlearn: 0.3000777\ttotal: 2.74s\tremaining: 3.31s\n",
      "453:\tlearn: 0.2999632\ttotal: 2.75s\tremaining: 3.3s\n",
      "454:\tlearn: 0.2999018\ttotal: 2.75s\tremaining: 3.3s\n",
      "455:\tlearn: 0.2998100\ttotal: 2.76s\tremaining: 3.29s\n",
      "456:\tlearn: 0.2997350\ttotal: 2.76s\tremaining: 3.28s\n",
      "457:\tlearn: 0.2996863\ttotal: 2.77s\tremaining: 3.27s\n",
      "458:\tlearn: 0.2996105\ttotal: 2.77s\tremaining: 3.27s\n",
      "459:\tlearn: 0.2995280\ttotal: 2.78s\tremaining: 3.26s\n",
      "460:\tlearn: 0.2994277\ttotal: 2.79s\tremaining: 3.26s\n",
      "461:\tlearn: 0.2993460\ttotal: 2.79s\tremaining: 3.25s\n",
      "462:\tlearn: 0.2992873\ttotal: 2.8s\tremaining: 3.24s\n",
      "463:\tlearn: 0.2992274\ttotal: 2.8s\tremaining: 3.24s\n",
      "464:\tlearn: 0.2990759\ttotal: 2.81s\tremaining: 3.23s\n",
      "465:\tlearn: 0.2990273\ttotal: 2.82s\tremaining: 3.23s\n",
      "466:\tlearn: 0.2988689\ttotal: 2.82s\tremaining: 3.22s\n",
      "467:\tlearn: 0.2988133\ttotal: 2.83s\tremaining: 3.21s\n",
      "468:\tlearn: 0.2986736\ttotal: 2.83s\tremaining: 3.21s\n",
      "469:\tlearn: 0.2986237\ttotal: 2.84s\tremaining: 3.2s\n",
      "470:\tlearn: 0.2985443\ttotal: 2.84s\tremaining: 3.19s\n",
      "471:\tlearn: 0.2984865\ttotal: 2.85s\tremaining: 3.19s\n",
      "472:\tlearn: 0.2984158\ttotal: 2.85s\tremaining: 3.18s\n",
      "473:\tlearn: 0.2982957\ttotal: 2.86s\tremaining: 3.17s\n",
      "474:\tlearn: 0.2981315\ttotal: 2.87s\tremaining: 3.17s\n",
      "475:\tlearn: 0.2979693\ttotal: 2.87s\tremaining: 3.16s\n",
      "476:\tlearn: 0.2978067\ttotal: 2.88s\tremaining: 3.15s\n",
      "477:\tlearn: 0.2977338\ttotal: 2.88s\tremaining: 3.15s\n",
      "478:\tlearn: 0.2976227\ttotal: 2.88s\tremaining: 3.14s\n",
      "479:\tlearn: 0.2975693\ttotal: 2.89s\tremaining: 3.13s\n",
      "480:\tlearn: 0.2974709\ttotal: 2.9s\tremaining: 3.12s\n",
      "481:\tlearn: 0.2973824\ttotal: 2.9s\tremaining: 3.12s\n",
      "482:\tlearn: 0.2972647\ttotal: 2.91s\tremaining: 3.11s\n",
      "483:\tlearn: 0.2971932\ttotal: 2.91s\tremaining: 3.11s\n",
      "484:\tlearn: 0.2970819\ttotal: 2.92s\tremaining: 3.1s\n",
      "485:\tlearn: 0.2969774\ttotal: 2.92s\tremaining: 3.09s\n",
      "486:\tlearn: 0.2968864\ttotal: 2.93s\tremaining: 3.08s\n",
      "487:\tlearn: 0.2967522\ttotal: 2.93s\tremaining: 3.08s\n",
      "488:\tlearn: 0.2966698\ttotal: 2.94s\tremaining: 3.07s\n",
      "489:\tlearn: 0.2965934\ttotal: 2.94s\tremaining: 3.06s\n",
      "490:\tlearn: 0.2965253\ttotal: 2.95s\tremaining: 3.06s\n",
      "491:\tlearn: 0.2963357\ttotal: 2.95s\tremaining: 3.05s\n",
      "492:\tlearn: 0.2961915\ttotal: 2.96s\tremaining: 3.04s\n",
      "493:\tlearn: 0.2960865\ttotal: 2.96s\tremaining: 3.04s\n",
      "494:\tlearn: 0.2959177\ttotal: 2.97s\tremaining: 3.03s\n",
      "495:\tlearn: 0.2958518\ttotal: 2.98s\tremaining: 3.02s\n",
      "496:\tlearn: 0.2957329\ttotal: 2.98s\tremaining: 3.02s\n",
      "497:\tlearn: 0.2955862\ttotal: 2.98s\tremaining: 3.01s\n",
      "498:\tlearn: 0.2955193\ttotal: 2.99s\tremaining: 3s\n",
      "499:\tlearn: 0.2953745\ttotal: 3s\tremaining: 3s\n",
      "500:\tlearn: 0.2953085\ttotal: 3s\tremaining: 2.99s\n",
      "501:\tlearn: 0.2952408\ttotal: 3.01s\tremaining: 2.98s\n",
      "502:\tlearn: 0.2951973\ttotal: 3.01s\tremaining: 2.98s\n",
      "503:\tlearn: 0.2951180\ttotal: 3.02s\tremaining: 2.97s\n",
      "504:\tlearn: 0.2950577\ttotal: 3.02s\tremaining: 2.96s\n",
      "505:\tlearn: 0.2949757\ttotal: 3.03s\tremaining: 2.96s\n",
      "506:\tlearn: 0.2948878\ttotal: 3.03s\tremaining: 2.95s\n",
      "507:\tlearn: 0.2947140\ttotal: 3.04s\tremaining: 2.94s\n",
      "508:\tlearn: 0.2945685\ttotal: 3.04s\tremaining: 2.94s\n",
      "509:\tlearn: 0.2944946\ttotal: 3.05s\tremaining: 2.93s\n",
      "510:\tlearn: 0.2943664\ttotal: 3.06s\tremaining: 2.92s\n",
      "511:\tlearn: 0.2943038\ttotal: 3.06s\tremaining: 2.92s\n",
      "512:\tlearn: 0.2942567\ttotal: 3.06s\tremaining: 2.91s\n",
      "513:\tlearn: 0.2942213\ttotal: 3.07s\tremaining: 2.9s\n",
      "514:\tlearn: 0.2941390\ttotal: 3.08s\tremaining: 2.9s\n",
      "515:\tlearn: 0.2940161\ttotal: 3.08s\tremaining: 2.89s\n",
      "516:\tlearn: 0.2939666\ttotal: 3.09s\tremaining: 2.88s\n",
      "517:\tlearn: 0.2938267\ttotal: 3.09s\tremaining: 2.88s\n",
      "518:\tlearn: 0.2936928\ttotal: 3.1s\tremaining: 2.87s\n",
      "519:\tlearn: 0.2936325\ttotal: 3.1s\tremaining: 2.87s\n",
      "520:\tlearn: 0.2935954\ttotal: 3.11s\tremaining: 2.86s\n",
      "521:\tlearn: 0.2935150\ttotal: 3.12s\tremaining: 2.85s\n",
      "522:\tlearn: 0.2934743\ttotal: 3.12s\tremaining: 2.85s\n",
      "523:\tlearn: 0.2933408\ttotal: 3.13s\tremaining: 2.84s\n",
      "524:\tlearn: 0.2932168\ttotal: 3.13s\tremaining: 2.83s\n",
      "525:\tlearn: 0.2931143\ttotal: 3.14s\tremaining: 2.83s\n",
      "526:\tlearn: 0.2930275\ttotal: 3.14s\tremaining: 2.82s\n",
      "527:\tlearn: 0.2929031\ttotal: 3.15s\tremaining: 2.81s\n",
      "528:\tlearn: 0.2928675\ttotal: 3.15s\tremaining: 2.81s\n",
      "529:\tlearn: 0.2927664\ttotal: 3.16s\tremaining: 2.8s\n",
      "530:\tlearn: 0.2926035\ttotal: 3.16s\tremaining: 2.79s\n",
      "531:\tlearn: 0.2925172\ttotal: 3.17s\tremaining: 2.79s\n",
      "532:\tlearn: 0.2924366\ttotal: 3.17s\tremaining: 2.78s\n",
      "533:\tlearn: 0.2923967\ttotal: 3.18s\tremaining: 2.77s\n",
      "534:\tlearn: 0.2922378\ttotal: 3.18s\tremaining: 2.77s\n",
      "535:\tlearn: 0.2921359\ttotal: 3.19s\tremaining: 2.76s\n",
      "536:\tlearn: 0.2920718\ttotal: 3.19s\tremaining: 2.75s\n",
      "537:\tlearn: 0.2919997\ttotal: 3.2s\tremaining: 2.75s\n",
      "538:\tlearn: 0.2918379\ttotal: 3.21s\tremaining: 2.74s\n",
      "539:\tlearn: 0.2917799\ttotal: 3.21s\tremaining: 2.73s\n",
      "540:\tlearn: 0.2916880\ttotal: 3.22s\tremaining: 2.73s\n",
      "541:\tlearn: 0.2915276\ttotal: 3.22s\tremaining: 2.72s\n",
      "542:\tlearn: 0.2914050\ttotal: 3.23s\tremaining: 2.72s\n",
      "543:\tlearn: 0.2913211\ttotal: 3.23s\tremaining: 2.71s\n",
      "544:\tlearn: 0.2912602\ttotal: 3.24s\tremaining: 2.7s\n",
      "545:\tlearn: 0.2911717\ttotal: 3.24s\tremaining: 2.7s\n",
      "546:\tlearn: 0.2910903\ttotal: 3.25s\tremaining: 2.69s\n",
      "547:\tlearn: 0.2910263\ttotal: 3.25s\tremaining: 2.68s\n",
      "548:\tlearn: 0.2908761\ttotal: 3.26s\tremaining: 2.68s\n",
      "549:\tlearn: 0.2907826\ttotal: 3.26s\tremaining: 2.67s\n",
      "550:\tlearn: 0.2907123\ttotal: 3.27s\tremaining: 2.67s\n",
      "551:\tlearn: 0.2905911\ttotal: 3.28s\tremaining: 2.66s\n",
      "552:\tlearn: 0.2905492\ttotal: 3.28s\tremaining: 2.65s\n",
      "553:\tlearn: 0.2904917\ttotal: 3.29s\tremaining: 2.65s\n",
      "554:\tlearn: 0.2904129\ttotal: 3.3s\tremaining: 2.64s\n",
      "555:\tlearn: 0.2902610\ttotal: 3.3s\tremaining: 2.64s\n",
      "556:\tlearn: 0.2902024\ttotal: 3.31s\tremaining: 2.63s\n",
      "557:\tlearn: 0.2901626\ttotal: 3.32s\tremaining: 2.63s\n",
      "558:\tlearn: 0.2900208\ttotal: 3.32s\tremaining: 2.62s\n",
      "559:\tlearn: 0.2899208\ttotal: 3.33s\tremaining: 2.62s\n",
      "560:\tlearn: 0.2897813\ttotal: 3.33s\tremaining: 2.61s\n",
      "561:\tlearn: 0.2896562\ttotal: 3.34s\tremaining: 2.6s\n",
      "562:\tlearn: 0.2895513\ttotal: 3.35s\tremaining: 2.6s\n",
      "563:\tlearn: 0.2895051\ttotal: 3.35s\tremaining: 2.59s\n",
      "564:\tlearn: 0.2894007\ttotal: 3.36s\tremaining: 2.58s\n",
      "565:\tlearn: 0.2892616\ttotal: 3.36s\tremaining: 2.58s\n",
      "566:\tlearn: 0.2891967\ttotal: 3.37s\tremaining: 2.57s\n",
      "567:\tlearn: 0.2890765\ttotal: 3.37s\tremaining: 2.56s\n",
      "568:\tlearn: 0.2889965\ttotal: 3.38s\tremaining: 2.56s\n",
      "569:\tlearn: 0.2888857\ttotal: 3.38s\tremaining: 2.55s\n",
      "570:\tlearn: 0.2888252\ttotal: 3.39s\tremaining: 2.54s\n",
      "571:\tlearn: 0.2887352\ttotal: 3.39s\tremaining: 2.54s\n",
      "572:\tlearn: 0.2886926\ttotal: 3.4s\tremaining: 2.53s\n",
      "573:\tlearn: 0.2885970\ttotal: 3.4s\tremaining: 2.52s\n",
      "574:\tlearn: 0.2884516\ttotal: 3.41s\tremaining: 2.52s\n",
      "575:\tlearn: 0.2883058\ttotal: 3.41s\tremaining: 2.51s\n",
      "576:\tlearn: 0.2881828\ttotal: 3.42s\tremaining: 2.51s\n",
      "577:\tlearn: 0.2880569\ttotal: 3.42s\tremaining: 2.5s\n",
      "578:\tlearn: 0.2879996\ttotal: 3.43s\tremaining: 2.49s\n",
      "579:\tlearn: 0.2879034\ttotal: 3.44s\tremaining: 2.49s\n",
      "580:\tlearn: 0.2877903\ttotal: 3.44s\tremaining: 2.48s\n",
      "581:\tlearn: 0.2876792\ttotal: 3.45s\tremaining: 2.48s\n",
      "582:\tlearn: 0.2875552\ttotal: 3.45s\tremaining: 2.47s\n",
      "583:\tlearn: 0.2874424\ttotal: 3.46s\tremaining: 2.46s\n",
      "584:\tlearn: 0.2874034\ttotal: 3.46s\tremaining: 2.46s\n",
      "585:\tlearn: 0.2872964\ttotal: 3.47s\tremaining: 2.45s\n",
      "586:\tlearn: 0.2872352\ttotal: 3.47s\tremaining: 2.44s\n",
      "587:\tlearn: 0.2871184\ttotal: 3.48s\tremaining: 2.44s\n",
      "588:\tlearn: 0.2870044\ttotal: 3.48s\tremaining: 2.43s\n",
      "589:\tlearn: 0.2869101\ttotal: 3.49s\tremaining: 2.42s\n",
      "590:\tlearn: 0.2868621\ttotal: 3.49s\tremaining: 2.42s\n",
      "591:\tlearn: 0.2867679\ttotal: 3.5s\tremaining: 2.41s\n",
      "592:\tlearn: 0.2866642\ttotal: 3.5s\tremaining: 2.4s\n",
      "593:\tlearn: 0.2865061\ttotal: 3.51s\tremaining: 2.4s\n",
      "594:\tlearn: 0.2863939\ttotal: 3.51s\tremaining: 2.39s\n",
      "595:\tlearn: 0.2862952\ttotal: 3.52s\tremaining: 2.39s\n",
      "596:\tlearn: 0.2862156\ttotal: 3.53s\tremaining: 2.38s\n",
      "597:\tlearn: 0.2860710\ttotal: 3.53s\tremaining: 2.38s\n",
      "598:\tlearn: 0.2859619\ttotal: 3.54s\tremaining: 2.37s\n",
      "599:\tlearn: 0.2858861\ttotal: 3.54s\tremaining: 2.36s\n",
      "600:\tlearn: 0.2858585\ttotal: 3.55s\tremaining: 2.36s\n",
      "601:\tlearn: 0.2857371\ttotal: 3.55s\tremaining: 2.35s\n",
      "602:\tlearn: 0.2856886\ttotal: 3.56s\tremaining: 2.34s\n",
      "603:\tlearn: 0.2855566\ttotal: 3.56s\tremaining: 2.34s\n",
      "604:\tlearn: 0.2854558\ttotal: 3.57s\tremaining: 2.33s\n",
      "605:\tlearn: 0.2853688\ttotal: 3.57s\tremaining: 2.32s\n",
      "606:\tlearn: 0.2853190\ttotal: 3.58s\tremaining: 2.32s\n",
      "607:\tlearn: 0.2852308\ttotal: 3.58s\tremaining: 2.31s\n",
      "608:\tlearn: 0.2851724\ttotal: 3.59s\tremaining: 2.3s\n",
      "609:\tlearn: 0.2850937\ttotal: 3.6s\tremaining: 2.3s\n",
      "610:\tlearn: 0.2850586\ttotal: 3.6s\tremaining: 2.29s\n",
      "611:\tlearn: 0.2849592\ttotal: 3.6s\tremaining: 2.29s\n",
      "612:\tlearn: 0.2848823\ttotal: 3.61s\tremaining: 2.28s\n",
      "613:\tlearn: 0.2848245\ttotal: 3.62s\tremaining: 2.27s\n",
      "614:\tlearn: 0.2847666\ttotal: 3.62s\tremaining: 2.27s\n",
      "615:\tlearn: 0.2846201\ttotal: 3.63s\tremaining: 2.26s\n",
      "616:\tlearn: 0.2845014\ttotal: 3.63s\tremaining: 2.25s\n",
      "617:\tlearn: 0.2844374\ttotal: 3.64s\tremaining: 2.25s\n",
      "618:\tlearn: 0.2843419\ttotal: 3.64s\tremaining: 2.24s\n",
      "619:\tlearn: 0.2843078\ttotal: 3.65s\tremaining: 2.24s\n",
      "620:\tlearn: 0.2842358\ttotal: 3.65s\tremaining: 2.23s\n",
      "621:\tlearn: 0.2841795\ttotal: 3.66s\tremaining: 2.22s\n",
      "622:\tlearn: 0.2841438\ttotal: 3.67s\tremaining: 2.22s\n",
      "623:\tlearn: 0.2840091\ttotal: 3.67s\tremaining: 2.21s\n",
      "624:\tlearn: 0.2839464\ttotal: 3.67s\tremaining: 2.21s\n",
      "625:\tlearn: 0.2838926\ttotal: 3.68s\tremaining: 2.2s\n",
      "626:\tlearn: 0.2837905\ttotal: 3.69s\tremaining: 2.19s\n",
      "627:\tlearn: 0.2836738\ttotal: 3.69s\tremaining: 2.19s\n",
      "628:\tlearn: 0.2835737\ttotal: 3.7s\tremaining: 2.18s\n",
      "629:\tlearn: 0.2835080\ttotal: 3.7s\tremaining: 2.17s\n",
      "630:\tlearn: 0.2833723\ttotal: 3.71s\tremaining: 2.17s\n",
      "631:\tlearn: 0.2832782\ttotal: 3.71s\tremaining: 2.16s\n",
      "632:\tlearn: 0.2832581\ttotal: 3.72s\tremaining: 2.15s\n",
      "633:\tlearn: 0.2831453\ttotal: 3.72s\tremaining: 2.15s\n",
      "634:\tlearn: 0.2830132\ttotal: 3.73s\tremaining: 2.14s\n",
      "635:\tlearn: 0.2829374\ttotal: 3.73s\tremaining: 2.14s\n",
      "636:\tlearn: 0.2828632\ttotal: 3.74s\tremaining: 2.13s\n",
      "637:\tlearn: 0.2827414\ttotal: 3.75s\tremaining: 2.13s\n",
      "638:\tlearn: 0.2826564\ttotal: 3.75s\tremaining: 2.12s\n",
      "639:\tlearn: 0.2825892\ttotal: 3.76s\tremaining: 2.11s\n",
      "640:\tlearn: 0.2824808\ttotal: 3.76s\tremaining: 2.11s\n",
      "641:\tlearn: 0.2823960\ttotal: 3.77s\tremaining: 2.1s\n",
      "642:\tlearn: 0.2823568\ttotal: 3.78s\tremaining: 2.1s\n",
      "643:\tlearn: 0.2822385\ttotal: 3.78s\tremaining: 2.09s\n",
      "644:\tlearn: 0.2820895\ttotal: 3.79s\tremaining: 2.09s\n",
      "645:\tlearn: 0.2820121\ttotal: 3.8s\tremaining: 2.08s\n",
      "646:\tlearn: 0.2819559\ttotal: 3.8s\tremaining: 2.08s\n",
      "647:\tlearn: 0.2819088\ttotal: 3.81s\tremaining: 2.07s\n",
      "648:\tlearn: 0.2818572\ttotal: 3.82s\tremaining: 2.06s\n",
      "649:\tlearn: 0.2817785\ttotal: 3.82s\tremaining: 2.06s\n",
      "650:\tlearn: 0.2817333\ttotal: 3.83s\tremaining: 2.05s\n",
      "651:\tlearn: 0.2816487\ttotal: 3.83s\tremaining: 2.05s\n",
      "652:\tlearn: 0.2816007\ttotal: 3.84s\tremaining: 2.04s\n",
      "653:\tlearn: 0.2815378\ttotal: 3.85s\tremaining: 2.03s\n",
      "654:\tlearn: 0.2814221\ttotal: 3.85s\tremaining: 2.03s\n",
      "655:\tlearn: 0.2813335\ttotal: 3.86s\tremaining: 2.02s\n",
      "656:\tlearn: 0.2812951\ttotal: 3.86s\tremaining: 2.02s\n",
      "657:\tlearn: 0.2812342\ttotal: 3.87s\tremaining: 2.01s\n",
      "658:\tlearn: 0.2811767\ttotal: 3.88s\tremaining: 2s\n",
      "659:\tlearn: 0.2811121\ttotal: 3.88s\tremaining: 2s\n",
      "660:\tlearn: 0.2810172\ttotal: 3.89s\tremaining: 1.99s\n",
      "661:\tlearn: 0.2809464\ttotal: 3.89s\tremaining: 1.99s\n",
      "662:\tlearn: 0.2808451\ttotal: 3.9s\tremaining: 1.98s\n",
      "663:\tlearn: 0.2807500\ttotal: 3.9s\tremaining: 1.98s\n",
      "664:\tlearn: 0.2806250\ttotal: 3.91s\tremaining: 1.97s\n",
      "665:\tlearn: 0.2805488\ttotal: 3.91s\tremaining: 1.96s\n",
      "666:\tlearn: 0.2804889\ttotal: 3.92s\tremaining: 1.96s\n",
      "667:\tlearn: 0.2804318\ttotal: 3.92s\tremaining: 1.95s\n",
      "668:\tlearn: 0.2803533\ttotal: 3.93s\tremaining: 1.94s\n",
      "669:\tlearn: 0.2802747\ttotal: 3.94s\tremaining: 1.94s\n",
      "670:\tlearn: 0.2801650\ttotal: 3.94s\tremaining: 1.93s\n",
      "671:\tlearn: 0.2801264\ttotal: 3.95s\tremaining: 1.93s\n",
      "672:\tlearn: 0.2799883\ttotal: 3.96s\tremaining: 1.92s\n",
      "673:\tlearn: 0.2798455\ttotal: 3.97s\tremaining: 1.92s\n",
      "674:\tlearn: 0.2798060\ttotal: 3.97s\tremaining: 1.91s\n",
      "675:\tlearn: 0.2797355\ttotal: 3.98s\tremaining: 1.91s\n",
      "676:\tlearn: 0.2796450\ttotal: 3.98s\tremaining: 1.9s\n",
      "677:\tlearn: 0.2795405\ttotal: 3.99s\tremaining: 1.9s\n",
      "678:\tlearn: 0.2794636\ttotal: 4s\tremaining: 1.89s\n",
      "679:\tlearn: 0.2793734\ttotal: 4s\tremaining: 1.88s\n",
      "680:\tlearn: 0.2793028\ttotal: 4.01s\tremaining: 1.88s\n",
      "681:\tlearn: 0.2792233\ttotal: 4.02s\tremaining: 1.87s\n",
      "682:\tlearn: 0.2791865\ttotal: 4.02s\tremaining: 1.87s\n",
      "683:\tlearn: 0.2791086\ttotal: 4.03s\tremaining: 1.86s\n",
      "684:\tlearn: 0.2790502\ttotal: 4.03s\tremaining: 1.85s\n",
      "685:\tlearn: 0.2789766\ttotal: 4.04s\tremaining: 1.85s\n",
      "686:\tlearn: 0.2788709\ttotal: 4.04s\tremaining: 1.84s\n",
      "687:\tlearn: 0.2787907\ttotal: 4.05s\tremaining: 1.83s\n",
      "688:\tlearn: 0.2787097\ttotal: 4.05s\tremaining: 1.83s\n",
      "689:\tlearn: 0.2786120\ttotal: 4.06s\tremaining: 1.82s\n",
      "690:\tlearn: 0.2785563\ttotal: 4.06s\tremaining: 1.82s\n",
      "691:\tlearn: 0.2784748\ttotal: 4.07s\tremaining: 1.81s\n",
      "692:\tlearn: 0.2783770\ttotal: 4.07s\tremaining: 1.8s\n",
      "693:\tlearn: 0.2782320\ttotal: 4.08s\tremaining: 1.8s\n",
      "694:\tlearn: 0.2781596\ttotal: 4.08s\tremaining: 1.79s\n",
      "695:\tlearn: 0.2780461\ttotal: 4.09s\tremaining: 1.79s\n",
      "696:\tlearn: 0.2780085\ttotal: 4.1s\tremaining: 1.78s\n",
      "697:\tlearn: 0.2779577\ttotal: 4.1s\tremaining: 1.77s\n",
      "698:\tlearn: 0.2778899\ttotal: 4.11s\tremaining: 1.77s\n",
      "699:\tlearn: 0.2777489\ttotal: 4.11s\tremaining: 1.76s\n",
      "700:\tlearn: 0.2777153\ttotal: 4.12s\tremaining: 1.76s\n",
      "701:\tlearn: 0.2776458\ttotal: 4.12s\tremaining: 1.75s\n",
      "702:\tlearn: 0.2776104\ttotal: 4.13s\tremaining: 1.74s\n",
      "703:\tlearn: 0.2775580\ttotal: 4.13s\tremaining: 1.74s\n",
      "704:\tlearn: 0.2774980\ttotal: 4.14s\tremaining: 1.73s\n",
      "705:\tlearn: 0.2773911\ttotal: 4.15s\tremaining: 1.73s\n",
      "706:\tlearn: 0.2772885\ttotal: 4.15s\tremaining: 1.72s\n",
      "707:\tlearn: 0.2772398\ttotal: 4.16s\tremaining: 1.71s\n",
      "708:\tlearn: 0.2771532\ttotal: 4.16s\tremaining: 1.71s\n",
      "709:\tlearn: 0.2770523\ttotal: 4.17s\tremaining: 1.7s\n",
      "710:\tlearn: 0.2769536\ttotal: 4.17s\tremaining: 1.7s\n",
      "711:\tlearn: 0.2768411\ttotal: 4.18s\tremaining: 1.69s\n",
      "712:\tlearn: 0.2767890\ttotal: 4.18s\tremaining: 1.68s\n",
      "713:\tlearn: 0.2767324\ttotal: 4.19s\tremaining: 1.68s\n",
      "714:\tlearn: 0.2766492\ttotal: 4.19s\tremaining: 1.67s\n",
      "715:\tlearn: 0.2765790\ttotal: 4.2s\tremaining: 1.67s\n",
      "716:\tlearn: 0.2764611\ttotal: 4.2s\tremaining: 1.66s\n",
      "717:\tlearn: 0.2763676\ttotal: 4.21s\tremaining: 1.65s\n",
      "718:\tlearn: 0.2763282\ttotal: 4.21s\tremaining: 1.65s\n",
      "719:\tlearn: 0.2762746\ttotal: 4.22s\tremaining: 1.64s\n",
      "720:\tlearn: 0.2761964\ttotal: 4.22s\tremaining: 1.63s\n",
      "721:\tlearn: 0.2761302\ttotal: 4.23s\tremaining: 1.63s\n",
      "722:\tlearn: 0.2760256\ttotal: 4.24s\tremaining: 1.62s\n",
      "723:\tlearn: 0.2759356\ttotal: 4.24s\tremaining: 1.62s\n",
      "724:\tlearn: 0.2758858\ttotal: 4.25s\tremaining: 1.61s\n",
      "725:\tlearn: 0.2758370\ttotal: 4.25s\tremaining: 1.6s\n",
      "726:\tlearn: 0.2757623\ttotal: 4.26s\tremaining: 1.6s\n",
      "727:\tlearn: 0.2756595\ttotal: 4.27s\tremaining: 1.59s\n",
      "728:\tlearn: 0.2755825\ttotal: 4.27s\tremaining: 1.59s\n",
      "729:\tlearn: 0.2754957\ttotal: 4.28s\tremaining: 1.58s\n",
      "730:\tlearn: 0.2753570\ttotal: 4.29s\tremaining: 1.58s\n",
      "731:\tlearn: 0.2752581\ttotal: 4.29s\tremaining: 1.57s\n",
      "732:\tlearn: 0.2751461\ttotal: 4.3s\tremaining: 1.56s\n",
      "733:\tlearn: 0.2750309\ttotal: 4.3s\tremaining: 1.56s\n",
      "734:\tlearn: 0.2749389\ttotal: 4.31s\tremaining: 1.55s\n",
      "735:\tlearn: 0.2748452\ttotal: 4.31s\tremaining: 1.55s\n",
      "736:\tlearn: 0.2747629\ttotal: 4.32s\tremaining: 1.54s\n",
      "737:\tlearn: 0.2746701\ttotal: 4.33s\tremaining: 1.53s\n",
      "738:\tlearn: 0.2746184\ttotal: 4.33s\tremaining: 1.53s\n",
      "739:\tlearn: 0.2745544\ttotal: 4.34s\tremaining: 1.52s\n",
      "740:\tlearn: 0.2744786\ttotal: 4.34s\tremaining: 1.52s\n",
      "741:\tlearn: 0.2743942\ttotal: 4.36s\tremaining: 1.51s\n",
      "742:\tlearn: 0.2743166\ttotal: 4.36s\tremaining: 1.51s\n",
      "743:\tlearn: 0.2742673\ttotal: 4.37s\tremaining: 1.5s\n",
      "744:\tlearn: 0.2742188\ttotal: 4.37s\tremaining: 1.5s\n",
      "745:\tlearn: 0.2741649\ttotal: 4.38s\tremaining: 1.49s\n",
      "746:\tlearn: 0.2741219\ttotal: 4.38s\tremaining: 1.48s\n",
      "747:\tlearn: 0.2739618\ttotal: 4.39s\tremaining: 1.48s\n",
      "748:\tlearn: 0.2738186\ttotal: 4.39s\tremaining: 1.47s\n",
      "749:\tlearn: 0.2737414\ttotal: 4.4s\tremaining: 1.47s\n",
      "750:\tlearn: 0.2735825\ttotal: 4.4s\tremaining: 1.46s\n",
      "751:\tlearn: 0.2734536\ttotal: 4.41s\tremaining: 1.45s\n",
      "752:\tlearn: 0.2733370\ttotal: 4.42s\tremaining: 1.45s\n",
      "753:\tlearn: 0.2732288\ttotal: 4.42s\tremaining: 1.44s\n",
      "754:\tlearn: 0.2731904\ttotal: 4.42s\tremaining: 1.44s\n",
      "755:\tlearn: 0.2731871\ttotal: 4.43s\tremaining: 1.43s\n",
      "756:\tlearn: 0.2731406\ttotal: 4.43s\tremaining: 1.42s\n",
      "757:\tlearn: 0.2730781\ttotal: 4.44s\tremaining: 1.42s\n",
      "758:\tlearn: 0.2729724\ttotal: 4.45s\tremaining: 1.41s\n",
      "759:\tlearn: 0.2728786\ttotal: 4.45s\tremaining: 1.41s\n",
      "760:\tlearn: 0.2728754\ttotal: 4.46s\tremaining: 1.4s\n",
      "761:\tlearn: 0.2728271\ttotal: 4.46s\tremaining: 1.39s\n",
      "762:\tlearn: 0.2727581\ttotal: 4.47s\tremaining: 1.39s\n",
      "763:\tlearn: 0.2726540\ttotal: 4.47s\tremaining: 1.38s\n",
      "764:\tlearn: 0.2726348\ttotal: 4.48s\tremaining: 1.38s\n",
      "765:\tlearn: 0.2725474\ttotal: 4.48s\tremaining: 1.37s\n",
      "766:\tlearn: 0.2724590\ttotal: 4.49s\tremaining: 1.36s\n",
      "767:\tlearn: 0.2723714\ttotal: 4.49s\tremaining: 1.36s\n",
      "768:\tlearn: 0.2722635\ttotal: 4.5s\tremaining: 1.35s\n",
      "769:\tlearn: 0.2722051\ttotal: 4.5s\tremaining: 1.34s\n",
      "770:\tlearn: 0.2721619\ttotal: 4.51s\tremaining: 1.34s\n",
      "771:\tlearn: 0.2720150\ttotal: 4.51s\tremaining: 1.33s\n",
      "772:\tlearn: 0.2719301\ttotal: 4.52s\tremaining: 1.33s\n",
      "773:\tlearn: 0.2718916\ttotal: 4.52s\tremaining: 1.32s\n",
      "774:\tlearn: 0.2717871\ttotal: 4.53s\tremaining: 1.31s\n",
      "775:\tlearn: 0.2716612\ttotal: 4.53s\tremaining: 1.31s\n",
      "776:\tlearn: 0.2715324\ttotal: 4.54s\tremaining: 1.3s\n",
      "777:\tlearn: 0.2714773\ttotal: 4.54s\tremaining: 1.3s\n",
      "778:\tlearn: 0.2714041\ttotal: 4.55s\tremaining: 1.29s\n",
      "779:\tlearn: 0.2713825\ttotal: 4.55s\tremaining: 1.28s\n",
      "780:\tlearn: 0.2713343\ttotal: 4.56s\tremaining: 1.28s\n",
      "781:\tlearn: 0.2712131\ttotal: 4.57s\tremaining: 1.27s\n",
      "782:\tlearn: 0.2711703\ttotal: 4.57s\tremaining: 1.27s\n",
      "783:\tlearn: 0.2711302\ttotal: 4.58s\tremaining: 1.26s\n",
      "784:\tlearn: 0.2710329\ttotal: 4.58s\tremaining: 1.25s\n",
      "785:\tlearn: 0.2709802\ttotal: 4.59s\tremaining: 1.25s\n",
      "786:\tlearn: 0.2708595\ttotal: 4.59s\tremaining: 1.24s\n",
      "787:\tlearn: 0.2707029\ttotal: 4.6s\tremaining: 1.24s\n",
      "788:\tlearn: 0.2705987\ttotal: 4.6s\tremaining: 1.23s\n",
      "789:\tlearn: 0.2704873\ttotal: 4.61s\tremaining: 1.23s\n",
      "790:\tlearn: 0.2704530\ttotal: 4.62s\tremaining: 1.22s\n",
      "791:\tlearn: 0.2703745\ttotal: 4.62s\tremaining: 1.21s\n",
      "792:\tlearn: 0.2703463\ttotal: 4.63s\tremaining: 1.21s\n",
      "793:\tlearn: 0.2702207\ttotal: 4.63s\tremaining: 1.2s\n",
      "794:\tlearn: 0.2701688\ttotal: 4.64s\tremaining: 1.2s\n",
      "795:\tlearn: 0.2701171\ttotal: 4.64s\tremaining: 1.19s\n",
      "796:\tlearn: 0.2700209\ttotal: 4.65s\tremaining: 1.18s\n",
      "797:\tlearn: 0.2698994\ttotal: 4.65s\tremaining: 1.18s\n",
      "798:\tlearn: 0.2697602\ttotal: 4.66s\tremaining: 1.17s\n",
      "799:\tlearn: 0.2696084\ttotal: 4.66s\tremaining: 1.17s\n",
      "800:\tlearn: 0.2695442\ttotal: 4.67s\tremaining: 1.16s\n",
      "801:\tlearn: 0.2694628\ttotal: 4.67s\tremaining: 1.15s\n",
      "802:\tlearn: 0.2693418\ttotal: 4.68s\tremaining: 1.15s\n",
      "803:\tlearn: 0.2692499\ttotal: 4.68s\tremaining: 1.14s\n",
      "804:\tlearn: 0.2691283\ttotal: 4.69s\tremaining: 1.14s\n",
      "805:\tlearn: 0.2689867\ttotal: 4.7s\tremaining: 1.13s\n",
      "806:\tlearn: 0.2688527\ttotal: 4.7s\tremaining: 1.12s\n",
      "807:\tlearn: 0.2687839\ttotal: 4.71s\tremaining: 1.12s\n",
      "808:\tlearn: 0.2687321\ttotal: 4.71s\tremaining: 1.11s\n",
      "809:\tlearn: 0.2686122\ttotal: 4.72s\tremaining: 1.11s\n",
      "810:\tlearn: 0.2684885\ttotal: 4.72s\tremaining: 1.1s\n",
      "811:\tlearn: 0.2684514\ttotal: 4.73s\tremaining: 1.09s\n",
      "812:\tlearn: 0.2683906\ttotal: 4.73s\tremaining: 1.09s\n",
      "813:\tlearn: 0.2682868\ttotal: 4.74s\tremaining: 1.08s\n",
      "814:\tlearn: 0.2682321\ttotal: 4.75s\tremaining: 1.08s\n",
      "815:\tlearn: 0.2681552\ttotal: 4.75s\tremaining: 1.07s\n",
      "816:\tlearn: 0.2680990\ttotal: 4.76s\tremaining: 1.07s\n",
      "817:\tlearn: 0.2680135\ttotal: 4.77s\tremaining: 1.06s\n",
      "818:\tlearn: 0.2679573\ttotal: 4.77s\tremaining: 1.05s\n",
      "819:\tlearn: 0.2679117\ttotal: 4.78s\tremaining: 1.05s\n",
      "820:\tlearn: 0.2678384\ttotal: 4.79s\tremaining: 1.04s\n",
      "821:\tlearn: 0.2677754\ttotal: 4.79s\tremaining: 1.04s\n",
      "822:\tlearn: 0.2677235\ttotal: 4.8s\tremaining: 1.03s\n",
      "823:\tlearn: 0.2676527\ttotal: 4.8s\tremaining: 1.02s\n",
      "824:\tlearn: 0.2675328\ttotal: 4.81s\tremaining: 1.02s\n",
      "825:\tlearn: 0.2674505\ttotal: 4.81s\tremaining: 1.01s\n",
      "826:\tlearn: 0.2673425\ttotal: 4.82s\tremaining: 1.01s\n",
      "827:\tlearn: 0.2672832\ttotal: 4.82s\tremaining: 1s\n",
      "828:\tlearn: 0.2671686\ttotal: 4.83s\tremaining: 996ms\n",
      "829:\tlearn: 0.2670860\ttotal: 4.83s\tremaining: 990ms\n",
      "830:\tlearn: 0.2669886\ttotal: 4.84s\tremaining: 984ms\n",
      "831:\tlearn: 0.2669281\ttotal: 4.84s\tremaining: 978ms\n",
      "832:\tlearn: 0.2668058\ttotal: 4.85s\tremaining: 972ms\n",
      "833:\tlearn: 0.2667177\ttotal: 4.86s\tremaining: 966ms\n",
      "834:\tlearn: 0.2666453\ttotal: 4.86s\tremaining: 960ms\n",
      "835:\tlearn: 0.2665487\ttotal: 4.87s\tremaining: 954ms\n",
      "836:\tlearn: 0.2664629\ttotal: 4.87s\tremaining: 949ms\n",
      "837:\tlearn: 0.2663864\ttotal: 4.88s\tremaining: 943ms\n",
      "838:\tlearn: 0.2663086\ttotal: 4.88s\tremaining: 937ms\n",
      "839:\tlearn: 0.2662306\ttotal: 4.89s\tremaining: 931ms\n",
      "840:\tlearn: 0.2661525\ttotal: 4.89s\tremaining: 925ms\n",
      "841:\tlearn: 0.2660692\ttotal: 4.9s\tremaining: 919ms\n",
      "842:\tlearn: 0.2660408\ttotal: 4.9s\tremaining: 913ms\n",
      "843:\tlearn: 0.2660099\ttotal: 4.91s\tremaining: 907ms\n",
      "844:\tlearn: 0.2658751\ttotal: 4.91s\tremaining: 901ms\n",
      "845:\tlearn: 0.2658480\ttotal: 4.92s\tremaining: 895ms\n",
      "846:\tlearn: 0.2658109\ttotal: 4.92s\tremaining: 889ms\n",
      "847:\tlearn: 0.2657389\ttotal: 4.93s\tremaining: 883ms\n",
      "848:\tlearn: 0.2656979\ttotal: 4.93s\tremaining: 877ms\n",
      "849:\tlearn: 0.2656278\ttotal: 4.94s\tremaining: 871ms\n",
      "850:\tlearn: 0.2655439\ttotal: 4.94s\tremaining: 866ms\n",
      "851:\tlearn: 0.2654303\ttotal: 4.95s\tremaining: 860ms\n",
      "852:\tlearn: 0.2653653\ttotal: 4.96s\tremaining: 854ms\n",
      "853:\tlearn: 0.2653241\ttotal: 4.96s\tremaining: 848ms\n",
      "854:\tlearn: 0.2652801\ttotal: 4.97s\tremaining: 843ms\n",
      "855:\tlearn: 0.2652233\ttotal: 4.97s\tremaining: 837ms\n",
      "856:\tlearn: 0.2651246\ttotal: 4.98s\tremaining: 831ms\n",
      "857:\tlearn: 0.2650747\ttotal: 4.99s\tremaining: 825ms\n",
      "858:\tlearn: 0.2650456\ttotal: 4.99s\tremaining: 820ms\n",
      "859:\tlearn: 0.2649360\ttotal: 5s\tremaining: 814ms\n",
      "860:\tlearn: 0.2648793\ttotal: 5s\tremaining: 808ms\n",
      "861:\tlearn: 0.2648140\ttotal: 5.01s\tremaining: 802ms\n",
      "862:\tlearn: 0.2647361\ttotal: 5.02s\tremaining: 796ms\n",
      "863:\tlearn: 0.2646798\ttotal: 5.02s\tremaining: 791ms\n",
      "864:\tlearn: 0.2645906\ttotal: 5.03s\tremaining: 785ms\n",
      "865:\tlearn: 0.2645194\ttotal: 5.03s\tremaining: 779ms\n",
      "866:\tlearn: 0.2643983\ttotal: 5.04s\tremaining: 773ms\n",
      "867:\tlearn: 0.2643531\ttotal: 5.05s\tremaining: 767ms\n",
      "868:\tlearn: 0.2642552\ttotal: 5.05s\tremaining: 762ms\n",
      "869:\tlearn: 0.2641458\ttotal: 5.06s\tremaining: 756ms\n",
      "870:\tlearn: 0.2640112\ttotal: 5.06s\tremaining: 750ms\n",
      "871:\tlearn: 0.2639135\ttotal: 5.07s\tremaining: 744ms\n",
      "872:\tlearn: 0.2638354\ttotal: 5.08s\tremaining: 738ms\n",
      "873:\tlearn: 0.2637859\ttotal: 5.08s\tremaining: 733ms\n",
      "874:\tlearn: 0.2637026\ttotal: 5.09s\tremaining: 727ms\n",
      "875:\tlearn: 0.2636029\ttotal: 5.09s\tremaining: 721ms\n",
      "876:\tlearn: 0.2635656\ttotal: 5.1s\tremaining: 715ms\n",
      "877:\tlearn: 0.2635228\ttotal: 5.11s\tremaining: 709ms\n",
      "878:\tlearn: 0.2634539\ttotal: 5.11s\tremaining: 704ms\n",
      "879:\tlearn: 0.2633931\ttotal: 5.12s\tremaining: 698ms\n",
      "880:\tlearn: 0.2633320\ttotal: 5.12s\tremaining: 692ms\n",
      "881:\tlearn: 0.2632766\ttotal: 5.13s\tremaining: 686ms\n",
      "882:\tlearn: 0.2632390\ttotal: 5.13s\tremaining: 680ms\n",
      "883:\tlearn: 0.2631281\ttotal: 5.14s\tremaining: 675ms\n",
      "884:\tlearn: 0.2630472\ttotal: 5.15s\tremaining: 669ms\n",
      "885:\tlearn: 0.2629428\ttotal: 5.15s\tremaining: 663ms\n",
      "886:\tlearn: 0.2628574\ttotal: 5.16s\tremaining: 657ms\n",
      "887:\tlearn: 0.2627803\ttotal: 5.16s\tremaining: 651ms\n",
      "888:\tlearn: 0.2627079\ttotal: 5.17s\tremaining: 646ms\n",
      "889:\tlearn: 0.2626415\ttotal: 5.18s\tremaining: 640ms\n",
      "890:\tlearn: 0.2625322\ttotal: 5.18s\tremaining: 634ms\n",
      "891:\tlearn: 0.2624967\ttotal: 5.19s\tremaining: 628ms\n",
      "892:\tlearn: 0.2623778\ttotal: 5.2s\tremaining: 623ms\n",
      "893:\tlearn: 0.2622727\ttotal: 5.2s\tremaining: 617ms\n",
      "894:\tlearn: 0.2622079\ttotal: 5.21s\tremaining: 611ms\n",
      "895:\tlearn: 0.2620831\ttotal: 5.21s\tremaining: 605ms\n",
      "896:\tlearn: 0.2620174\ttotal: 5.22s\tremaining: 599ms\n",
      "897:\tlearn: 0.2619331\ttotal: 5.23s\tremaining: 594ms\n",
      "898:\tlearn: 0.2618948\ttotal: 5.23s\tremaining: 588ms\n",
      "899:\tlearn: 0.2618501\ttotal: 5.24s\tremaining: 582ms\n",
      "900:\tlearn: 0.2616981\ttotal: 5.25s\tremaining: 576ms\n",
      "901:\tlearn: 0.2615819\ttotal: 5.25s\tremaining: 571ms\n",
      "902:\tlearn: 0.2615160\ttotal: 5.26s\tremaining: 565ms\n",
      "903:\tlearn: 0.2614027\ttotal: 5.27s\tremaining: 560ms\n",
      "904:\tlearn: 0.2613459\ttotal: 5.28s\tremaining: 554ms\n",
      "905:\tlearn: 0.2613435\ttotal: 5.28s\tremaining: 548ms\n",
      "906:\tlearn: 0.2612970\ttotal: 5.29s\tremaining: 542ms\n",
      "907:\tlearn: 0.2612424\ttotal: 5.29s\tremaining: 536ms\n",
      "908:\tlearn: 0.2612108\ttotal: 5.3s\tremaining: 531ms\n",
      "909:\tlearn: 0.2611295\ttotal: 5.31s\tremaining: 525ms\n",
      "910:\tlearn: 0.2610635\ttotal: 5.31s\tremaining: 519ms\n",
      "911:\tlearn: 0.2609467\ttotal: 5.32s\tremaining: 513ms\n",
      "912:\tlearn: 0.2608779\ttotal: 5.33s\tremaining: 508ms\n",
      "913:\tlearn: 0.2608018\ttotal: 5.33s\tremaining: 502ms\n",
      "914:\tlearn: 0.2607304\ttotal: 5.34s\tremaining: 496ms\n",
      "915:\tlearn: 0.2606858\ttotal: 5.34s\tremaining: 490ms\n",
      "916:\tlearn: 0.2606450\ttotal: 5.35s\tremaining: 484ms\n",
      "917:\tlearn: 0.2605660\ttotal: 5.36s\tremaining: 478ms\n",
      "918:\tlearn: 0.2605061\ttotal: 5.36s\tremaining: 473ms\n",
      "919:\tlearn: 0.2604702\ttotal: 5.37s\tremaining: 467ms\n",
      "920:\tlearn: 0.2604241\ttotal: 5.37s\tremaining: 461ms\n",
      "921:\tlearn: 0.2603936\ttotal: 5.38s\tremaining: 455ms\n",
      "922:\tlearn: 0.2602985\ttotal: 5.39s\tremaining: 449ms\n",
      "923:\tlearn: 0.2602152\ttotal: 5.39s\tremaining: 444ms\n",
      "924:\tlearn: 0.2601912\ttotal: 5.4s\tremaining: 438ms\n",
      "925:\tlearn: 0.2601025\ttotal: 5.41s\tremaining: 432ms\n",
      "926:\tlearn: 0.2600067\ttotal: 5.41s\tremaining: 426ms\n",
      "927:\tlearn: 0.2599090\ttotal: 5.42s\tremaining: 420ms\n",
      "928:\tlearn: 0.2598221\ttotal: 5.42s\tremaining: 415ms\n",
      "929:\tlearn: 0.2597665\ttotal: 5.43s\tremaining: 409ms\n",
      "930:\tlearn: 0.2596541\ttotal: 5.43s\tremaining: 403ms\n",
      "931:\tlearn: 0.2596452\ttotal: 5.44s\tremaining: 397ms\n",
      "932:\tlearn: 0.2595597\ttotal: 5.45s\tremaining: 391ms\n",
      "933:\tlearn: 0.2594926\ttotal: 5.45s\tremaining: 385ms\n",
      "934:\tlearn: 0.2594661\ttotal: 5.46s\tremaining: 380ms\n",
      "935:\tlearn: 0.2593702\ttotal: 5.46s\tremaining: 374ms\n",
      "936:\tlearn: 0.2593153\ttotal: 5.47s\tremaining: 368ms\n",
      "937:\tlearn: 0.2592802\ttotal: 5.48s\tremaining: 362ms\n",
      "938:\tlearn: 0.2592307\ttotal: 5.48s\tremaining: 356ms\n",
      "939:\tlearn: 0.2591946\ttotal: 5.49s\tremaining: 350ms\n",
      "940:\tlearn: 0.2591462\ttotal: 5.49s\tremaining: 345ms\n",
      "941:\tlearn: 0.2591124\ttotal: 5.5s\tremaining: 339ms\n",
      "942:\tlearn: 0.2590775\ttotal: 5.51s\tremaining: 333ms\n",
      "943:\tlearn: 0.2590129\ttotal: 5.51s\tremaining: 327ms\n",
      "944:\tlearn: 0.2589479\ttotal: 5.52s\tremaining: 321ms\n",
      "945:\tlearn: 0.2589201\ttotal: 5.52s\tremaining: 315ms\n",
      "946:\tlearn: 0.2589057\ttotal: 5.53s\tremaining: 309ms\n",
      "947:\tlearn: 0.2588005\ttotal: 5.54s\tremaining: 304ms\n",
      "948:\tlearn: 0.2587192\ttotal: 5.54s\tremaining: 298ms\n",
      "949:\tlearn: 0.2586757\ttotal: 5.55s\tremaining: 292ms\n",
      "950:\tlearn: 0.2585928\ttotal: 5.55s\tremaining: 286ms\n",
      "951:\tlearn: 0.2585273\ttotal: 5.56s\tremaining: 280ms\n",
      "952:\tlearn: 0.2584445\ttotal: 5.56s\tremaining: 274ms\n",
      "953:\tlearn: 0.2583567\ttotal: 5.57s\tremaining: 269ms\n",
      "954:\tlearn: 0.2583028\ttotal: 5.58s\tremaining: 263ms\n",
      "955:\tlearn: 0.2581875\ttotal: 5.58s\tremaining: 257ms\n",
      "956:\tlearn: 0.2581251\ttotal: 5.59s\tremaining: 251ms\n",
      "957:\tlearn: 0.2580511\ttotal: 5.59s\tremaining: 245ms\n",
      "958:\tlearn: 0.2579958\ttotal: 5.6s\tremaining: 239ms\n",
      "959:\tlearn: 0.2579268\ttotal: 5.61s\tremaining: 234ms\n",
      "960:\tlearn: 0.2578455\ttotal: 5.61s\tremaining: 228ms\n",
      "961:\tlearn: 0.2577748\ttotal: 5.62s\tremaining: 222ms\n",
      "962:\tlearn: 0.2577275\ttotal: 5.63s\tremaining: 216ms\n",
      "963:\tlearn: 0.2576224\ttotal: 5.63s\tremaining: 210ms\n",
      "964:\tlearn: 0.2575316\ttotal: 5.64s\tremaining: 204ms\n",
      "965:\tlearn: 0.2574382\ttotal: 5.64s\tremaining: 199ms\n",
      "966:\tlearn: 0.2573570\ttotal: 5.65s\tremaining: 193ms\n",
      "967:\tlearn: 0.2573337\ttotal: 5.66s\tremaining: 187ms\n",
      "968:\tlearn: 0.2572527\ttotal: 5.66s\tremaining: 181ms\n",
      "969:\tlearn: 0.2571892\ttotal: 5.67s\tremaining: 175ms\n",
      "970:\tlearn: 0.2571469\ttotal: 5.67s\tremaining: 169ms\n",
      "971:\tlearn: 0.2570734\ttotal: 5.68s\tremaining: 164ms\n",
      "972:\tlearn: 0.2570301\ttotal: 5.68s\tremaining: 158ms\n",
      "973:\tlearn: 0.2570043\ttotal: 5.69s\tremaining: 152ms\n",
      "974:\tlearn: 0.2569717\ttotal: 5.7s\tremaining: 146ms\n",
      "975:\tlearn: 0.2569356\ttotal: 5.7s\tremaining: 140ms\n",
      "976:\tlearn: 0.2568057\ttotal: 5.71s\tremaining: 134ms\n",
      "977:\tlearn: 0.2568039\ttotal: 5.71s\tremaining: 129ms\n",
      "978:\tlearn: 0.2567063\ttotal: 5.72s\tremaining: 123ms\n",
      "979:\tlearn: 0.2566481\ttotal: 5.73s\tremaining: 117ms\n",
      "980:\tlearn: 0.2565624\ttotal: 5.73s\tremaining: 111ms\n",
      "981:\tlearn: 0.2565049\ttotal: 5.74s\tremaining: 105ms\n",
      "982:\tlearn: 0.2564626\ttotal: 5.75s\tremaining: 99.4ms\n",
      "983:\tlearn: 0.2563767\ttotal: 5.75s\tremaining: 93.6ms\n",
      "984:\tlearn: 0.2563095\ttotal: 5.76s\tremaining: 87.7ms\n",
      "985:\tlearn: 0.2561807\ttotal: 5.77s\tremaining: 81.9ms\n",
      "986:\tlearn: 0.2561417\ttotal: 5.77s\tremaining: 76.1ms\n",
      "987:\tlearn: 0.2560940\ttotal: 5.78s\tremaining: 70.2ms\n",
      "988:\tlearn: 0.2560796\ttotal: 5.79s\tremaining: 64.4ms\n",
      "989:\tlearn: 0.2560779\ttotal: 5.79s\tremaining: 58.5ms\n",
      "990:\tlearn: 0.2559781\ttotal: 5.8s\tremaining: 52.7ms\n",
      "991:\tlearn: 0.2559371\ttotal: 5.8s\tremaining: 46.8ms\n",
      "992:\tlearn: 0.2558508\ttotal: 5.81s\tremaining: 41ms\n",
      "993:\tlearn: 0.2557391\ttotal: 5.82s\tremaining: 35.1ms\n",
      "994:\tlearn: 0.2556727\ttotal: 5.82s\tremaining: 29.3ms\n",
      "995:\tlearn: 0.2555950\ttotal: 5.83s\tremaining: 23.4ms\n",
      "996:\tlearn: 0.2555395\ttotal: 5.83s\tremaining: 17.6ms\n",
      "997:\tlearn: 0.2554150\ttotal: 5.84s\tremaining: 11.7ms\n",
      "998:\tlearn: 0.2552839\ttotal: 5.85s\tremaining: 5.85ms\n",
      "999:\tlearn: 0.2552121\ttotal: 5.85s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cb = CatBoostClassifier()\n",
    "cb.fit(x_train,y_train)\n",
    "cb.score(x_train,y_train)\n",
    "cb.score(x_test,y_test)\n",
    "y_pred = cb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------CatBoost Classifier---------------------------------\n",
      "For Y variable\n",
      "---------------------------------------------------------------------\n",
      "the Accuracy score for H1N1 vaccine : 0.8561622464898596\n",
      "---------------------------------------------------------------------\n",
      "the classification report for H1N1 vaccine :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      5024\n",
      "           1       0.74      0.51      0.61      1386\n",
      "\n",
      "    accuracy                           0.86      6410\n",
      "   macro avg       0.81      0.73      0.76      6410\n",
      "weighted avg       0.85      0.86      0.85      6410\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "the confusion matrix for H1N1 vaccine : [[4779  245]\n",
      " [ 677  709]]\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------CatBoost Classifier---------------------------------\")\n",
    "print(\"For Y variable\")\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(f'the Accuracy score for H1N1 vaccine : {accuracy_score(y_test,y_pred)}')\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(f'the classification report for H1N1 vaccine : {classification_report(y_test,y_pred)}')\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(f'the confusion matrix for H1N1 vaccine : {confusion_matrix(y_test,y_pred)}')\n",
    "print(\"---------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-29 18:03:04,286] A new study created in memory with name: no-name-dd0a9922-2734-472b-9ac1-80edb0febf9c\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:03:04,801] Trial 0 finished with value: 0.8497659906396255 and parameters: {'iterations': 100, 'learning_rate': 0.035894396442059134, 'min_data_in_leaf': 4, 'max_depth': 5, 'l2_leaf_reg': 9.47666119413604e-05}. Best is trial 0 with value: 0.8497659906396255.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:03:13,726] Trial 1 finished with value: 0.8452418096723869 and parameters: {'iterations': 300, 'learning_rate': 0.05975602127649394, 'min_data_in_leaf': 5, 'max_depth': 10, 'l2_leaf_reg': 1.505039676213395e-08}. Best is trial 0 with value: 0.8497659906396255.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:03:15,370] Trial 2 finished with value: 0.8525741029641186 and parameters: {'iterations': 500, 'learning_rate': 0.10273532066122266, 'min_data_in_leaf': 8, 'max_depth': 2, 'l2_leaf_reg': 8.735534268261519e-07}. Best is trial 2 with value: 0.8525741029641186.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:03:22,444] Trial 3 finished with value: 0.8444617784711388 and parameters: {'iterations': 700, 'learning_rate': 0.208080818691416, 'min_data_in_leaf': 4, 'max_depth': 8, 'l2_leaf_reg': 0.25316112131962065}. Best is trial 2 with value: 0.8525741029641186.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:03:28,011] Trial 4 finished with value: 0.8418096723868955 and parameters: {'iterations': 700, 'learning_rate': 0.1420457038831878, 'min_data_in_leaf': 1, 'max_depth': 7, 'l2_leaf_reg': 5.703491082507723e-07}. Best is trial 2 with value: 0.8525741029641186.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:03:30,358] Trial 5 finished with value: 0.8380655226209048 and parameters: {'iterations': 300, 'learning_rate': 0.20433633149644126, 'min_data_in_leaf': 3, 'max_depth': 7, 'l2_leaf_reg': 5.993184464679285e-05}. Best is trial 2 with value: 0.8525741029641186.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:03:34,140] Trial 6 finished with value: 0.8522620904836193 and parameters: {'iterations': 500, 'learning_rate': 0.09126346192730868, 'min_data_in_leaf': 6, 'max_depth': 7, 'l2_leaf_reg': 0.018844324161302425}. Best is trial 2 with value: 0.8525741029641186.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:03:44,739] Trial 7 finished with value: 0.8494539781591264 and parameters: {'iterations': 700, 'learning_rate': 0.06760407067891355, 'min_data_in_leaf': 7, 'max_depth': 9, 'l2_leaf_reg': 1.6162021560746067e-06}. Best is trial 2 with value: 0.8525741029641186.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:03:47,063] Trial 8 finished with value: 0.8371294851794072 and parameters: {'iterations': 300, 'learning_rate': 0.29415467414618274, 'min_data_in_leaf': 1, 'max_depth': 7, 'l2_leaf_reg': 0.049527557188882264}. Best is trial 2 with value: 0.8525741029641186.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:03:54,003] Trial 9 finished with value: 0.8474258970358814 and parameters: {'iterations': 900, 'learning_rate': 0.13501043626617013, 'min_data_in_leaf': 9, 'max_depth': 7, 'l2_leaf_reg': 0.0677411458550689}. Best is trial 2 with value: 0.8525741029641186.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:03:55,614] Trial 10 finished with value: 0.8538221528861154 and parameters: {'iterations': 500, 'learning_rate': 0.24575297060332252, 'min_data_in_leaf': 10, 'max_depth': 2, 'l2_leaf_reg': 1.6436799072361776e-08}. Best is trial 10 with value: 0.8538221528861154.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:03:57,451] Trial 11 finished with value: 0.8563182527301092 and parameters: {'iterations': 500, 'learning_rate': 0.28823888189991503, 'min_data_in_leaf': 10, 'max_depth': 2, 'l2_leaf_reg': 43.629124765348124}. Best is trial 11 with value: 0.8563182527301092.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:03:59,314] Trial 12 finished with value: 0.8556942277691107 and parameters: {'iterations': 500, 'learning_rate': 0.2952407047909869, 'min_data_in_leaf': 10, 'max_depth': 2, 'l2_leaf_reg': 32.41100887451459}. Best is trial 11 with value: 0.8563182527301092.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:03:59,884] Trial 13 finished with value: 0.858814352574103 and parameters: {'iterations': 100, 'learning_rate': 0.28142974595361897, 'min_data_in_leaf': 10, 'max_depth': 4, 'l2_leaf_reg': 70.22181499869039}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:00,459] Trial 14 finished with value: 0.8555382215288612 and parameters: {'iterations': 100, 'learning_rate': 0.2431653961316018, 'min_data_in_leaf': 8, 'max_depth': 4, 'l2_leaf_reg': 82.5295295725384}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:01,023] Trial 15 finished with value: 0.8564742589703588 and parameters: {'iterations': 100, 'learning_rate': 0.24359608321965667, 'min_data_in_leaf': 10, 'max_depth': 4, 'l2_leaf_reg': 2.2146295325277463}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:01,597] Trial 16 finished with value: 0.8519500780031202 and parameters: {'iterations': 100, 'learning_rate': 0.19427970267806174, 'min_data_in_leaf': 8, 'max_depth': 4, 'l2_leaf_reg': 1.42879273993627}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:02,166] Trial 17 finished with value: 0.8561622464898596 and parameters: {'iterations': 100, 'learning_rate': 0.24880736026491704, 'min_data_in_leaf': 9, 'max_depth': 4, 'l2_leaf_reg': 3.126871894366928}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:03,828] Trial 18 finished with value: 0.8361934477379095 and parameters: {'iterations': 300, 'learning_rate': 0.0015780614464229736, 'min_data_in_leaf': 7, 'max_depth': 5, 'l2_leaf_reg': 2.945876003504569}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:04,261] Trial 19 finished with value: 0.8552262090483619 and parameters: {'iterations': 100, 'learning_rate': 0.16411236257705475, 'min_data_in_leaf': 9, 'max_depth': 3, 'l2_leaf_reg': 0.0034432250485592498}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:05,849] Trial 20 finished with value: 0.849609984399376 and parameters: {'iterations': 300, 'learning_rate': 0.25321880422426424, 'min_data_in_leaf': 6, 'max_depth': 5, 'l2_leaf_reg': 0.6458070511068894}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:09,499] Trial 21 finished with value: 0.8482059282371295 and parameters: {'iterations': 900, 'learning_rate': 0.2750896389616659, 'min_data_in_leaf': 10, 'max_depth': 3, 'l2_leaf_reg': 12.07431704012429}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:09,971] Trial 22 finished with value: 0.8546021840873635 and parameters: {'iterations': 100, 'learning_rate': 0.2720432924379538, 'min_data_in_leaf': 10, 'max_depth': 3, 'l2_leaf_reg': 12.59899536867366}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:11,288] Trial 23 finished with value: 0.8555382215288612 and parameters: {'iterations': 300, 'learning_rate': 0.22427113143001343, 'min_data_in_leaf': 9, 'max_depth': 3, 'l2_leaf_reg': 84.1730026240078}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:15,597] Trial 24 finished with value: 0.8414976599063962 and parameters: {'iterations': 700, 'learning_rate': 0.2998850224226772, 'min_data_in_leaf': 10, 'max_depth': 6, 'l2_leaf_reg': 7.399948329324592}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:16,099] Trial 25 finished with value: 0.8546021840873635 and parameters: {'iterations': 100, 'learning_rate': 0.27552570080853306, 'min_data_in_leaf': 8, 'max_depth': 4, 'l2_leaf_reg': 0.26824427724369965}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:17,692] Trial 26 finished with value: 0.8567862714508581 and parameters: {'iterations': 300, 'learning_rate': 0.1753094352670665, 'min_data_in_leaf': 7, 'max_depth': 5, 'l2_leaf_reg': 89.9549430720076}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:19,554] Trial 27 finished with value: 0.847581903276131 and parameters: {'iterations': 300, 'learning_rate': 0.17243623761707264, 'min_data_in_leaf': 7, 'max_depth': 6, 'l2_leaf_reg': 0.005963619965875222}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:20,104] Trial 28 finished with value: 0.8519500780031202 and parameters: {'iterations': 100, 'learning_rate': 0.1773423485811938, 'min_data_in_leaf': 2, 'max_depth': 5, 'l2_leaf_reg': 0.00016643742618198696}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:20,688] Trial 29 finished with value: 0.8552262090483619 and parameters: {'iterations': 100, 'learning_rate': 0.2199455322387373, 'min_data_in_leaf': 5, 'max_depth': 5, 'l2_leaf_reg': 0.6770784369343749}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:22,535] Trial 30 finished with value: 0.853198127925117 and parameters: {'iterations': 300, 'learning_rate': 0.23097498119642992, 'min_data_in_leaf': 4, 'max_depth': 6, 'l2_leaf_reg': 13.503052327368437}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:24,851] Trial 31 finished with value: 0.8535101404056162 and parameters: {'iterations': 500, 'learning_rate': 0.268182064982598, 'min_data_in_leaf': 9, 'max_depth': 4, 'l2_leaf_reg': 95.20206264619831}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:26,132] Trial 32 finished with value: 0.8541341653666147 and parameters: {'iterations': 300, 'learning_rate': 0.2698596178432455, 'min_data_in_leaf': 10, 'max_depth': 3, 'l2_leaf_reg': 22.314469416612077}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:26,514] Trial 33 finished with value: 0.8486739469578783 and parameters: {'iterations': 100, 'learning_rate': 0.12684404695673865, 'min_data_in_leaf': 9, 'max_depth': 2, 'l2_leaf_reg': 3.21039788504254}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:29,121] Trial 34 finished with value: 0.8521060842433698 and parameters: {'iterations': 500, 'learning_rate': 0.18837465374679616, 'min_data_in_leaf': 8, 'max_depth': 5, 'l2_leaf_reg': 40.57443704180066}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:32,158] Trial 35 finished with value: 0.8483619344773791 and parameters: {'iterations': 100, 'learning_rate': 0.2572562159087462, 'min_data_in_leaf': 10, 'max_depth': 10, 'l2_leaf_reg': 0.22519684444344626}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:33,689] Trial 36 finished with value: 0.8544461778471139 and parameters: {'iterations': 300, 'learning_rate': 0.11321489467399962, 'min_data_in_leaf': 7, 'max_depth': 4, 'l2_leaf_reg': 3.3316045324322214}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:34,949] Trial 37 finished with value: 0.8564742589703588 and parameters: {'iterations': 300, 'learning_rate': 0.208095012378705, 'min_data_in_leaf': 3, 'max_depth': 2, 'l2_leaf_reg': 28.84967172828127}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:36,072] Trial 38 finished with value: 0.8469578783151326 and parameters: {'iterations': 100, 'learning_rate': 0.15202851713979043, 'min_data_in_leaf': 3, 'max_depth': 8, 'l2_leaf_reg': 0.0004818864526298305}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:37,374] Trial 39 finished with value: 0.8516380655226209 and parameters: {'iterations': 300, 'learning_rate': 0.2100944253435337, 'min_data_in_leaf': 3, 'max_depth': 3, 'l2_leaf_reg': 3.199067396007431e-06}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:38,972] Trial 40 finished with value: 0.8464898595943837 and parameters: {'iterations': 300, 'learning_rate': 0.19863214293742798, 'min_data_in_leaf': 5, 'max_depth': 5, 'l2_leaf_reg': 1.693755898165701e-05}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:41,633] Trial 41 finished with value: 0.8553822152886116 and parameters: {'iterations': 700, 'learning_rate': 0.23058826626373513, 'min_data_in_leaf': 4, 'max_depth': 2, 'l2_leaf_reg': 35.915765129739746}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:43,549] Trial 42 finished with value: 0.8549141965678627 and parameters: {'iterations': 500, 'learning_rate': 0.27887764015400196, 'min_data_in_leaf': 2, 'max_depth': 2, 'l2_leaf_reg': 8.385267447281446}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:45,335] Trial 43 finished with value: 0.8538221528861154 and parameters: {'iterations': 500, 'learning_rate': 0.2846615279160929, 'min_data_in_leaf': 6, 'max_depth': 2, 'l2_leaf_reg': 1.0941456671802727}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:47,477] Trial 44 finished with value: 0.8536661466458658 and parameters: {'iterations': 500, 'learning_rate': 0.23555157995024376, 'min_data_in_leaf': 9, 'max_depth': 3, 'l2_leaf_reg': 36.66827085705003}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:48,918] Trial 45 finished with value: 0.8547581903276131 and parameters: {'iterations': 300, 'learning_rate': 0.21646369091175838, 'min_data_in_leaf': 10, 'max_depth': 4, 'l2_leaf_reg': 4.649866766369649}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:53,181] Trial 46 finished with value: 0.8425897035881436 and parameters: {'iterations': 700, 'learning_rate': 0.18349702247772998, 'min_data_in_leaf': 2, 'max_depth': 6, 'l2_leaf_reg': 0.07182630685301199}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:53,603] Trial 47 finished with value: 0.8535101404056162 and parameters: {'iterations': 100, 'learning_rate': 0.26113826411804336, 'min_data_in_leaf': 8, 'max_depth': 2, 'l2_leaf_reg': 67.7754840928646}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:55,786] Trial 48 finished with value: 0.8494539781591264 and parameters: {'iterations': 500, 'learning_rate': 0.16030693600866078, 'min_data_in_leaf': 1, 'max_depth': 4, 'l2_leaf_reg': 1.4055501111133744e-07}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:56,266] Trial 49 finished with value: 0.8566302652106085 and parameters: {'iterations': 100, 'learning_rate': 0.28756664029688805, 'min_data_in_leaf': 7, 'max_depth': 3, 'l2_leaf_reg': 19.573450319990382}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:56,694] Trial 50 finished with value: 0.8516380655226209 and parameters: {'iterations': 100, 'learning_rate': 0.08243383464085259, 'min_data_in_leaf': 7, 'max_depth': 3, 'l2_leaf_reg': 0.2162006782466049}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:57,169] Trial 51 finished with value: 0.8533541341653667 and parameters: {'iterations': 100, 'learning_rate': 0.29032223763820286, 'min_data_in_leaf': 6, 'max_depth': 3, 'l2_leaf_reg': 24.386140482011232}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:57,589] Trial 52 finished with value: 0.8533541341653667 and parameters: {'iterations': 100, 'learning_rate': 0.2431461688053919, 'min_data_in_leaf': 9, 'max_depth': 2, 'l2_leaf_reg': 1.5525854469748308}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:04:59,060] Trial 53 finished with value: 0.8517940717628705 and parameters: {'iterations': 300, 'learning_rate': 0.28673519375995954, 'min_data_in_leaf': 7, 'max_depth': 4, 'l2_leaf_reg': 16.141401507903275}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:00,268] Trial 54 finished with value: 0.8547581903276131 and parameters: {'iterations': 300, 'learning_rate': 0.25763277648311683, 'min_data_in_leaf': 5, 'max_depth': 2, 'l2_leaf_reg': 97.1518554481717}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:00,741] Trial 55 finished with value: 0.8538221528861154 and parameters: {'iterations': 100, 'learning_rate': 0.2638308259867165, 'min_data_in_leaf': 8, 'max_depth': 3, 'l2_leaf_reg': 7.055204165321259}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:01,338] Trial 56 finished with value: 0.8556942277691107 and parameters: {'iterations': 100, 'learning_rate': 0.29935333519246693, 'min_data_in_leaf': 10, 'max_depth': 5, 'l2_leaf_reg': 33.369104562716416}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:04,250] Trial 57 finished with value: 0.8517940717628705 and parameters: {'iterations': 700, 'learning_rate': 0.24236084433627633, 'min_data_in_leaf': 6, 'max_depth': 3, 'l2_leaf_reg': 2.2955838374283726}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:04,778] Trial 58 finished with value: 0.8550702028081123 and parameters: {'iterations': 100, 'learning_rate': 0.20313256674769223, 'min_data_in_leaf': 9, 'max_depth': 4, 'l2_leaf_reg': 7.219271045843171}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:05,852] Trial 59 finished with value: 0.8542901716068643 and parameters: {'iterations': 300, 'learning_rate': 0.28230990285552104, 'min_data_in_leaf': 5, 'max_depth': 2, 'l2_leaf_reg': 0.5218559205898826}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:10,214] Trial 60 finished with value: 0.846021840873635 and parameters: {'iterations': 900, 'learning_rate': 0.2520077167046081, 'min_data_in_leaf': 10, 'max_depth': 4, 'l2_leaf_reg': 16.75786343685438}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:10,828] Trial 61 finished with value: 0.8544461778471139 and parameters: {'iterations': 100, 'learning_rate': 0.24931010056421923, 'min_data_in_leaf': 10, 'max_depth': 5, 'l2_leaf_reg': 53.984820958086644}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:11,394] Trial 62 finished with value: 0.85600624024961 and parameters: {'iterations': 100, 'learning_rate': 0.2229037364603676, 'min_data_in_leaf': 9, 'max_depth': 4, 'l2_leaf_reg': 5.25145084080691}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:11,922] Trial 63 finished with value: 0.8563182527301092 and parameters: {'iterations': 100, 'learning_rate': 0.27207941496728405, 'min_data_in_leaf': 9, 'max_depth': 3, 'l2_leaf_reg': 18.11616435739461}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:12,423] Trial 64 finished with value: 0.8541341653666147 and parameters: {'iterations': 100, 'learning_rate': 0.2926133138145258, 'min_data_in_leaf': 8, 'max_depth': 3, 'l2_leaf_reg': 12.459299479884038}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:12,921] Trial 65 finished with value: 0.8553822152886116 and parameters: {'iterations': 100, 'learning_rate': 0.2726807590182571, 'min_data_in_leaf': 10, 'max_depth': 3, 'l2_leaf_reg': 30.393257262764383}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:14,125] Trial 66 finished with value: 0.8297971918876755 and parameters: {'iterations': 300, 'learning_rate': 0.004177037316935639, 'min_data_in_leaf': 9, 'max_depth': 2, 'l2_leaf_reg': 93.97656844505407}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:14,705] Trial 67 finished with value: 0.85600624024961 and parameters: {'iterations': 100, 'learning_rate': 0.26563055240581734, 'min_data_in_leaf': 10, 'max_depth': 4, 'l2_leaf_reg': 1.6079460716063938}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:15,217] Trial 68 finished with value: 0.8547581903276131 and parameters: {'iterations': 100, 'learning_rate': 0.2111865899150791, 'min_data_in_leaf': 8, 'max_depth': 3, 'l2_leaf_reg': 21.501618480975125}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:19,905] Trial 69 finished with value: 0.8438377535101405 and parameters: {'iterations': 300, 'learning_rate': 0.23542833139622577, 'min_data_in_leaf': 7, 'max_depth': 9, 'l2_leaf_reg': 0.013073327127893218}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:21,086] Trial 70 finished with value: 0.8544461778471139 and parameters: {'iterations': 300, 'learning_rate': 0.28021345090172767, 'min_data_in_leaf': 9, 'max_depth': 2, 'l2_leaf_reg': 51.86273315649098}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:21,681] Trial 71 finished with value: 0.8556942277691107 and parameters: {'iterations': 100, 'learning_rate': 0.17287910249329616, 'min_data_in_leaf': 10, 'max_depth': 5, 'l2_leaf_reg': 3.7901848890915857}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:22,224] Trial 72 finished with value: 0.8541341653666147 and parameters: {'iterations': 100, 'learning_rate': 0.19079277978289094, 'min_data_in_leaf': 9, 'max_depth': 4, 'l2_leaf_reg': 12.235412645611873}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:22,813] Trial 73 finished with value: 0.8533541341653667 and parameters: {'iterations': 100, 'learning_rate': 0.13818466968192694, 'min_data_in_leaf': 9, 'max_depth': 4, 'l2_leaf_reg': 8.067116394059385}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:23,431] Trial 74 finished with value: 0.8555382215288612 and parameters: {'iterations': 100, 'learning_rate': 0.2732782280746744, 'min_data_in_leaf': 10, 'max_depth': 5, 'l2_leaf_reg': 0.6868086971534165}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:25,550] Trial 75 finished with value: 0.8510140405616224 and parameters: {'iterations': 500, 'learning_rate': 0.2904913866649859, 'min_data_in_leaf': 4, 'max_depth': 3, 'l2_leaf_reg': 2.806923628286639}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:26,216] Trial 76 finished with value: 0.8547581903276131 and parameters: {'iterations': 100, 'learning_rate': 0.2520807830916927, 'min_data_in_leaf': 9, 'max_depth': 6, 'l2_leaf_reg': 48.13186165435711}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:26,720] Trial 77 finished with value: 0.8561622464898596 and parameters: {'iterations': 100, 'learning_rate': 0.22961514960339585, 'min_data_in_leaf': 8, 'max_depth': 4, 'l2_leaf_reg': 0.10127547148239219}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:27,166] Trial 78 finished with value: 0.8550702028081123 and parameters: {'iterations': 100, 'learning_rate': 0.24087246670703494, 'min_data_in_leaf': 10, 'max_depth': 3, 'l2_leaf_reg': 0.0024091053721049588}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:28,479] Trial 79 finished with value: 0.8542901716068643 and parameters: {'iterations': 300, 'learning_rate': 0.25962381374819316, 'min_data_in_leaf': 10, 'max_depth': 3, 'l2_leaf_reg': 20.99627318646454}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:30,306] Trial 80 finished with value: 0.8570982839313572 and parameters: {'iterations': 500, 'learning_rate': 0.2985470281700748, 'min_data_in_leaf': 7, 'max_depth': 2, 'l2_leaf_reg': 51.99421535029474}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:32,153] Trial 81 finished with value: 0.8552262090483619 and parameters: {'iterations': 500, 'learning_rate': 0.2956951795926547, 'min_data_in_leaf': 7, 'max_depth': 2, 'l2_leaf_reg': 48.0709777862996}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:34,014] Trial 82 finished with value: 0.8572542901716068 and parameters: {'iterations': 500, 'learning_rate': 0.28489942929677203, 'min_data_in_leaf': 6, 'max_depth': 2, 'l2_leaf_reg': 98.36138074942897}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:35,875] Trial 83 finished with value: 0.8563182527301092 and parameters: {'iterations': 500, 'learning_rate': 0.27771916921537465, 'min_data_in_leaf': 6, 'max_depth': 2, 'l2_leaf_reg': 98.32449404931208}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:37,741] Trial 84 finished with value: 0.8536661466458658 and parameters: {'iterations': 500, 'learning_rate': 0.286176635708005, 'min_data_in_leaf': 6, 'max_depth': 2, 'l2_leaf_reg': 23.91575311679219}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:39,568] Trial 85 finished with value: 0.8546021840873635 and parameters: {'iterations': 500, 'learning_rate': 0.2673684470929412, 'min_data_in_leaf': 7, 'max_depth': 2, 'l2_leaf_reg': 12.289731800277151}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:41,468] Trial 86 finished with value: 0.8569422776911076 and parameters: {'iterations': 500, 'learning_rate': 0.2945624350878152, 'min_data_in_leaf': 5, 'max_depth': 2, 'l2_leaf_reg': 57.769607526760545}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:43,326] Trial 87 finished with value: 0.8569422776911076 and parameters: {'iterations': 500, 'learning_rate': 0.29749355723973697, 'min_data_in_leaf': 3, 'max_depth': 2, 'l2_leaf_reg': 48.46863501146286}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:45,359] Trial 88 finished with value: 0.8555382215288612 and parameters: {'iterations': 500, 'learning_rate': 0.2966692641520874, 'min_data_in_leaf': 3, 'max_depth': 2, 'l2_leaf_reg': 57.53997704189088}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:47,318] Trial 89 finished with value: 0.8556942277691107 and parameters: {'iterations': 500, 'learning_rate': 0.2816605950640796, 'min_data_in_leaf': 3, 'max_depth': 2, 'l2_leaf_reg': 34.554229107164105}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:49,103] Trial 90 finished with value: 0.8552262090483619 and parameters: {'iterations': 500, 'learning_rate': 0.29887972718695927, 'min_data_in_leaf': 2, 'max_depth': 2, 'l2_leaf_reg': 5.6629401749835555}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:51,589] Trial 91 finished with value: 0.853198127925117 and parameters: {'iterations': 700, 'learning_rate': 0.2891758833740812, 'min_data_in_leaf': 5, 'max_depth': 2, 'l2_leaf_reg': 57.29280317108985}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:53,394] Trial 92 finished with value: 0.8558502340093603 and parameters: {'iterations': 500, 'learning_rate': 0.2860101639860296, 'min_data_in_leaf': 4, 'max_depth': 2, 'l2_leaf_reg': 95.19445651291254}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:55,207] Trial 93 finished with value: 0.8541341653666147 and parameters: {'iterations': 500, 'learning_rate': 0.27703740485447054, 'min_data_in_leaf': 3, 'max_depth': 2, 'l2_leaf_reg': 10.448505549845718}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:57,025] Trial 94 finished with value: 0.8553822152886116 and parameters: {'iterations': 500, 'learning_rate': 0.15033022558411596, 'min_data_in_leaf': 6, 'max_depth': 2, 'l2_leaf_reg': 26.684643647588842}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:05:59,049] Trial 95 finished with value: 0.853198127925117 and parameters: {'iterations': 500, 'learning_rate': 0.29228448301101506, 'min_data_in_leaf': 7, 'max_depth': 3, 'l2_leaf_reg': 57.36462726230719}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:06:00,826] Trial 96 finished with value: 0.8538221528861154 and parameters: {'iterations': 500, 'learning_rate': 0.28337607854702057, 'min_data_in_leaf': 5, 'max_depth': 2, 'l2_leaf_reg': 34.00060519930816}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:06:02,413] Trial 97 finished with value: 0.8525741029641186 and parameters: {'iterations': 500, 'learning_rate': 0.29936802369571464, 'min_data_in_leaf': 2, 'max_depth': 2, 'l2_leaf_reg': 5.2097552170265694e-05}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:06:05,251] Trial 98 finished with value: 0.8507020280811233 and parameters: {'iterations': 700, 'learning_rate': 0.26559683855066724, 'min_data_in_leaf': 6, 'max_depth': 3, 'l2_leaf_reg': 18.893675987692493}. Best is trial 13 with value: 0.858814352574103.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\484094950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 18:06:07,085] Trial 99 finished with value: 0.8552262090483619 and parameters: {'iterations': 500, 'learning_rate': 0.1798013275139349, 'min_data_in_leaf': 3, 'max_depth': 2, 'l2_leaf_reg': 9.05594331533848}. Best is trial 13 with value: 0.858814352574103.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.858814352574103"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000, step=200),\n",
    "        'learning_rate':trial.suggest_float(\"learning_rate\", 0.001, 0.3),\n",
    "        'min_data_in_leaf':trial.suggest_int(\"min_data_in_leaf\", 1,10),\n",
    "        \"depth\": trial.suggest_int(\"max_depth\", 2,10),\n",
    "        \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
    "        }\n",
    "    from catboost import CatBoostClassifier\n",
    "    model = CatBoostClassifier(**param)\n",
    "    model.fit(x_train, y_train, early_stopping_rounds=50, verbose=False)\n",
    "    y_pred = model.predict(x_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    return acc\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "study.best_params\n",
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-29 19:14:01,420] A new study created in memory with name: no-name-689c8475-78fc-4787-b52d-cdc5f7014f97\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:14:04,190] Trial 0 finished with value: 0.8419656786271451 and parameters: {'iterations': 500, 'learning_rate': 0.13232555266631332, 'random_strength': 7, 'bagging_temperature': 10, 'max_bin': 29, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 2, 'max_depth': 2, 'l2_leaf_reg': 1.3978496463640443e-06, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 0 with value: 0.8419656786271451.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:14:06,248] Trial 1 finished with value: 0.8405616224648986 and parameters: {'iterations': 300, 'learning_rate': 0.22247822860762004, 'random_strength': 7, 'bagging_temperature': 8, 'max_bin': 23, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 8, 'max_depth': 5, 'l2_leaf_reg': 0.005240022547610033, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 0 with value: 0.8419656786271451.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:14:13,557] Trial 2 finished with value: 0.8346333853354134 and parameters: {'iterations': 300, 'learning_rate': 0.2004310710884731, 'random_strength': 1, 'bagging_temperature': 9, 'max_bin': 8, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 6, 'max_depth': 10, 'l2_leaf_reg': 0.029080510804651113, 'auto_class_weights': 'Balanced'}. Best is trial 0 with value: 0.8419656786271451.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:14:18,638] Trial 3 finished with value: 0.8372854914196568 and parameters: {'iterations': 300, 'learning_rate': 0.23243513537462462, 'random_strength': 10, 'bagging_temperature': 6, 'max_bin': 22, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 1, 'max_depth': 8, 'l2_leaf_reg': 5.97584469637175e-08, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 0 with value: 0.8419656786271451.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:14:21,536] Trial 4 finished with value: 0.8249609984399376 and parameters: {'iterations': 300, 'learning_rate': 0.2241250990095061, 'random_strength': 6, 'bagging_temperature': 7, 'max_bin': 12, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 8, 'max_depth': 10, 'l2_leaf_reg': 1.612001338715048e-08, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 0 with value: 0.8419656786271451.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:14:22,951] Trial 5 finished with value: 0.8365054602184088 and parameters: {'iterations': 100, 'learning_rate': 0.1888523075859325, 'random_strength': 1, 'bagging_temperature': 2, 'max_bin': 10, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 5, 'max_depth': 10, 'l2_leaf_reg': 1.1849923179255676e-08, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 0 with value: 0.8419656786271451.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:14:33,263] Trial 6 finished with value: 0.8519500780031202 and parameters: {'iterations': 700, 'learning_rate': 0.03532253394952553, 'random_strength': 3, 'bagging_temperature': 1, 'max_bin': 20, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 9, 'max_depth': 10, 'l2_leaf_reg': 1.7220694710044397, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:14:34,674] Trial 7 finished with value: 0.8288611544461778 and parameters: {'iterations': 100, 'learning_rate': 0.25978298862919236, 'random_strength': 7, 'bagging_temperature': 7, 'max_bin': 2, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 4, 'max_depth': 7, 'l2_leaf_reg': 3.4238465114339096, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:14:43,962] Trial 8 finished with value: 0.8269890795631826 and parameters: {'iterations': 900, 'learning_rate': 0.2783236121143497, 'random_strength': 1, 'bagging_temperature': 9, 'max_bin': 4, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 3, 'max_depth': 7, 'l2_leaf_reg': 0.004141436778520328, 'auto_class_weights': 'Balanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:14:54,582] Trial 9 finished with value: 0.8307332293291732 and parameters: {'iterations': 900, 'learning_rate': 0.18498527501017464, 'random_strength': 8, 'bagging_temperature': 6, 'max_bin': 11, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 3, 'max_depth': 5, 'l2_leaf_reg': 0.00086108715451657, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:14:59,933] Trial 10 finished with value: 0.7861154446177847 and parameters: {'iterations': 700, 'learning_rate': 0.014042760754212163, 'random_strength': 4, 'bagging_temperature': 0, 'max_bin': 18, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 10, 'max_depth': 2, 'l2_leaf_reg': 45.82060764131276, 'auto_class_weights': 'Balanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:15:05,150] Trial 11 finished with value: 0.8427457098283931 and parameters: {'iterations': 700, 'learning_rate': 0.0797835449171837, 'random_strength': 4, 'bagging_temperature': 3, 'max_bin': 28, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 1, 'max_depth': 2, 'l2_leaf_reg': 1.8758727674202354e-05, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:15:11,886] Trial 12 finished with value: 0.8402496099843993 and parameters: {'iterations': 700, 'learning_rate': 0.04808662802079618, 'random_strength': 4, 'bagging_temperature': 3, 'max_bin': 28, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 10, 'max_depth': 4, 'l2_leaf_reg': 2.2905375198336604e-05, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:15:17,987] Trial 13 finished with value: 0.8379095163806553 and parameters: {'iterations': 700, 'learning_rate': 0.08766971919749625, 'random_strength': 3, 'bagging_temperature': 3, 'max_bin': 24, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 7, 'max_depth': 3, 'l2_leaf_reg': 0.21057714572031175, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:15:23,623] Trial 14 finished with value: 0.8327613104524181 and parameters: {'iterations': 500, 'learning_rate': 0.10248349271056754, 'random_strength': 3, 'bagging_temperature': 0, 'max_bin': 17, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 1, 'max_depth': 8, 'l2_leaf_reg': 7.923272764259336e-05, 'auto_class_weights': 'Balanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:15:29,228] Trial 15 finished with value: 0.8449297971918877 and parameters: {'iterations': 700, 'learning_rate': 0.05249733231274638, 'random_strength': 4, 'bagging_temperature': 2, 'max_bin': 26, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 9, 'max_depth': 4, 'l2_leaf_reg': 0.5084063239915172, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:15:36,815] Trial 16 finished with value: 0.8391575663026521 and parameters: {'iterations': 900, 'learning_rate': 0.006222505900883395, 'random_strength': 3, 'bagging_temperature': 1, 'max_bin': 19, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 9, 'max_depth': 5, 'l2_leaf_reg': 1.8711434805731124, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:15:41,007] Trial 17 finished with value: 0.843213728549142 and parameters: {'iterations': 500, 'learning_rate': 0.03969071013779457, 'random_strength': 5, 'bagging_temperature': 4, 'max_bin': 25, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 8, 'max_depth': 4, 'l2_leaf_reg': 95.19999185566829, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:15:49,709] Trial 18 finished with value: 0.8418096723868955 and parameters: {'iterations': 700, 'learning_rate': 0.1288769081055091, 'random_strength': 2, 'bagging_temperature': 1, 'max_bin': 14, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 6, 'max_depth': 9, 'l2_leaf_reg': 0.4735406983817251, 'auto_class_weights': 'Balanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:15:57,839] Trial 19 finished with value: 0.8418096723868955 and parameters: {'iterations': 900, 'learning_rate': 0.05979416388913953, 'random_strength': 5, 'bagging_temperature': 4, 'max_bin': 21, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 9, 'max_depth': 6, 'l2_leaf_reg': 8.483324819102188, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:16:04,124] Trial 20 finished with value: 0.8447737909516381 and parameters: {'iterations': 700, 'learning_rate': 0.03039978547318297, 'random_strength': 2, 'bagging_temperature': 1, 'max_bin': 25, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 7, 'max_depth': 6, 'l2_leaf_reg': 0.12193304552784266, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:16:10,325] Trial 21 finished with value: 0.8458658346333854 and parameters: {'iterations': 700, 'learning_rate': 0.02535579145530931, 'random_strength': 2, 'bagging_temperature': 1, 'max_bin': 26, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 7, 'max_depth': 6, 'l2_leaf_reg': 0.12605206192677326, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:16:14,238] Trial 22 finished with value: 0.8435257410296412 and parameters: {'iterations': 500, 'learning_rate': 0.0724099506851079, 'random_strength': 2, 'bagging_temperature': 2, 'max_bin': 30, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 9, 'max_depth': 4, 'l2_leaf_reg': 0.040688632938517176, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:16:21,039] Trial 23 finished with value: 0.8357254290171607 and parameters: {'iterations': 700, 'learning_rate': 0.002090028107954056, 'random_strength': 3, 'bagging_temperature': 2, 'max_bin': 26, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 7, 'max_depth': 7, 'l2_leaf_reg': 0.8156645926635593, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:16:30,579] Trial 24 finished with value: 0.8433697347893916 and parameters: {'iterations': 900, 'learning_rate': 0.09895408514943602, 'random_strength': 4, 'bagging_temperature': 0, 'max_bin': 20, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 10, 'max_depth': 8, 'l2_leaf_reg': 7.559976057833966, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:16:35,931] Trial 25 finished with value: 0.8407176287051482 and parameters: {'iterations': 700, 'learning_rate': 0.032384905198924306, 'random_strength': 2, 'bagging_temperature': 4, 'max_bin': 16, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 9, 'max_depth': 3, 'l2_leaf_reg': 0.018726307518337173, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:16:42,207] Trial 26 finished with value: 0.8380655226209048 and parameters: {'iterations': 500, 'learning_rate': 0.15754863833424126, 'random_strength': 5, 'bagging_temperature': 1, 'max_bin': 26, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 8, 'max_depth': 9, 'l2_leaf_reg': 10.978622043042023, 'auto_class_weights': 'Balanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:16:48,479] Trial 27 finished with value: 0.8396255850234009 and parameters: {'iterations': 700, 'learning_rate': 0.05956884642325477, 'random_strength': 6, 'bagging_temperature': 2, 'max_bin': 22, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 5, 'max_depth': 6, 'l2_leaf_reg': 0.00041671650200192774, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:16:54,941] Trial 28 finished with value: 0.8377535101404057 and parameters: {'iterations': 900, 'learning_rate': 0.11320500380997817, 'random_strength': 3, 'bagging_temperature': 5, 'max_bin': 27, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 7, 'max_depth': 3, 'l2_leaf_reg': 0.14802911780218453, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:17:00,000] Trial 29 finished with value: 0.837597503900156 and parameters: {'iterations': 500, 'learning_rate': 0.1546546530801432, 'random_strength': 10, 'bagging_temperature': 0, 'max_bin': 30, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 9, 'max_depth': 5, 'l2_leaf_reg': 1.137517787519817, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:17:08,552] Trial 30 finished with value: 0.8477379095163806 and parameters: {'iterations': 700, 'learning_rate': 0.021880721114597934, 'random_strength': 2, 'bagging_temperature': 3, 'max_bin': 20, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 6, 'max_depth': 9, 'l2_leaf_reg': 23.096234491395652, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:17:17,097] Trial 31 finished with value: 0.8502340093603744 and parameters: {'iterations': 700, 'learning_rate': 0.025233644662369492, 'random_strength': 2, 'bagging_temperature': 3, 'max_bin': 19, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 6, 'max_depth': 9, 'l2_leaf_reg': 27.819681239716463, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:17:25,477] Trial 32 finished with value: 0.8488299531981279 and parameters: {'iterations': 700, 'learning_rate': 0.0248025467263867, 'random_strength': 1, 'bagging_temperature': 3, 'max_bin': 14, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 6, 'max_depth': 9, 'l2_leaf_reg': 35.253269153535676, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:17:31,496] Trial 33 finished with value: 0.8452418096723869 and parameters: {'iterations': 500, 'learning_rate': 0.017079841020081473, 'random_strength': 1, 'bagging_temperature': 5, 'max_bin': 14, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 6, 'max_depth': 9, 'l2_leaf_reg': 31.23939301136093, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:17:39,974] Trial 34 finished with value: 0.8491419656786271 and parameters: {'iterations': 700, 'learning_rate': 0.06858906027120837, 'random_strength': 1, 'bagging_temperature': 3, 'max_bin': 15, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 5, 'max_depth': 9, 'l2_leaf_reg': 19.72534661471111, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:17:55,415] Trial 35 finished with value: 0.8480499219968799 and parameters: {'iterations': 900, 'learning_rate': 0.07295354548662994, 'random_strength': 1, 'bagging_temperature': 5, 'max_bin': 15, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 4, 'max_depth': 10, 'l2_leaf_reg': 98.12488864751047, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:18:02,749] Trial 36 finished with value: 0.8516380655226209 and parameters: {'iterations': 300, 'learning_rate': 0.051140824702262486, 'random_strength': 1, 'bagging_temperature': 4, 'max_bin': 13, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 5, 'max_depth': 10, 'l2_leaf_reg': 3.9825667680525356, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:18:10,380] Trial 37 finished with value: 0.8352574102964119 and parameters: {'iterations': 300, 'learning_rate': 0.060693639752898376, 'random_strength': 1, 'bagging_temperature': 4, 'max_bin': 9, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 4, 'max_depth': 10, 'l2_leaf_reg': 4.815468393301381, 'auto_class_weights': 'Balanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:18:19,584] Trial 38 finished with value: 0.8365054602184088 and parameters: {'iterations': 300, 'learning_rate': 0.11811604497954759, 'random_strength': 1, 'bagging_temperature': 4, 'max_bin': 6, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 5, 'max_depth': 10, 'l2_leaf_reg': 9.91197743553325e-07, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:18:21,297] Trial 39 finished with value: 0.8421216848673947 and parameters: {'iterations': 100, 'learning_rate': 0.04250980425129333, 'random_strength': 2, 'bagging_temperature': 6, 'max_bin': 12, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 3, 'max_depth': 8, 'l2_leaf_reg': 2.618728051754481, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:18:29,849] Trial 40 finished with value: 0.8400936037441498 and parameters: {'iterations': 300, 'learning_rate': 0.08871226134726623, 'random_strength': 8, 'bagging_temperature': 6, 'max_bin': 17, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 5, 'max_depth': 10, 'l2_leaf_reg': 0.006290266338521501, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:18:41,169] Trial 41 finished with value: 0.8372854914196568 and parameters: {'iterations': 500, 'learning_rate': 0.0022018122740751767, 'random_strength': 1, 'bagging_temperature': 3, 'max_bin': 13, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 4, 'max_depth': 9, 'l2_leaf_reg': 22.14468052109597, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:18:42,467] Trial 42 finished with value: 0.843213728549142 and parameters: {'iterations': 100, 'learning_rate': 0.03700385702326852, 'random_strength': 1, 'bagging_temperature': 3, 'max_bin': 7, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 6, 'max_depth': 9, 'l2_leaf_reg': 13.210384993024327, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:18:48,398] Trial 43 finished with value: 0.8436817472698908 and parameters: {'iterations': 500, 'learning_rate': 0.051234551471909896, 'random_strength': 1, 'bagging_temperature': 5, 'max_bin': 11, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 5, 'max_depth': 8, 'l2_leaf_reg': 4.518330428708035, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:19:06,921] Trial 44 finished with value: 0.8464898595943837 and parameters: {'iterations': 700, 'learning_rate': 0.01736597391075485, 'random_strength': 2, 'bagging_temperature': 10, 'max_bin': 18, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 4, 'max_depth': 10, 'l2_leaf_reg': 45.21832376491487, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:19:15,848] Trial 45 finished with value: 0.8396255850234009 and parameters: {'iterations': 700, 'learning_rate': 0.07074782500854819, 'random_strength': 3, 'bagging_temperature': 2, 'max_bin': 15, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 3, 'max_depth': 9, 'l2_leaf_reg': 1.7326237244368825, 'auto_class_weights': 'Balanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:19:26,721] Trial 46 finished with value: 0.8436817472698908 and parameters: {'iterations': 900, 'learning_rate': 0.04072430184528674, 'random_strength': 1, 'bagging_temperature': 7, 'max_bin': 17, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 6, 'max_depth': 8, 'l2_leaf_reg': 95.19180892860862, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:19:36,846] Trial 47 finished with value: 0.8393135725429017 and parameters: {'iterations': 700, 'learning_rate': 0.2549530037753682, 'random_strength': 2, 'bagging_temperature': 3, 'max_bin': 10, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 2, 'max_depth': 10, 'l2_leaf_reg': 0.3301970031427831, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:19:43,750] Trial 48 finished with value: 0.8436817472698908 and parameters: {'iterations': 500, 'learning_rate': 0.2945754795933243, 'random_strength': 9, 'bagging_temperature': 4, 'max_bin': 23, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 5, 'max_depth': 9, 'l2_leaf_reg': 3.5346624577872157, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:19:48,267] Trial 49 finished with value: 0.8372854914196568 and parameters: {'iterations': 300, 'learning_rate': 0.1683998122078108, 'random_strength': 3, 'bagging_temperature': 3, 'max_bin': 13, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 8, 'max_depth': 7, 'l2_leaf_reg': 2.4671191056115786e-07, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:19:59,085] Trial 50 finished with value: 0.8371294851794072 and parameters: {'iterations': 700, 'learning_rate': 0.21286666741583588, 'random_strength': 2, 'bagging_temperature': 2, 'max_bin': 19, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 2, 'max_depth': 10, 'l2_leaf_reg': 0.048568657421161524, 'auto_class_weights': 'Balanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:20:15,833] Trial 51 finished with value: 0.846801872074883 and parameters: {'iterations': 900, 'learning_rate': 0.07544350142367151, 'random_strength': 1, 'bagging_temperature': 5, 'max_bin': 15, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 4, 'max_depth': 10, 'l2_leaf_reg': 95.66089078935785, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:20:33,210] Trial 52 finished with value: 0.8488299531981279 and parameters: {'iterations': 900, 'learning_rate': 0.08646233618485284, 'random_strength': 1, 'bagging_temperature': 5, 'max_bin': 16, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 4, 'max_depth': 10, 'l2_leaf_reg': 18.118852642946326, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:20:45,233] Trial 53 finished with value: 0.8452418096723869 and parameters: {'iterations': 900, 'learning_rate': 0.09126881472893815, 'random_strength': 1, 'bagging_temperature': 8, 'max_bin': 16, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 5, 'max_depth': 9, 'l2_leaf_reg': 17.783541582634736, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:20:58,115] Trial 54 finished with value: 0.8472698907956319 and parameters: {'iterations': 700, 'learning_rate': 0.06046420833163814, 'random_strength': 2, 'bagging_temperature': 4, 'max_bin': 13, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 3, 'max_depth': 10, 'l2_leaf_reg': 7.715248647801484, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:21:09,301] Trial 55 finished with value: 0.8458658346333854 and parameters: {'iterations': 900, 'learning_rate': 0.026381656775888444, 'random_strength': 1, 'bagging_temperature': 4, 'max_bin': 19, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 6, 'max_depth': 8, 'l2_leaf_reg': 1.059575230141796, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:21:18,324] Trial 56 finished with value: 0.8477379095163806 and parameters: {'iterations': 700, 'learning_rate': 0.048864585610530226, 'random_strength': 2, 'bagging_temperature': 6, 'max_bin': 21, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 5, 'max_depth': 9, 'l2_leaf_reg': 39.32112738929438, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:21:31,578] Trial 57 finished with value: 0.8455538221528861 and parameters: {'iterations': 700, 'learning_rate': 0.1361324726858378, 'random_strength': 3, 'bagging_temperature': 5, 'max_bin': 18, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 4, 'max_depth': 10, 'l2_leaf_reg': 2.8438585993569045, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:21:43,426] Trial 58 finished with value: 0.8461778471138846 and parameters: {'iterations': 900, 'learning_rate': 0.010414239038172353, 'random_strength': 1, 'bagging_temperature': 2, 'max_bin': 12, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 7, 'max_depth': 9, 'l2_leaf_reg': 13.395731358623147, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:21:44,744] Trial 59 finished with value: 0.8433697347893916 and parameters: {'iterations': 100, 'learning_rate': 0.10451963638904913, 'random_strength': 2, 'bagging_temperature': 3, 'max_bin': 14, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 6, 'max_depth': 9, 'l2_leaf_reg': 0.5137551759293901, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:21:49,801] Trial 60 finished with value: 0.8037441497659906 and parameters: {'iterations': 500, 'learning_rate': 0.03423695599569829, 'random_strength': 3, 'bagging_temperature': 1, 'max_bin': 22, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 5, 'max_depth': 7, 'l2_leaf_reg': 46.171424220948495, 'auto_class_weights': 'Balanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:22:06,210] Trial 61 finished with value: 0.8480499219968799 and parameters: {'iterations': 900, 'learning_rate': 0.08161120225652196, 'random_strength': 1, 'bagging_temperature': 5, 'max_bin': 16, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 4, 'max_depth': 10, 'l2_leaf_reg': 94.6010570697097, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:22:23,819] Trial 62 finished with value: 0.8482059282371295 and parameters: {'iterations': 900, 'learning_rate': 0.06884597980013848, 'random_strength': 1, 'bagging_temperature': 5, 'max_bin': 17, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 3, 'max_depth': 10, 'l2_leaf_reg': 8.190977710018391, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:22:46,492] Trial 63 finished with value: 0.8107644305772231 and parameters: {'iterations': 900, 'learning_rate': 0.06362858505043446, 'random_strength': 1, 'bagging_temperature': 3, 'max_bin': 1, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 3, 'max_depth': 10, 'l2_leaf_reg': 6.117436657940667, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:23:00,324] Trial 64 finished with value: 0.8488299531981279 and parameters: {'iterations': 700, 'learning_rate': 0.050654580178773126, 'random_strength': 2, 'bagging_temperature': 4, 'max_bin': 17, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 2, 'max_depth': 10, 'l2_leaf_reg': 1.6109318592971589, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:23:09,802] Trial 65 finished with value: 0.849609984399376 and parameters: {'iterations': 700, 'learning_rate': 0.048644918034819074, 'random_strength': 2, 'bagging_temperature': 4, 'max_bin': 20, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 1, 'max_depth': 9, 'l2_leaf_reg': 1.485003600488059, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:23:19,250] Trial 66 finished with value: 0.8492979719188768 and parameters: {'iterations': 700, 'learning_rate': 0.027873792242191043, 'random_strength': 2, 'bagging_temperature': 4, 'max_bin': 20, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 7, 'max_depth': 9, 'l2_leaf_reg': 0.2619149662625629, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:23:28,237] Trial 67 finished with value: 0.8408736349453978 and parameters: {'iterations': 700, 'learning_rate': 0.01109670344314679, 'random_strength': 4, 'bagging_temperature': 4, 'max_bin': 20, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 1, 'max_depth': 8, 'l2_leaf_reg': 0.7117640552996395, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:23:37,690] Trial 68 finished with value: 0.8507020280811233 and parameters: {'iterations': 700, 'learning_rate': 0.02641296368217481, 'random_strength': 3, 'bagging_temperature': 3, 'max_bin': 23, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 7, 'max_depth': 9, 'l2_leaf_reg': 0.21870407690963753, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:23:49,920] Trial 69 finished with value: 0.8463338533541341 and parameters: {'iterations': 700, 'learning_rate': 0.030636052855093285, 'random_strength': 3, 'bagging_temperature': 4, 'max_bin': 24, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 8, 'max_depth': 8, 'l2_leaf_reg': 0.07343727534095852, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:23:59,373] Trial 70 finished with value: 0.850390015600624 and parameters: {'iterations': 700, 'learning_rate': 0.04427620993945294, 'random_strength': 4, 'bagging_temperature': 2, 'max_bin': 21, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 7, 'max_depth': 9, 'l2_leaf_reg': 0.015328265411290452, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:24:08,639] Trial 71 finished with value: 0.849609984399376 and parameters: {'iterations': 700, 'learning_rate': 0.043452574298486174, 'random_strength': 4, 'bagging_temperature': 2, 'max_bin': 21, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 7, 'max_depth': 9, 'l2_leaf_reg': 0.015129048761691372, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:24:18,257] Trial 72 finished with value: 0.846021840873635 and parameters: {'iterations': 700, 'learning_rate': 0.04548736105332126, 'random_strength': 4, 'bagging_temperature': 2, 'max_bin': 22, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 7, 'max_depth': 9, 'l2_leaf_reg': 0.0013947029645140973, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:24:27,471] Trial 73 finished with value: 0.8429017160686427 and parameters: {'iterations': 700, 'learning_rate': 0.015557443322482004, 'random_strength': 5, 'bagging_temperature': 1, 'max_bin': 21, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 7, 'max_depth': 9, 'l2_leaf_reg': 0.013448378059129957, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:24:35,676] Trial 74 finished with value: 0.8482059282371295 and parameters: {'iterations': 700, 'learning_rate': 0.03819847018104307, 'random_strength': 4, 'bagging_temperature': 2, 'max_bin': 23, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 8, 'max_depth': 8, 'l2_leaf_reg': 0.2518644543507865, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:24:45,379] Trial 75 finished with value: 0.8480499219968799 and parameters: {'iterations': 700, 'learning_rate': 0.025509512886581296, 'random_strength': 4, 'bagging_temperature': 1, 'max_bin': 24, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 8, 'max_depth': 9, 'l2_leaf_reg': 0.002360381134649578, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:24:55,031] Trial 76 finished with value: 0.846021840873635 and parameters: {'iterations': 700, 'learning_rate': 0.057433275415724856, 'random_strength': 3, 'bagging_temperature': 2, 'max_bin': 20, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 7, 'max_depth': 9, 'l2_leaf_reg': 0.010776257835206615, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:25:09,496] Trial 77 finished with value: 0.8315132605304212 and parameters: {'iterations': 700, 'learning_rate': 0.020381182039328927, 'random_strength': 5, 'bagging_temperature': 0, 'max_bin': 19, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 7, 'max_depth': 9, 'l2_leaf_reg': 0.0003510587080094916, 'auto_class_weights': 'Balanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:25:15,009] Trial 78 finished with value: 0.837597503900156 and parameters: {'iterations': 500, 'learning_rate': 0.0065661949701818, 'random_strength': 4, 'bagging_temperature': 3, 'max_bin': 21, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 10, 'max_depth': 7, 'l2_leaf_reg': 0.09485240090114233, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:25:23,576] Trial 79 finished with value: 0.8478939157566303 and parameters: {'iterations': 700, 'learning_rate': 0.04281167830117763, 'random_strength': 3, 'bagging_temperature': 2, 'max_bin': 22, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 7, 'max_depth': 8, 'l2_leaf_reg': 0.04088919698313383, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:25:31,392] Trial 80 finished with value: 0.8499219968798752 and parameters: {'iterations': 500, 'learning_rate': 0.030418907591141266, 'random_strength': 3, 'bagging_temperature': 1, 'max_bin': 23, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 8, 'max_depth': 9, 'l2_leaf_reg': 0.2780373839800315, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:25:40,180] Trial 81 finished with value: 0.8483619344773791 and parameters: {'iterations': 500, 'learning_rate': 0.032102681814018055, 'random_strength': 3, 'bagging_temperature': 1, 'max_bin': 23, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 8, 'max_depth': 9, 'l2_leaf_reg': 0.16050507584145157, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:25:50,644] Trial 82 finished with value: 0.8492979719188768 and parameters: {'iterations': 700, 'learning_rate': 0.05495471175351829, 'random_strength': 6, 'bagging_temperature': 1, 'max_bin': 23, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 9, 'max_depth': 9, 'l2_leaf_reg': 0.019412681768605018, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:25:55,702] Trial 83 finished with value: 0.8405616224648986 and parameters: {'iterations': 300, 'learning_rate': 0.020901857814775743, 'random_strength': 4, 'bagging_temperature': 0, 'max_bin': 25, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 8, 'max_depth': 9, 'l2_leaf_reg': 0.21598250781006734, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:26:01,767] Trial 84 finished with value: 0.8486739469578783 and parameters: {'iterations': 500, 'learning_rate': 0.04524416835637019, 'random_strength': 3, 'bagging_temperature': 2, 'max_bin': 20, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 9, 'max_depth': 8, 'l2_leaf_reg': 0.0068819833273859685, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:26:15,035] Trial 85 finished with value: 0.8491419656786271 and parameters: {'iterations': 700, 'learning_rate': 0.03539575828954787, 'random_strength': 2, 'bagging_temperature': 3, 'max_bin': 18, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 7, 'max_depth': 10, 'l2_leaf_reg': 0.4419579939073273, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:26:29,369] Trial 86 finished with value: 0.8449297971918877 and parameters: {'iterations': 700, 'learning_rate': 0.01337937817419798, 'random_strength': 3, 'bagging_temperature': 3, 'max_bin': 22, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 6, 'max_depth': 9, 'l2_leaf_reg': 0.06404296487430575, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:26:38,299] Trial 87 finished with value: 0.838377535101404 and parameters: {'iterations': 700, 'learning_rate': 0.0022435136520384084, 'random_strength': 2, 'bagging_temperature': 1, 'max_bin': 21, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 7, 'max_depth': 8, 'l2_leaf_reg': 0.02798732720839483, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:26:51,787] Trial 88 finished with value: 0.8513260530421217 and parameters: {'iterations': 700, 'learning_rate': 0.028061356968125013, 'random_strength': 4, 'bagging_temperature': 2, 'max_bin': 24, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 8, 'max_depth': 10, 'l2_leaf_reg': 1.2286700520532918, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:26:57,618] Trial 89 finished with value: 0.8268330733229329 and parameters: {'iterations': 300, 'learning_rate': 0.04982894531019831, 'random_strength': 5, 'bagging_temperature': 1, 'max_bin': 27, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 9, 'max_depth': 10, 'l2_leaf_reg': 1.6147553268041468, 'auto_class_weights': 'Balanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:27:07,491] Trial 90 finished with value: 0.8491419656786271 and parameters: {'iterations': 500, 'learning_rate': 0.0368624029390418, 'random_strength': 4, 'bagging_temperature': 2, 'max_bin': 25, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 8, 'max_depth': 10, 'l2_leaf_reg': 1.0152459671378262, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:27:16,989] Trial 91 finished with value: 0.8485179407176288 and parameters: {'iterations': 700, 'learning_rate': 0.028067214508913845, 'random_strength': 4, 'bagging_temperature': 4, 'max_bin': 24, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 8, 'max_depth': 9, 'l2_leaf_reg': 0.6202815985577489, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:27:30,864] Trial 92 finished with value: 0.8494539781591264 and parameters: {'iterations': 700, 'learning_rate': 0.018660610785605276, 'random_strength': 3, 'bagging_temperature': 2, 'max_bin': 19, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 10, 'max_depth': 10, 'l2_leaf_reg': 2.9642652107369454, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:27:45,081] Trial 93 finished with value: 0.8471138845553822 and parameters: {'iterations': 700, 'learning_rate': 0.06348248410971136, 'random_strength': 3, 'bagging_temperature': 2, 'max_bin': 19, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 10, 'max_depth': 10, 'l2_leaf_reg': 3.3015344497426136, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:27:58,910] Trial 94 finished with value: 0.8416536661466458 and parameters: {'iterations': 700, 'learning_rate': 0.00902784899480072, 'random_strength': 5, 'bagging_temperature': 2, 'max_bin': 24, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 10, 'max_depth': 10, 'l2_leaf_reg': 2.6360928743063243, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 6 with value: 0.8519500780031202.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:28:13,170] Trial 95 finished with value: 0.8524180967238689 and parameters: {'iterations': 700, 'learning_rate': 0.020215803120752895, 'random_strength': 3, 'bagging_temperature': 2, 'max_bin': 21, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 10, 'max_depth': 10, 'l2_leaf_reg': 1.3790588634537881, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 95 with value: 0.8524180967238689.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:28:30,785] Trial 96 finished with value: 0.8463338533541341 and parameters: {'iterations': 700, 'learning_rate': 0.042357293266211155, 'random_strength': 3, 'bagging_temperature': 1, 'max_bin': 21, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 9, 'max_depth': 10, 'l2_leaf_reg': 1.2506306911365175, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 95 with value: 0.8524180967238689.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:28:44,919] Trial 97 finished with value: 0.8517940717628705 and parameters: {'iterations': 700, 'learning_rate': 0.022142305287893127, 'random_strength': 4, 'bagging_temperature': 0, 'max_bin': 22, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 6, 'max_depth': 10, 'l2_leaf_reg': 0.3937639827287372, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 95 with value: 0.8524180967238689.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:28:51,071] Trial 98 finished with value: 0.8400936037441498 and parameters: {'iterations': 300, 'learning_rate': 0.015799405400836897, 'random_strength': 4, 'bagging_temperature': 0, 'max_bin': 23, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 6, 'max_depth': 10, 'l2_leaf_reg': 0.32772613465865696, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 95 with value: 0.8524180967238689.\n",
      "C:\\ANA\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [100, 1000] and step=200, but the range is not divisible by `step`. It will be replaced by [100, 900].\n",
      "  warnings.warn(\n",
      "C:\\Users\\俊俊\\AppData\\Local\\Temp\\ipykernel_25752\\2033722853.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
      "[I 2024-05-29 19:29:05,464] Trial 99 finished with value: 0.8464898595943837 and parameters: {'iterations': 700, 'learning_rate': 0.1865903846601051, 'random_strength': 3, 'bagging_temperature': 0, 'max_bin': 22, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 9, 'max_depth': 10, 'l2_leaf_reg': 4.955262741622253, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 95 with value: 0.8524180967238689.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8524180967238689"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000, step=200),\n",
    "        'learning_rate':trial.suggest_float(\"learning_rate\", 0.001, 0.3),\n",
    "        'random_strength':trial.suggest_int(\"random_strength\", 1,10),\n",
    "        'bagging_temperature':trial.suggest_int(\"bagging_temperature\", 0,10),\n",
    "        'max_bin':trial.suggest_int('max_bin', 1,30),\n",
    "        'grow_policy':trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
    "        'min_data_in_leaf':trial.suggest_int(\"min_data_in_leaf\", 1,10),\n",
    "        \"depth\": trial.suggest_int(\"max_depth\", 2,10),\n",
    "        \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
    "        'auto_class_weights':trial.suggest_categorical('auto_class_weights', ['Balanced', 'SqrtBalanced']),\n",
    "        }\n",
    "\n",
    "    from catboost import CatBoostClassifier\n",
    "    model = CatBoostClassifier(**param)\n",
    "    model.fit(x_train, y_train, early_stopping_rounds=50, verbose=False)\n",
    "    y_pred = model.predict(x_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    return acc\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "study.best_params\n",
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'iterations': 700, 'learning_rate': 0.020215803120752895, 'random_strength': 3, 'bagging_temperature': 2, 'max_bin': 21, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 10, 'max_depth': 10, 'l2_leaf_reg': 1.3790588634537881, 'auto_class_weights': 'SqrtBalanced'}\n",
      "Best Accuracy:  0.8524180967238689\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "print(\"Best Parameters: \", best_params)\n",
    "print(\"Best Accuracy: \", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6815874\ttotal: 21.8ms\tremaining: 15.3s\n",
      "1:\tlearn: 0.6705641\ttotal: 42.8ms\tremaining: 14.9s\n",
      "2:\tlearn: 0.6609064\ttotal: 62.9ms\tremaining: 14.6s\n",
      "3:\tlearn: 0.6506499\ttotal: 83.4ms\tremaining: 14.5s\n",
      "4:\tlearn: 0.6421343\ttotal: 104ms\tremaining: 14.4s\n",
      "5:\tlearn: 0.6325351\ttotal: 124ms\tremaining: 14.4s\n",
      "6:\tlearn: 0.6245241\ttotal: 144ms\tremaining: 14.2s\n",
      "7:\tlearn: 0.6162135\ttotal: 163ms\tremaining: 14.1s\n",
      "8:\tlearn: 0.6088154\ttotal: 183ms\tremaining: 14.1s\n",
      "9:\tlearn: 0.6009587\ttotal: 204ms\tremaining: 14.1s\n",
      "10:\tlearn: 0.5941832\ttotal: 225ms\tremaining: 14.1s\n",
      "11:\tlearn: 0.5871656\ttotal: 245ms\tremaining: 14s\n",
      "12:\tlearn: 0.5823015\ttotal: 256ms\tremaining: 13.5s\n",
      "13:\tlearn: 0.5764657\ttotal: 277ms\tremaining: 13.6s\n",
      "14:\tlearn: 0.5704984\ttotal: 298ms\tremaining: 13.6s\n",
      "15:\tlearn: 0.5647957\ttotal: 318ms\tremaining: 13.6s\n",
      "16:\tlearn: 0.5584722\ttotal: 343ms\tremaining: 13.8s\n",
      "17:\tlearn: 0.5530626\ttotal: 363ms\tremaining: 13.8s\n",
      "18:\tlearn: 0.5479949\ttotal: 383ms\tremaining: 13.7s\n",
      "19:\tlearn: 0.5423410\ttotal: 403ms\tremaining: 13.7s\n",
      "20:\tlearn: 0.5371050\ttotal: 425ms\tremaining: 13.8s\n",
      "21:\tlearn: 0.5318610\ttotal: 445ms\tremaining: 13.7s\n",
      "22:\tlearn: 0.5284632\ttotal: 465ms\tremaining: 13.7s\n",
      "23:\tlearn: 0.5236886\ttotal: 485ms\tremaining: 13.7s\n",
      "24:\tlearn: 0.5195894\ttotal: 505ms\tremaining: 13.6s\n",
      "25:\tlearn: 0.5146857\ttotal: 525ms\tremaining: 13.6s\n",
      "26:\tlearn: 0.5104800\ttotal: 545ms\tremaining: 13.6s\n",
      "27:\tlearn: 0.5069898\ttotal: 565ms\tremaining: 13.6s\n",
      "28:\tlearn: 0.5035556\ttotal: 584ms\tremaining: 13.5s\n",
      "29:\tlearn: 0.4997366\ttotal: 604ms\tremaining: 13.5s\n",
      "30:\tlearn: 0.4962409\ttotal: 625ms\tremaining: 13.5s\n",
      "31:\tlearn: 0.4919964\ttotal: 645ms\tremaining: 13.5s\n",
      "32:\tlearn: 0.4882916\ttotal: 665ms\tremaining: 13.4s\n",
      "33:\tlearn: 0.4860618\ttotal: 684ms\tremaining: 13.4s\n",
      "34:\tlearn: 0.4822874\ttotal: 705ms\tremaining: 13.4s\n",
      "35:\tlearn: 0.4795026\ttotal: 725ms\tremaining: 13.4s\n",
      "36:\tlearn: 0.4783993\ttotal: 733ms\tremaining: 13.1s\n",
      "37:\tlearn: 0.4753118\ttotal: 753ms\tremaining: 13.1s\n",
      "38:\tlearn: 0.4726285\ttotal: 773ms\tremaining: 13.1s\n",
      "39:\tlearn: 0.4695745\ttotal: 794ms\tremaining: 13.1s\n",
      "40:\tlearn: 0.4675022\ttotal: 816ms\tremaining: 13.1s\n",
      "41:\tlearn: 0.4649805\ttotal: 836ms\tremaining: 13.1s\n",
      "42:\tlearn: 0.4628603\ttotal: 856ms\tremaining: 13.1s\n",
      "43:\tlearn: 0.4610236\ttotal: 875ms\tremaining: 13.1s\n",
      "44:\tlearn: 0.4585817\ttotal: 895ms\tremaining: 13s\n",
      "45:\tlearn: 0.4565098\ttotal: 915ms\tremaining: 13s\n",
      "46:\tlearn: 0.4540652\ttotal: 934ms\tremaining: 13s\n",
      "47:\tlearn: 0.4522868\ttotal: 954ms\tremaining: 13s\n",
      "48:\tlearn: 0.4508454\ttotal: 974ms\tremaining: 12.9s\n",
      "49:\tlearn: 0.4486463\ttotal: 994ms\tremaining: 12.9s\n",
      "50:\tlearn: 0.4472766\ttotal: 1.01s\tremaining: 12.9s\n",
      "51:\tlearn: 0.4457634\ttotal: 1.03s\tremaining: 12.9s\n",
      "52:\tlearn: 0.4437398\ttotal: 1.05s\tremaining: 12.9s\n",
      "53:\tlearn: 0.4414797\ttotal: 1.07s\tremaining: 12.9s\n",
      "54:\tlearn: 0.4393679\ttotal: 1.09s\tremaining: 12.8s\n",
      "55:\tlearn: 0.4377192\ttotal: 1.11s\tremaining: 12.8s\n",
      "56:\tlearn: 0.4362878\ttotal: 1.13s\tremaining: 12.8s\n",
      "57:\tlearn: 0.4350143\ttotal: 1.15s\tremaining: 12.8s\n",
      "58:\tlearn: 0.4336441\ttotal: 1.17s\tremaining: 12.8s\n",
      "59:\tlearn: 0.4320378\ttotal: 1.19s\tremaining: 12.7s\n",
      "60:\tlearn: 0.4308157\ttotal: 1.22s\tremaining: 12.7s\n",
      "61:\tlearn: 0.4292568\ttotal: 1.24s\tremaining: 12.7s\n",
      "62:\tlearn: 0.4280019\ttotal: 1.25s\tremaining: 12.7s\n",
      "63:\tlearn: 0.4268357\ttotal: 1.28s\tremaining: 12.7s\n",
      "64:\tlearn: 0.4255488\ttotal: 1.3s\tremaining: 12.7s\n",
      "65:\tlearn: 0.4245018\ttotal: 1.32s\tremaining: 12.7s\n",
      "66:\tlearn: 0.4231112\ttotal: 1.34s\tremaining: 12.6s\n",
      "67:\tlearn: 0.4223177\ttotal: 1.36s\tremaining: 12.6s\n",
      "68:\tlearn: 0.4210247\ttotal: 1.38s\tremaining: 12.6s\n",
      "69:\tlearn: 0.4198412\ttotal: 1.4s\tremaining: 12.6s\n",
      "70:\tlearn: 0.4187814\ttotal: 1.42s\tremaining: 12.6s\n",
      "71:\tlearn: 0.4173752\ttotal: 1.44s\tremaining: 12.5s\n",
      "72:\tlearn: 0.4159410\ttotal: 1.46s\tremaining: 12.5s\n",
      "73:\tlearn: 0.4146074\ttotal: 1.48s\tremaining: 12.5s\n",
      "74:\tlearn: 0.4133185\ttotal: 1.5s\tremaining: 12.5s\n",
      "75:\tlearn: 0.4127096\ttotal: 1.52s\tremaining: 12.5s\n",
      "76:\tlearn: 0.4118129\ttotal: 1.54s\tremaining: 12.4s\n",
      "77:\tlearn: 0.4109345\ttotal: 1.55s\tremaining: 12.4s\n",
      "78:\tlearn: 0.4098700\ttotal: 1.57s\tremaining: 12.4s\n",
      "79:\tlearn: 0.4085271\ttotal: 1.59s\tremaining: 12.4s\n",
      "80:\tlearn: 0.4071595\ttotal: 1.62s\tremaining: 12.3s\n",
      "81:\tlearn: 0.4067627\ttotal: 1.63s\tremaining: 12.3s\n",
      "82:\tlearn: 0.4058853\ttotal: 1.65s\tremaining: 12.2s\n",
      "83:\tlearn: 0.4049635\ttotal: 1.67s\tremaining: 12.2s\n",
      "84:\tlearn: 0.4041449\ttotal: 1.69s\tremaining: 12.2s\n",
      "85:\tlearn: 0.4031137\ttotal: 1.71s\tremaining: 12.2s\n",
      "86:\tlearn: 0.4024326\ttotal: 1.73s\tremaining: 12.2s\n",
      "87:\tlearn: 0.4013083\ttotal: 1.75s\tremaining: 12.2s\n",
      "88:\tlearn: 0.4003105\ttotal: 1.77s\tremaining: 12.2s\n",
      "89:\tlearn: 0.3997406\ttotal: 1.79s\tremaining: 12.1s\n",
      "90:\tlearn: 0.3986433\ttotal: 1.81s\tremaining: 12.1s\n",
      "91:\tlearn: 0.3973358\ttotal: 1.84s\tremaining: 12.1s\n",
      "92:\tlearn: 0.3965336\ttotal: 1.86s\tremaining: 12.1s\n",
      "93:\tlearn: 0.3956996\ttotal: 1.88s\tremaining: 12.1s\n",
      "94:\tlearn: 0.3951901\ttotal: 1.9s\tremaining: 12.1s\n",
      "95:\tlearn: 0.3942649\ttotal: 1.92s\tremaining: 12.1s\n",
      "96:\tlearn: 0.3932565\ttotal: 1.94s\tremaining: 12s\n",
      "97:\tlearn: 0.3919772\ttotal: 1.96s\tremaining: 12s\n",
      "98:\tlearn: 0.3909523\ttotal: 1.98s\tremaining: 12s\n",
      "99:\tlearn: 0.3902053\ttotal: 2s\tremaining: 12s\n",
      "100:\tlearn: 0.3896706\ttotal: 2.01s\tremaining: 11.9s\n",
      "101:\tlearn: 0.3890968\ttotal: 2.03s\tremaining: 11.9s\n",
      "102:\tlearn: 0.3880485\ttotal: 2.05s\tremaining: 11.9s\n",
      "103:\tlearn: 0.3867917\ttotal: 2.08s\tremaining: 11.9s\n",
      "104:\tlearn: 0.3861903\ttotal: 2.09s\tremaining: 11.9s\n",
      "105:\tlearn: 0.3856566\ttotal: 2.11s\tremaining: 11.8s\n",
      "106:\tlearn: 0.3848846\ttotal: 2.13s\tremaining: 11.8s\n",
      "107:\tlearn: 0.3841188\ttotal: 2.15s\tremaining: 11.8s\n",
      "108:\tlearn: 0.3830330\ttotal: 2.17s\tremaining: 11.8s\n",
      "109:\tlearn: 0.3823493\ttotal: 2.19s\tremaining: 11.8s\n",
      "110:\tlearn: 0.3814875\ttotal: 2.21s\tremaining: 11.8s\n",
      "111:\tlearn: 0.3805065\ttotal: 2.23s\tremaining: 11.7s\n",
      "112:\tlearn: 0.3799771\ttotal: 2.25s\tremaining: 11.7s\n",
      "113:\tlearn: 0.3794672\ttotal: 2.28s\tremaining: 11.7s\n",
      "114:\tlearn: 0.3787132\ttotal: 2.3s\tremaining: 11.7s\n",
      "115:\tlearn: 0.3779188\ttotal: 2.32s\tremaining: 11.7s\n",
      "116:\tlearn: 0.3774677\ttotal: 2.34s\tremaining: 11.6s\n",
      "117:\tlearn: 0.3766420\ttotal: 2.36s\tremaining: 11.6s\n",
      "118:\tlearn: 0.3762053\ttotal: 2.38s\tremaining: 11.6s\n",
      "119:\tlearn: 0.3754408\ttotal: 2.4s\tremaining: 11.6s\n",
      "120:\tlearn: 0.3747573\ttotal: 2.42s\tremaining: 11.6s\n",
      "121:\tlearn: 0.3740333\ttotal: 2.44s\tremaining: 11.6s\n",
      "122:\tlearn: 0.3735220\ttotal: 2.46s\tremaining: 11.5s\n",
      "123:\tlearn: 0.3730450\ttotal: 2.48s\tremaining: 11.5s\n",
      "124:\tlearn: 0.3724648\ttotal: 2.5s\tremaining: 11.5s\n",
      "125:\tlearn: 0.3722603\ttotal: 2.51s\tremaining: 11.4s\n",
      "126:\tlearn: 0.3715784\ttotal: 2.53s\tremaining: 11.4s\n",
      "127:\tlearn: 0.3709779\ttotal: 2.55s\tremaining: 11.4s\n",
      "128:\tlearn: 0.3706322\ttotal: 2.56s\tremaining: 11.4s\n",
      "129:\tlearn: 0.3698395\ttotal: 2.58s\tremaining: 11.3s\n",
      "130:\tlearn: 0.3690765\ttotal: 2.61s\tremaining: 11.3s\n",
      "131:\tlearn: 0.3685633\ttotal: 2.63s\tremaining: 11.3s\n",
      "132:\tlearn: 0.3679213\ttotal: 2.65s\tremaining: 11.3s\n",
      "133:\tlearn: 0.3672107\ttotal: 2.67s\tremaining: 11.3s\n",
      "134:\tlearn: 0.3668013\ttotal: 2.69s\tremaining: 11.2s\n",
      "135:\tlearn: 0.3662184\ttotal: 2.71s\tremaining: 11.2s\n",
      "136:\tlearn: 0.3658161\ttotal: 2.72s\tremaining: 11.2s\n",
      "137:\tlearn: 0.3647555\ttotal: 2.74s\tremaining: 11.2s\n",
      "138:\tlearn: 0.3642034\ttotal: 2.77s\tremaining: 11.2s\n",
      "139:\tlearn: 0.3636209\ttotal: 2.79s\tremaining: 11.1s\n",
      "140:\tlearn: 0.3625296\ttotal: 2.81s\tremaining: 11.1s\n",
      "141:\tlearn: 0.3621620\ttotal: 2.83s\tremaining: 11.1s\n",
      "142:\tlearn: 0.3618287\ttotal: 2.85s\tremaining: 11.1s\n",
      "143:\tlearn: 0.3611379\ttotal: 2.87s\tremaining: 11.1s\n",
      "144:\tlearn: 0.3604215\ttotal: 2.89s\tremaining: 11.1s\n",
      "145:\tlearn: 0.3599032\ttotal: 2.91s\tremaining: 11s\n",
      "146:\tlearn: 0.3593613\ttotal: 2.93s\tremaining: 11s\n",
      "147:\tlearn: 0.3583268\ttotal: 2.95s\tremaining: 11s\n",
      "148:\tlearn: 0.3578205\ttotal: 2.97s\tremaining: 11s\n",
      "149:\tlearn: 0.3570861\ttotal: 2.99s\tremaining: 11s\n",
      "150:\tlearn: 0.3567284\ttotal: 3.01s\tremaining: 10.9s\n",
      "151:\tlearn: 0.3560731\ttotal: 3.04s\tremaining: 10.9s\n",
      "152:\tlearn: 0.3555586\ttotal: 3.06s\tremaining: 10.9s\n",
      "153:\tlearn: 0.3548563\ttotal: 3.08s\tremaining: 10.9s\n",
      "154:\tlearn: 0.3544428\ttotal: 3.1s\tremaining: 10.9s\n",
      "155:\tlearn: 0.3538332\ttotal: 3.12s\tremaining: 10.9s\n",
      "156:\tlearn: 0.3530926\ttotal: 3.14s\tremaining: 10.8s\n",
      "157:\tlearn: 0.3526753\ttotal: 3.16s\tremaining: 10.8s\n",
      "158:\tlearn: 0.3521708\ttotal: 3.17s\tremaining: 10.8s\n",
      "159:\tlearn: 0.3514921\ttotal: 3.19s\tremaining: 10.8s\n",
      "160:\tlearn: 0.3510041\ttotal: 3.21s\tremaining: 10.8s\n",
      "161:\tlearn: 0.3505351\ttotal: 3.23s\tremaining: 10.7s\n",
      "162:\tlearn: 0.3500496\ttotal: 3.25s\tremaining: 10.7s\n",
      "163:\tlearn: 0.3492835\ttotal: 3.28s\tremaining: 10.7s\n",
      "164:\tlearn: 0.3482961\ttotal: 3.3s\tremaining: 10.7s\n",
      "165:\tlearn: 0.3477572\ttotal: 3.32s\tremaining: 10.7s\n",
      "166:\tlearn: 0.3474371\ttotal: 3.34s\tremaining: 10.7s\n",
      "167:\tlearn: 0.3470916\ttotal: 3.36s\tremaining: 10.6s\n",
      "168:\tlearn: 0.3463797\ttotal: 3.38s\tremaining: 10.6s\n",
      "169:\tlearn: 0.3459066\ttotal: 3.4s\tremaining: 10.6s\n",
      "170:\tlearn: 0.3453352\ttotal: 3.42s\tremaining: 10.6s\n",
      "171:\tlearn: 0.3447548\ttotal: 3.44s\tremaining: 10.6s\n",
      "172:\tlearn: 0.3443290\ttotal: 3.46s\tremaining: 10.5s\n",
      "173:\tlearn: 0.3437385\ttotal: 3.48s\tremaining: 10.5s\n",
      "174:\tlearn: 0.3433089\ttotal: 3.5s\tremaining: 10.5s\n",
      "175:\tlearn: 0.3426198\ttotal: 3.52s\tremaining: 10.5s\n",
      "176:\tlearn: 0.3420353\ttotal: 3.54s\tremaining: 10.5s\n",
      "177:\tlearn: 0.3418395\ttotal: 3.56s\tremaining: 10.4s\n",
      "178:\tlearn: 0.3417461\ttotal: 3.57s\tremaining: 10.4s\n",
      "179:\tlearn: 0.3411291\ttotal: 3.59s\tremaining: 10.4s\n",
      "180:\tlearn: 0.3408380\ttotal: 3.61s\tremaining: 10.4s\n",
      "181:\tlearn: 0.3403322\ttotal: 3.63s\tremaining: 10.3s\n",
      "182:\tlearn: 0.3399145\ttotal: 3.65s\tremaining: 10.3s\n",
      "183:\tlearn: 0.3395985\ttotal: 3.67s\tremaining: 10.3s\n",
      "184:\tlearn: 0.3390381\ttotal: 3.69s\tremaining: 10.3s\n",
      "185:\tlearn: 0.3386427\ttotal: 3.71s\tremaining: 10.2s\n",
      "186:\tlearn: 0.3382411\ttotal: 3.73s\tremaining: 10.2s\n",
      "187:\tlearn: 0.3378596\ttotal: 3.75s\tremaining: 10.2s\n",
      "188:\tlearn: 0.3372182\ttotal: 3.77s\tremaining: 10.2s\n",
      "189:\tlearn: 0.3367515\ttotal: 3.79s\tremaining: 10.2s\n",
      "190:\tlearn: 0.3364988\ttotal: 3.81s\tremaining: 10.2s\n",
      "191:\tlearn: 0.3360004\ttotal: 3.83s\tremaining: 10.1s\n",
      "192:\tlearn: 0.3354456\ttotal: 3.85s\tremaining: 10.1s\n",
      "193:\tlearn: 0.3348034\ttotal: 3.87s\tremaining: 10.1s\n",
      "194:\tlearn: 0.3344943\ttotal: 3.89s\tremaining: 10.1s\n",
      "195:\tlearn: 0.3344316\ttotal: 3.9s\tremaining: 10s\n",
      "196:\tlearn: 0.3341270\ttotal: 3.92s\tremaining: 10s\n",
      "197:\tlearn: 0.3333239\ttotal: 3.94s\tremaining: 9.99s\n",
      "198:\tlearn: 0.3330813\ttotal: 3.96s\tremaining: 9.97s\n",
      "199:\tlearn: 0.3324411\ttotal: 3.98s\tremaining: 9.95s\n",
      "200:\tlearn: 0.3319771\ttotal: 4s\tremaining: 9.93s\n",
      "201:\tlearn: 0.3316574\ttotal: 4.02s\tremaining: 9.91s\n",
      "202:\tlearn: 0.3313387\ttotal: 4.04s\tremaining: 9.88s\n",
      "203:\tlearn: 0.3308957\ttotal: 4.06s\tremaining: 9.86s\n",
      "204:\tlearn: 0.3305962\ttotal: 4.08s\tremaining: 9.84s\n",
      "205:\tlearn: 0.3302119\ttotal: 4.09s\tremaining: 9.82s\n",
      "206:\tlearn: 0.3299357\ttotal: 4.12s\tremaining: 9.8s\n",
      "207:\tlearn: 0.3293533\ttotal: 4.13s\tremaining: 9.78s\n",
      "208:\tlearn: 0.3288434\ttotal: 4.16s\tremaining: 9.76s\n",
      "209:\tlearn: 0.3285066\ttotal: 4.17s\tremaining: 9.74s\n",
      "210:\tlearn: 0.3279018\ttotal: 4.2s\tremaining: 9.72s\n",
      "211:\tlearn: 0.3275489\ttotal: 4.21s\tremaining: 9.7s\n",
      "212:\tlearn: 0.3273181\ttotal: 4.23s\tremaining: 9.68s\n",
      "213:\tlearn: 0.3270512\ttotal: 4.25s\tremaining: 9.66s\n",
      "214:\tlearn: 0.3266149\ttotal: 4.28s\tremaining: 9.65s\n",
      "215:\tlearn: 0.3262500\ttotal: 4.3s\tremaining: 9.63s\n",
      "216:\tlearn: 0.3257844\ttotal: 4.32s\tremaining: 9.61s\n",
      "217:\tlearn: 0.3253234\ttotal: 4.34s\tremaining: 9.59s\n",
      "218:\tlearn: 0.3248875\ttotal: 4.36s\tremaining: 9.57s\n",
      "219:\tlearn: 0.3244136\ttotal: 4.38s\tremaining: 9.55s\n",
      "220:\tlearn: 0.3241248\ttotal: 4.4s\tremaining: 9.53s\n",
      "221:\tlearn: 0.3237883\ttotal: 4.42s\tremaining: 9.51s\n",
      "222:\tlearn: 0.3231207\ttotal: 4.44s\tremaining: 9.49s\n",
      "223:\tlearn: 0.3225081\ttotal: 4.46s\tremaining: 9.47s\n",
      "224:\tlearn: 0.3216903\ttotal: 4.48s\tremaining: 9.45s\n",
      "225:\tlearn: 0.3212014\ttotal: 4.5s\tremaining: 9.43s\n",
      "226:\tlearn: 0.3205226\ttotal: 4.52s\tremaining: 9.41s\n",
      "227:\tlearn: 0.3199862\ttotal: 4.54s\tremaining: 9.4s\n",
      "228:\tlearn: 0.3197292\ttotal: 4.56s\tremaining: 9.38s\n",
      "229:\tlearn: 0.3192654\ttotal: 4.58s\tremaining: 9.36s\n",
      "230:\tlearn: 0.3188716\ttotal: 4.6s\tremaining: 9.33s\n",
      "231:\tlearn: 0.3183086\ttotal: 4.62s\tremaining: 9.31s\n",
      "232:\tlearn: 0.3180387\ttotal: 4.64s\tremaining: 9.29s\n",
      "233:\tlearn: 0.3178763\ttotal: 4.66s\tremaining: 9.27s\n",
      "234:\tlearn: 0.3173489\ttotal: 4.68s\tremaining: 9.25s\n",
      "235:\tlearn: 0.3171083\ttotal: 4.7s\tremaining: 9.23s\n",
      "236:\tlearn: 0.3167830\ttotal: 4.71s\tremaining: 9.21s\n",
      "237:\tlearn: 0.3162782\ttotal: 4.74s\tremaining: 9.19s\n",
      "238:\tlearn: 0.3156670\ttotal: 4.76s\tremaining: 9.18s\n",
      "239:\tlearn: 0.3151522\ttotal: 4.78s\tremaining: 9.16s\n",
      "240:\tlearn: 0.3147870\ttotal: 4.8s\tremaining: 9.14s\n",
      "241:\tlearn: 0.3143407\ttotal: 4.82s\tremaining: 9.13s\n",
      "242:\tlearn: 0.3139865\ttotal: 4.84s\tremaining: 9.11s\n",
      "243:\tlearn: 0.3136467\ttotal: 4.86s\tremaining: 9.09s\n",
      "244:\tlearn: 0.3130489\ttotal: 4.88s\tremaining: 9.06s\n",
      "245:\tlearn: 0.3126857\ttotal: 4.9s\tremaining: 9.04s\n",
      "246:\tlearn: 0.3122813\ttotal: 4.92s\tremaining: 9.02s\n",
      "247:\tlearn: 0.3120069\ttotal: 4.94s\tremaining: 9s\n",
      "248:\tlearn: 0.3115243\ttotal: 4.96s\tremaining: 8.98s\n",
      "249:\tlearn: 0.3111000\ttotal: 4.98s\tremaining: 8.96s\n",
      "250:\tlearn: 0.3107515\ttotal: 5s\tremaining: 8.94s\n",
      "251:\tlearn: 0.3105138\ttotal: 5.02s\tremaining: 8.92s\n",
      "252:\tlearn: 0.3101032\ttotal: 5.04s\tremaining: 8.9s\n",
      "253:\tlearn: 0.3097915\ttotal: 5.06s\tremaining: 8.88s\n",
      "254:\tlearn: 0.3094766\ttotal: 5.08s\tremaining: 8.86s\n",
      "255:\tlearn: 0.3091319\ttotal: 5.1s\tremaining: 8.84s\n",
      "256:\tlearn: 0.3088439\ttotal: 5.12s\tremaining: 8.82s\n",
      "257:\tlearn: 0.3085311\ttotal: 5.14s\tremaining: 8.8s\n",
      "258:\tlearn: 0.3083808\ttotal: 5.16s\tremaining: 8.78s\n",
      "259:\tlearn: 0.3080291\ttotal: 5.17s\tremaining: 8.76s\n",
      "260:\tlearn: 0.3077530\ttotal: 5.2s\tremaining: 8.74s\n",
      "261:\tlearn: 0.3071462\ttotal: 5.22s\tremaining: 8.72s\n",
      "262:\tlearn: 0.3069946\ttotal: 5.24s\tremaining: 8.7s\n",
      "263:\tlearn: 0.3067561\ttotal: 5.25s\tremaining: 8.68s\n",
      "264:\tlearn: 0.3063678\ttotal: 5.28s\tremaining: 8.66s\n",
      "265:\tlearn: 0.3061257\ttotal: 5.3s\tremaining: 8.64s\n",
      "266:\tlearn: 0.3058170\ttotal: 5.32s\tremaining: 8.62s\n",
      "267:\tlearn: 0.3054536\ttotal: 5.34s\tremaining: 8.6s\n",
      "268:\tlearn: 0.3051108\ttotal: 5.36s\tremaining: 8.58s\n",
      "269:\tlearn: 0.3046621\ttotal: 5.38s\tremaining: 8.56s\n",
      "270:\tlearn: 0.3041336\ttotal: 5.39s\tremaining: 8.54s\n",
      "271:\tlearn: 0.3037482\ttotal: 5.42s\tremaining: 8.52s\n",
      "272:\tlearn: 0.3034221\ttotal: 5.43s\tremaining: 8.5s\n",
      "273:\tlearn: 0.3031480\ttotal: 5.45s\tremaining: 8.48s\n",
      "274:\tlearn: 0.3028913\ttotal: 5.47s\tremaining: 8.46s\n",
      "275:\tlearn: 0.3023052\ttotal: 5.49s\tremaining: 8.44s\n",
      "276:\tlearn: 0.3018175\ttotal: 5.51s\tremaining: 8.42s\n",
      "277:\tlearn: 0.3014051\ttotal: 5.53s\tremaining: 8.4s\n",
      "278:\tlearn: 0.3010803\ttotal: 5.55s\tremaining: 8.38s\n",
      "279:\tlearn: 0.3008182\ttotal: 5.57s\tremaining: 8.36s\n",
      "280:\tlearn: 0.3005576\ttotal: 5.59s\tremaining: 8.34s\n",
      "281:\tlearn: 0.3003118\ttotal: 5.61s\tremaining: 8.32s\n",
      "282:\tlearn: 0.3000792\ttotal: 5.63s\tremaining: 8.3s\n",
      "283:\tlearn: 0.2996007\ttotal: 5.65s\tremaining: 8.28s\n",
      "284:\tlearn: 0.2992743\ttotal: 5.67s\tremaining: 8.26s\n",
      "285:\tlearn: 0.2988783\ttotal: 5.69s\tremaining: 8.24s\n",
      "286:\tlearn: 0.2985208\ttotal: 5.71s\tremaining: 8.22s\n",
      "287:\tlearn: 0.2982473\ttotal: 5.73s\tremaining: 8.2s\n",
      "288:\tlearn: 0.2978133\ttotal: 5.75s\tremaining: 8.18s\n",
      "289:\tlearn: 0.2974743\ttotal: 5.77s\tremaining: 8.16s\n",
      "290:\tlearn: 0.2970213\ttotal: 5.79s\tremaining: 8.14s\n",
      "291:\tlearn: 0.2965333\ttotal: 5.81s\tremaining: 8.12s\n",
      "292:\tlearn: 0.2965061\ttotal: 5.82s\tremaining: 8.09s\n",
      "293:\tlearn: 0.2958692\ttotal: 5.84s\tremaining: 8.07s\n",
      "294:\tlearn: 0.2951886\ttotal: 5.86s\tremaining: 8.05s\n",
      "295:\tlearn: 0.2947554\ttotal: 5.88s\tremaining: 8.03s\n",
      "296:\tlearn: 0.2941334\ttotal: 5.9s\tremaining: 8.01s\n",
      "297:\tlearn: 0.2937094\ttotal: 5.92s\tremaining: 7.99s\n",
      "298:\tlearn: 0.2933161\ttotal: 5.94s\tremaining: 7.97s\n",
      "299:\tlearn: 0.2928569\ttotal: 5.96s\tremaining: 7.95s\n",
      "300:\tlearn: 0.2925740\ttotal: 5.98s\tremaining: 7.93s\n",
      "301:\tlearn: 0.2923730\ttotal: 6s\tremaining: 7.91s\n",
      "302:\tlearn: 0.2919393\ttotal: 6.02s\tremaining: 7.89s\n",
      "303:\tlearn: 0.2917211\ttotal: 6.04s\tremaining: 7.87s\n",
      "304:\tlearn: 0.2915262\ttotal: 6.06s\tremaining: 7.85s\n",
      "305:\tlearn: 0.2912843\ttotal: 6.08s\tremaining: 7.83s\n",
      "306:\tlearn: 0.2909422\ttotal: 6.1s\tremaining: 7.81s\n",
      "307:\tlearn: 0.2906659\ttotal: 6.12s\tremaining: 7.79s\n",
      "308:\tlearn: 0.2902283\ttotal: 6.14s\tremaining: 7.77s\n",
      "309:\tlearn: 0.2900164\ttotal: 6.16s\tremaining: 7.75s\n",
      "310:\tlearn: 0.2895165\ttotal: 6.18s\tremaining: 7.73s\n",
      "311:\tlearn: 0.2891920\ttotal: 6.2s\tremaining: 7.71s\n",
      "312:\tlearn: 0.2889753\ttotal: 6.22s\tremaining: 7.69s\n",
      "313:\tlearn: 0.2887620\ttotal: 6.24s\tremaining: 7.67s\n",
      "314:\tlearn: 0.2883094\ttotal: 6.26s\tremaining: 7.65s\n",
      "315:\tlearn: 0.2880545\ttotal: 6.28s\tremaining: 7.63s\n",
      "316:\tlearn: 0.2876064\ttotal: 6.3s\tremaining: 7.61s\n",
      "317:\tlearn: 0.2872956\ttotal: 6.32s\tremaining: 7.59s\n",
      "318:\tlearn: 0.2872677\ttotal: 6.33s\tremaining: 7.56s\n",
      "319:\tlearn: 0.2870758\ttotal: 6.35s\tremaining: 7.54s\n",
      "320:\tlearn: 0.2867544\ttotal: 6.37s\tremaining: 7.52s\n",
      "321:\tlearn: 0.2864116\ttotal: 6.39s\tremaining: 7.5s\n",
      "322:\tlearn: 0.2862166\ttotal: 6.41s\tremaining: 7.48s\n",
      "323:\tlearn: 0.2860329\ttotal: 6.43s\tremaining: 7.46s\n",
      "324:\tlearn: 0.2856639\ttotal: 6.45s\tremaining: 7.44s\n",
      "325:\tlearn: 0.2854821\ttotal: 6.47s\tremaining: 7.42s\n",
      "326:\tlearn: 0.2852655\ttotal: 6.49s\tremaining: 7.4s\n",
      "327:\tlearn: 0.2848270\ttotal: 6.51s\tremaining: 7.38s\n",
      "328:\tlearn: 0.2845565\ttotal: 6.53s\tremaining: 7.36s\n",
      "329:\tlearn: 0.2840384\ttotal: 6.55s\tremaining: 7.34s\n",
      "330:\tlearn: 0.2836764\ttotal: 6.57s\tremaining: 7.32s\n",
      "331:\tlearn: 0.2831066\ttotal: 6.59s\tremaining: 7.3s\n",
      "332:\tlearn: 0.2828341\ttotal: 6.61s\tremaining: 7.28s\n",
      "333:\tlearn: 0.2823990\ttotal: 6.63s\tremaining: 7.26s\n",
      "334:\tlearn: 0.2821745\ttotal: 6.65s\tremaining: 7.24s\n",
      "335:\tlearn: 0.2819880\ttotal: 6.67s\tremaining: 7.22s\n",
      "336:\tlearn: 0.2817142\ttotal: 6.69s\tremaining: 7.2s\n",
      "337:\tlearn: 0.2813351\ttotal: 6.71s\tremaining: 7.18s\n",
      "338:\tlearn: 0.2809100\ttotal: 6.73s\tremaining: 7.16s\n",
      "339:\tlearn: 0.2807250\ttotal: 6.75s\tremaining: 7.14s\n",
      "340:\tlearn: 0.2805124\ttotal: 6.76s\tremaining: 7.12s\n",
      "341:\tlearn: 0.2802820\ttotal: 6.79s\tremaining: 7.1s\n",
      "342:\tlearn: 0.2798089\ttotal: 6.81s\tremaining: 7.08s\n",
      "343:\tlearn: 0.2796033\ttotal: 6.83s\tremaining: 7.07s\n",
      "344:\tlearn: 0.2794731\ttotal: 6.85s\tremaining: 7.04s\n",
      "345:\tlearn: 0.2789058\ttotal: 6.87s\tremaining: 7.03s\n",
      "346:\tlearn: 0.2786712\ttotal: 6.89s\tremaining: 7s\n",
      "347:\tlearn: 0.2782562\ttotal: 6.91s\tremaining: 6.99s\n",
      "348:\tlearn: 0.2780409\ttotal: 6.92s\tremaining: 6.96s\n",
      "349:\tlearn: 0.2775103\ttotal: 6.95s\tremaining: 6.95s\n",
      "350:\tlearn: 0.2771279\ttotal: 6.97s\tremaining: 6.93s\n",
      "351:\tlearn: 0.2767938\ttotal: 6.99s\tremaining: 6.91s\n",
      "352:\tlearn: 0.2765270\ttotal: 7.01s\tremaining: 6.89s\n",
      "353:\tlearn: 0.2761255\ttotal: 7.03s\tremaining: 6.87s\n",
      "354:\tlearn: 0.2757787\ttotal: 7.05s\tremaining: 6.85s\n",
      "355:\tlearn: 0.2755613\ttotal: 7.07s\tremaining: 6.83s\n",
      "356:\tlearn: 0.2751273\ttotal: 7.08s\tremaining: 6.81s\n",
      "357:\tlearn: 0.2750020\ttotal: 7.1s\tremaining: 6.79s\n",
      "358:\tlearn: 0.2746569\ttotal: 7.12s\tremaining: 6.77s\n",
      "359:\tlearn: 0.2744565\ttotal: 7.14s\tremaining: 6.75s\n",
      "360:\tlearn: 0.2741318\ttotal: 7.17s\tremaining: 6.73s\n",
      "361:\tlearn: 0.2739781\ttotal: 7.19s\tremaining: 6.71s\n",
      "362:\tlearn: 0.2737685\ttotal: 7.21s\tremaining: 6.7s\n",
      "363:\tlearn: 0.2735351\ttotal: 7.23s\tremaining: 6.67s\n",
      "364:\tlearn: 0.2732130\ttotal: 7.25s\tremaining: 6.66s\n",
      "365:\tlearn: 0.2726139\ttotal: 7.27s\tremaining: 6.64s\n",
      "366:\tlearn: 0.2721236\ttotal: 7.29s\tremaining: 6.62s\n",
      "367:\tlearn: 0.2719428\ttotal: 7.31s\tremaining: 6.6s\n",
      "368:\tlearn: 0.2717151\ttotal: 7.33s\tremaining: 6.58s\n",
      "369:\tlearn: 0.2713913\ttotal: 7.35s\tremaining: 6.56s\n",
      "370:\tlearn: 0.2711617\ttotal: 7.37s\tremaining: 6.54s\n",
      "371:\tlearn: 0.2707666\ttotal: 7.39s\tremaining: 6.52s\n",
      "372:\tlearn: 0.2705451\ttotal: 7.42s\tremaining: 6.5s\n",
      "373:\tlearn: 0.2700157\ttotal: 7.43s\tremaining: 6.48s\n",
      "374:\tlearn: 0.2695891\ttotal: 7.46s\tremaining: 6.46s\n",
      "375:\tlearn: 0.2694698\ttotal: 7.47s\tremaining: 6.44s\n",
      "376:\tlearn: 0.2689923\ttotal: 7.49s\tremaining: 6.42s\n",
      "377:\tlearn: 0.2686920\ttotal: 7.51s\tremaining: 6.4s\n",
      "378:\tlearn: 0.2686382\ttotal: 7.53s\tremaining: 6.37s\n",
      "379:\tlearn: 0.2684694\ttotal: 7.54s\tremaining: 6.35s\n",
      "380:\tlearn: 0.2682261\ttotal: 7.56s\tremaining: 6.33s\n",
      "381:\tlearn: 0.2678001\ttotal: 7.58s\tremaining: 6.31s\n",
      "382:\tlearn: 0.2674022\ttotal: 7.61s\tremaining: 6.29s\n",
      "383:\tlearn: 0.2672366\ttotal: 7.63s\tremaining: 6.28s\n",
      "384:\tlearn: 0.2669868\ttotal: 7.64s\tremaining: 6.25s\n",
      "385:\tlearn: 0.2668625\ttotal: 7.66s\tremaining: 6.24s\n",
      "386:\tlearn: 0.2667421\ttotal: 7.68s\tremaining: 6.21s\n",
      "387:\tlearn: 0.2664920\ttotal: 7.7s\tremaining: 6.2s\n",
      "388:\tlearn: 0.2659896\ttotal: 7.72s\tremaining: 6.17s\n",
      "389:\tlearn: 0.2655876\ttotal: 7.74s\tremaining: 6.16s\n",
      "390:\tlearn: 0.2651398\ttotal: 7.77s\tremaining: 6.14s\n",
      "391:\tlearn: 0.2648282\ttotal: 7.79s\tremaining: 6.12s\n",
      "392:\tlearn: 0.2645267\ttotal: 7.81s\tremaining: 6.1s\n",
      "393:\tlearn: 0.2643893\ttotal: 7.83s\tremaining: 6.08s\n",
      "394:\tlearn: 0.2640672\ttotal: 7.85s\tremaining: 6.06s\n",
      "395:\tlearn: 0.2636212\ttotal: 7.87s\tremaining: 6.04s\n",
      "396:\tlearn: 0.2632622\ttotal: 7.89s\tremaining: 6.02s\n",
      "397:\tlearn: 0.2630081\ttotal: 7.91s\tremaining: 6s\n",
      "398:\tlearn: 0.2627930\ttotal: 7.93s\tremaining: 5.98s\n",
      "399:\tlearn: 0.2624194\ttotal: 7.95s\tremaining: 5.96s\n",
      "400:\tlearn: 0.2620072\ttotal: 7.97s\tremaining: 5.94s\n",
      "401:\tlearn: 0.2615901\ttotal: 7.99s\tremaining: 5.92s\n",
      "402:\tlearn: 0.2613708\ttotal: 8.01s\tremaining: 5.9s\n",
      "403:\tlearn: 0.2609052\ttotal: 8.03s\tremaining: 5.88s\n",
      "404:\tlearn: 0.2605286\ttotal: 8.05s\tremaining: 5.87s\n",
      "405:\tlearn: 0.2603255\ttotal: 8.07s\tremaining: 5.84s\n",
      "406:\tlearn: 0.2601095\ttotal: 8.09s\tremaining: 5.83s\n",
      "407:\tlearn: 0.2597378\ttotal: 8.11s\tremaining: 5.8s\n",
      "408:\tlearn: 0.2593811\ttotal: 8.13s\tremaining: 5.79s\n",
      "409:\tlearn: 0.2590961\ttotal: 8.15s\tremaining: 5.76s\n",
      "410:\tlearn: 0.2587361\ttotal: 8.17s\tremaining: 5.75s\n",
      "411:\tlearn: 0.2583836\ttotal: 8.19s\tremaining: 5.73s\n",
      "412:\tlearn: 0.2580594\ttotal: 8.21s\tremaining: 5.71s\n",
      "413:\tlearn: 0.2575660\ttotal: 8.23s\tremaining: 5.69s\n",
      "414:\tlearn: 0.2572594\ttotal: 8.25s\tremaining: 5.67s\n",
      "415:\tlearn: 0.2569093\ttotal: 8.27s\tremaining: 5.65s\n",
      "416:\tlearn: 0.2565751\ttotal: 8.3s\tremaining: 5.63s\n",
      "417:\tlearn: 0.2563750\ttotal: 8.31s\tremaining: 5.61s\n",
      "418:\tlearn: 0.2559725\ttotal: 8.34s\tremaining: 5.59s\n",
      "419:\tlearn: 0.2558858\ttotal: 8.36s\tremaining: 5.57s\n",
      "420:\tlearn: 0.2558673\ttotal: 8.37s\tremaining: 5.54s\n",
      "421:\tlearn: 0.2555618\ttotal: 8.38s\tremaining: 5.52s\n",
      "422:\tlearn: 0.2554330\ttotal: 8.4s\tremaining: 5.5s\n",
      "423:\tlearn: 0.2549486\ttotal: 8.43s\tremaining: 5.48s\n",
      "424:\tlearn: 0.2547272\ttotal: 8.44s\tremaining: 5.46s\n",
      "425:\tlearn: 0.2546418\ttotal: 8.46s\tremaining: 5.44s\n",
      "426:\tlearn: 0.2545558\ttotal: 8.48s\tremaining: 5.42s\n",
      "427:\tlearn: 0.2545388\ttotal: 8.49s\tremaining: 5.4s\n",
      "428:\tlearn: 0.2543140\ttotal: 8.51s\tremaining: 5.38s\n",
      "429:\tlearn: 0.2541299\ttotal: 8.53s\tremaining: 5.36s\n",
      "430:\tlearn: 0.2539304\ttotal: 8.55s\tremaining: 5.34s\n",
      "431:\tlearn: 0.2536647\ttotal: 8.57s\tremaining: 5.32s\n",
      "432:\tlearn: 0.2534566\ttotal: 8.59s\tremaining: 5.3s\n",
      "433:\tlearn: 0.2530956\ttotal: 8.61s\tremaining: 5.28s\n",
      "434:\tlearn: 0.2528733\ttotal: 8.63s\tremaining: 5.26s\n",
      "435:\tlearn: 0.2526214\ttotal: 8.65s\tremaining: 5.24s\n",
      "436:\tlearn: 0.2522343\ttotal: 8.67s\tremaining: 5.22s\n",
      "437:\tlearn: 0.2517892\ttotal: 8.69s\tremaining: 5.2s\n",
      "438:\tlearn: 0.2514561\ttotal: 8.71s\tremaining: 5.18s\n",
      "439:\tlearn: 0.2511161\ttotal: 8.73s\tremaining: 5.16s\n",
      "440:\tlearn: 0.2504111\ttotal: 8.75s\tremaining: 5.14s\n",
      "441:\tlearn: 0.2501420\ttotal: 8.77s\tremaining: 5.12s\n",
      "442:\tlearn: 0.2497623\ttotal: 8.79s\tremaining: 5.1s\n",
      "443:\tlearn: 0.2496378\ttotal: 8.81s\tremaining: 5.08s\n",
      "444:\tlearn: 0.2494064\ttotal: 8.83s\tremaining: 5.06s\n",
      "445:\tlearn: 0.2491778\ttotal: 8.85s\tremaining: 5.04s\n",
      "446:\tlearn: 0.2491776\ttotal: 8.86s\tremaining: 5.01s\n",
      "447:\tlearn: 0.2489514\ttotal: 8.88s\tremaining: 5s\n",
      "448:\tlearn: 0.2487895\ttotal: 8.9s\tremaining: 4.98s\n",
      "449:\tlearn: 0.2482326\ttotal: 8.92s\tremaining: 4.96s\n",
      "450:\tlearn: 0.2478154\ttotal: 8.94s\tremaining: 4.94s\n",
      "451:\tlearn: 0.2473105\ttotal: 8.96s\tremaining: 4.92s\n",
      "452:\tlearn: 0.2469447\ttotal: 8.98s\tremaining: 4.9s\n",
      "453:\tlearn: 0.2467414\ttotal: 9s\tremaining: 4.88s\n",
      "454:\tlearn: 0.2465356\ttotal: 9.02s\tremaining: 4.86s\n",
      "455:\tlearn: 0.2461419\ttotal: 9.04s\tremaining: 4.84s\n",
      "456:\tlearn: 0.2457283\ttotal: 9.06s\tremaining: 4.82s\n",
      "457:\tlearn: 0.2453254\ttotal: 9.08s\tremaining: 4.8s\n",
      "458:\tlearn: 0.2447658\ttotal: 9.1s\tremaining: 4.78s\n",
      "459:\tlearn: 0.2445819\ttotal: 9.12s\tremaining: 4.76s\n",
      "460:\tlearn: 0.2443182\ttotal: 9.14s\tremaining: 4.74s\n",
      "461:\tlearn: 0.2438803\ttotal: 9.17s\tremaining: 4.72s\n",
      "462:\tlearn: 0.2436834\ttotal: 9.19s\tremaining: 4.7s\n",
      "463:\tlearn: 0.2434386\ttotal: 9.21s\tremaining: 4.68s\n",
      "464:\tlearn: 0.2432381\ttotal: 9.23s\tremaining: 4.66s\n",
      "465:\tlearn: 0.2430673\ttotal: 9.25s\tremaining: 4.64s\n",
      "466:\tlearn: 0.2429221\ttotal: 9.27s\tremaining: 4.62s\n",
      "467:\tlearn: 0.2426427\ttotal: 9.29s\tremaining: 4.61s\n",
      "468:\tlearn: 0.2422437\ttotal: 9.31s\tremaining: 4.59s\n",
      "469:\tlearn: 0.2418423\ttotal: 9.34s\tremaining: 4.57s\n",
      "470:\tlearn: 0.2415077\ttotal: 9.36s\tremaining: 4.55s\n",
      "471:\tlearn: 0.2411057\ttotal: 9.38s\tremaining: 4.53s\n",
      "472:\tlearn: 0.2407010\ttotal: 9.4s\tremaining: 4.51s\n",
      "473:\tlearn: 0.2407004\ttotal: 9.41s\tremaining: 4.49s\n",
      "474:\tlearn: 0.2406800\ttotal: 9.42s\tremaining: 4.46s\n",
      "475:\tlearn: 0.2404848\ttotal: 9.44s\tremaining: 4.44s\n",
      "476:\tlearn: 0.2403552\ttotal: 9.46s\tremaining: 4.42s\n",
      "477:\tlearn: 0.2401742\ttotal: 9.48s\tremaining: 4.4s\n",
      "478:\tlearn: 0.2400765\ttotal: 9.5s\tremaining: 4.38s\n",
      "479:\tlearn: 0.2397517\ttotal: 9.52s\tremaining: 4.36s\n",
      "480:\tlearn: 0.2393866\ttotal: 9.54s\tremaining: 4.34s\n",
      "481:\tlearn: 0.2392289\ttotal: 9.56s\tremaining: 4.32s\n",
      "482:\tlearn: 0.2388444\ttotal: 9.58s\tremaining: 4.3s\n",
      "483:\tlearn: 0.2384895\ttotal: 9.6s\tremaining: 4.28s\n",
      "484:\tlearn: 0.2383752\ttotal: 9.62s\tremaining: 4.26s\n",
      "485:\tlearn: 0.2379638\ttotal: 9.64s\tremaining: 4.24s\n",
      "486:\tlearn: 0.2376964\ttotal: 9.66s\tremaining: 4.22s\n",
      "487:\tlearn: 0.2374031\ttotal: 9.68s\tremaining: 4.2s\n",
      "488:\tlearn: 0.2372401\ttotal: 9.7s\tremaining: 4.18s\n",
      "489:\tlearn: 0.2370583\ttotal: 9.72s\tremaining: 4.17s\n",
      "490:\tlearn: 0.2369252\ttotal: 9.74s\tremaining: 4.14s\n",
      "491:\tlearn: 0.2365696\ttotal: 9.76s\tremaining: 4.13s\n",
      "492:\tlearn: 0.2364335\ttotal: 9.78s\tremaining: 4.11s\n",
      "493:\tlearn: 0.2360879\ttotal: 9.8s\tremaining: 4.09s\n",
      "494:\tlearn: 0.2357104\ttotal: 9.82s\tremaining: 4.07s\n",
      "495:\tlearn: 0.2354741\ttotal: 9.85s\tremaining: 4.05s\n",
      "496:\tlearn: 0.2352137\ttotal: 9.87s\tremaining: 4.03s\n",
      "497:\tlearn: 0.2349857\ttotal: 9.89s\tremaining: 4.01s\n",
      "498:\tlearn: 0.2345414\ttotal: 9.91s\tremaining: 3.99s\n",
      "499:\tlearn: 0.2342173\ttotal: 9.93s\tremaining: 3.97s\n",
      "500:\tlearn: 0.2338577\ttotal: 9.95s\tremaining: 3.95s\n",
      "501:\tlearn: 0.2335577\ttotal: 9.97s\tremaining: 3.93s\n",
      "502:\tlearn: 0.2331767\ttotal: 9.99s\tremaining: 3.91s\n",
      "503:\tlearn: 0.2328989\ttotal: 10s\tremaining: 3.89s\n",
      "504:\tlearn: 0.2327567\ttotal: 10s\tremaining: 3.87s\n",
      "505:\tlearn: 0.2325367\ttotal: 10.1s\tremaining: 3.85s\n",
      "506:\tlearn: 0.2322414\ttotal: 10.1s\tremaining: 3.83s\n",
      "507:\tlearn: 0.2319088\ttotal: 10.1s\tremaining: 3.81s\n",
      "508:\tlearn: 0.2316267\ttotal: 10.1s\tremaining: 3.79s\n",
      "509:\tlearn: 0.2314070\ttotal: 10.1s\tremaining: 3.77s\n",
      "510:\tlearn: 0.2312552\ttotal: 10.2s\tremaining: 3.75s\n",
      "511:\tlearn: 0.2311682\ttotal: 10.2s\tremaining: 3.73s\n",
      "512:\tlearn: 0.2309317\ttotal: 10.2s\tremaining: 3.71s\n",
      "513:\tlearn: 0.2306624\ttotal: 10.2s\tremaining: 3.69s\n",
      "514:\tlearn: 0.2304101\ttotal: 10.2s\tremaining: 3.67s\n",
      "515:\tlearn: 0.2301266\ttotal: 10.3s\tremaining: 3.66s\n",
      "516:\tlearn: 0.2297043\ttotal: 10.3s\tremaining: 3.64s\n",
      "517:\tlearn: 0.2293662\ttotal: 10.3s\tremaining: 3.62s\n",
      "518:\tlearn: 0.2290232\ttotal: 10.3s\tremaining: 3.6s\n",
      "519:\tlearn: 0.2288054\ttotal: 10.3s\tremaining: 3.58s\n",
      "520:\tlearn: 0.2286429\ttotal: 10.4s\tremaining: 3.56s\n",
      "521:\tlearn: 0.2283580\ttotal: 10.4s\tremaining: 3.54s\n",
      "522:\tlearn: 0.2279629\ttotal: 10.4s\tremaining: 3.52s\n",
      "523:\tlearn: 0.2274052\ttotal: 10.4s\tremaining: 3.5s\n",
      "524:\tlearn: 0.2271245\ttotal: 10.4s\tremaining: 3.48s\n",
      "525:\tlearn: 0.2269486\ttotal: 10.5s\tremaining: 3.46s\n",
      "526:\tlearn: 0.2267692\ttotal: 10.5s\tremaining: 3.44s\n",
      "527:\tlearn: 0.2264497\ttotal: 10.5s\tremaining: 3.42s\n",
      "528:\tlearn: 0.2262091\ttotal: 10.5s\tremaining: 3.4s\n",
      "529:\tlearn: 0.2260746\ttotal: 10.5s\tremaining: 3.38s\n",
      "530:\tlearn: 0.2257278\ttotal: 10.6s\tremaining: 3.36s\n",
      "531:\tlearn: 0.2253545\ttotal: 10.6s\tremaining: 3.34s\n",
      "532:\tlearn: 0.2252490\ttotal: 10.6s\tremaining: 3.32s\n",
      "533:\tlearn: 0.2250292\ttotal: 10.6s\tremaining: 3.3s\n",
      "534:\tlearn: 0.2245823\ttotal: 10.6s\tremaining: 3.28s\n",
      "535:\tlearn: 0.2244116\ttotal: 10.7s\tremaining: 3.26s\n",
      "536:\tlearn: 0.2242146\ttotal: 10.7s\tremaining: 3.24s\n",
      "537:\tlearn: 0.2239147\ttotal: 10.7s\tremaining: 3.22s\n",
      "538:\tlearn: 0.2237068\ttotal: 10.7s\tremaining: 3.2s\n",
      "539:\tlearn: 0.2235198\ttotal: 10.7s\tremaining: 3.19s\n",
      "540:\tlearn: 0.2231861\ttotal: 10.8s\tremaining: 3.17s\n",
      "541:\tlearn: 0.2229182\ttotal: 10.8s\tremaining: 3.15s\n",
      "542:\tlearn: 0.2225356\ttotal: 10.8s\tremaining: 3.13s\n",
      "543:\tlearn: 0.2221670\ttotal: 10.8s\tremaining: 3.11s\n",
      "544:\tlearn: 0.2220507\ttotal: 10.9s\tremaining: 3.09s\n",
      "545:\tlearn: 0.2218144\ttotal: 10.9s\tremaining: 3.07s\n",
      "546:\tlearn: 0.2215519\ttotal: 10.9s\tremaining: 3.05s\n",
      "547:\tlearn: 0.2211661\ttotal: 10.9s\tremaining: 3.03s\n",
      "548:\tlearn: 0.2209573\ttotal: 10.9s\tremaining: 3.01s\n",
      "549:\tlearn: 0.2207079\ttotal: 11s\tremaining: 2.99s\n",
      "550:\tlearn: 0.2203852\ttotal: 11s\tremaining: 2.97s\n",
      "551:\tlearn: 0.2200138\ttotal: 11s\tremaining: 2.95s\n",
      "552:\tlearn: 0.2198005\ttotal: 11s\tremaining: 2.93s\n",
      "553:\tlearn: 0.2193005\ttotal: 11s\tremaining: 2.91s\n",
      "554:\tlearn: 0.2190377\ttotal: 11.1s\tremaining: 2.89s\n",
      "555:\tlearn: 0.2187789\ttotal: 11.1s\tremaining: 2.87s\n",
      "556:\tlearn: 0.2186880\ttotal: 11.1s\tremaining: 2.85s\n",
      "557:\tlearn: 0.2183745\ttotal: 11.1s\tremaining: 2.83s\n",
      "558:\tlearn: 0.2181114\ttotal: 11.1s\tremaining: 2.81s\n",
      "559:\tlearn: 0.2178555\ttotal: 11.2s\tremaining: 2.79s\n",
      "560:\tlearn: 0.2175683\ttotal: 11.2s\tremaining: 2.77s\n",
      "561:\tlearn: 0.2173870\ttotal: 11.2s\tremaining: 2.75s\n",
      "562:\tlearn: 0.2168828\ttotal: 11.2s\tremaining: 2.73s\n",
      "563:\tlearn: 0.2166656\ttotal: 11.2s\tremaining: 2.71s\n",
      "564:\tlearn: 0.2163973\ttotal: 11.3s\tremaining: 2.69s\n",
      "565:\tlearn: 0.2159526\ttotal: 11.3s\tremaining: 2.67s\n",
      "566:\tlearn: 0.2156185\ttotal: 11.3s\tremaining: 2.65s\n",
      "567:\tlearn: 0.2151702\ttotal: 11.3s\tremaining: 2.64s\n",
      "568:\tlearn: 0.2149552\ttotal: 11.4s\tremaining: 2.62s\n",
      "569:\tlearn: 0.2147001\ttotal: 11.4s\tremaining: 2.6s\n",
      "570:\tlearn: 0.2144140\ttotal: 11.4s\tremaining: 2.58s\n",
      "571:\tlearn: 0.2140456\ttotal: 11.4s\tremaining: 2.56s\n",
      "572:\tlearn: 0.2136321\ttotal: 11.4s\tremaining: 2.54s\n",
      "573:\tlearn: 0.2134714\ttotal: 11.5s\tremaining: 2.52s\n",
      "574:\tlearn: 0.2131854\ttotal: 11.5s\tremaining: 2.5s\n",
      "575:\tlearn: 0.2128515\ttotal: 11.5s\tremaining: 2.48s\n",
      "576:\tlearn: 0.2125956\ttotal: 11.5s\tremaining: 2.46s\n",
      "577:\tlearn: 0.2122766\ttotal: 11.5s\tremaining: 2.44s\n",
      "578:\tlearn: 0.2118496\ttotal: 11.6s\tremaining: 2.42s\n",
      "579:\tlearn: 0.2114643\ttotal: 11.6s\tremaining: 2.4s\n",
      "580:\tlearn: 0.2111932\ttotal: 11.6s\tremaining: 2.38s\n",
      "581:\tlearn: 0.2110018\ttotal: 11.6s\tremaining: 2.36s\n",
      "582:\tlearn: 0.2107671\ttotal: 11.6s\tremaining: 2.34s\n",
      "583:\tlearn: 0.2105279\ttotal: 11.7s\tremaining: 2.32s\n",
      "584:\tlearn: 0.2101567\ttotal: 11.7s\tremaining: 2.3s\n",
      "585:\tlearn: 0.2100152\ttotal: 11.7s\tremaining: 2.28s\n",
      "586:\tlearn: 0.2097895\ttotal: 11.7s\tremaining: 2.26s\n",
      "587:\tlearn: 0.2094569\ttotal: 11.8s\tremaining: 2.24s\n",
      "588:\tlearn: 0.2089827\ttotal: 11.8s\tremaining: 2.22s\n",
      "589:\tlearn: 0.2087438\ttotal: 11.8s\tremaining: 2.2s\n",
      "590:\tlearn: 0.2086129\ttotal: 11.8s\tremaining: 2.18s\n",
      "591:\tlearn: 0.2085344\ttotal: 11.8s\tremaining: 2.16s\n",
      "592:\tlearn: 0.2083249\ttotal: 11.9s\tremaining: 2.14s\n",
      "593:\tlearn: 0.2081342\ttotal: 11.9s\tremaining: 2.12s\n",
      "594:\tlearn: 0.2077923\ttotal: 11.9s\tremaining: 2.1s\n",
      "595:\tlearn: 0.2076381\ttotal: 11.9s\tremaining: 2.08s\n",
      "596:\tlearn: 0.2074319\ttotal: 11.9s\tremaining: 2.06s\n",
      "597:\tlearn: 0.2071682\ttotal: 12s\tremaining: 2.04s\n",
      "598:\tlearn: 0.2067868\ttotal: 12s\tremaining: 2.02s\n",
      "599:\tlearn: 0.2067061\ttotal: 12s\tremaining: 2s\n",
      "600:\tlearn: 0.2064626\ttotal: 12s\tremaining: 1.98s\n",
      "601:\tlearn: 0.2061692\ttotal: 12s\tremaining: 1.96s\n",
      "602:\tlearn: 0.2057609\ttotal: 12.1s\tremaining: 1.94s\n",
      "603:\tlearn: 0.2054464\ttotal: 12.1s\tremaining: 1.92s\n",
      "604:\tlearn: 0.2051554\ttotal: 12.1s\tremaining: 1.9s\n",
      "605:\tlearn: 0.2047948\ttotal: 12.1s\tremaining: 1.88s\n",
      "606:\tlearn: 0.2045129\ttotal: 12.1s\tremaining: 1.86s\n",
      "607:\tlearn: 0.2042231\ttotal: 12.2s\tremaining: 1.84s\n",
      "608:\tlearn: 0.2039489\ttotal: 12.2s\tremaining: 1.82s\n",
      "609:\tlearn: 0.2036940\ttotal: 12.2s\tremaining: 1.8s\n",
      "610:\tlearn: 0.2034276\ttotal: 12.2s\tremaining: 1.78s\n",
      "611:\tlearn: 0.2030036\ttotal: 12.2s\tremaining: 1.76s\n",
      "612:\tlearn: 0.2025961\ttotal: 12.3s\tremaining: 1.74s\n",
      "613:\tlearn: 0.2021825\ttotal: 12.3s\tremaining: 1.72s\n",
      "614:\tlearn: 0.2018762\ttotal: 12.3s\tremaining: 1.7s\n",
      "615:\tlearn: 0.2016659\ttotal: 12.3s\tremaining: 1.68s\n",
      "616:\tlearn: 0.2013981\ttotal: 12.3s\tremaining: 1.66s\n",
      "617:\tlearn: 0.2012388\ttotal: 12.4s\tremaining: 1.64s\n",
      "618:\tlearn: 0.2009388\ttotal: 12.4s\tremaining: 1.62s\n",
      "619:\tlearn: 0.2007559\ttotal: 12.4s\tremaining: 1.6s\n",
      "620:\tlearn: 0.2005103\ttotal: 12.4s\tremaining: 1.58s\n",
      "621:\tlearn: 0.2001857\ttotal: 12.5s\tremaining: 1.56s\n",
      "622:\tlearn: 0.1999435\ttotal: 12.5s\tremaining: 1.54s\n",
      "623:\tlearn: 0.1996316\ttotal: 12.5s\tremaining: 1.52s\n",
      "624:\tlearn: 0.1992614\ttotal: 12.5s\tremaining: 1.5s\n",
      "625:\tlearn: 0.1990069\ttotal: 12.5s\tremaining: 1.48s\n",
      "626:\tlearn: 0.1987805\ttotal: 12.6s\tremaining: 1.46s\n",
      "627:\tlearn: 0.1985505\ttotal: 12.6s\tremaining: 1.44s\n",
      "628:\tlearn: 0.1983565\ttotal: 12.6s\tremaining: 1.42s\n",
      "629:\tlearn: 0.1980633\ttotal: 12.6s\tremaining: 1.4s\n",
      "630:\tlearn: 0.1977675\ttotal: 12.6s\tremaining: 1.38s\n",
      "631:\tlearn: 0.1974873\ttotal: 12.7s\tremaining: 1.36s\n",
      "632:\tlearn: 0.1971297\ttotal: 12.7s\tremaining: 1.34s\n",
      "633:\tlearn: 0.1968665\ttotal: 12.7s\tremaining: 1.32s\n",
      "634:\tlearn: 0.1965895\ttotal: 12.7s\tremaining: 1.3s\n",
      "635:\tlearn: 0.1963891\ttotal: 12.7s\tremaining: 1.28s\n",
      "636:\tlearn: 0.1961151\ttotal: 12.8s\tremaining: 1.26s\n",
      "637:\tlearn: 0.1958422\ttotal: 12.8s\tremaining: 1.24s\n",
      "638:\tlearn: 0.1955492\ttotal: 12.8s\tremaining: 1.22s\n",
      "639:\tlearn: 0.1951711\ttotal: 12.8s\tremaining: 1.2s\n",
      "640:\tlearn: 0.1948755\ttotal: 12.8s\tremaining: 1.18s\n",
      "641:\tlearn: 0.1946445\ttotal: 12.9s\tremaining: 1.16s\n",
      "642:\tlearn: 0.1944465\ttotal: 12.9s\tremaining: 1.14s\n",
      "643:\tlearn: 0.1941365\ttotal: 12.9s\tremaining: 1.12s\n",
      "644:\tlearn: 0.1938758\ttotal: 12.9s\tremaining: 1.1s\n",
      "645:\tlearn: 0.1936548\ttotal: 12.9s\tremaining: 1.08s\n",
      "646:\tlearn: 0.1934325\ttotal: 13s\tremaining: 1.06s\n",
      "647:\tlearn: 0.1932389\ttotal: 13s\tremaining: 1.04s\n",
      "648:\tlearn: 0.1928851\ttotal: 13s\tremaining: 1.02s\n",
      "649:\tlearn: 0.1927163\ttotal: 13s\tremaining: 1s\n",
      "650:\tlearn: 0.1924375\ttotal: 13s\tremaining: 981ms\n",
      "651:\tlearn: 0.1922329\ttotal: 13.1s\tremaining: 961ms\n",
      "652:\tlearn: 0.1920696\ttotal: 13.1s\tremaining: 941ms\n",
      "653:\tlearn: 0.1917900\ttotal: 13.1s\tremaining: 921ms\n",
      "654:\tlearn: 0.1915544\ttotal: 13.1s\tremaining: 901ms\n",
      "655:\tlearn: 0.1913572\ttotal: 13.1s\tremaining: 881ms\n",
      "656:\tlearn: 0.1910961\ttotal: 13.2s\tremaining: 861ms\n",
      "657:\tlearn: 0.1909016\ttotal: 13.2s\tremaining: 841ms\n",
      "658:\tlearn: 0.1907172\ttotal: 13.2s\tremaining: 821ms\n",
      "659:\tlearn: 0.1904931\ttotal: 13.2s\tremaining: 801ms\n",
      "660:\tlearn: 0.1902805\ttotal: 13.2s\tremaining: 781ms\n",
      "661:\tlearn: 0.1900548\ttotal: 13.3s\tremaining: 761ms\n",
      "662:\tlearn: 0.1898178\ttotal: 13.3s\tremaining: 741ms\n",
      "663:\tlearn: 0.1896041\ttotal: 13.3s\tremaining: 721ms\n",
      "664:\tlearn: 0.1894856\ttotal: 13.3s\tremaining: 701ms\n",
      "665:\tlearn: 0.1892558\ttotal: 13.3s\tremaining: 681ms\n",
      "666:\tlearn: 0.1891194\ttotal: 13.4s\tremaining: 661ms\n",
      "667:\tlearn: 0.1888816\ttotal: 13.4s\tremaining: 641ms\n",
      "668:\tlearn: 0.1886478\ttotal: 13.4s\tremaining: 621ms\n",
      "669:\tlearn: 0.1884638\ttotal: 13.4s\tremaining: 601ms\n",
      "670:\tlearn: 0.1882341\ttotal: 13.4s\tremaining: 581ms\n",
      "671:\tlearn: 0.1880565\ttotal: 13.5s\tremaining: 561ms\n",
      "672:\tlearn: 0.1878367\ttotal: 13.5s\tremaining: 541ms\n",
      "673:\tlearn: 0.1877215\ttotal: 13.5s\tremaining: 521ms\n",
      "674:\tlearn: 0.1874982\ttotal: 13.5s\tremaining: 501ms\n",
      "675:\tlearn: 0.1872670\ttotal: 13.5s\tremaining: 481ms\n",
      "676:\tlearn: 0.1871082\ttotal: 13.6s\tremaining: 461ms\n",
      "677:\tlearn: 0.1869315\ttotal: 13.6s\tremaining: 441ms\n",
      "678:\tlearn: 0.1867182\ttotal: 13.6s\tremaining: 421ms\n",
      "679:\tlearn: 0.1865689\ttotal: 13.6s\tremaining: 401ms\n",
      "680:\tlearn: 0.1863275\ttotal: 13.6s\tremaining: 381ms\n",
      "681:\tlearn: 0.1861069\ttotal: 13.7s\tremaining: 360ms\n",
      "682:\tlearn: 0.1858427\ttotal: 13.7s\tremaining: 340ms\n",
      "683:\tlearn: 0.1856312\ttotal: 13.7s\tremaining: 320ms\n",
      "684:\tlearn: 0.1854971\ttotal: 13.7s\tremaining: 300ms\n",
      "685:\tlearn: 0.1853546\ttotal: 13.7s\tremaining: 280ms\n",
      "686:\tlearn: 0.1851778\ttotal: 13.8s\tremaining: 260ms\n",
      "687:\tlearn: 0.1848853\ttotal: 13.8s\tremaining: 240ms\n",
      "688:\tlearn: 0.1845849\ttotal: 13.8s\tremaining: 220ms\n",
      "689:\tlearn: 0.1843545\ttotal: 13.8s\tremaining: 200ms\n",
      "690:\tlearn: 0.1841290\ttotal: 13.8s\tremaining: 180ms\n",
      "691:\tlearn: 0.1839649\ttotal: 13.9s\tremaining: 160ms\n",
      "692:\tlearn: 0.1838251\ttotal: 13.9s\tremaining: 140ms\n",
      "693:\tlearn: 0.1835956\ttotal: 13.9s\tremaining: 120ms\n",
      "694:\tlearn: 0.1833943\ttotal: 13.9s\tremaining: 100ms\n",
      "695:\tlearn: 0.1830724\ttotal: 13.9s\tremaining: 80.2ms\n",
      "696:\tlearn: 0.1827514\ttotal: 14s\tremaining: 60.1ms\n",
      "697:\tlearn: 0.1825648\ttotal: 14s\tremaining: 40.1ms\n",
      "698:\tlearn: 0.1823304\ttotal: 14s\tremaining: 20ms\n",
      "699:\tlearn: 0.1821551\ttotal: 14s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1741039d690>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = CatBoostClassifier(**best_params)\n",
    "best_model.fit(x_train, y_train, early_stopping_rounds=50, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iterations': 700,\n",
       " 'learning_rate': 0.020215803120752895,\n",
       " 'random_strength': 3,\n",
       " 'bagging_temperature': 2,\n",
       " 'max_bin': 21,\n",
       " 'grow_policy': 'SymmetricTree',\n",
       " 'min_data_in_leaf': 10,\n",
       " 'max_depth': 10,\n",
       " 'l2_leaf_reg': 1.3790588634537881,\n",
       " 'auto_class_weights': 'SqrtBalanced'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6819327\ttotal: 23.6ms\tremaining: 16.5s\n",
      "1:\tlearn: 0.6721585\ttotal: 45.5ms\tremaining: 15.9s\n",
      "2:\tlearn: 0.6622909\ttotal: 67.9ms\tremaining: 15.8s\n",
      "3:\tlearn: 0.6553698\ttotal: 78.2ms\tremaining: 13.6s\n",
      "4:\tlearn: 0.6462026\ttotal: 101ms\tremaining: 14.1s\n",
      "5:\tlearn: 0.6363630\ttotal: 125ms\tremaining: 14.5s\n",
      "6:\tlearn: 0.6279855\ttotal: 148ms\tremaining: 14.6s\n",
      "7:\tlearn: 0.6192942\ttotal: 170ms\tremaining: 14.7s\n",
      "8:\tlearn: 0.6122767\ttotal: 193ms\tremaining: 14.8s\n",
      "9:\tlearn: 0.6048089\ttotal: 215ms\tremaining: 14.9s\n",
      "10:\tlearn: 0.5975765\ttotal: 237ms\tremaining: 14.9s\n",
      "11:\tlearn: 0.5899186\ttotal: 261ms\tremaining: 15s\n",
      "12:\tlearn: 0.5832847\ttotal: 283ms\tremaining: 15s\n",
      "13:\tlearn: 0.5772189\ttotal: 305ms\tremaining: 15s\n",
      "14:\tlearn: 0.5709975\ttotal: 327ms\tremaining: 14.9s\n",
      "15:\tlearn: 0.5646429\ttotal: 349ms\tremaining: 14.9s\n",
      "16:\tlearn: 0.5586778\ttotal: 371ms\tremaining: 14.9s\n",
      "17:\tlearn: 0.5536993\ttotal: 394ms\tremaining: 14.9s\n",
      "18:\tlearn: 0.5489729\ttotal: 416ms\tremaining: 14.9s\n",
      "19:\tlearn: 0.5439677\ttotal: 437ms\tremaining: 14.9s\n",
      "20:\tlearn: 0.5384767\ttotal: 460ms\tremaining: 14.9s\n",
      "21:\tlearn: 0.5342793\ttotal: 482ms\tremaining: 14.9s\n",
      "22:\tlearn: 0.5306196\ttotal: 499ms\tremaining: 14.7s\n",
      "23:\tlearn: 0.5280466\ttotal: 508ms\tremaining: 14.3s\n",
      "24:\tlearn: 0.5243238\ttotal: 530ms\tremaining: 14.3s\n",
      "25:\tlearn: 0.5205465\ttotal: 552ms\tremaining: 14.3s\n",
      "26:\tlearn: 0.5174750\ttotal: 574ms\tremaining: 14.3s\n",
      "27:\tlearn: 0.5134445\ttotal: 598ms\tremaining: 14.3s\n",
      "28:\tlearn: 0.5099307\ttotal: 621ms\tremaining: 14.4s\n",
      "29:\tlearn: 0.5059557\ttotal: 644ms\tremaining: 14.4s\n",
      "30:\tlearn: 0.5028640\ttotal: 666ms\tremaining: 14.4s\n",
      "31:\tlearn: 0.4999139\ttotal: 689ms\tremaining: 14.4s\n",
      "32:\tlearn: 0.4966687\ttotal: 711ms\tremaining: 14.4s\n",
      "33:\tlearn: 0.4940274\ttotal: 734ms\tremaining: 14.4s\n",
      "34:\tlearn: 0.4910425\ttotal: 756ms\tremaining: 14.4s\n",
      "35:\tlearn: 0.4874200\ttotal: 778ms\tremaining: 14.4s\n",
      "36:\tlearn: 0.4838276\ttotal: 801ms\tremaining: 14.3s\n",
      "37:\tlearn: 0.4807722\ttotal: 823ms\tremaining: 14.3s\n",
      "38:\tlearn: 0.4788345\ttotal: 844ms\tremaining: 14.3s\n",
      "39:\tlearn: 0.4760577\ttotal: 867ms\tremaining: 14.3s\n",
      "40:\tlearn: 0.4734462\ttotal: 890ms\tremaining: 14.3s\n",
      "41:\tlearn: 0.4710991\ttotal: 913ms\tremaining: 14.3s\n",
      "42:\tlearn: 0.4690531\ttotal: 935ms\tremaining: 14.3s\n",
      "43:\tlearn: 0.4671882\ttotal: 957ms\tremaining: 14.3s\n",
      "44:\tlearn: 0.4654895\ttotal: 980ms\tremaining: 14.3s\n",
      "45:\tlearn: 0.4644391\ttotal: 990ms\tremaining: 14.1s\n",
      "46:\tlearn: 0.4614405\ttotal: 1.01s\tremaining: 14.1s\n",
      "47:\tlearn: 0.4596809\ttotal: 1.03s\tremaining: 14s\n",
      "48:\tlearn: 0.4574731\ttotal: 1.05s\tremaining: 14s\n",
      "49:\tlearn: 0.4552775\ttotal: 1.08s\tremaining: 14s\n",
      "50:\tlearn: 0.4536688\ttotal: 1.1s\tremaining: 14s\n",
      "51:\tlearn: 0.4516344\ttotal: 1.13s\tremaining: 14s\n",
      "52:\tlearn: 0.4500843\ttotal: 1.15s\tremaining: 14.1s\n",
      "53:\tlearn: 0.4486620\ttotal: 1.18s\tremaining: 14.1s\n",
      "54:\tlearn: 0.4468875\ttotal: 1.2s\tremaining: 14s\n",
      "55:\tlearn: 0.4447653\ttotal: 1.22s\tremaining: 14s\n",
      "56:\tlearn: 0.4434276\ttotal: 1.24s\tremaining: 14s\n",
      "57:\tlearn: 0.4421418\ttotal: 1.26s\tremaining: 14s\n",
      "58:\tlearn: 0.4415941\ttotal: 1.28s\tremaining: 13.9s\n",
      "59:\tlearn: 0.4400527\ttotal: 1.3s\tremaining: 13.9s\n",
      "60:\tlearn: 0.4388391\ttotal: 1.32s\tremaining: 13.8s\n",
      "61:\tlearn: 0.4367844\ttotal: 1.34s\tremaining: 13.8s\n",
      "62:\tlearn: 0.4352149\ttotal: 1.37s\tremaining: 13.8s\n",
      "63:\tlearn: 0.4335705\ttotal: 1.39s\tremaining: 13.8s\n",
      "64:\tlearn: 0.4320494\ttotal: 1.41s\tremaining: 13.8s\n",
      "65:\tlearn: 0.4302159\ttotal: 1.44s\tremaining: 13.8s\n",
      "66:\tlearn: 0.4284083\ttotal: 1.46s\tremaining: 13.8s\n",
      "67:\tlearn: 0.4274979\ttotal: 1.48s\tremaining: 13.7s\n",
      "68:\tlearn: 0.4259225\ttotal: 1.5s\tremaining: 13.7s\n",
      "69:\tlearn: 0.4246979\ttotal: 1.52s\tremaining: 13.7s\n",
      "70:\tlearn: 0.4237055\ttotal: 1.54s\tremaining: 13.7s\n",
      "71:\tlearn: 0.4225933\ttotal: 1.57s\tremaining: 13.7s\n",
      "72:\tlearn: 0.4215895\ttotal: 1.59s\tremaining: 13.7s\n",
      "73:\tlearn: 0.4204610\ttotal: 1.61s\tremaining: 13.7s\n",
      "74:\tlearn: 0.4192048\ttotal: 1.64s\tremaining: 13.6s\n",
      "75:\tlearn: 0.4180565\ttotal: 1.66s\tremaining: 13.6s\n",
      "76:\tlearn: 0.4169293\ttotal: 1.68s\tremaining: 13.6s\n",
      "77:\tlearn: 0.4161609\ttotal: 1.7s\tremaining: 13.6s\n",
      "78:\tlearn: 0.4147594\ttotal: 1.72s\tremaining: 13.6s\n",
      "79:\tlearn: 0.4138443\ttotal: 1.75s\tremaining: 13.5s\n",
      "80:\tlearn: 0.4123359\ttotal: 1.77s\tremaining: 13.5s\n",
      "81:\tlearn: 0.4114645\ttotal: 1.79s\tremaining: 13.5s\n",
      "82:\tlearn: 0.4106590\ttotal: 1.82s\tremaining: 13.6s\n",
      "83:\tlearn: 0.4098499\ttotal: 1.84s\tremaining: 13.5s\n",
      "84:\tlearn: 0.4088685\ttotal: 1.87s\tremaining: 13.5s\n",
      "85:\tlearn: 0.4077404\ttotal: 1.89s\tremaining: 13.5s\n",
      "86:\tlearn: 0.4067875\ttotal: 1.91s\tremaining: 13.5s\n",
      "87:\tlearn: 0.4059409\ttotal: 1.93s\tremaining: 13.4s\n",
      "88:\tlearn: 0.4047936\ttotal: 1.96s\tremaining: 13.4s\n",
      "89:\tlearn: 0.4041903\ttotal: 1.98s\tremaining: 13.4s\n",
      "90:\tlearn: 0.4034634\ttotal: 2s\tremaining: 13.4s\n",
      "91:\tlearn: 0.4024550\ttotal: 2.02s\tremaining: 13.4s\n",
      "92:\tlearn: 0.4016700\ttotal: 2.04s\tremaining: 13.3s\n",
      "93:\tlearn: 0.4006028\ttotal: 2.07s\tremaining: 13.3s\n",
      "94:\tlearn: 0.3995759\ttotal: 2.09s\tremaining: 13.3s\n",
      "95:\tlearn: 0.3986244\ttotal: 2.11s\tremaining: 13.3s\n",
      "96:\tlearn: 0.3977955\ttotal: 2.13s\tremaining: 13.3s\n",
      "97:\tlearn: 0.3966182\ttotal: 2.16s\tremaining: 13.3s\n",
      "98:\tlearn: 0.3956500\ttotal: 2.18s\tremaining: 13.2s\n",
      "99:\tlearn: 0.3949717\ttotal: 2.2s\tremaining: 13.2s\n",
      "100:\tlearn: 0.3939686\ttotal: 2.23s\tremaining: 13.2s\n",
      "101:\tlearn: 0.3932086\ttotal: 2.25s\tremaining: 13.2s\n",
      "102:\tlearn: 0.3926786\ttotal: 2.27s\tremaining: 13.2s\n",
      "103:\tlearn: 0.3920738\ttotal: 2.29s\tremaining: 13.1s\n",
      "104:\tlearn: 0.3914590\ttotal: 2.31s\tremaining: 13.1s\n",
      "105:\tlearn: 0.3904091\ttotal: 2.33s\tremaining: 13.1s\n",
      "106:\tlearn: 0.3898511\ttotal: 2.36s\tremaining: 13.1s\n",
      "107:\tlearn: 0.3892559\ttotal: 2.38s\tremaining: 13s\n",
      "108:\tlearn: 0.3885550\ttotal: 2.4s\tremaining: 13s\n",
      "109:\tlearn: 0.3877576\ttotal: 2.42s\tremaining: 13s\n",
      "110:\tlearn: 0.3872258\ttotal: 2.45s\tremaining: 13s\n",
      "111:\tlearn: 0.3866683\ttotal: 2.47s\tremaining: 13s\n",
      "112:\tlearn: 0.3857983\ttotal: 2.5s\tremaining: 13s\n",
      "113:\tlearn: 0.3850722\ttotal: 2.52s\tremaining: 12.9s\n",
      "114:\tlearn: 0.3844262\ttotal: 2.54s\tremaining: 12.9s\n",
      "115:\tlearn: 0.3836736\ttotal: 2.56s\tremaining: 12.9s\n",
      "116:\tlearn: 0.3831505\ttotal: 2.58s\tremaining: 12.9s\n",
      "117:\tlearn: 0.3823604\ttotal: 2.61s\tremaining: 12.9s\n",
      "118:\tlearn: 0.3816024\ttotal: 2.63s\tremaining: 12.9s\n",
      "119:\tlearn: 0.3810262\ttotal: 2.66s\tremaining: 12.8s\n",
      "120:\tlearn: 0.3801858\ttotal: 2.68s\tremaining: 12.8s\n",
      "121:\tlearn: 0.3796051\ttotal: 2.7s\tremaining: 12.8s\n",
      "122:\tlearn: 0.3785728\ttotal: 2.72s\tremaining: 12.8s\n",
      "123:\tlearn: 0.3779323\ttotal: 2.75s\tremaining: 12.8s\n",
      "124:\tlearn: 0.3768763\ttotal: 2.77s\tremaining: 12.7s\n",
      "125:\tlearn: 0.3760817\ttotal: 2.79s\tremaining: 12.7s\n",
      "126:\tlearn: 0.3753507\ttotal: 2.81s\tremaining: 12.7s\n",
      "127:\tlearn: 0.3744480\ttotal: 2.83s\tremaining: 12.7s\n",
      "128:\tlearn: 0.3737093\ttotal: 2.86s\tremaining: 12.6s\n",
      "129:\tlearn: 0.3733232\ttotal: 2.88s\tremaining: 12.6s\n",
      "130:\tlearn: 0.3726538\ttotal: 2.9s\tremaining: 12.6s\n",
      "131:\tlearn: 0.3719662\ttotal: 2.92s\tremaining: 12.6s\n",
      "132:\tlearn: 0.3713637\ttotal: 2.94s\tremaining: 12.6s\n",
      "133:\tlearn: 0.3709088\ttotal: 2.97s\tremaining: 12.5s\n",
      "134:\tlearn: 0.3705030\ttotal: 2.99s\tremaining: 12.5s\n",
      "135:\tlearn: 0.3699494\ttotal: 3.01s\tremaining: 12.5s\n",
      "136:\tlearn: 0.3694210\ttotal: 3.03s\tremaining: 12.5s\n",
      "137:\tlearn: 0.3689516\ttotal: 3.05s\tremaining: 12.4s\n",
      "138:\tlearn: 0.3684416\ttotal: 3.07s\tremaining: 12.4s\n",
      "139:\tlearn: 0.3676272\ttotal: 3.1s\tremaining: 12.4s\n",
      "140:\tlearn: 0.3669085\ttotal: 3.12s\tremaining: 12.4s\n",
      "141:\tlearn: 0.3664441\ttotal: 3.15s\tremaining: 12.4s\n",
      "142:\tlearn: 0.3657584\ttotal: 3.17s\tremaining: 12.3s\n",
      "143:\tlearn: 0.3650402\ttotal: 3.19s\tremaining: 12.3s\n",
      "144:\tlearn: 0.3645745\ttotal: 3.21s\tremaining: 12.3s\n",
      "145:\tlearn: 0.3639598\ttotal: 3.23s\tremaining: 12.3s\n",
      "146:\tlearn: 0.3634424\ttotal: 3.25s\tremaining: 12.2s\n",
      "147:\tlearn: 0.3628139\ttotal: 3.27s\tremaining: 12.2s\n",
      "148:\tlearn: 0.3623472\ttotal: 3.3s\tremaining: 12.2s\n",
      "149:\tlearn: 0.3619213\ttotal: 3.32s\tremaining: 12.2s\n",
      "150:\tlearn: 0.3614394\ttotal: 3.34s\tremaining: 12.1s\n",
      "151:\tlearn: 0.3608646\ttotal: 3.36s\tremaining: 12.1s\n",
      "152:\tlearn: 0.3602712\ttotal: 3.38s\tremaining: 12.1s\n",
      "153:\tlearn: 0.3597033\ttotal: 3.41s\tremaining: 12.1s\n",
      "154:\tlearn: 0.3593747\ttotal: 3.43s\tremaining: 12.1s\n",
      "155:\tlearn: 0.3587952\ttotal: 3.45s\tremaining: 12s\n",
      "156:\tlearn: 0.3583388\ttotal: 3.47s\tremaining: 12s\n",
      "157:\tlearn: 0.3579718\ttotal: 3.49s\tremaining: 12s\n",
      "158:\tlearn: 0.3575809\ttotal: 3.51s\tremaining: 12s\n",
      "159:\tlearn: 0.3568124\ttotal: 3.54s\tremaining: 11.9s\n",
      "160:\tlearn: 0.3561379\ttotal: 3.56s\tremaining: 11.9s\n",
      "161:\tlearn: 0.3555409\ttotal: 3.58s\tremaining: 11.9s\n",
      "162:\tlearn: 0.3550261\ttotal: 3.6s\tremaining: 11.9s\n",
      "163:\tlearn: 0.3546058\ttotal: 3.63s\tremaining: 11.9s\n",
      "164:\tlearn: 0.3543072\ttotal: 3.65s\tremaining: 11.8s\n",
      "165:\tlearn: 0.3536333\ttotal: 3.67s\tremaining: 11.8s\n",
      "166:\tlearn: 0.3531789\ttotal: 3.69s\tremaining: 11.8s\n",
      "167:\tlearn: 0.3525952\ttotal: 3.71s\tremaining: 11.8s\n",
      "168:\tlearn: 0.3519985\ttotal: 3.74s\tremaining: 11.7s\n",
      "169:\tlearn: 0.3514544\ttotal: 3.76s\tremaining: 11.7s\n",
      "170:\tlearn: 0.3508469\ttotal: 3.78s\tremaining: 11.7s\n",
      "171:\tlearn: 0.3504490\ttotal: 3.8s\tremaining: 11.7s\n",
      "172:\tlearn: 0.3501516\ttotal: 3.82s\tremaining: 11.7s\n",
      "173:\tlearn: 0.3495897\ttotal: 3.85s\tremaining: 11.6s\n",
      "174:\tlearn: 0.3493301\ttotal: 3.87s\tremaining: 11.6s\n",
      "175:\tlearn: 0.3489706\ttotal: 3.89s\tremaining: 11.6s\n",
      "176:\tlearn: 0.3483060\ttotal: 3.91s\tremaining: 11.6s\n",
      "177:\tlearn: 0.3476429\ttotal: 3.93s\tremaining: 11.5s\n",
      "178:\tlearn: 0.3472608\ttotal: 3.96s\tremaining: 11.5s\n",
      "179:\tlearn: 0.3468653\ttotal: 3.98s\tremaining: 11.5s\n",
      "180:\tlearn: 0.3461542\ttotal: 4s\tremaining: 11.5s\n",
      "181:\tlearn: 0.3456780\ttotal: 4.02s\tremaining: 11.4s\n",
      "182:\tlearn: 0.3451041\ttotal: 4.04s\tremaining: 11.4s\n",
      "183:\tlearn: 0.3446534\ttotal: 4.06s\tremaining: 11.4s\n",
      "184:\tlearn: 0.3440860\ttotal: 4.09s\tremaining: 11.4s\n",
      "185:\tlearn: 0.3439362\ttotal: 4.11s\tremaining: 11.4s\n",
      "186:\tlearn: 0.3434811\ttotal: 4.13s\tremaining: 11.3s\n",
      "187:\tlearn: 0.3430883\ttotal: 4.16s\tremaining: 11.3s\n",
      "188:\tlearn: 0.3427537\ttotal: 4.18s\tremaining: 11.3s\n",
      "189:\tlearn: 0.3422665\ttotal: 4.2s\tremaining: 11.3s\n",
      "190:\tlearn: 0.3418113\ttotal: 4.22s\tremaining: 11.3s\n",
      "191:\tlearn: 0.3415626\ttotal: 4.25s\tremaining: 11.2s\n",
      "192:\tlearn: 0.3411384\ttotal: 4.27s\tremaining: 11.2s\n",
      "193:\tlearn: 0.3407760\ttotal: 4.29s\tremaining: 11.2s\n",
      "194:\tlearn: 0.3403526\ttotal: 4.31s\tremaining: 11.2s\n",
      "195:\tlearn: 0.3399670\ttotal: 4.33s\tremaining: 11.1s\n",
      "196:\tlearn: 0.3394400\ttotal: 4.35s\tremaining: 11.1s\n",
      "197:\tlearn: 0.3388036\ttotal: 4.38s\tremaining: 11.1s\n",
      "198:\tlearn: 0.3384266\ttotal: 4.4s\tremaining: 11.1s\n",
      "199:\tlearn: 0.3377495\ttotal: 4.42s\tremaining: 11s\n",
      "200:\tlearn: 0.3374356\ttotal: 4.44s\tremaining: 11s\n",
      "201:\tlearn: 0.3371749\ttotal: 4.46s\tremaining: 11s\n",
      "202:\tlearn: 0.3368867\ttotal: 4.48s\tremaining: 11s\n",
      "203:\tlearn: 0.3363615\ttotal: 4.51s\tremaining: 11s\n",
      "204:\tlearn: 0.3358553\ttotal: 4.53s\tremaining: 10.9s\n",
      "205:\tlearn: 0.3352854\ttotal: 4.55s\tremaining: 10.9s\n",
      "206:\tlearn: 0.3348250\ttotal: 4.57s\tremaining: 10.9s\n",
      "207:\tlearn: 0.3342923\ttotal: 4.59s\tremaining: 10.9s\n",
      "208:\tlearn: 0.3338728\ttotal: 4.62s\tremaining: 10.8s\n",
      "209:\tlearn: 0.3335094\ttotal: 4.64s\tremaining: 10.8s\n",
      "210:\tlearn: 0.3331113\ttotal: 4.66s\tremaining: 10.8s\n",
      "211:\tlearn: 0.3327066\ttotal: 4.68s\tremaining: 10.8s\n",
      "212:\tlearn: 0.3323081\ttotal: 4.71s\tremaining: 10.8s\n",
      "213:\tlearn: 0.3320445\ttotal: 4.72s\tremaining: 10.7s\n",
      "214:\tlearn: 0.3317450\ttotal: 4.74s\tremaining: 10.7s\n",
      "215:\tlearn: 0.3312482\ttotal: 4.76s\tremaining: 10.7s\n",
      "216:\tlearn: 0.3304588\ttotal: 4.79s\tremaining: 10.7s\n",
      "217:\tlearn: 0.3300031\ttotal: 4.81s\tremaining: 10.6s\n",
      "218:\tlearn: 0.3297704\ttotal: 4.83s\tremaining: 10.6s\n",
      "219:\tlearn: 0.3294831\ttotal: 4.85s\tremaining: 10.6s\n",
      "220:\tlearn: 0.3290397\ttotal: 4.87s\tremaining: 10.6s\n",
      "221:\tlearn: 0.3287516\ttotal: 4.89s\tremaining: 10.5s\n",
      "222:\tlearn: 0.3282834\ttotal: 4.92s\tremaining: 10.5s\n",
      "223:\tlearn: 0.3280169\ttotal: 4.94s\tremaining: 10.5s\n",
      "224:\tlearn: 0.3274488\ttotal: 4.96s\tremaining: 10.5s\n",
      "225:\tlearn: 0.3272207\ttotal: 4.98s\tremaining: 10.4s\n",
      "226:\tlearn: 0.3265444\ttotal: 5s\tremaining: 10.4s\n",
      "227:\tlearn: 0.3259424\ttotal: 5.03s\tremaining: 10.4s\n",
      "228:\tlearn: 0.3256324\ttotal: 5.05s\tremaining: 10.4s\n",
      "229:\tlearn: 0.3253658\ttotal: 5.07s\tremaining: 10.4s\n",
      "230:\tlearn: 0.3248826\ttotal: 5.09s\tremaining: 10.3s\n",
      "231:\tlearn: 0.3244452\ttotal: 5.12s\tremaining: 10.3s\n",
      "232:\tlearn: 0.3241788\ttotal: 5.14s\tremaining: 10.3s\n",
      "233:\tlearn: 0.3239253\ttotal: 5.16s\tremaining: 10.3s\n",
      "234:\tlearn: 0.3233956\ttotal: 5.18s\tremaining: 10.3s\n",
      "235:\tlearn: 0.3231125\ttotal: 5.21s\tremaining: 10.2s\n",
      "236:\tlearn: 0.3228520\ttotal: 5.23s\tremaining: 10.2s\n",
      "237:\tlearn: 0.3225497\ttotal: 5.25s\tremaining: 10.2s\n",
      "238:\tlearn: 0.3222994\ttotal: 5.27s\tremaining: 10.2s\n",
      "239:\tlearn: 0.3219538\ttotal: 5.29s\tremaining: 10.1s\n",
      "240:\tlearn: 0.3215554\ttotal: 5.31s\tremaining: 10.1s\n",
      "241:\tlearn: 0.3210155\ttotal: 5.33s\tremaining: 10.1s\n",
      "242:\tlearn: 0.3207961\ttotal: 5.36s\tremaining: 10.1s\n",
      "243:\tlearn: 0.3205353\ttotal: 5.38s\tremaining: 10.1s\n",
      "244:\tlearn: 0.3200406\ttotal: 5.4s\tremaining: 10s\n",
      "245:\tlearn: 0.3196808\ttotal: 5.42s\tremaining: 10s\n",
      "246:\tlearn: 0.3193045\ttotal: 5.44s\tremaining: 9.98s\n",
      "247:\tlearn: 0.3189475\ttotal: 5.47s\tremaining: 9.96s\n",
      "248:\tlearn: 0.3186150\ttotal: 5.49s\tremaining: 9.94s\n",
      "249:\tlearn: 0.3182141\ttotal: 5.52s\tremaining: 9.93s\n",
      "250:\tlearn: 0.3181613\ttotal: 5.53s\tremaining: 9.89s\n",
      "251:\tlearn: 0.3178037\ttotal: 5.55s\tremaining: 9.87s\n",
      "252:\tlearn: 0.3172930\ttotal: 5.57s\tremaining: 9.85s\n",
      "253:\tlearn: 0.3169126\ttotal: 5.6s\tremaining: 9.83s\n",
      "254:\tlearn: 0.3163980\ttotal: 5.62s\tremaining: 9.81s\n",
      "255:\tlearn: 0.3159684\ttotal: 5.64s\tremaining: 9.79s\n",
      "256:\tlearn: 0.3154782\ttotal: 5.67s\tremaining: 9.77s\n",
      "257:\tlearn: 0.3152249\ttotal: 5.69s\tremaining: 9.74s\n",
      "258:\tlearn: 0.3149748\ttotal: 5.71s\tremaining: 9.72s\n",
      "259:\tlearn: 0.3146734\ttotal: 5.73s\tremaining: 9.7s\n",
      "260:\tlearn: 0.3142830\ttotal: 5.75s\tremaining: 9.68s\n",
      "261:\tlearn: 0.3137312\ttotal: 5.78s\tremaining: 9.66s\n",
      "262:\tlearn: 0.3135275\ttotal: 5.8s\tremaining: 9.63s\n",
      "263:\tlearn: 0.3131917\ttotal: 5.82s\tremaining: 9.61s\n",
      "264:\tlearn: 0.3129053\ttotal: 5.84s\tremaining: 9.59s\n",
      "265:\tlearn: 0.3126939\ttotal: 5.86s\tremaining: 9.56s\n",
      "266:\tlearn: 0.3121228\ttotal: 5.88s\tremaining: 9.54s\n",
      "267:\tlearn: 0.3119580\ttotal: 5.91s\tremaining: 9.52s\n",
      "268:\tlearn: 0.3117860\ttotal: 5.93s\tremaining: 9.5s\n",
      "269:\tlearn: 0.3115061\ttotal: 5.95s\tremaining: 9.47s\n",
      "270:\tlearn: 0.3110178\ttotal: 5.97s\tremaining: 9.45s\n",
      "271:\tlearn: 0.3106359\ttotal: 5.99s\tremaining: 9.43s\n",
      "272:\tlearn: 0.3102027\ttotal: 6.01s\tremaining: 9.41s\n",
      "273:\tlearn: 0.3096870\ttotal: 6.04s\tremaining: 9.38s\n",
      "274:\tlearn: 0.3090917\ttotal: 6.06s\tremaining: 9.36s\n",
      "275:\tlearn: 0.3087001\ttotal: 6.08s\tremaining: 9.34s\n",
      "276:\tlearn: 0.3085658\ttotal: 6.1s\tremaining: 9.32s\n",
      "277:\tlearn: 0.3082787\ttotal: 6.13s\tremaining: 9.3s\n",
      "278:\tlearn: 0.3078444\ttotal: 6.15s\tremaining: 9.28s\n",
      "279:\tlearn: 0.3078082\ttotal: 6.16s\tremaining: 9.24s\n",
      "280:\tlearn: 0.3077417\ttotal: 6.17s\tremaining: 9.21s\n",
      "281:\tlearn: 0.3075395\ttotal: 6.2s\tremaining: 9.18s\n",
      "282:\tlearn: 0.3072671\ttotal: 6.22s\tremaining: 9.16s\n",
      "283:\tlearn: 0.3068842\ttotal: 6.24s\tremaining: 9.14s\n",
      "284:\tlearn: 0.3062309\ttotal: 6.26s\tremaining: 9.12s\n",
      "285:\tlearn: 0.3057017\ttotal: 6.28s\tremaining: 9.09s\n",
      "286:\tlearn: 0.3054709\ttotal: 6.3s\tremaining: 9.07s\n",
      "287:\tlearn: 0.3053051\ttotal: 6.32s\tremaining: 9.05s\n",
      "288:\tlearn: 0.3048376\ttotal: 6.35s\tremaining: 9.03s\n",
      "289:\tlearn: 0.3044827\ttotal: 6.37s\tremaining: 9s\n",
      "290:\tlearn: 0.3041778\ttotal: 6.39s\tremaining: 8.98s\n",
      "291:\tlearn: 0.3038738\ttotal: 6.41s\tremaining: 8.96s\n",
      "292:\tlearn: 0.3036530\ttotal: 6.43s\tremaining: 8.94s\n",
      "293:\tlearn: 0.3030556\ttotal: 6.46s\tremaining: 8.91s\n",
      "294:\tlearn: 0.3027812\ttotal: 6.48s\tremaining: 8.89s\n",
      "295:\tlearn: 0.3023984\ttotal: 6.5s\tremaining: 8.87s\n",
      "296:\tlearn: 0.3021212\ttotal: 6.52s\tremaining: 8.85s\n",
      "297:\tlearn: 0.3013408\ttotal: 6.54s\tremaining: 8.82s\n",
      "298:\tlearn: 0.3013177\ttotal: 6.55s\tremaining: 8.79s\n",
      "299:\tlearn: 0.3008127\ttotal: 6.57s\tremaining: 8.77s\n",
      "300:\tlearn: 0.3003546\ttotal: 6.6s\tremaining: 8.75s\n",
      "301:\tlearn: 0.3001060\ttotal: 6.62s\tremaining: 8.72s\n",
      "302:\tlearn: 0.2999435\ttotal: 6.64s\tremaining: 8.7s\n",
      "303:\tlearn: 0.2995601\ttotal: 6.66s\tremaining: 8.68s\n",
      "304:\tlearn: 0.2991535\ttotal: 6.68s\tremaining: 8.66s\n",
      "305:\tlearn: 0.2985954\ttotal: 6.71s\tremaining: 8.63s\n",
      "306:\tlearn: 0.2984505\ttotal: 6.73s\tremaining: 8.61s\n",
      "307:\tlearn: 0.2977249\ttotal: 6.75s\tremaining: 8.59s\n",
      "308:\tlearn: 0.2974185\ttotal: 6.77s\tremaining: 8.57s\n",
      "309:\tlearn: 0.2971181\ttotal: 6.79s\tremaining: 8.54s\n",
      "310:\tlearn: 0.2967606\ttotal: 6.81s\tremaining: 8.52s\n",
      "311:\tlearn: 0.2964185\ttotal: 6.83s\tremaining: 8.5s\n",
      "312:\tlearn: 0.2961421\ttotal: 6.86s\tremaining: 8.48s\n",
      "313:\tlearn: 0.2958187\ttotal: 6.88s\tremaining: 8.46s\n",
      "314:\tlearn: 0.2953975\ttotal: 6.9s\tremaining: 8.43s\n",
      "315:\tlearn: 0.2949985\ttotal: 6.92s\tremaining: 8.41s\n",
      "316:\tlearn: 0.2948018\ttotal: 6.94s\tremaining: 8.39s\n",
      "317:\tlearn: 0.2943756\ttotal: 6.96s\tremaining: 8.37s\n",
      "318:\tlearn: 0.2939322\ttotal: 6.99s\tremaining: 8.35s\n",
      "319:\tlearn: 0.2934578\ttotal: 7.01s\tremaining: 8.32s\n",
      "320:\tlearn: 0.2930374\ttotal: 7.03s\tremaining: 8.3s\n",
      "321:\tlearn: 0.2926453\ttotal: 7.05s\tremaining: 8.28s\n",
      "322:\tlearn: 0.2924944\ttotal: 7.07s\tremaining: 8.26s\n",
      "323:\tlearn: 0.2920774\ttotal: 7.1s\tremaining: 8.24s\n",
      "324:\tlearn: 0.2918536\ttotal: 7.12s\tremaining: 8.22s\n",
      "325:\tlearn: 0.2916556\ttotal: 7.14s\tremaining: 8.2s\n",
      "326:\tlearn: 0.2913664\ttotal: 7.17s\tremaining: 8.18s\n",
      "327:\tlearn: 0.2909108\ttotal: 7.19s\tremaining: 8.15s\n",
      "328:\tlearn: 0.2906615\ttotal: 7.21s\tremaining: 8.13s\n",
      "329:\tlearn: 0.2902553\ttotal: 7.23s\tremaining: 8.11s\n",
      "330:\tlearn: 0.2896354\ttotal: 7.25s\tremaining: 8.09s\n",
      "331:\tlearn: 0.2892741\ttotal: 7.28s\tremaining: 8.06s\n",
      "332:\tlearn: 0.2890886\ttotal: 7.3s\tremaining: 8.04s\n",
      "333:\tlearn: 0.2888287\ttotal: 7.32s\tremaining: 8.02s\n",
      "334:\tlearn: 0.2884156\ttotal: 7.34s\tremaining: 8s\n",
      "335:\tlearn: 0.2882644\ttotal: 7.36s\tremaining: 7.97s\n",
      "336:\tlearn: 0.2881281\ttotal: 7.38s\tremaining: 7.95s\n",
      "337:\tlearn: 0.2878070\ttotal: 7.4s\tremaining: 7.93s\n",
      "338:\tlearn: 0.2873624\ttotal: 7.42s\tremaining: 7.91s\n",
      "339:\tlearn: 0.2870488\ttotal: 7.45s\tremaining: 7.89s\n",
      "340:\tlearn: 0.2868295\ttotal: 7.47s\tremaining: 7.86s\n",
      "341:\tlearn: 0.2864683\ttotal: 7.49s\tremaining: 7.84s\n",
      "342:\tlearn: 0.2860518\ttotal: 7.51s\tremaining: 7.82s\n",
      "343:\tlearn: 0.2856759\ttotal: 7.53s\tremaining: 7.8s\n",
      "344:\tlearn: 0.2853126\ttotal: 7.56s\tremaining: 7.78s\n",
      "345:\tlearn: 0.2847784\ttotal: 7.58s\tremaining: 7.75s\n",
      "346:\tlearn: 0.2843685\ttotal: 7.6s\tremaining: 7.74s\n",
      "347:\tlearn: 0.2840777\ttotal: 7.63s\tremaining: 7.71s\n",
      "348:\tlearn: 0.2837812\ttotal: 7.65s\tremaining: 7.69s\n",
      "349:\tlearn: 0.2835340\ttotal: 7.67s\tremaining: 7.67s\n",
      "350:\tlearn: 0.2835171\ttotal: 7.68s\tremaining: 7.64s\n",
      "351:\tlearn: 0.2831999\ttotal: 7.7s\tremaining: 7.61s\n",
      "352:\tlearn: 0.2829133\ttotal: 7.72s\tremaining: 7.59s\n",
      "353:\tlearn: 0.2826225\ttotal: 7.75s\tremaining: 7.57s\n",
      "354:\tlearn: 0.2823047\ttotal: 7.77s\tremaining: 7.55s\n",
      "355:\tlearn: 0.2821346\ttotal: 7.79s\tremaining: 7.53s\n",
      "356:\tlearn: 0.2816826\ttotal: 7.81s\tremaining: 7.5s\n",
      "357:\tlearn: 0.2812466\ttotal: 7.83s\tremaining: 7.48s\n",
      "358:\tlearn: 0.2809575\ttotal: 7.85s\tremaining: 7.46s\n",
      "359:\tlearn: 0.2808309\ttotal: 7.87s\tremaining: 7.44s\n",
      "360:\tlearn: 0.2805112\ttotal: 7.9s\tremaining: 7.42s\n",
      "361:\tlearn: 0.2800413\ttotal: 7.92s\tremaining: 7.4s\n",
      "362:\tlearn: 0.2798963\ttotal: 7.95s\tremaining: 7.38s\n",
      "363:\tlearn: 0.2795315\ttotal: 7.97s\tremaining: 7.36s\n",
      "364:\tlearn: 0.2792453\ttotal: 7.99s\tremaining: 7.33s\n",
      "365:\tlearn: 0.2789713\ttotal: 8.01s\tremaining: 7.31s\n",
      "366:\tlearn: 0.2787241\ttotal: 8.03s\tremaining: 7.29s\n",
      "367:\tlearn: 0.2785394\ttotal: 8.05s\tremaining: 7.27s\n",
      "368:\tlearn: 0.2781483\ttotal: 8.08s\tremaining: 7.25s\n",
      "369:\tlearn: 0.2777575\ttotal: 8.1s\tremaining: 7.23s\n",
      "370:\tlearn: 0.2773750\ttotal: 8.13s\tremaining: 7.21s\n",
      "371:\tlearn: 0.2771865\ttotal: 8.15s\tremaining: 7.18s\n",
      "372:\tlearn: 0.2770119\ttotal: 8.17s\tremaining: 7.16s\n",
      "373:\tlearn: 0.2767311\ttotal: 8.19s\tremaining: 7.14s\n",
      "374:\tlearn: 0.2761957\ttotal: 8.21s\tremaining: 7.12s\n",
      "375:\tlearn: 0.2759327\ttotal: 8.23s\tremaining: 7.1s\n",
      "376:\tlearn: 0.2757174\ttotal: 8.26s\tremaining: 7.07s\n",
      "377:\tlearn: 0.2757152\ttotal: 8.27s\tremaining: 7.04s\n",
      "378:\tlearn: 0.2753877\ttotal: 8.29s\tremaining: 7.02s\n",
      "379:\tlearn: 0.2752050\ttotal: 8.31s\tremaining: 7s\n",
      "380:\tlearn: 0.2748862\ttotal: 8.33s\tremaining: 6.97s\n",
      "381:\tlearn: 0.2744151\ttotal: 8.35s\tremaining: 6.95s\n",
      "382:\tlearn: 0.2741299\ttotal: 8.37s\tremaining: 6.93s\n",
      "383:\tlearn: 0.2739419\ttotal: 8.39s\tremaining: 6.91s\n",
      "384:\tlearn: 0.2736369\ttotal: 8.42s\tremaining: 6.89s\n",
      "385:\tlearn: 0.2731965\ttotal: 8.44s\tremaining: 6.87s\n",
      "386:\tlearn: 0.2728713\ttotal: 8.46s\tremaining: 6.84s\n",
      "387:\tlearn: 0.2728373\ttotal: 8.47s\tremaining: 6.81s\n",
      "388:\tlearn: 0.2724426\ttotal: 8.49s\tremaining: 6.79s\n",
      "389:\tlearn: 0.2722482\ttotal: 8.52s\tremaining: 6.77s\n",
      "390:\tlearn: 0.2720973\ttotal: 8.54s\tremaining: 6.75s\n",
      "391:\tlearn: 0.2719441\ttotal: 8.56s\tremaining: 6.73s\n",
      "392:\tlearn: 0.2716687\ttotal: 8.58s\tremaining: 6.71s\n",
      "393:\tlearn: 0.2714846\ttotal: 8.61s\tremaining: 6.68s\n",
      "394:\tlearn: 0.2712269\ttotal: 8.63s\tremaining: 6.67s\n",
      "395:\tlearn: 0.2708963\ttotal: 8.65s\tremaining: 6.64s\n",
      "396:\tlearn: 0.2707441\ttotal: 8.68s\tremaining: 6.62s\n",
      "397:\tlearn: 0.2705887\ttotal: 8.7s\tremaining: 6.6s\n",
      "398:\tlearn: 0.2703275\ttotal: 8.72s\tremaining: 6.58s\n",
      "399:\tlearn: 0.2703238\ttotal: 8.73s\tremaining: 6.55s\n",
      "400:\tlearn: 0.2701133\ttotal: 8.75s\tremaining: 6.52s\n",
      "401:\tlearn: 0.2697724\ttotal: 8.77s\tremaining: 6.5s\n",
      "402:\tlearn: 0.2694745\ttotal: 8.79s\tremaining: 6.48s\n",
      "403:\tlearn: 0.2692820\ttotal: 8.82s\tremaining: 6.46s\n",
      "404:\tlearn: 0.2689993\ttotal: 8.84s\tremaining: 6.44s\n",
      "405:\tlearn: 0.2688151\ttotal: 8.86s\tremaining: 6.41s\n",
      "406:\tlearn: 0.2686588\ttotal: 8.88s\tremaining: 6.39s\n",
      "407:\tlearn: 0.2684041\ttotal: 8.9s\tremaining: 6.37s\n",
      "408:\tlearn: 0.2679653\ttotal: 8.92s\tremaining: 6.35s\n",
      "409:\tlearn: 0.2675301\ttotal: 8.95s\tremaining: 6.33s\n",
      "410:\tlearn: 0.2672500\ttotal: 8.97s\tremaining: 6.3s\n",
      "411:\tlearn: 0.2669248\ttotal: 8.99s\tremaining: 6.28s\n",
      "412:\tlearn: 0.2667570\ttotal: 9.01s\tremaining: 6.26s\n",
      "413:\tlearn: 0.2666521\ttotal: 9.03s\tremaining: 6.24s\n",
      "414:\tlearn: 0.2664393\ttotal: 9.05s\tremaining: 6.22s\n",
      "415:\tlearn: 0.2662107\ttotal: 9.07s\tremaining: 6.19s\n",
      "416:\tlearn: 0.2659794\ttotal: 9.1s\tremaining: 6.17s\n",
      "417:\tlearn: 0.2657383\ttotal: 9.12s\tremaining: 6.15s\n",
      "418:\tlearn: 0.2654183\ttotal: 9.14s\tremaining: 6.13s\n",
      "419:\tlearn: 0.2651068\ttotal: 9.16s\tremaining: 6.11s\n",
      "420:\tlearn: 0.2647662\ttotal: 9.19s\tremaining: 6.09s\n",
      "421:\tlearn: 0.2646089\ttotal: 9.21s\tremaining: 6.07s\n",
      "422:\tlearn: 0.2642870\ttotal: 9.23s\tremaining: 6.04s\n",
      "423:\tlearn: 0.2642315\ttotal: 9.25s\tremaining: 6.02s\n",
      "424:\tlearn: 0.2639889\ttotal: 9.27s\tremaining: 6s\n",
      "425:\tlearn: 0.2636619\ttotal: 9.29s\tremaining: 5.98s\n",
      "426:\tlearn: 0.2632622\ttotal: 9.31s\tremaining: 5.96s\n",
      "427:\tlearn: 0.2632160\ttotal: 9.33s\tremaining: 5.93s\n",
      "428:\tlearn: 0.2628530\ttotal: 9.35s\tremaining: 5.91s\n",
      "429:\tlearn: 0.2624791\ttotal: 9.37s\tremaining: 5.88s\n",
      "430:\tlearn: 0.2621572\ttotal: 9.39s\tremaining: 5.86s\n",
      "431:\tlearn: 0.2618952\ttotal: 9.42s\tremaining: 5.84s\n",
      "432:\tlearn: 0.2616342\ttotal: 9.45s\tremaining: 5.83s\n",
      "433:\tlearn: 0.2613713\ttotal: 9.47s\tremaining: 5.8s\n",
      "434:\tlearn: 0.2609166\ttotal: 9.49s\tremaining: 5.78s\n",
      "435:\tlearn: 0.2605750\ttotal: 9.51s\tremaining: 5.76s\n",
      "436:\tlearn: 0.2604331\ttotal: 9.53s\tremaining: 5.74s\n",
      "437:\tlearn: 0.2602848\ttotal: 9.55s\tremaining: 5.71s\n",
      "438:\tlearn: 0.2600644\ttotal: 9.58s\tremaining: 5.69s\n",
      "439:\tlearn: 0.2598765\ttotal: 9.6s\tremaining: 5.67s\n",
      "440:\tlearn: 0.2597716\ttotal: 9.62s\tremaining: 5.65s\n",
      "441:\tlearn: 0.2596280\ttotal: 9.65s\tremaining: 5.63s\n",
      "442:\tlearn: 0.2591956\ttotal: 9.67s\tremaining: 5.61s\n",
      "443:\tlearn: 0.2588161\ttotal: 9.7s\tremaining: 5.59s\n",
      "444:\tlearn: 0.2586267\ttotal: 9.72s\tremaining: 5.57s\n",
      "445:\tlearn: 0.2582768\ttotal: 9.74s\tremaining: 5.55s\n",
      "446:\tlearn: 0.2578756\ttotal: 9.76s\tremaining: 5.52s\n",
      "447:\tlearn: 0.2576567\ttotal: 9.78s\tremaining: 5.5s\n",
      "448:\tlearn: 0.2574047\ttotal: 9.8s\tremaining: 5.48s\n",
      "449:\tlearn: 0.2573830\ttotal: 9.81s\tremaining: 5.45s\n",
      "450:\tlearn: 0.2569165\ttotal: 9.84s\tremaining: 5.43s\n",
      "451:\tlearn: 0.2565528\ttotal: 9.86s\tremaining: 5.41s\n",
      "452:\tlearn: 0.2561637\ttotal: 9.88s\tremaining: 5.39s\n",
      "453:\tlearn: 0.2558119\ttotal: 9.9s\tremaining: 5.37s\n",
      "454:\tlearn: 0.2557311\ttotal: 9.92s\tremaining: 5.34s\n",
      "455:\tlearn: 0.2555537\ttotal: 9.95s\tremaining: 5.32s\n",
      "456:\tlearn: 0.2550922\ttotal: 9.97s\tremaining: 5.3s\n",
      "457:\tlearn: 0.2546573\ttotal: 9.99s\tremaining: 5.28s\n",
      "458:\tlearn: 0.2541655\ttotal: 10s\tremaining: 5.26s\n",
      "459:\tlearn: 0.2539826\ttotal: 10s\tremaining: 5.23s\n",
      "460:\tlearn: 0.2537987\ttotal: 10.1s\tremaining: 5.21s\n",
      "461:\tlearn: 0.2535633\ttotal: 10.1s\tremaining: 5.19s\n",
      "462:\tlearn: 0.2532891\ttotal: 10.1s\tremaining: 5.17s\n",
      "463:\tlearn: 0.2529710\ttotal: 10.1s\tremaining: 5.15s\n",
      "464:\tlearn: 0.2525214\ttotal: 10.2s\tremaining: 5.13s\n",
      "465:\tlearn: 0.2522063\ttotal: 10.2s\tremaining: 5.11s\n",
      "466:\tlearn: 0.2521046\ttotal: 10.2s\tremaining: 5.09s\n",
      "467:\tlearn: 0.2519616\ttotal: 10.2s\tremaining: 5.06s\n",
      "468:\tlearn: 0.2517427\ttotal: 10.2s\tremaining: 5.04s\n",
      "469:\tlearn: 0.2516249\ttotal: 10.3s\tremaining: 5.02s\n",
      "470:\tlearn: 0.2513846\ttotal: 10.3s\tremaining: 5s\n",
      "471:\tlearn: 0.2509987\ttotal: 10.3s\tremaining: 4.98s\n",
      "472:\tlearn: 0.2507512\ttotal: 10.3s\tremaining: 4.95s\n",
      "473:\tlearn: 0.2505373\ttotal: 10.3s\tremaining: 4.93s\n",
      "474:\tlearn: 0.2502205\ttotal: 10.4s\tremaining: 4.91s\n",
      "475:\tlearn: 0.2499937\ttotal: 10.4s\tremaining: 4.89s\n",
      "476:\tlearn: 0.2497735\ttotal: 10.4s\tremaining: 4.87s\n",
      "477:\tlearn: 0.2494968\ttotal: 10.4s\tremaining: 4.84s\n",
      "478:\tlearn: 0.2492960\ttotal: 10.5s\tremaining: 4.82s\n",
      "479:\tlearn: 0.2489482\ttotal: 10.5s\tremaining: 4.8s\n",
      "480:\tlearn: 0.2486248\ttotal: 10.5s\tremaining: 4.78s\n",
      "481:\tlearn: 0.2483193\ttotal: 10.5s\tremaining: 4.76s\n",
      "482:\tlearn: 0.2479839\ttotal: 10.5s\tremaining: 4.74s\n",
      "483:\tlearn: 0.2477995\ttotal: 10.6s\tremaining: 4.71s\n",
      "484:\tlearn: 0.2474935\ttotal: 10.6s\tremaining: 4.69s\n",
      "485:\tlearn: 0.2469612\ttotal: 10.6s\tremaining: 4.67s\n",
      "486:\tlearn: 0.2467816\ttotal: 10.6s\tremaining: 4.65s\n",
      "487:\tlearn: 0.2463857\ttotal: 10.7s\tremaining: 4.63s\n",
      "488:\tlearn: 0.2461366\ttotal: 10.7s\tremaining: 4.61s\n",
      "489:\tlearn: 0.2458796\ttotal: 10.7s\tremaining: 4.58s\n",
      "490:\tlearn: 0.2456473\ttotal: 10.7s\tremaining: 4.56s\n",
      "491:\tlearn: 0.2453493\ttotal: 10.7s\tremaining: 4.54s\n",
      "492:\tlearn: 0.2451527\ttotal: 10.8s\tremaining: 4.52s\n",
      "493:\tlearn: 0.2449529\ttotal: 10.8s\tremaining: 4.5s\n",
      "494:\tlearn: 0.2446206\ttotal: 10.8s\tremaining: 4.47s\n",
      "495:\tlearn: 0.2442864\ttotal: 10.8s\tremaining: 4.45s\n",
      "496:\tlearn: 0.2439007\ttotal: 10.8s\tremaining: 4.43s\n",
      "497:\tlearn: 0.2435698\ttotal: 10.9s\tremaining: 4.41s\n",
      "498:\tlearn: 0.2433915\ttotal: 10.9s\tremaining: 4.39s\n",
      "499:\tlearn: 0.2431933\ttotal: 10.9s\tremaining: 4.36s\n",
      "500:\tlearn: 0.2428614\ttotal: 10.9s\tremaining: 4.34s\n",
      "501:\tlearn: 0.2427917\ttotal: 11s\tremaining: 4.32s\n",
      "502:\tlearn: 0.2425775\ttotal: 11s\tremaining: 4.3s\n",
      "503:\tlearn: 0.2423521\ttotal: 11s\tremaining: 4.28s\n",
      "504:\tlearn: 0.2421697\ttotal: 11s\tremaining: 4.25s\n",
      "505:\tlearn: 0.2420664\ttotal: 11s\tremaining: 4.23s\n",
      "506:\tlearn: 0.2417537\ttotal: 11.1s\tremaining: 4.21s\n",
      "507:\tlearn: 0.2414260\ttotal: 11.1s\tremaining: 4.19s\n",
      "508:\tlearn: 0.2410782\ttotal: 11.1s\tremaining: 4.17s\n",
      "509:\tlearn: 0.2408219\ttotal: 11.1s\tremaining: 4.15s\n",
      "510:\tlearn: 0.2406450\ttotal: 11.2s\tremaining: 4.12s\n",
      "511:\tlearn: 0.2404088\ttotal: 11.2s\tremaining: 4.1s\n",
      "512:\tlearn: 0.2400773\ttotal: 11.2s\tremaining: 4.08s\n",
      "513:\tlearn: 0.2397272\ttotal: 11.2s\tremaining: 4.06s\n",
      "514:\tlearn: 0.2395485\ttotal: 11.2s\tremaining: 4.04s\n",
      "515:\tlearn: 0.2390496\ttotal: 11.3s\tremaining: 4.01s\n",
      "516:\tlearn: 0.2386063\ttotal: 11.3s\tremaining: 3.99s\n",
      "517:\tlearn: 0.2381810\ttotal: 11.3s\tremaining: 3.97s\n",
      "518:\tlearn: 0.2377645\ttotal: 11.3s\tremaining: 3.95s\n",
      "519:\tlearn: 0.2372951\ttotal: 11.3s\tremaining: 3.93s\n",
      "520:\tlearn: 0.2370393\ttotal: 11.4s\tremaining: 3.91s\n",
      "521:\tlearn: 0.2367931\ttotal: 11.4s\tremaining: 3.88s\n",
      "522:\tlearn: 0.2365314\ttotal: 11.4s\tremaining: 3.86s\n",
      "523:\tlearn: 0.2362630\ttotal: 11.4s\tremaining: 3.84s\n",
      "524:\tlearn: 0.2360215\ttotal: 11.5s\tremaining: 3.82s\n",
      "525:\tlearn: 0.2357242\ttotal: 11.5s\tremaining: 3.8s\n",
      "526:\tlearn: 0.2356050\ttotal: 11.5s\tremaining: 3.77s\n",
      "527:\tlearn: 0.2353337\ttotal: 11.5s\tremaining: 3.75s\n",
      "528:\tlearn: 0.2350792\ttotal: 11.5s\tremaining: 3.73s\n",
      "529:\tlearn: 0.2347063\ttotal: 11.6s\tremaining: 3.71s\n",
      "530:\tlearn: 0.2344871\ttotal: 11.6s\tremaining: 3.69s\n",
      "531:\tlearn: 0.2342094\ttotal: 11.6s\tremaining: 3.67s\n",
      "532:\tlearn: 0.2340013\ttotal: 11.6s\tremaining: 3.65s\n",
      "533:\tlearn: 0.2338454\ttotal: 11.7s\tremaining: 3.62s\n",
      "534:\tlearn: 0.2336980\ttotal: 11.7s\tremaining: 3.6s\n",
      "535:\tlearn: 0.2333759\ttotal: 11.7s\tremaining: 3.58s\n",
      "536:\tlearn: 0.2331110\ttotal: 11.7s\tremaining: 3.56s\n",
      "537:\tlearn: 0.2327889\ttotal: 11.7s\tremaining: 3.54s\n",
      "538:\tlearn: 0.2321933\ttotal: 11.8s\tremaining: 3.51s\n",
      "539:\tlearn: 0.2319621\ttotal: 11.8s\tremaining: 3.49s\n",
      "540:\tlearn: 0.2315867\ttotal: 11.8s\tremaining: 3.47s\n",
      "541:\tlearn: 0.2313487\ttotal: 11.8s\tremaining: 3.45s\n",
      "542:\tlearn: 0.2310698\ttotal: 11.9s\tremaining: 3.43s\n",
      "543:\tlearn: 0.2308631\ttotal: 11.9s\tremaining: 3.4s\n",
      "544:\tlearn: 0.2306310\ttotal: 11.9s\tremaining: 3.38s\n",
      "545:\tlearn: 0.2301586\ttotal: 11.9s\tremaining: 3.36s\n",
      "546:\tlearn: 0.2298942\ttotal: 11.9s\tremaining: 3.34s\n",
      "547:\tlearn: 0.2296645\ttotal: 12s\tremaining: 3.32s\n",
      "548:\tlearn: 0.2293227\ttotal: 12s\tremaining: 3.29s\n",
      "549:\tlearn: 0.2288382\ttotal: 12s\tremaining: 3.27s\n",
      "550:\tlearn: 0.2283190\ttotal: 12s\tremaining: 3.25s\n",
      "551:\tlearn: 0.2281095\ttotal: 12s\tremaining: 3.23s\n",
      "552:\tlearn: 0.2279248\ttotal: 12.1s\tremaining: 3.21s\n",
      "553:\tlearn: 0.2275887\ttotal: 12.1s\tremaining: 3.19s\n",
      "554:\tlearn: 0.2273888\ttotal: 12.1s\tremaining: 3.17s\n",
      "555:\tlearn: 0.2269848\ttotal: 12.1s\tremaining: 3.14s\n",
      "556:\tlearn: 0.2268115\ttotal: 12.2s\tremaining: 3.12s\n",
      "557:\tlearn: 0.2265165\ttotal: 12.2s\tremaining: 3.1s\n",
      "558:\tlearn: 0.2261607\ttotal: 12.2s\tremaining: 3.08s\n",
      "559:\tlearn: 0.2259727\ttotal: 12.2s\tremaining: 3.06s\n",
      "560:\tlearn: 0.2258037\ttotal: 12.2s\tremaining: 3.03s\n",
      "561:\tlearn: 0.2254611\ttotal: 12.3s\tremaining: 3.01s\n",
      "562:\tlearn: 0.2252776\ttotal: 12.3s\tremaining: 2.99s\n",
      "563:\tlearn: 0.2251217\ttotal: 12.3s\tremaining: 2.97s\n",
      "564:\tlearn: 0.2248501\ttotal: 12.3s\tremaining: 2.95s\n",
      "565:\tlearn: 0.2246338\ttotal: 12.3s\tremaining: 2.92s\n",
      "566:\tlearn: 0.2242959\ttotal: 12.4s\tremaining: 2.9s\n",
      "567:\tlearn: 0.2238297\ttotal: 12.4s\tremaining: 2.88s\n",
      "568:\tlearn: 0.2235355\ttotal: 12.4s\tremaining: 2.86s\n",
      "569:\tlearn: 0.2232845\ttotal: 12.4s\tremaining: 2.84s\n",
      "570:\tlearn: 0.2230909\ttotal: 12.5s\tremaining: 2.81s\n",
      "571:\tlearn: 0.2228932\ttotal: 12.5s\tremaining: 2.79s\n",
      "572:\tlearn: 0.2226653\ttotal: 12.5s\tremaining: 2.77s\n",
      "573:\tlearn: 0.2223892\ttotal: 12.5s\tremaining: 2.75s\n",
      "574:\tlearn: 0.2222056\ttotal: 12.5s\tremaining: 2.73s\n",
      "575:\tlearn: 0.2220028\ttotal: 12.6s\tremaining: 2.71s\n",
      "576:\tlearn: 0.2218272\ttotal: 12.6s\tremaining: 2.68s\n",
      "577:\tlearn: 0.2215757\ttotal: 12.6s\tremaining: 2.66s\n",
      "578:\tlearn: 0.2212101\ttotal: 12.6s\tremaining: 2.64s\n",
      "579:\tlearn: 0.2209093\ttotal: 12.7s\tremaining: 2.62s\n",
      "580:\tlearn: 0.2206591\ttotal: 12.7s\tremaining: 2.6s\n",
      "581:\tlearn: 0.2204694\ttotal: 12.7s\tremaining: 2.57s\n",
      "582:\tlearn: 0.2202453\ttotal: 12.7s\tremaining: 2.55s\n",
      "583:\tlearn: 0.2198995\ttotal: 12.7s\tremaining: 2.53s\n",
      "584:\tlearn: 0.2196126\ttotal: 12.8s\tremaining: 2.51s\n",
      "585:\tlearn: 0.2193803\ttotal: 12.8s\tremaining: 2.49s\n",
      "586:\tlearn: 0.2191597\ttotal: 12.8s\tremaining: 2.46s\n",
      "587:\tlearn: 0.2188923\ttotal: 12.8s\tremaining: 2.44s\n",
      "588:\tlearn: 0.2185366\ttotal: 12.8s\tremaining: 2.42s\n",
      "589:\tlearn: 0.2182952\ttotal: 12.9s\tremaining: 2.4s\n",
      "590:\tlearn: 0.2179603\ttotal: 12.9s\tremaining: 2.38s\n",
      "591:\tlearn: 0.2174928\ttotal: 12.9s\tremaining: 2.35s\n",
      "592:\tlearn: 0.2171911\ttotal: 12.9s\tremaining: 2.33s\n",
      "593:\tlearn: 0.2169275\ttotal: 13s\tremaining: 2.31s\n",
      "594:\tlearn: 0.2166514\ttotal: 13s\tremaining: 2.29s\n",
      "595:\tlearn: 0.2162516\ttotal: 13s\tremaining: 2.27s\n",
      "596:\tlearn: 0.2159640\ttotal: 13s\tremaining: 2.25s\n",
      "597:\tlearn: 0.2157696\ttotal: 13s\tremaining: 2.22s\n",
      "598:\tlearn: 0.2155319\ttotal: 13.1s\tremaining: 2.2s\n",
      "599:\tlearn: 0.2152861\ttotal: 13.1s\tremaining: 2.18s\n",
      "600:\tlearn: 0.2150616\ttotal: 13.1s\tremaining: 2.16s\n",
      "601:\tlearn: 0.2147745\ttotal: 13.1s\tremaining: 2.14s\n",
      "602:\tlearn: 0.2145205\ttotal: 13.2s\tremaining: 2.12s\n",
      "603:\tlearn: 0.2143922\ttotal: 13.2s\tremaining: 2.09s\n",
      "604:\tlearn: 0.2141324\ttotal: 13.2s\tremaining: 2.07s\n",
      "605:\tlearn: 0.2138854\ttotal: 13.2s\tremaining: 2.05s\n",
      "606:\tlearn: 0.2137101\ttotal: 13.2s\tremaining: 2.03s\n",
      "607:\tlearn: 0.2135189\ttotal: 13.3s\tremaining: 2.01s\n",
      "608:\tlearn: 0.2132902\ttotal: 13.3s\tremaining: 1.98s\n",
      "609:\tlearn: 0.2130216\ttotal: 13.3s\tremaining: 1.96s\n",
      "610:\tlearn: 0.2129045\ttotal: 13.3s\tremaining: 1.94s\n",
      "611:\tlearn: 0.2127012\ttotal: 13.3s\tremaining: 1.92s\n",
      "612:\tlearn: 0.2124796\ttotal: 13.4s\tremaining: 1.9s\n",
      "613:\tlearn: 0.2120826\ttotal: 13.4s\tremaining: 1.88s\n",
      "614:\tlearn: 0.2116808\ttotal: 13.4s\tremaining: 1.85s\n",
      "615:\tlearn: 0.2114634\ttotal: 13.4s\tremaining: 1.83s\n",
      "616:\tlearn: 0.2112705\ttotal: 13.5s\tremaining: 1.81s\n",
      "617:\tlearn: 0.2110566\ttotal: 13.5s\tremaining: 1.79s\n",
      "618:\tlearn: 0.2108617\ttotal: 13.5s\tremaining: 1.77s\n",
      "619:\tlearn: 0.2106713\ttotal: 13.5s\tremaining: 1.75s\n",
      "620:\tlearn: 0.2104596\ttotal: 13.5s\tremaining: 1.72s\n",
      "621:\tlearn: 0.2102503\ttotal: 13.6s\tremaining: 1.7s\n",
      "622:\tlearn: 0.2101488\ttotal: 13.6s\tremaining: 1.68s\n",
      "623:\tlearn: 0.2099890\ttotal: 13.6s\tremaining: 1.66s\n",
      "624:\tlearn: 0.2098270\ttotal: 13.6s\tremaining: 1.64s\n",
      "625:\tlearn: 0.2096345\ttotal: 13.7s\tremaining: 1.61s\n",
      "626:\tlearn: 0.2092855\ttotal: 13.7s\tremaining: 1.59s\n",
      "627:\tlearn: 0.2088418\ttotal: 13.7s\tremaining: 1.57s\n",
      "628:\tlearn: 0.2087094\ttotal: 13.7s\tremaining: 1.55s\n",
      "629:\tlearn: 0.2084935\ttotal: 13.7s\tremaining: 1.53s\n",
      "630:\tlearn: 0.2081174\ttotal: 13.8s\tremaining: 1.5s\n",
      "631:\tlearn: 0.2078973\ttotal: 13.8s\tremaining: 1.48s\n",
      "632:\tlearn: 0.2076129\ttotal: 13.8s\tremaining: 1.46s\n",
      "633:\tlearn: 0.2074297\ttotal: 13.8s\tremaining: 1.44s\n",
      "634:\tlearn: 0.2072013\ttotal: 13.8s\tremaining: 1.42s\n",
      "635:\tlearn: 0.2070477\ttotal: 13.9s\tremaining: 1.4s\n",
      "636:\tlearn: 0.2068867\ttotal: 13.9s\tremaining: 1.37s\n",
      "637:\tlearn: 0.2067041\ttotal: 13.9s\tremaining: 1.35s\n",
      "638:\tlearn: 0.2064753\ttotal: 13.9s\tremaining: 1.33s\n",
      "639:\tlearn: 0.2061418\ttotal: 14s\tremaining: 1.31s\n",
      "640:\tlearn: 0.2058353\ttotal: 14s\tremaining: 1.29s\n",
      "641:\tlearn: 0.2056645\ttotal: 14s\tremaining: 1.26s\n",
      "642:\tlearn: 0.2054047\ttotal: 14s\tremaining: 1.24s\n",
      "643:\tlearn: 0.2051754\ttotal: 14s\tremaining: 1.22s\n",
      "644:\tlearn: 0.2048516\ttotal: 14.1s\tremaining: 1.2s\n",
      "645:\tlearn: 0.2047067\ttotal: 14.1s\tremaining: 1.18s\n",
      "646:\tlearn: 0.2045082\ttotal: 14.1s\tremaining: 1.16s\n",
      "647:\tlearn: 0.2042686\ttotal: 14.1s\tremaining: 1.13s\n",
      "648:\tlearn: 0.2040416\ttotal: 14.2s\tremaining: 1.11s\n",
      "649:\tlearn: 0.2037977\ttotal: 14.2s\tremaining: 1.09s\n",
      "650:\tlearn: 0.2036399\ttotal: 14.2s\tremaining: 1.07s\n",
      "651:\tlearn: 0.2034748\ttotal: 14.2s\tremaining: 1.05s\n",
      "652:\tlearn: 0.2033668\ttotal: 14.2s\tremaining: 1.02s\n",
      "653:\tlearn: 0.2031305\ttotal: 14.3s\tremaining: 1s\n",
      "654:\tlearn: 0.2029771\ttotal: 14.3s\tremaining: 981ms\n",
      "655:\tlearn: 0.2026884\ttotal: 14.3s\tremaining: 959ms\n",
      "656:\tlearn: 0.2024488\ttotal: 14.3s\tremaining: 937ms\n",
      "657:\tlearn: 0.2021348\ttotal: 14.3s\tremaining: 916ms\n",
      "658:\tlearn: 0.2018800\ttotal: 14.4s\tremaining: 894ms\n",
      "659:\tlearn: 0.2016704\ttotal: 14.4s\tremaining: 872ms\n",
      "660:\tlearn: 0.2014030\ttotal: 14.4s\tremaining: 850ms\n",
      "661:\tlearn: 0.2011836\ttotal: 14.4s\tremaining: 828ms\n",
      "662:\tlearn: 0.2010752\ttotal: 14.4s\tremaining: 806ms\n",
      "663:\tlearn: 0.2007263\ttotal: 14.5s\tremaining: 785ms\n",
      "664:\tlearn: 0.2003878\ttotal: 14.5s\tremaining: 763ms\n",
      "665:\tlearn: 0.2000376\ttotal: 14.5s\tremaining: 741ms\n",
      "666:\tlearn: 0.1996313\ttotal: 14.5s\tremaining: 719ms\n",
      "667:\tlearn: 0.1993467\ttotal: 14.6s\tremaining: 697ms\n",
      "668:\tlearn: 0.1991909\ttotal: 14.6s\tremaining: 676ms\n",
      "669:\tlearn: 0.1989504\ttotal: 14.6s\tremaining: 654ms\n",
      "670:\tlearn: 0.1987901\ttotal: 14.6s\tremaining: 632ms\n",
      "671:\tlearn: 0.1984528\ttotal: 14.6s\tremaining: 610ms\n",
      "672:\tlearn: 0.1982003\ttotal: 14.7s\tremaining: 589ms\n",
      "673:\tlearn: 0.1980395\ttotal: 14.7s\tremaining: 567ms\n",
      "674:\tlearn: 0.1978068\ttotal: 14.7s\tremaining: 545ms\n",
      "675:\tlearn: 0.1976579\ttotal: 14.7s\tremaining: 523ms\n",
      "676:\tlearn: 0.1973459\ttotal: 14.8s\tremaining: 501ms\n",
      "677:\tlearn: 0.1970884\ttotal: 14.8s\tremaining: 479ms\n",
      "678:\tlearn: 0.1967941\ttotal: 14.8s\tremaining: 458ms\n",
      "679:\tlearn: 0.1965651\ttotal: 14.8s\tremaining: 436ms\n",
      "680:\tlearn: 0.1964573\ttotal: 14.8s\tremaining: 414ms\n",
      "681:\tlearn: 0.1962776\ttotal: 14.9s\tremaining: 392ms\n",
      "682:\tlearn: 0.1959700\ttotal: 14.9s\tremaining: 370ms\n",
      "683:\tlearn: 0.1958476\ttotal: 14.9s\tremaining: 349ms\n",
      "684:\tlearn: 0.1956918\ttotal: 14.9s\tremaining: 327ms\n",
      "685:\tlearn: 0.1955021\ttotal: 14.9s\tremaining: 305ms\n",
      "686:\tlearn: 0.1952266\ttotal: 15s\tremaining: 283ms\n",
      "687:\tlearn: 0.1948269\ttotal: 15s\tremaining: 261ms\n",
      "688:\tlearn: 0.1946271\ttotal: 15s\tremaining: 240ms\n",
      "689:\tlearn: 0.1944442\ttotal: 15s\tremaining: 218ms\n",
      "690:\tlearn: 0.1942487\ttotal: 15.1s\tremaining: 196ms\n",
      "691:\tlearn: 0.1938671\ttotal: 15.1s\tremaining: 174ms\n",
      "692:\tlearn: 0.1936449\ttotal: 15.1s\tremaining: 153ms\n",
      "693:\tlearn: 0.1934535\ttotal: 15.1s\tremaining: 131ms\n",
      "694:\tlearn: 0.1932334\ttotal: 15.1s\tremaining: 109ms\n",
      "695:\tlearn: 0.1931288\ttotal: 15.2s\tremaining: 87.1ms\n",
      "696:\tlearn: 0.1928987\ttotal: 15.2s\tremaining: 65.4ms\n",
      "697:\tlearn: 0.1926142\ttotal: 15.2s\tremaining: 43.6ms\n",
      "698:\tlearn: 0.1923427\ttotal: 15.2s\tremaining: 21.8ms\n",
      "699:\tlearn: 0.1920987\ttotal: 15.2s\tremaining: 0us\n",
      "0:\tlearn: 0.6818364\ttotal: 20.9ms\tremaining: 14.6s\n",
      "1:\tlearn: 0.6718688\ttotal: 41ms\tremaining: 14.3s\n",
      "2:\tlearn: 0.6620584\ttotal: 62ms\tremaining: 14.4s\n",
      "3:\tlearn: 0.6552077\ttotal: 71.5ms\tremaining: 12.4s\n",
      "4:\tlearn: 0.6458031\ttotal: 91.3ms\tremaining: 12.7s\n",
      "5:\tlearn: 0.6370648\ttotal: 112ms\tremaining: 13s\n",
      "6:\tlearn: 0.6282879\ttotal: 133ms\tremaining: 13.2s\n",
      "7:\tlearn: 0.6194172\ttotal: 155ms\tremaining: 13.4s\n",
      "8:\tlearn: 0.6137480\ttotal: 177ms\tremaining: 13.6s\n",
      "9:\tlearn: 0.6058624\ttotal: 197ms\tremaining: 13.6s\n",
      "10:\tlearn: 0.5999894\ttotal: 218ms\tremaining: 13.6s\n",
      "11:\tlearn: 0.5925052\ttotal: 239ms\tremaining: 13.7s\n",
      "12:\tlearn: 0.5856271\ttotal: 259ms\tremaining: 13.7s\n",
      "13:\tlearn: 0.5793225\ttotal: 279ms\tremaining: 13.7s\n",
      "14:\tlearn: 0.5728145\ttotal: 300ms\tremaining: 13.7s\n",
      "15:\tlearn: 0.5660777\ttotal: 320ms\tremaining: 13.7s\n",
      "16:\tlearn: 0.5606585\ttotal: 340ms\tremaining: 13.7s\n",
      "17:\tlearn: 0.5557586\ttotal: 360ms\tremaining: 13.7s\n",
      "18:\tlearn: 0.5506519\ttotal: 380ms\tremaining: 13.6s\n",
      "19:\tlearn: 0.5452014\ttotal: 401ms\tremaining: 13.6s\n",
      "20:\tlearn: 0.5392476\ttotal: 421ms\tremaining: 13.6s\n",
      "21:\tlearn: 0.5355185\ttotal: 442ms\tremaining: 13.6s\n",
      "22:\tlearn: 0.5315221\ttotal: 457ms\tremaining: 13.5s\n",
      "23:\tlearn: 0.5288365\ttotal: 467ms\tremaining: 13.1s\n",
      "24:\tlearn: 0.5238815\ttotal: 487ms\tremaining: 13.1s\n",
      "25:\tlearn: 0.5193252\ttotal: 507ms\tremaining: 13.1s\n",
      "26:\tlearn: 0.5153755\ttotal: 527ms\tremaining: 13.1s\n",
      "27:\tlearn: 0.5103131\ttotal: 548ms\tremaining: 13.1s\n",
      "28:\tlearn: 0.5070089\ttotal: 568ms\tremaining: 13.1s\n",
      "29:\tlearn: 0.5022122\ttotal: 589ms\tremaining: 13.1s\n",
      "30:\tlearn: 0.4992099\ttotal: 609ms\tremaining: 13.1s\n",
      "31:\tlearn: 0.4956460\ttotal: 630ms\tremaining: 13.2s\n",
      "32:\tlearn: 0.4921676\ttotal: 652ms\tremaining: 13.2s\n",
      "33:\tlearn: 0.4888897\ttotal: 677ms\tremaining: 13.3s\n",
      "34:\tlearn: 0.4853929\ttotal: 701ms\tremaining: 13.3s\n",
      "35:\tlearn: 0.4825942\ttotal: 722ms\tremaining: 13.3s\n",
      "36:\tlearn: 0.4794465\ttotal: 743ms\tremaining: 13.3s\n",
      "37:\tlearn: 0.4763671\ttotal: 764ms\tremaining: 13.3s\n",
      "38:\tlearn: 0.4735695\ttotal: 784ms\tremaining: 13.3s\n",
      "39:\tlearn: 0.4711733\ttotal: 804ms\tremaining: 13.3s\n",
      "40:\tlearn: 0.4682354\ttotal: 825ms\tremaining: 13.3s\n",
      "41:\tlearn: 0.4654496\ttotal: 846ms\tremaining: 13.3s\n",
      "42:\tlearn: 0.4628250\ttotal: 867ms\tremaining: 13.3s\n",
      "43:\tlearn: 0.4607900\ttotal: 889ms\tremaining: 13.2s\n",
      "44:\tlearn: 0.4586127\ttotal: 909ms\tremaining: 13.2s\n",
      "45:\tlearn: 0.4564484\ttotal: 930ms\tremaining: 13.2s\n",
      "46:\tlearn: 0.4548417\ttotal: 950ms\tremaining: 13.2s\n",
      "47:\tlearn: 0.4527212\ttotal: 971ms\tremaining: 13.2s\n",
      "48:\tlearn: 0.4501188\ttotal: 992ms\tremaining: 13.2s\n",
      "49:\tlearn: 0.4484184\ttotal: 1.01s\tremaining: 13.2s\n",
      "50:\tlearn: 0.4463792\ttotal: 1.03s\tremaining: 13.1s\n",
      "51:\tlearn: 0.4443300\ttotal: 1.05s\tremaining: 13.1s\n",
      "52:\tlearn: 0.4427851\ttotal: 1.07s\tremaining: 13.1s\n",
      "53:\tlearn: 0.4406209\ttotal: 1.09s\tremaining: 13.1s\n",
      "54:\tlearn: 0.4381425\ttotal: 1.11s\tremaining: 13.1s\n",
      "55:\tlearn: 0.4361049\ttotal: 1.14s\tremaining: 13.1s\n",
      "56:\tlearn: 0.4344604\ttotal: 1.16s\tremaining: 13.1s\n",
      "57:\tlearn: 0.4329759\ttotal: 1.18s\tremaining: 13.1s\n",
      "58:\tlearn: 0.4307458\ttotal: 1.2s\tremaining: 13.1s\n",
      "59:\tlearn: 0.4296121\ttotal: 1.22s\tremaining: 13s\n",
      "60:\tlearn: 0.4277958\ttotal: 1.24s\tremaining: 13s\n",
      "61:\tlearn: 0.4253558\ttotal: 1.26s\tremaining: 13s\n",
      "62:\tlearn: 0.4234578\ttotal: 1.28s\tremaining: 13s\n",
      "63:\tlearn: 0.4224358\ttotal: 1.3s\tremaining: 12.9s\n",
      "64:\tlearn: 0.4208326\ttotal: 1.32s\tremaining: 12.9s\n",
      "65:\tlearn: 0.4191064\ttotal: 1.34s\tremaining: 12.9s\n",
      "66:\tlearn: 0.4177181\ttotal: 1.37s\tremaining: 12.9s\n",
      "67:\tlearn: 0.4162645\ttotal: 1.39s\tremaining: 12.9s\n",
      "68:\tlearn: 0.4148765\ttotal: 1.41s\tremaining: 12.9s\n",
      "69:\tlearn: 0.4139672\ttotal: 1.43s\tremaining: 12.8s\n",
      "70:\tlearn: 0.4125433\ttotal: 1.45s\tremaining: 12.8s\n",
      "71:\tlearn: 0.4111931\ttotal: 1.47s\tremaining: 12.8s\n",
      "72:\tlearn: 0.4101971\ttotal: 1.49s\tremaining: 12.8s\n",
      "73:\tlearn: 0.4085979\ttotal: 1.51s\tremaining: 12.8s\n",
      "74:\tlearn: 0.4074087\ttotal: 1.53s\tremaining: 12.8s\n",
      "75:\tlearn: 0.4064070\ttotal: 1.55s\tremaining: 12.7s\n",
      "76:\tlearn: 0.4050248\ttotal: 1.57s\tremaining: 12.7s\n",
      "77:\tlearn: 0.4033348\ttotal: 1.59s\tremaining: 12.7s\n",
      "78:\tlearn: 0.4019259\ttotal: 1.61s\tremaining: 12.7s\n",
      "79:\tlearn: 0.4009198\ttotal: 1.63s\tremaining: 12.7s\n",
      "80:\tlearn: 0.4001548\ttotal: 1.66s\tremaining: 12.7s\n",
      "81:\tlearn: 0.3991735\ttotal: 1.68s\tremaining: 12.6s\n",
      "82:\tlearn: 0.3981033\ttotal: 1.7s\tremaining: 12.6s\n",
      "83:\tlearn: 0.3967168\ttotal: 1.72s\tremaining: 12.6s\n",
      "84:\tlearn: 0.3957682\ttotal: 1.74s\tremaining: 12.6s\n",
      "85:\tlearn: 0.3946459\ttotal: 1.77s\tremaining: 12.6s\n",
      "86:\tlearn: 0.3933498\ttotal: 1.79s\tremaining: 12.6s\n",
      "87:\tlearn: 0.3923485\ttotal: 1.81s\tremaining: 12.6s\n",
      "88:\tlearn: 0.3912071\ttotal: 1.83s\tremaining: 12.6s\n",
      "89:\tlearn: 0.3899901\ttotal: 1.85s\tremaining: 12.5s\n",
      "90:\tlearn: 0.3887736\ttotal: 1.87s\tremaining: 12.5s\n",
      "91:\tlearn: 0.3878220\ttotal: 1.89s\tremaining: 12.5s\n",
      "92:\tlearn: 0.3869267\ttotal: 1.92s\tremaining: 12.5s\n",
      "93:\tlearn: 0.3863950\ttotal: 1.94s\tremaining: 12.5s\n",
      "94:\tlearn: 0.3857919\ttotal: 1.96s\tremaining: 12.5s\n",
      "95:\tlearn: 0.3849088\ttotal: 1.98s\tremaining: 12.5s\n",
      "96:\tlearn: 0.3839388\ttotal: 2s\tremaining: 12.4s\n",
      "97:\tlearn: 0.3829926\ttotal: 2.02s\tremaining: 12.4s\n",
      "98:\tlearn: 0.3822952\ttotal: 2.04s\tremaining: 12.4s\n",
      "99:\tlearn: 0.3811354\ttotal: 2.06s\tremaining: 12.4s\n",
      "100:\tlearn: 0.3804622\ttotal: 2.08s\tremaining: 12.3s\n",
      "101:\tlearn: 0.3797880\ttotal: 2.1s\tremaining: 12.3s\n",
      "102:\tlearn: 0.3788048\ttotal: 2.12s\tremaining: 12.3s\n",
      "103:\tlearn: 0.3778215\ttotal: 2.14s\tremaining: 12.3s\n",
      "104:\tlearn: 0.3769580\ttotal: 2.17s\tremaining: 12.3s\n",
      "105:\tlearn: 0.3760390\ttotal: 2.19s\tremaining: 12.3s\n",
      "106:\tlearn: 0.3755136\ttotal: 2.21s\tremaining: 12.3s\n",
      "107:\tlearn: 0.3744793\ttotal: 2.23s\tremaining: 12.2s\n",
      "108:\tlearn: 0.3736175\ttotal: 2.25s\tremaining: 12.2s\n",
      "109:\tlearn: 0.3731645\ttotal: 2.27s\tremaining: 12.2s\n",
      "110:\tlearn: 0.3724855\ttotal: 2.29s\tremaining: 12.2s\n",
      "111:\tlearn: 0.3720910\ttotal: 2.31s\tremaining: 12.1s\n",
      "112:\tlearn: 0.3710953\ttotal: 2.33s\tremaining: 12.1s\n",
      "113:\tlearn: 0.3703853\ttotal: 2.35s\tremaining: 12.1s\n",
      "114:\tlearn: 0.3693778\ttotal: 2.37s\tremaining: 12.1s\n",
      "115:\tlearn: 0.3686069\ttotal: 2.39s\tremaining: 12.1s\n",
      "116:\tlearn: 0.3678941\ttotal: 2.41s\tremaining: 12s\n",
      "117:\tlearn: 0.3673436\ttotal: 2.43s\tremaining: 12s\n",
      "118:\tlearn: 0.3667503\ttotal: 2.45s\tremaining: 12s\n",
      "119:\tlearn: 0.3659127\ttotal: 2.48s\tremaining: 12s\n",
      "120:\tlearn: 0.3648553\ttotal: 2.5s\tremaining: 11.9s\n",
      "121:\tlearn: 0.3642896\ttotal: 2.52s\tremaining: 11.9s\n",
      "122:\tlearn: 0.3636386\ttotal: 2.54s\tremaining: 11.9s\n",
      "123:\tlearn: 0.3625928\ttotal: 2.56s\tremaining: 11.9s\n",
      "124:\tlearn: 0.3616058\ttotal: 2.58s\tremaining: 11.9s\n",
      "125:\tlearn: 0.3607474\ttotal: 2.6s\tremaining: 11.8s\n",
      "126:\tlearn: 0.3600342\ttotal: 2.62s\tremaining: 11.8s\n",
      "127:\tlearn: 0.3595431\ttotal: 2.64s\tremaining: 11.8s\n",
      "128:\tlearn: 0.3582777\ttotal: 2.66s\tremaining: 11.8s\n",
      "129:\tlearn: 0.3577969\ttotal: 2.68s\tremaining: 11.8s\n",
      "130:\tlearn: 0.3571138\ttotal: 2.7s\tremaining: 11.7s\n",
      "131:\tlearn: 0.3563021\ttotal: 2.72s\tremaining: 11.7s\n",
      "132:\tlearn: 0.3558107\ttotal: 2.74s\tremaining: 11.7s\n",
      "133:\tlearn: 0.3548795\ttotal: 2.77s\tremaining: 11.7s\n",
      "134:\tlearn: 0.3541400\ttotal: 2.79s\tremaining: 11.7s\n",
      "135:\tlearn: 0.3537036\ttotal: 2.81s\tremaining: 11.6s\n",
      "136:\tlearn: 0.3532470\ttotal: 2.83s\tremaining: 11.6s\n",
      "137:\tlearn: 0.3526793\ttotal: 2.85s\tremaining: 11.6s\n",
      "138:\tlearn: 0.3516908\ttotal: 2.87s\tremaining: 11.6s\n",
      "139:\tlearn: 0.3510785\ttotal: 2.89s\tremaining: 11.6s\n",
      "140:\tlearn: 0.3506619\ttotal: 2.91s\tremaining: 11.5s\n",
      "141:\tlearn: 0.3500123\ttotal: 2.93s\tremaining: 11.5s\n",
      "142:\tlearn: 0.3494620\ttotal: 2.95s\tremaining: 11.5s\n",
      "143:\tlearn: 0.3493895\ttotal: 2.96s\tremaining: 11.4s\n",
      "144:\tlearn: 0.3485199\ttotal: 2.98s\tremaining: 11.4s\n",
      "145:\tlearn: 0.3476908\ttotal: 3s\tremaining: 11.4s\n",
      "146:\tlearn: 0.3471120\ttotal: 3.02s\tremaining: 11.4s\n",
      "147:\tlearn: 0.3465616\ttotal: 3.04s\tremaining: 11.3s\n",
      "148:\tlearn: 0.3458958\ttotal: 3.06s\tremaining: 11.3s\n",
      "149:\tlearn: 0.3453811\ttotal: 3.08s\tremaining: 11.3s\n",
      "150:\tlearn: 0.3445255\ttotal: 3.1s\tremaining: 11.3s\n",
      "151:\tlearn: 0.3439388\ttotal: 3.12s\tremaining: 11.3s\n",
      "152:\tlearn: 0.3436043\ttotal: 3.15s\tremaining: 11.3s\n",
      "153:\tlearn: 0.3430631\ttotal: 3.17s\tremaining: 11.2s\n",
      "154:\tlearn: 0.3427669\ttotal: 3.19s\tremaining: 11.2s\n",
      "155:\tlearn: 0.3417488\ttotal: 3.21s\tremaining: 11.2s\n",
      "156:\tlearn: 0.3412957\ttotal: 3.23s\tremaining: 11.2s\n",
      "157:\tlearn: 0.3407050\ttotal: 3.25s\tremaining: 11.1s\n",
      "158:\tlearn: 0.3402215\ttotal: 3.27s\tremaining: 11.1s\n",
      "159:\tlearn: 0.3397904\ttotal: 3.29s\tremaining: 11.1s\n",
      "160:\tlearn: 0.3394335\ttotal: 3.31s\tremaining: 11.1s\n",
      "161:\tlearn: 0.3388078\ttotal: 3.33s\tremaining: 11.1s\n",
      "162:\tlearn: 0.3383312\ttotal: 3.35s\tremaining: 11s\n",
      "163:\tlearn: 0.3379796\ttotal: 3.37s\tremaining: 11s\n",
      "164:\tlearn: 0.3370079\ttotal: 3.39s\tremaining: 11s\n",
      "165:\tlearn: 0.3365248\ttotal: 3.41s\tremaining: 11s\n",
      "166:\tlearn: 0.3361097\ttotal: 3.43s\tremaining: 11s\n",
      "167:\tlearn: 0.3356832\ttotal: 3.45s\tremaining: 10.9s\n",
      "168:\tlearn: 0.3348837\ttotal: 3.47s\tremaining: 10.9s\n",
      "169:\tlearn: 0.3343457\ttotal: 3.5s\tremaining: 10.9s\n",
      "170:\tlearn: 0.3336390\ttotal: 3.52s\tremaining: 10.9s\n",
      "171:\tlearn: 0.3330786\ttotal: 3.54s\tremaining: 10.9s\n",
      "172:\tlearn: 0.3325148\ttotal: 3.56s\tremaining: 10.8s\n",
      "173:\tlearn: 0.3318461\ttotal: 3.58s\tremaining: 10.8s\n",
      "174:\tlearn: 0.3315471\ttotal: 3.6s\tremaining: 10.8s\n",
      "175:\tlearn: 0.3311036\ttotal: 3.62s\tremaining: 10.8s\n",
      "176:\tlearn: 0.3305596\ttotal: 3.64s\tremaining: 10.8s\n",
      "177:\tlearn: 0.3299815\ttotal: 3.66s\tremaining: 10.7s\n",
      "178:\tlearn: 0.3291384\ttotal: 3.69s\tremaining: 10.7s\n",
      "179:\tlearn: 0.3285234\ttotal: 3.71s\tremaining: 10.7s\n",
      "180:\tlearn: 0.3280719\ttotal: 3.73s\tremaining: 10.7s\n",
      "181:\tlearn: 0.3276004\ttotal: 3.75s\tremaining: 10.7s\n",
      "182:\tlearn: 0.3268949\ttotal: 3.77s\tremaining: 10.7s\n",
      "183:\tlearn: 0.3262714\ttotal: 3.79s\tremaining: 10.6s\n",
      "184:\tlearn: 0.3258880\ttotal: 3.81s\tremaining: 10.6s\n",
      "185:\tlearn: 0.3256714\ttotal: 3.83s\tremaining: 10.6s\n",
      "186:\tlearn: 0.3254362\ttotal: 3.85s\tremaining: 10.6s\n",
      "187:\tlearn: 0.3251645\ttotal: 3.87s\tremaining: 10.5s\n",
      "188:\tlearn: 0.3251019\ttotal: 3.88s\tremaining: 10.5s\n",
      "189:\tlearn: 0.3247816\ttotal: 3.9s\tremaining: 10.5s\n",
      "190:\tlearn: 0.3241655\ttotal: 3.92s\tremaining: 10.4s\n",
      "191:\tlearn: 0.3238870\ttotal: 3.94s\tremaining: 10.4s\n",
      "192:\tlearn: 0.3234295\ttotal: 3.96s\tremaining: 10.4s\n",
      "193:\tlearn: 0.3230272\ttotal: 3.98s\tremaining: 10.4s\n",
      "194:\tlearn: 0.3225462\ttotal: 4s\tremaining: 10.4s\n",
      "195:\tlearn: 0.3221343\ttotal: 4.02s\tremaining: 10.3s\n",
      "196:\tlearn: 0.3217073\ttotal: 4.04s\tremaining: 10.3s\n",
      "197:\tlearn: 0.3209784\ttotal: 4.06s\tremaining: 10.3s\n",
      "198:\tlearn: 0.3209741\ttotal: 4.07s\tremaining: 10.3s\n",
      "199:\tlearn: 0.3205329\ttotal: 4.09s\tremaining: 10.2s\n",
      "200:\tlearn: 0.3200734\ttotal: 4.11s\tremaining: 10.2s\n",
      "201:\tlearn: 0.3198148\ttotal: 4.14s\tremaining: 10.2s\n",
      "202:\tlearn: 0.3195547\ttotal: 4.16s\tremaining: 10.2s\n",
      "203:\tlearn: 0.3189764\ttotal: 4.18s\tremaining: 10.2s\n",
      "204:\tlearn: 0.3183841\ttotal: 4.2s\tremaining: 10.1s\n",
      "205:\tlearn: 0.3177243\ttotal: 4.22s\tremaining: 10.1s\n",
      "206:\tlearn: 0.3172518\ttotal: 4.24s\tremaining: 10.1s\n",
      "207:\tlearn: 0.3168044\ttotal: 4.26s\tremaining: 10.1s\n",
      "208:\tlearn: 0.3163940\ttotal: 4.28s\tremaining: 10.1s\n",
      "209:\tlearn: 0.3158843\ttotal: 4.3s\tremaining: 10s\n",
      "210:\tlearn: 0.3153544\ttotal: 4.32s\tremaining: 10s\n",
      "211:\tlearn: 0.3148250\ttotal: 4.34s\tremaining: 10s\n",
      "212:\tlearn: 0.3144302\ttotal: 4.37s\tremaining: 9.98s\n",
      "213:\tlearn: 0.3138920\ttotal: 4.4s\tremaining: 9.98s\n",
      "214:\tlearn: 0.3133672\ttotal: 4.43s\tremaining: 10s\n",
      "215:\tlearn: 0.3130996\ttotal: 4.46s\tremaining: 9.99s\n",
      "216:\tlearn: 0.3126975\ttotal: 4.49s\tremaining: 9.98s\n",
      "217:\tlearn: 0.3126817\ttotal: 4.49s\tremaining: 9.94s\n",
      "218:\tlearn: 0.3122118\ttotal: 4.52s\tremaining: 9.92s\n",
      "219:\tlearn: 0.3117584\ttotal: 4.54s\tremaining: 9.9s\n",
      "220:\tlearn: 0.3114675\ttotal: 4.56s\tremaining: 9.88s\n",
      "221:\tlearn: 0.3109976\ttotal: 4.58s\tremaining: 9.86s\n",
      "222:\tlearn: 0.3105739\ttotal: 4.6s\tremaining: 9.84s\n",
      "223:\tlearn: 0.3098586\ttotal: 4.62s\tremaining: 9.82s\n",
      "224:\tlearn: 0.3094230\ttotal: 4.64s\tremaining: 9.81s\n",
      "225:\tlearn: 0.3090799\ttotal: 4.67s\tremaining: 9.79s\n",
      "226:\tlearn: 0.3085478\ttotal: 4.69s\tremaining: 9.77s\n",
      "227:\tlearn: 0.3079270\ttotal: 4.71s\tremaining: 9.75s\n",
      "228:\tlearn: 0.3075481\ttotal: 4.73s\tremaining: 9.72s\n",
      "229:\tlearn: 0.3066104\ttotal: 4.75s\tremaining: 9.71s\n",
      "230:\tlearn: 0.3064239\ttotal: 4.77s\tremaining: 9.68s\n",
      "231:\tlearn: 0.3057985\ttotal: 4.79s\tremaining: 9.66s\n",
      "232:\tlearn: 0.3053243\ttotal: 4.81s\tremaining: 9.64s\n",
      "233:\tlearn: 0.3047808\ttotal: 4.83s\tremaining: 9.62s\n",
      "234:\tlearn: 0.3044958\ttotal: 4.85s\tremaining: 9.6s\n",
      "235:\tlearn: 0.3042048\ttotal: 4.87s\tremaining: 9.57s\n",
      "236:\tlearn: 0.3036375\ttotal: 4.89s\tremaining: 9.55s\n",
      "237:\tlearn: 0.3030960\ttotal: 4.91s\tremaining: 9.53s\n",
      "238:\tlearn: 0.3027443\ttotal: 4.93s\tremaining: 9.51s\n",
      "239:\tlearn: 0.3021963\ttotal: 4.95s\tremaining: 9.49s\n",
      "240:\tlearn: 0.3016692\ttotal: 4.97s\tremaining: 9.47s\n",
      "241:\tlearn: 0.3011500\ttotal: 4.99s\tremaining: 9.45s\n",
      "242:\tlearn: 0.3006705\ttotal: 5.01s\tremaining: 9.43s\n",
      "243:\tlearn: 0.3003253\ttotal: 5.04s\tremaining: 9.41s\n",
      "244:\tlearn: 0.3001799\ttotal: 5.06s\tremaining: 9.39s\n",
      "245:\tlearn: 0.2998951\ttotal: 5.08s\tremaining: 9.37s\n",
      "246:\tlearn: 0.2994440\ttotal: 5.1s\tremaining: 9.35s\n",
      "247:\tlearn: 0.2991566\ttotal: 5.12s\tremaining: 9.33s\n",
      "248:\tlearn: 0.2990906\ttotal: 5.13s\tremaining: 9.29s\n",
      "249:\tlearn: 0.2984194\ttotal: 5.15s\tremaining: 9.27s\n",
      "250:\tlearn: 0.2980035\ttotal: 5.18s\tremaining: 9.26s\n",
      "251:\tlearn: 0.2978647\ttotal: 5.19s\tremaining: 9.23s\n",
      "252:\tlearn: 0.2975176\ttotal: 5.21s\tremaining: 9.21s\n",
      "253:\tlearn: 0.2971712\ttotal: 5.23s\tremaining: 9.19s\n",
      "254:\tlearn: 0.2968117\ttotal: 5.25s\tremaining: 9.17s\n",
      "255:\tlearn: 0.2962951\ttotal: 5.27s\tremaining: 9.14s\n",
      "256:\tlearn: 0.2957329\ttotal: 5.29s\tremaining: 9.13s\n",
      "257:\tlearn: 0.2953490\ttotal: 5.31s\tremaining: 9.1s\n",
      "258:\tlearn: 0.2948470\ttotal: 5.33s\tremaining: 9.08s\n",
      "259:\tlearn: 0.2945924\ttotal: 5.35s\tremaining: 9.06s\n",
      "260:\tlearn: 0.2943488\ttotal: 5.37s\tremaining: 9.04s\n",
      "261:\tlearn: 0.2941164\ttotal: 5.39s\tremaining: 9.02s\n",
      "262:\tlearn: 0.2938380\ttotal: 5.42s\tremaining: 9s\n",
      "263:\tlearn: 0.2936198\ttotal: 5.43s\tremaining: 8.98s\n",
      "264:\tlearn: 0.2932058\ttotal: 5.46s\tremaining: 8.97s\n",
      "265:\tlearn: 0.2927985\ttotal: 5.49s\tremaining: 8.95s\n",
      "266:\tlearn: 0.2921902\ttotal: 5.51s\tremaining: 8.93s\n",
      "267:\tlearn: 0.2917903\ttotal: 5.53s\tremaining: 8.91s\n",
      "268:\tlearn: 0.2912409\ttotal: 5.55s\tremaining: 8.89s\n",
      "269:\tlearn: 0.2907779\ttotal: 5.57s\tremaining: 8.87s\n",
      "270:\tlearn: 0.2903849\ttotal: 5.59s\tremaining: 8.85s\n",
      "271:\tlearn: 0.2899770\ttotal: 5.61s\tremaining: 8.83s\n",
      "272:\tlearn: 0.2897282\ttotal: 5.63s\tremaining: 8.81s\n",
      "273:\tlearn: 0.2892546\ttotal: 5.65s\tremaining: 8.79s\n",
      "274:\tlearn: 0.2890338\ttotal: 5.67s\tremaining: 8.77s\n",
      "275:\tlearn: 0.2884580\ttotal: 5.69s\tremaining: 8.75s\n",
      "276:\tlearn: 0.2880561\ttotal: 5.71s\tremaining: 8.73s\n",
      "277:\tlearn: 0.2876777\ttotal: 5.74s\tremaining: 8.71s\n",
      "278:\tlearn: 0.2874571\ttotal: 5.75s\tremaining: 8.69s\n",
      "279:\tlearn: 0.2868446\ttotal: 5.78s\tremaining: 8.66s\n",
      "280:\tlearn: 0.2867117\ttotal: 5.8s\tremaining: 8.64s\n",
      "281:\tlearn: 0.2864932\ttotal: 5.82s\tremaining: 8.62s\n",
      "282:\tlearn: 0.2862387\ttotal: 5.84s\tremaining: 8.6s\n",
      "283:\tlearn: 0.2859946\ttotal: 5.86s\tremaining: 8.58s\n",
      "284:\tlearn: 0.2856100\ttotal: 5.88s\tremaining: 8.56s\n",
      "285:\tlearn: 0.2851845\ttotal: 5.9s\tremaining: 8.54s\n",
      "286:\tlearn: 0.2849442\ttotal: 5.92s\tremaining: 8.52s\n",
      "287:\tlearn: 0.2843450\ttotal: 5.94s\tremaining: 8.5s\n",
      "288:\tlearn: 0.2840227\ttotal: 5.96s\tremaining: 8.48s\n",
      "289:\tlearn: 0.2834342\ttotal: 5.98s\tremaining: 8.46s\n",
      "290:\tlearn: 0.2830132\ttotal: 6s\tremaining: 8.43s\n",
      "291:\tlearn: 0.2824567\ttotal: 6.02s\tremaining: 8.41s\n",
      "292:\tlearn: 0.2822403\ttotal: 6.04s\tremaining: 8.39s\n",
      "293:\tlearn: 0.2818755\ttotal: 6.06s\tremaining: 8.37s\n",
      "294:\tlearn: 0.2816728\ttotal: 6.08s\tremaining: 8.35s\n",
      "295:\tlearn: 0.2811744\ttotal: 6.1s\tremaining: 8.33s\n",
      "296:\tlearn: 0.2809183\ttotal: 6.12s\tremaining: 8.31s\n",
      "297:\tlearn: 0.2806012\ttotal: 6.15s\tremaining: 8.29s\n",
      "298:\tlearn: 0.2804059\ttotal: 6.17s\tremaining: 8.27s\n",
      "299:\tlearn: 0.2800866\ttotal: 6.19s\tremaining: 8.25s\n",
      "300:\tlearn: 0.2797275\ttotal: 6.21s\tremaining: 8.23s\n",
      "301:\tlearn: 0.2793476\ttotal: 6.23s\tremaining: 8.21s\n",
      "302:\tlearn: 0.2793471\ttotal: 6.24s\tremaining: 8.17s\n",
      "303:\tlearn: 0.2789108\ttotal: 6.26s\tremaining: 8.15s\n",
      "304:\tlearn: 0.2788941\ttotal: 6.27s\tremaining: 8.12s\n",
      "305:\tlearn: 0.2784194\ttotal: 6.29s\tremaining: 8.1s\n",
      "306:\tlearn: 0.2781264\ttotal: 6.31s\tremaining: 8.08s\n",
      "307:\tlearn: 0.2776716\ttotal: 6.33s\tremaining: 8.06s\n",
      "308:\tlearn: 0.2774228\ttotal: 6.35s\tremaining: 8.04s\n",
      "309:\tlearn: 0.2769483\ttotal: 6.37s\tremaining: 8.02s\n",
      "310:\tlearn: 0.2765067\ttotal: 6.39s\tremaining: 7.99s\n",
      "311:\tlearn: 0.2760760\ttotal: 6.41s\tremaining: 7.97s\n",
      "312:\tlearn: 0.2759132\ttotal: 6.43s\tremaining: 7.95s\n",
      "313:\tlearn: 0.2755170\ttotal: 6.45s\tremaining: 7.93s\n",
      "314:\tlearn: 0.2750769\ttotal: 6.47s\tremaining: 7.91s\n",
      "315:\tlearn: 0.2748783\ttotal: 6.49s\tremaining: 7.89s\n",
      "316:\tlearn: 0.2746181\ttotal: 6.51s\tremaining: 7.87s\n",
      "317:\tlearn: 0.2743134\ttotal: 6.53s\tremaining: 7.85s\n",
      "318:\tlearn: 0.2742114\ttotal: 6.55s\tremaining: 7.82s\n",
      "319:\tlearn: 0.2739102\ttotal: 6.57s\tremaining: 7.8s\n",
      "320:\tlearn: 0.2734422\ttotal: 6.59s\tremaining: 7.78s\n",
      "321:\tlearn: 0.2730268\ttotal: 6.61s\tremaining: 7.76s\n",
      "322:\tlearn: 0.2728785\ttotal: 6.63s\tremaining: 7.74s\n",
      "323:\tlearn: 0.2724403\ttotal: 6.66s\tremaining: 7.72s\n",
      "324:\tlearn: 0.2721630\ttotal: 6.68s\tremaining: 7.71s\n",
      "325:\tlearn: 0.2717683\ttotal: 6.7s\tremaining: 7.68s\n",
      "326:\tlearn: 0.2715704\ttotal: 6.72s\tremaining: 7.66s\n",
      "327:\tlearn: 0.2711794\ttotal: 6.74s\tremaining: 7.64s\n",
      "328:\tlearn: 0.2711078\ttotal: 6.76s\tremaining: 7.62s\n",
      "329:\tlearn: 0.2708171\ttotal: 6.78s\tremaining: 7.6s\n",
      "330:\tlearn: 0.2704249\ttotal: 6.8s\tremaining: 7.58s\n",
      "331:\tlearn: 0.2701230\ttotal: 6.82s\tremaining: 7.56s\n",
      "332:\tlearn: 0.2699351\ttotal: 6.84s\tremaining: 7.54s\n",
      "333:\tlearn: 0.2696909\ttotal: 6.86s\tremaining: 7.52s\n",
      "334:\tlearn: 0.2696513\ttotal: 6.87s\tremaining: 7.49s\n",
      "335:\tlearn: 0.2690610\ttotal: 6.89s\tremaining: 7.47s\n",
      "336:\tlearn: 0.2688503\ttotal: 6.91s\tremaining: 7.45s\n",
      "337:\tlearn: 0.2682756\ttotal: 6.93s\tremaining: 7.43s\n",
      "338:\tlearn: 0.2679918\ttotal: 6.95s\tremaining: 7.41s\n",
      "339:\tlearn: 0.2675580\ttotal: 6.98s\tremaining: 7.39s\n",
      "340:\tlearn: 0.2672655\ttotal: 7s\tremaining: 7.37s\n",
      "341:\tlearn: 0.2668162\ttotal: 7.02s\tremaining: 7.34s\n",
      "342:\tlearn: 0.2663329\ttotal: 7.04s\tremaining: 7.33s\n",
      "343:\tlearn: 0.2659215\ttotal: 7.06s\tremaining: 7.3s\n",
      "344:\tlearn: 0.2655646\ttotal: 7.08s\tremaining: 7.28s\n",
      "345:\tlearn: 0.2652830\ttotal: 7.1s\tremaining: 7.26s\n",
      "346:\tlearn: 0.2648217\ttotal: 7.12s\tremaining: 7.24s\n",
      "347:\tlearn: 0.2643701\ttotal: 7.14s\tremaining: 7.22s\n",
      "348:\tlearn: 0.2641508\ttotal: 7.16s\tremaining: 7.21s\n",
      "349:\tlearn: 0.2638905\ttotal: 7.18s\tremaining: 7.18s\n",
      "350:\tlearn: 0.2636198\ttotal: 7.21s\tremaining: 7.17s\n",
      "351:\tlearn: 0.2631658\ttotal: 7.23s\tremaining: 7.14s\n",
      "352:\tlearn: 0.2631298\ttotal: 7.24s\tremaining: 7.12s\n",
      "353:\tlearn: 0.2629394\ttotal: 7.26s\tremaining: 7.09s\n",
      "354:\tlearn: 0.2624823\ttotal: 7.28s\tremaining: 7.07s\n",
      "355:\tlearn: 0.2623043\ttotal: 7.3s\tremaining: 7.05s\n",
      "356:\tlearn: 0.2619590\ttotal: 7.32s\tremaining: 7.03s\n",
      "357:\tlearn: 0.2615812\ttotal: 7.34s\tremaining: 7.01s\n",
      "358:\tlearn: 0.2610845\ttotal: 7.36s\tremaining: 6.99s\n",
      "359:\tlearn: 0.2604212\ttotal: 7.38s\tremaining: 6.97s\n",
      "360:\tlearn: 0.2600814\ttotal: 7.4s\tremaining: 6.95s\n",
      "361:\tlearn: 0.2598094\ttotal: 7.42s\tremaining: 6.93s\n",
      "362:\tlearn: 0.2594426\ttotal: 7.44s\tremaining: 6.91s\n",
      "363:\tlearn: 0.2588342\ttotal: 7.46s\tremaining: 6.89s\n",
      "364:\tlearn: 0.2585363\ttotal: 7.49s\tremaining: 6.87s\n",
      "365:\tlearn: 0.2582531\ttotal: 7.5s\tremaining: 6.85s\n",
      "366:\tlearn: 0.2580159\ttotal: 7.53s\tremaining: 6.83s\n",
      "367:\tlearn: 0.2575702\ttotal: 7.55s\tremaining: 6.81s\n",
      "368:\tlearn: 0.2573027\ttotal: 7.57s\tremaining: 6.79s\n",
      "369:\tlearn: 0.2570794\ttotal: 7.59s\tremaining: 6.77s\n",
      "370:\tlearn: 0.2569488\ttotal: 7.61s\tremaining: 6.75s\n",
      "371:\tlearn: 0.2567423\ttotal: 7.63s\tremaining: 6.73s\n",
      "372:\tlearn: 0.2564149\ttotal: 7.65s\tremaining: 6.71s\n",
      "373:\tlearn: 0.2560298\ttotal: 7.67s\tremaining: 6.69s\n",
      "374:\tlearn: 0.2556414\ttotal: 7.69s\tremaining: 6.67s\n",
      "375:\tlearn: 0.2552377\ttotal: 7.71s\tremaining: 6.65s\n",
      "376:\tlearn: 0.2547080\ttotal: 7.74s\tremaining: 6.63s\n",
      "377:\tlearn: 0.2545829\ttotal: 7.75s\tremaining: 6.61s\n",
      "378:\tlearn: 0.2543189\ttotal: 7.78s\tremaining: 6.59s\n",
      "379:\tlearn: 0.2540960\ttotal: 7.8s\tremaining: 6.57s\n",
      "380:\tlearn: 0.2539616\ttotal: 7.82s\tremaining: 6.54s\n",
      "381:\tlearn: 0.2534934\ttotal: 7.84s\tremaining: 6.52s\n",
      "382:\tlearn: 0.2529407\ttotal: 7.86s\tremaining: 6.5s\n",
      "383:\tlearn: 0.2527573\ttotal: 7.88s\tremaining: 6.48s\n",
      "384:\tlearn: 0.2525569\ttotal: 7.9s\tremaining: 6.46s\n",
      "385:\tlearn: 0.2524333\ttotal: 7.92s\tremaining: 6.44s\n",
      "386:\tlearn: 0.2520277\ttotal: 7.94s\tremaining: 6.42s\n",
      "387:\tlearn: 0.2517600\ttotal: 7.96s\tremaining: 6.4s\n",
      "388:\tlearn: 0.2514540\ttotal: 7.98s\tremaining: 6.38s\n",
      "389:\tlearn: 0.2511437\ttotal: 8s\tremaining: 6.36s\n",
      "390:\tlearn: 0.2509100\ttotal: 8.02s\tremaining: 6.34s\n",
      "391:\tlearn: 0.2507138\ttotal: 8.04s\tremaining: 6.32s\n",
      "392:\tlearn: 0.2503492\ttotal: 8.06s\tremaining: 6.3s\n",
      "393:\tlearn: 0.2500304\ttotal: 8.08s\tremaining: 6.28s\n",
      "394:\tlearn: 0.2498951\ttotal: 8.1s\tremaining: 6.26s\n",
      "395:\tlearn: 0.2495270\ttotal: 8.12s\tremaining: 6.24s\n",
      "396:\tlearn: 0.2492291\ttotal: 8.15s\tremaining: 6.22s\n",
      "397:\tlearn: 0.2487692\ttotal: 8.17s\tremaining: 6.2s\n",
      "398:\tlearn: 0.2484219\ttotal: 8.19s\tremaining: 6.18s\n",
      "399:\tlearn: 0.2479974\ttotal: 8.21s\tremaining: 6.16s\n",
      "400:\tlearn: 0.2477034\ttotal: 8.23s\tremaining: 6.14s\n",
      "401:\tlearn: 0.2472134\ttotal: 8.26s\tremaining: 6.12s\n",
      "402:\tlearn: 0.2470014\ttotal: 8.28s\tremaining: 6.1s\n",
      "403:\tlearn: 0.2466575\ttotal: 8.3s\tremaining: 6.08s\n",
      "404:\tlearn: 0.2463336\ttotal: 8.32s\tremaining: 6.06s\n",
      "405:\tlearn: 0.2460206\ttotal: 8.34s\tremaining: 6.04s\n",
      "406:\tlearn: 0.2456602\ttotal: 8.36s\tremaining: 6.02s\n",
      "407:\tlearn: 0.2454473\ttotal: 8.38s\tremaining: 6s\n",
      "408:\tlearn: 0.2451853\ttotal: 8.4s\tremaining: 5.98s\n",
      "409:\tlearn: 0.2447136\ttotal: 8.42s\tremaining: 5.96s\n",
      "410:\tlearn: 0.2443352\ttotal: 8.44s\tremaining: 5.93s\n",
      "411:\tlearn: 0.2439637\ttotal: 8.46s\tremaining: 5.92s\n",
      "412:\tlearn: 0.2438069\ttotal: 8.48s\tremaining: 5.89s\n",
      "413:\tlearn: 0.2435910\ttotal: 8.5s\tremaining: 5.87s\n",
      "414:\tlearn: 0.2431750\ttotal: 8.52s\tremaining: 5.85s\n",
      "415:\tlearn: 0.2428891\ttotal: 8.54s\tremaining: 5.83s\n",
      "416:\tlearn: 0.2426827\ttotal: 8.56s\tremaining: 5.81s\n",
      "417:\tlearn: 0.2423708\ttotal: 8.59s\tremaining: 5.79s\n",
      "418:\tlearn: 0.2419973\ttotal: 8.61s\tremaining: 5.77s\n",
      "419:\tlearn: 0.2417660\ttotal: 8.63s\tremaining: 5.75s\n",
      "420:\tlearn: 0.2417484\ttotal: 8.64s\tremaining: 5.73s\n",
      "421:\tlearn: 0.2414744\ttotal: 8.66s\tremaining: 5.71s\n",
      "422:\tlearn: 0.2410573\ttotal: 8.68s\tremaining: 5.68s\n",
      "423:\tlearn: 0.2409464\ttotal: 8.7s\tremaining: 5.66s\n",
      "424:\tlearn: 0.2407391\ttotal: 8.72s\tremaining: 5.64s\n",
      "425:\tlearn: 0.2402957\ttotal: 8.74s\tremaining: 5.62s\n",
      "426:\tlearn: 0.2399859\ttotal: 8.76s\tremaining: 5.6s\n",
      "427:\tlearn: 0.2396698\ttotal: 8.78s\tremaining: 5.58s\n",
      "428:\tlearn: 0.2392775\ttotal: 8.8s\tremaining: 5.56s\n",
      "429:\tlearn: 0.2391539\ttotal: 8.82s\tremaining: 5.54s\n",
      "430:\tlearn: 0.2388996\ttotal: 8.85s\tremaining: 5.52s\n",
      "431:\tlearn: 0.2386065\ttotal: 8.87s\tremaining: 5.5s\n",
      "432:\tlearn: 0.2383417\ttotal: 8.89s\tremaining: 5.48s\n",
      "433:\tlearn: 0.2381750\ttotal: 8.91s\tremaining: 5.46s\n",
      "434:\tlearn: 0.2373970\ttotal: 8.93s\tremaining: 5.44s\n",
      "435:\tlearn: 0.2373794\ttotal: 8.94s\tremaining: 5.41s\n",
      "436:\tlearn: 0.2371902\ttotal: 8.96s\tremaining: 5.39s\n",
      "437:\tlearn: 0.2368594\ttotal: 8.98s\tremaining: 5.37s\n",
      "438:\tlearn: 0.2364739\ttotal: 9s\tremaining: 5.35s\n",
      "439:\tlearn: 0.2358875\ttotal: 9.02s\tremaining: 5.33s\n",
      "440:\tlearn: 0.2357132\ttotal: 9.04s\tremaining: 5.31s\n",
      "441:\tlearn: 0.2355728\ttotal: 9.06s\tremaining: 5.29s\n",
      "442:\tlearn: 0.2353054\ttotal: 9.08s\tremaining: 5.27s\n",
      "443:\tlearn: 0.2349365\ttotal: 9.11s\tremaining: 5.25s\n",
      "444:\tlearn: 0.2347314\ttotal: 9.13s\tremaining: 5.23s\n",
      "445:\tlearn: 0.2343379\ttotal: 9.15s\tremaining: 5.21s\n",
      "446:\tlearn: 0.2339059\ttotal: 9.17s\tremaining: 5.19s\n",
      "447:\tlearn: 0.2336522\ttotal: 9.19s\tremaining: 5.17s\n",
      "448:\tlearn: 0.2334806\ttotal: 9.21s\tremaining: 5.15s\n",
      "449:\tlearn: 0.2332072\ttotal: 9.23s\tremaining: 5.13s\n",
      "450:\tlearn: 0.2331110\ttotal: 9.25s\tremaining: 5.11s\n",
      "451:\tlearn: 0.2329212\ttotal: 9.27s\tremaining: 5.09s\n",
      "452:\tlearn: 0.2326523\ttotal: 9.29s\tremaining: 5.07s\n",
      "453:\tlearn: 0.2324498\ttotal: 9.31s\tremaining: 5.05s\n",
      "454:\tlearn: 0.2321307\ttotal: 9.34s\tremaining: 5.03s\n",
      "455:\tlearn: 0.2317728\ttotal: 9.36s\tremaining: 5.01s\n",
      "456:\tlearn: 0.2315863\ttotal: 9.38s\tremaining: 4.99s\n",
      "457:\tlearn: 0.2312806\ttotal: 9.4s\tremaining: 4.97s\n",
      "458:\tlearn: 0.2309579\ttotal: 9.42s\tremaining: 4.95s\n",
      "459:\tlearn: 0.2308310\ttotal: 9.44s\tremaining: 4.92s\n",
      "460:\tlearn: 0.2303705\ttotal: 9.46s\tremaining: 4.9s\n",
      "461:\tlearn: 0.2301676\ttotal: 9.48s\tremaining: 4.88s\n",
      "462:\tlearn: 0.2299465\ttotal: 9.5s\tremaining: 4.86s\n",
      "463:\tlearn: 0.2298031\ttotal: 9.52s\tremaining: 4.84s\n",
      "464:\tlearn: 0.2295686\ttotal: 9.54s\tremaining: 4.82s\n",
      "465:\tlearn: 0.2292595\ttotal: 9.56s\tremaining: 4.8s\n",
      "466:\tlearn: 0.2289599\ttotal: 9.58s\tremaining: 4.78s\n",
      "467:\tlearn: 0.2285604\ttotal: 9.61s\tremaining: 4.76s\n",
      "468:\tlearn: 0.2282481\ttotal: 9.63s\tremaining: 4.74s\n",
      "469:\tlearn: 0.2276576\ttotal: 9.65s\tremaining: 4.72s\n",
      "470:\tlearn: 0.2271833\ttotal: 9.67s\tremaining: 4.7s\n",
      "471:\tlearn: 0.2269392\ttotal: 9.7s\tremaining: 4.68s\n",
      "472:\tlearn: 0.2268094\ttotal: 9.71s\tremaining: 4.66s\n",
      "473:\tlearn: 0.2267063\ttotal: 9.73s\tremaining: 4.64s\n",
      "474:\tlearn: 0.2264024\ttotal: 9.76s\tremaining: 4.62s\n",
      "475:\tlearn: 0.2261040\ttotal: 9.78s\tremaining: 4.6s\n",
      "476:\tlearn: 0.2259684\ttotal: 9.8s\tremaining: 4.58s\n",
      "477:\tlearn: 0.2257645\ttotal: 9.82s\tremaining: 4.56s\n",
      "478:\tlearn: 0.2253030\ttotal: 9.85s\tremaining: 4.54s\n",
      "479:\tlearn: 0.2251621\ttotal: 9.87s\tremaining: 4.52s\n",
      "480:\tlearn: 0.2249379\ttotal: 9.89s\tremaining: 4.5s\n",
      "481:\tlearn: 0.2246749\ttotal: 9.91s\tremaining: 4.48s\n",
      "482:\tlearn: 0.2245316\ttotal: 9.93s\tremaining: 4.46s\n",
      "483:\tlearn: 0.2243266\ttotal: 9.95s\tremaining: 4.44s\n",
      "484:\tlearn: 0.2240834\ttotal: 9.97s\tremaining: 4.42s\n",
      "485:\tlearn: 0.2238048\ttotal: 9.99s\tremaining: 4.4s\n",
      "486:\tlearn: 0.2231598\ttotal: 10s\tremaining: 4.38s\n",
      "487:\tlearn: 0.2229869\ttotal: 10s\tremaining: 4.36s\n",
      "488:\tlearn: 0.2227283\ttotal: 10.1s\tremaining: 4.34s\n",
      "489:\tlearn: 0.2225699\ttotal: 10.1s\tremaining: 4.32s\n",
      "490:\tlearn: 0.2221798\ttotal: 10.1s\tremaining: 4.29s\n",
      "491:\tlearn: 0.2219750\ttotal: 10.1s\tremaining: 4.28s\n",
      "492:\tlearn: 0.2217483\ttotal: 10.1s\tremaining: 4.25s\n",
      "493:\tlearn: 0.2215018\ttotal: 10.2s\tremaining: 4.24s\n",
      "494:\tlearn: 0.2212484\ttotal: 10.2s\tremaining: 4.21s\n",
      "495:\tlearn: 0.2205320\ttotal: 10.2s\tremaining: 4.2s\n",
      "496:\tlearn: 0.2201875\ttotal: 10.2s\tremaining: 4.17s\n",
      "497:\tlearn: 0.2199576\ttotal: 10.2s\tremaining: 4.15s\n",
      "498:\tlearn: 0.2197663\ttotal: 10.3s\tremaining: 4.13s\n",
      "499:\tlearn: 0.2193011\ttotal: 10.3s\tremaining: 4.11s\n",
      "500:\tlearn: 0.2190178\ttotal: 10.3s\tremaining: 4.09s\n",
      "501:\tlearn: 0.2185274\ttotal: 10.3s\tremaining: 4.07s\n",
      "502:\tlearn: 0.2181864\ttotal: 10.3s\tremaining: 4.05s\n",
      "503:\tlearn: 0.2179797\ttotal: 10.4s\tremaining: 4.03s\n",
      "504:\tlearn: 0.2172206\ttotal: 10.4s\tremaining: 4.01s\n",
      "505:\tlearn: 0.2165866\ttotal: 10.4s\tremaining: 3.99s\n",
      "506:\tlearn: 0.2163924\ttotal: 10.4s\tremaining: 3.97s\n",
      "507:\tlearn: 0.2161153\ttotal: 10.4s\tremaining: 3.95s\n",
      "508:\tlearn: 0.2159253\ttotal: 10.5s\tremaining: 3.93s\n",
      "509:\tlearn: 0.2156997\ttotal: 10.5s\tremaining: 3.91s\n",
      "510:\tlearn: 0.2155426\ttotal: 10.5s\tremaining: 3.89s\n",
      "511:\tlearn: 0.2153144\ttotal: 10.5s\tremaining: 3.87s\n",
      "512:\tlearn: 0.2152179\ttotal: 10.6s\tremaining: 3.85s\n",
      "513:\tlearn: 0.2149153\ttotal: 10.6s\tremaining: 3.83s\n",
      "514:\tlearn: 0.2145962\ttotal: 10.6s\tremaining: 3.81s\n",
      "515:\tlearn: 0.2142430\ttotal: 10.6s\tremaining: 3.79s\n",
      "516:\tlearn: 0.2139648\ttotal: 10.6s\tremaining: 3.77s\n",
      "517:\tlearn: 0.2135234\ttotal: 10.7s\tremaining: 3.75s\n",
      "518:\tlearn: 0.2132171\ttotal: 10.7s\tremaining: 3.72s\n",
      "519:\tlearn: 0.2127632\ttotal: 10.7s\tremaining: 3.7s\n",
      "520:\tlearn: 0.2121408\ttotal: 10.7s\tremaining: 3.68s\n",
      "521:\tlearn: 0.2119539\ttotal: 10.7s\tremaining: 3.66s\n",
      "522:\tlearn: 0.2116606\ttotal: 10.8s\tremaining: 3.64s\n",
      "523:\tlearn: 0.2111485\ttotal: 10.8s\tremaining: 3.62s\n",
      "524:\tlearn: 0.2109734\ttotal: 10.8s\tremaining: 3.6s\n",
      "525:\tlearn: 0.2109614\ttotal: 10.8s\tremaining: 3.58s\n",
      "526:\tlearn: 0.2107759\ttotal: 10.8s\tremaining: 3.56s\n",
      "527:\tlearn: 0.2102992\ttotal: 10.9s\tremaining: 3.54s\n",
      "528:\tlearn: 0.2100521\ttotal: 10.9s\tremaining: 3.52s\n",
      "529:\tlearn: 0.2097478\ttotal: 10.9s\tremaining: 3.5s\n",
      "530:\tlearn: 0.2095778\ttotal: 10.9s\tremaining: 3.47s\n",
      "531:\tlearn: 0.2095728\ttotal: 10.9s\tremaining: 3.45s\n",
      "532:\tlearn: 0.2093969\ttotal: 10.9s\tremaining: 3.43s\n",
      "533:\tlearn: 0.2091650\ttotal: 11s\tremaining: 3.41s\n",
      "534:\tlearn: 0.2089329\ttotal: 11s\tremaining: 3.39s\n",
      "535:\tlearn: 0.2088308\ttotal: 11s\tremaining: 3.37s\n",
      "536:\tlearn: 0.2084127\ttotal: 11s\tremaining: 3.35s\n",
      "537:\tlearn: 0.2081578\ttotal: 11s\tremaining: 3.33s\n",
      "538:\tlearn: 0.2079093\ttotal: 11.1s\tremaining: 3.31s\n",
      "539:\tlearn: 0.2077250\ttotal: 11.1s\tremaining: 3.29s\n",
      "540:\tlearn: 0.2074319\ttotal: 11.1s\tremaining: 3.27s\n",
      "541:\tlearn: 0.2071178\ttotal: 11.1s\tremaining: 3.25s\n",
      "542:\tlearn: 0.2068196\ttotal: 11.2s\tremaining: 3.23s\n",
      "543:\tlearn: 0.2064599\ttotal: 11.2s\tremaining: 3.21s\n",
      "544:\tlearn: 0.2060780\ttotal: 11.2s\tremaining: 3.19s\n",
      "545:\tlearn: 0.2057929\ttotal: 11.2s\tremaining: 3.17s\n",
      "546:\tlearn: 0.2055060\ttotal: 11.2s\tremaining: 3.14s\n",
      "547:\tlearn: 0.2051900\ttotal: 11.3s\tremaining: 3.12s\n",
      "548:\tlearn: 0.2048885\ttotal: 11.3s\tremaining: 3.1s\n",
      "549:\tlearn: 0.2045538\ttotal: 11.3s\tremaining: 3.08s\n",
      "550:\tlearn: 0.2044405\ttotal: 11.3s\tremaining: 3.06s\n",
      "551:\tlearn: 0.2041283\ttotal: 11.3s\tremaining: 3.04s\n",
      "552:\tlearn: 0.2039265\ttotal: 11.4s\tremaining: 3.02s\n",
      "553:\tlearn: 0.2036692\ttotal: 11.4s\tremaining: 3s\n",
      "554:\tlearn: 0.2032716\ttotal: 11.4s\tremaining: 2.98s\n",
      "555:\tlearn: 0.2028811\ttotal: 11.4s\tremaining: 2.96s\n",
      "556:\tlearn: 0.2025465\ttotal: 11.4s\tremaining: 2.94s\n",
      "557:\tlearn: 0.2021858\ttotal: 11.5s\tremaining: 2.92s\n",
      "558:\tlearn: 0.2017469\ttotal: 11.5s\tremaining: 2.9s\n",
      "559:\tlearn: 0.2014438\ttotal: 11.5s\tremaining: 2.88s\n",
      "560:\tlearn: 0.2011415\ttotal: 11.5s\tremaining: 2.86s\n",
      "561:\tlearn: 0.2009317\ttotal: 11.6s\tremaining: 2.84s\n",
      "562:\tlearn: 0.2007978\ttotal: 11.6s\tremaining: 2.82s\n",
      "563:\tlearn: 0.2005753\ttotal: 11.6s\tremaining: 2.79s\n",
      "564:\tlearn: 0.1999708\ttotal: 11.6s\tremaining: 2.77s\n",
      "565:\tlearn: 0.1995633\ttotal: 11.6s\tremaining: 2.75s\n",
      "566:\tlearn: 0.1993029\ttotal: 11.7s\tremaining: 2.73s\n",
      "567:\tlearn: 0.1988984\ttotal: 11.7s\tremaining: 2.71s\n",
      "568:\tlearn: 0.1985021\ttotal: 11.7s\tremaining: 2.69s\n",
      "569:\tlearn: 0.1980929\ttotal: 11.7s\tremaining: 2.67s\n",
      "570:\tlearn: 0.1979315\ttotal: 11.7s\tremaining: 2.65s\n",
      "571:\tlearn: 0.1976959\ttotal: 11.8s\tremaining: 2.63s\n",
      "572:\tlearn: 0.1974282\ttotal: 11.8s\tremaining: 2.61s\n",
      "573:\tlearn: 0.1970866\ttotal: 11.8s\tremaining: 2.59s\n",
      "574:\tlearn: 0.1966425\ttotal: 11.8s\tremaining: 2.57s\n",
      "575:\tlearn: 0.1962520\ttotal: 11.8s\tremaining: 2.55s\n",
      "576:\tlearn: 0.1960084\ttotal: 11.9s\tremaining: 2.53s\n",
      "577:\tlearn: 0.1957164\ttotal: 11.9s\tremaining: 2.51s\n",
      "578:\tlearn: 0.1955743\ttotal: 11.9s\tremaining: 2.49s\n",
      "579:\tlearn: 0.1954479\ttotal: 11.9s\tremaining: 2.47s\n",
      "580:\tlearn: 0.1952430\ttotal: 11.9s\tremaining: 2.45s\n",
      "581:\tlearn: 0.1951176\ttotal: 12s\tremaining: 2.43s\n",
      "582:\tlearn: 0.1947957\ttotal: 12s\tremaining: 2.41s\n",
      "583:\tlearn: 0.1946009\ttotal: 12s\tremaining: 2.38s\n",
      "584:\tlearn: 0.1944236\ttotal: 12s\tremaining: 2.37s\n",
      "585:\tlearn: 0.1941725\ttotal: 12.1s\tremaining: 2.34s\n",
      "586:\tlearn: 0.1937474\ttotal: 12.1s\tremaining: 2.32s\n",
      "587:\tlearn: 0.1932157\ttotal: 12.1s\tremaining: 2.3s\n",
      "588:\tlearn: 0.1930433\ttotal: 12.1s\tremaining: 2.28s\n",
      "589:\tlearn: 0.1927829\ttotal: 12.1s\tremaining: 2.26s\n",
      "590:\tlearn: 0.1925047\ttotal: 12.2s\tremaining: 2.24s\n",
      "591:\tlearn: 0.1919516\ttotal: 12.2s\tremaining: 2.22s\n",
      "592:\tlearn: 0.1917902\ttotal: 12.2s\tremaining: 2.2s\n",
      "593:\tlearn: 0.1915380\ttotal: 12.2s\tremaining: 2.18s\n",
      "594:\tlearn: 0.1913111\ttotal: 12.2s\tremaining: 2.16s\n",
      "595:\tlearn: 0.1909937\ttotal: 12.3s\tremaining: 2.14s\n",
      "596:\tlearn: 0.1908015\ttotal: 12.3s\tremaining: 2.12s\n",
      "597:\tlearn: 0.1906281\ttotal: 12.3s\tremaining: 2.1s\n",
      "598:\tlearn: 0.1904397\ttotal: 12.3s\tremaining: 2.08s\n",
      "599:\tlearn: 0.1898939\ttotal: 12.3s\tremaining: 2.06s\n",
      "600:\tlearn: 0.1893940\ttotal: 12.4s\tremaining: 2.04s\n",
      "601:\tlearn: 0.1891694\ttotal: 12.4s\tremaining: 2.02s\n",
      "602:\tlearn: 0.1889868\ttotal: 12.4s\tremaining: 2s\n",
      "603:\tlearn: 0.1886138\ttotal: 12.4s\tremaining: 1.98s\n",
      "604:\tlearn: 0.1881793\ttotal: 12.4s\tremaining: 1.95s\n",
      "605:\tlearn: 0.1880334\ttotal: 12.5s\tremaining: 1.93s\n",
      "606:\tlearn: 0.1878057\ttotal: 12.5s\tremaining: 1.91s\n",
      "607:\tlearn: 0.1875036\ttotal: 12.5s\tremaining: 1.89s\n",
      "608:\tlearn: 0.1872131\ttotal: 12.5s\tremaining: 1.87s\n",
      "609:\tlearn: 0.1869616\ttotal: 12.6s\tremaining: 1.85s\n",
      "610:\tlearn: 0.1867371\ttotal: 12.6s\tremaining: 1.83s\n",
      "611:\tlearn: 0.1863670\ttotal: 12.6s\tremaining: 1.81s\n",
      "612:\tlearn: 0.1861333\ttotal: 12.6s\tremaining: 1.79s\n",
      "613:\tlearn: 0.1857960\ttotal: 12.6s\tremaining: 1.77s\n",
      "614:\tlearn: 0.1855975\ttotal: 12.7s\tremaining: 1.75s\n",
      "615:\tlearn: 0.1853844\ttotal: 12.7s\tremaining: 1.73s\n",
      "616:\tlearn: 0.1852126\ttotal: 12.7s\tremaining: 1.71s\n",
      "617:\tlearn: 0.1850718\ttotal: 12.7s\tremaining: 1.69s\n",
      "618:\tlearn: 0.1849212\ttotal: 12.8s\tremaining: 1.67s\n",
      "619:\tlearn: 0.1845665\ttotal: 12.8s\tremaining: 1.65s\n",
      "620:\tlearn: 0.1842821\ttotal: 12.8s\tremaining: 1.63s\n",
      "621:\tlearn: 0.1840465\ttotal: 12.8s\tremaining: 1.61s\n",
      "622:\tlearn: 0.1838288\ttotal: 12.8s\tremaining: 1.59s\n",
      "623:\tlearn: 0.1835284\ttotal: 12.9s\tremaining: 1.57s\n",
      "624:\tlearn: 0.1831760\ttotal: 12.9s\tremaining: 1.54s\n",
      "625:\tlearn: 0.1828575\ttotal: 12.9s\tremaining: 1.52s\n",
      "626:\tlearn: 0.1826331\ttotal: 12.9s\tremaining: 1.5s\n",
      "627:\tlearn: 0.1824139\ttotal: 12.9s\tremaining: 1.48s\n",
      "628:\tlearn: 0.1820718\ttotal: 13s\tremaining: 1.46s\n",
      "629:\tlearn: 0.1817954\ttotal: 13s\tremaining: 1.44s\n",
      "630:\tlearn: 0.1815753\ttotal: 13s\tremaining: 1.42s\n",
      "631:\tlearn: 0.1813891\ttotal: 13s\tremaining: 1.4s\n",
      "632:\tlearn: 0.1811283\ttotal: 13s\tremaining: 1.38s\n",
      "633:\tlearn: 0.1808405\ttotal: 13.1s\tremaining: 1.36s\n",
      "634:\tlearn: 0.1806642\ttotal: 13.1s\tremaining: 1.34s\n",
      "635:\tlearn: 0.1804317\ttotal: 13.1s\tremaining: 1.32s\n",
      "636:\tlearn: 0.1802204\ttotal: 13.1s\tremaining: 1.3s\n",
      "637:\tlearn: 0.1800457\ttotal: 13.2s\tremaining: 1.28s\n",
      "638:\tlearn: 0.1797934\ttotal: 13.2s\tremaining: 1.26s\n",
      "639:\tlearn: 0.1794475\ttotal: 13.2s\tremaining: 1.24s\n",
      "640:\tlearn: 0.1791377\ttotal: 13.2s\tremaining: 1.22s\n",
      "641:\tlearn: 0.1788213\ttotal: 13.2s\tremaining: 1.2s\n",
      "642:\tlearn: 0.1786579\ttotal: 13.3s\tremaining: 1.18s\n",
      "643:\tlearn: 0.1784414\ttotal: 13.3s\tremaining: 1.16s\n",
      "644:\tlearn: 0.1781338\ttotal: 13.3s\tremaining: 1.13s\n",
      "645:\tlearn: 0.1778631\ttotal: 13.3s\tremaining: 1.11s\n",
      "646:\tlearn: 0.1776252\ttotal: 13.3s\tremaining: 1.09s\n",
      "647:\tlearn: 0.1773850\ttotal: 13.4s\tremaining: 1.07s\n",
      "648:\tlearn: 0.1771465\ttotal: 13.4s\tremaining: 1.05s\n",
      "649:\tlearn: 0.1769703\ttotal: 13.4s\tremaining: 1.03s\n",
      "650:\tlearn: 0.1767548\ttotal: 13.4s\tremaining: 1.01s\n",
      "651:\tlearn: 0.1766222\ttotal: 13.5s\tremaining: 990ms\n",
      "652:\tlearn: 0.1764321\ttotal: 13.5s\tremaining: 970ms\n",
      "653:\tlearn: 0.1759900\ttotal: 13.5s\tremaining: 949ms\n",
      "654:\tlearn: 0.1757498\ttotal: 13.5s\tremaining: 929ms\n",
      "655:\tlearn: 0.1755910\ttotal: 13.5s\tremaining: 908ms\n",
      "656:\tlearn: 0.1753765\ttotal: 13.6s\tremaining: 887ms\n",
      "657:\tlearn: 0.1752188\ttotal: 13.6s\tremaining: 867ms\n",
      "658:\tlearn: 0.1748800\ttotal: 13.6s\tremaining: 846ms\n",
      "659:\tlearn: 0.1746569\ttotal: 13.6s\tremaining: 826ms\n",
      "660:\tlearn: 0.1743892\ttotal: 13.6s\tremaining: 805ms\n",
      "661:\tlearn: 0.1742185\ttotal: 13.7s\tremaining: 785ms\n",
      "662:\tlearn: 0.1740301\ttotal: 13.7s\tremaining: 764ms\n",
      "663:\tlearn: 0.1737575\ttotal: 13.7s\tremaining: 743ms\n",
      "664:\tlearn: 0.1735827\ttotal: 13.7s\tremaining: 723ms\n",
      "665:\tlearn: 0.1732186\ttotal: 13.8s\tremaining: 703ms\n",
      "666:\tlearn: 0.1729138\ttotal: 13.8s\tremaining: 682ms\n",
      "667:\tlearn: 0.1726179\ttotal: 13.8s\tremaining: 661ms\n",
      "668:\tlearn: 0.1724114\ttotal: 13.8s\tremaining: 641ms\n",
      "669:\tlearn: 0.1720377\ttotal: 13.8s\tremaining: 620ms\n",
      "670:\tlearn: 0.1718803\ttotal: 13.9s\tremaining: 599ms\n",
      "671:\tlearn: 0.1717729\ttotal: 13.9s\tremaining: 579ms\n",
      "672:\tlearn: 0.1715853\ttotal: 13.9s\tremaining: 558ms\n",
      "673:\tlearn: 0.1713473\ttotal: 13.9s\tremaining: 537ms\n",
      "674:\tlearn: 0.1709562\ttotal: 14s\tremaining: 517ms\n",
      "675:\tlearn: 0.1706955\ttotal: 14s\tremaining: 496ms\n",
      "676:\tlearn: 0.1705269\ttotal: 14s\tremaining: 476ms\n",
      "677:\tlearn: 0.1701744\ttotal: 14s\tremaining: 455ms\n",
      "678:\tlearn: 0.1700140\ttotal: 14s\tremaining: 434ms\n",
      "679:\tlearn: 0.1697699\ttotal: 14.1s\tremaining: 414ms\n",
      "680:\tlearn: 0.1695445\ttotal: 14.1s\tremaining: 393ms\n",
      "681:\tlearn: 0.1693503\ttotal: 14.1s\tremaining: 372ms\n",
      "682:\tlearn: 0.1691556\ttotal: 14.1s\tremaining: 352ms\n",
      "683:\tlearn: 0.1689081\ttotal: 14.2s\tremaining: 331ms\n",
      "684:\tlearn: 0.1687125\ttotal: 14.2s\tremaining: 310ms\n",
      "685:\tlearn: 0.1684985\ttotal: 14.2s\tremaining: 290ms\n",
      "686:\tlearn: 0.1682966\ttotal: 14.2s\tremaining: 269ms\n",
      "687:\tlearn: 0.1680864\ttotal: 14.2s\tremaining: 248ms\n",
      "688:\tlearn: 0.1677320\ttotal: 14.3s\tremaining: 228ms\n",
      "689:\tlearn: 0.1676184\ttotal: 14.3s\tremaining: 207ms\n",
      "690:\tlearn: 0.1674286\ttotal: 14.3s\tremaining: 186ms\n",
      "691:\tlearn: 0.1672193\ttotal: 14.3s\tremaining: 166ms\n",
      "692:\tlearn: 0.1670870\ttotal: 14.3s\tremaining: 145ms\n",
      "693:\tlearn: 0.1668202\ttotal: 14.4s\tremaining: 124ms\n",
      "694:\tlearn: 0.1666202\ttotal: 14.4s\tremaining: 104ms\n",
      "695:\tlearn: 0.1664702\ttotal: 14.4s\tremaining: 82.8ms\n",
      "696:\tlearn: 0.1662667\ttotal: 14.4s\tremaining: 62.1ms\n",
      "697:\tlearn: 0.1658850\ttotal: 14.4s\tremaining: 41.4ms\n",
      "698:\tlearn: 0.1656641\ttotal: 14.5s\tremaining: 20.7ms\n",
      "699:\tlearn: 0.1655052\ttotal: 14.5s\tremaining: 0us\n",
      "0:\tlearn: 0.6818013\ttotal: 22.5ms\tremaining: 15.7s\n",
      "1:\tlearn: 0.6720300\ttotal: 43.4ms\tremaining: 15.1s\n",
      "2:\tlearn: 0.6623844\ttotal: 64.7ms\tremaining: 15s\n",
      "3:\tlearn: 0.6553675\ttotal: 74.5ms\tremaining: 13s\n",
      "4:\tlearn: 0.6461221\ttotal: 95.2ms\tremaining: 13.2s\n",
      "5:\tlearn: 0.6364442\ttotal: 116ms\tremaining: 13.4s\n",
      "6:\tlearn: 0.6273695\ttotal: 137ms\tremaining: 13.5s\n",
      "7:\tlearn: 0.6184077\ttotal: 158ms\tremaining: 13.6s\n",
      "8:\tlearn: 0.6122601\ttotal: 179ms\tremaining: 13.7s\n",
      "9:\tlearn: 0.6047572\ttotal: 199ms\tremaining: 13.8s\n",
      "10:\tlearn: 0.5972823\ttotal: 220ms\tremaining: 13.8s\n",
      "11:\tlearn: 0.5895530\ttotal: 243ms\tremaining: 13.9s\n",
      "12:\tlearn: 0.5826538\ttotal: 264ms\tremaining: 13.9s\n",
      "13:\tlearn: 0.5763732\ttotal: 284ms\tremaining: 13.9s\n",
      "14:\tlearn: 0.5699190\ttotal: 305ms\tremaining: 13.9s\n",
      "15:\tlearn: 0.5631680\ttotal: 326ms\tremaining: 14s\n",
      "16:\tlearn: 0.5566814\ttotal: 347ms\tremaining: 14s\n",
      "17:\tlearn: 0.5515375\ttotal: 368ms\tremaining: 13.9s\n",
      "18:\tlearn: 0.5473759\ttotal: 390ms\tremaining: 14s\n",
      "19:\tlearn: 0.5420984\ttotal: 411ms\tremaining: 14s\n",
      "20:\tlearn: 0.5374431\ttotal: 432ms\tremaining: 14s\n",
      "21:\tlearn: 0.5331483\ttotal: 454ms\tremaining: 14s\n",
      "22:\tlearn: 0.5286281\ttotal: 472ms\tremaining: 13.9s\n",
      "23:\tlearn: 0.5260246\ttotal: 483ms\tremaining: 13.6s\n",
      "24:\tlearn: 0.5219318\ttotal: 505ms\tremaining: 13.6s\n",
      "25:\tlearn: 0.5174147\ttotal: 526ms\tremaining: 13.6s\n",
      "26:\tlearn: 0.5136962\ttotal: 546ms\tremaining: 13.6s\n",
      "27:\tlearn: 0.5092336\ttotal: 568ms\tremaining: 13.6s\n",
      "28:\tlearn: 0.5058859\ttotal: 590ms\tremaining: 13.7s\n",
      "29:\tlearn: 0.5014768\ttotal: 612ms\tremaining: 13.7s\n",
      "30:\tlearn: 0.4984516\ttotal: 635ms\tremaining: 13.7s\n",
      "31:\tlearn: 0.4945847\ttotal: 658ms\tremaining: 13.7s\n",
      "32:\tlearn: 0.4913346\ttotal: 679ms\tremaining: 13.7s\n",
      "33:\tlearn: 0.4880652\ttotal: 702ms\tremaining: 13.8s\n",
      "34:\tlearn: 0.4847612\ttotal: 723ms\tremaining: 13.7s\n",
      "35:\tlearn: 0.4820504\ttotal: 745ms\tremaining: 13.7s\n",
      "36:\tlearn: 0.4790654\ttotal: 766ms\tremaining: 13.7s\n",
      "37:\tlearn: 0.4761628\ttotal: 788ms\tremaining: 13.7s\n",
      "38:\tlearn: 0.4731579\ttotal: 809ms\tremaining: 13.7s\n",
      "39:\tlearn: 0.4708242\ttotal: 830ms\tremaining: 13.7s\n",
      "40:\tlearn: 0.4681116\ttotal: 854ms\tremaining: 13.7s\n",
      "41:\tlearn: 0.4649637\ttotal: 875ms\tremaining: 13.7s\n",
      "42:\tlearn: 0.4622686\ttotal: 900ms\tremaining: 13.7s\n",
      "43:\tlearn: 0.4602118\ttotal: 921ms\tremaining: 13.7s\n",
      "44:\tlearn: 0.4580264\ttotal: 943ms\tremaining: 13.7s\n",
      "45:\tlearn: 0.4562272\ttotal: 965ms\tremaining: 13.7s\n",
      "46:\tlearn: 0.4546798\ttotal: 987ms\tremaining: 13.7s\n",
      "47:\tlearn: 0.4520243\ttotal: 1.01s\tremaining: 13.8s\n",
      "48:\tlearn: 0.4494384\ttotal: 1.03s\tremaining: 13.8s\n",
      "49:\tlearn: 0.4478063\ttotal: 1.05s\tremaining: 13.7s\n",
      "50:\tlearn: 0.4457935\ttotal: 1.08s\tremaining: 13.7s\n",
      "51:\tlearn: 0.4438209\ttotal: 1.1s\tremaining: 13.7s\n",
      "52:\tlearn: 0.4423282\ttotal: 1.12s\tremaining: 13.7s\n",
      "53:\tlearn: 0.4401466\ttotal: 1.14s\tremaining: 13.6s\n",
      "54:\tlearn: 0.4377015\ttotal: 1.16s\tremaining: 13.6s\n",
      "55:\tlearn: 0.4362244\ttotal: 1.18s\tremaining: 13.6s\n",
      "56:\tlearn: 0.4346753\ttotal: 1.2s\tremaining: 13.6s\n",
      "57:\tlearn: 0.4335723\ttotal: 1.22s\tremaining: 13.5s\n",
      "58:\tlearn: 0.4317364\ttotal: 1.24s\tremaining: 13.5s\n",
      "59:\tlearn: 0.4307450\ttotal: 1.26s\tremaining: 13.5s\n",
      "60:\tlearn: 0.4289410\ttotal: 1.28s\tremaining: 13.4s\n",
      "61:\tlearn: 0.4263684\ttotal: 1.3s\tremaining: 13.4s\n",
      "62:\tlearn: 0.4244806\ttotal: 1.32s\tremaining: 13.4s\n",
      "63:\tlearn: 0.4234340\ttotal: 1.34s\tremaining: 13.4s\n",
      "64:\tlearn: 0.4220462\ttotal: 1.36s\tremaining: 13.3s\n",
      "65:\tlearn: 0.4206628\ttotal: 1.39s\tremaining: 13.3s\n",
      "66:\tlearn: 0.4189969\ttotal: 1.41s\tremaining: 13.3s\n",
      "67:\tlearn: 0.4174620\ttotal: 1.43s\tremaining: 13.3s\n",
      "68:\tlearn: 0.4161201\ttotal: 1.45s\tremaining: 13.2s\n",
      "69:\tlearn: 0.4151699\ttotal: 1.47s\tremaining: 13.2s\n",
      "70:\tlearn: 0.4138692\ttotal: 1.49s\tremaining: 13.2s\n",
      "71:\tlearn: 0.4126011\ttotal: 1.51s\tremaining: 13.2s\n",
      "72:\tlearn: 0.4116067\ttotal: 1.53s\tremaining: 13.2s\n",
      "73:\tlearn: 0.4100307\ttotal: 1.55s\tremaining: 13.2s\n",
      "74:\tlearn: 0.4087941\ttotal: 1.58s\tremaining: 13.1s\n",
      "75:\tlearn: 0.4078499\ttotal: 1.6s\tremaining: 13.1s\n",
      "76:\tlearn: 0.4067217\ttotal: 1.62s\tremaining: 13.1s\n",
      "77:\tlearn: 0.4050963\ttotal: 1.64s\tremaining: 13.1s\n",
      "78:\tlearn: 0.4036948\ttotal: 1.66s\tremaining: 13.1s\n",
      "79:\tlearn: 0.4027265\ttotal: 1.69s\tremaining: 13.1s\n",
      "80:\tlearn: 0.4017209\ttotal: 1.71s\tremaining: 13.1s\n",
      "81:\tlearn: 0.4007419\ttotal: 1.73s\tremaining: 13s\n",
      "82:\tlearn: 0.3997117\ttotal: 1.75s\tremaining: 13s\n",
      "83:\tlearn: 0.3983260\ttotal: 1.77s\tremaining: 13s\n",
      "84:\tlearn: 0.3974478\ttotal: 1.8s\tremaining: 13s\n",
      "85:\tlearn: 0.3965439\ttotal: 1.82s\tremaining: 13s\n",
      "86:\tlearn: 0.3952414\ttotal: 1.84s\tremaining: 12.9s\n",
      "87:\tlearn: 0.3941000\ttotal: 1.86s\tremaining: 12.9s\n",
      "88:\tlearn: 0.3930090\ttotal: 1.88s\tremaining: 12.9s\n",
      "89:\tlearn: 0.3917832\ttotal: 1.9s\tremaining: 12.9s\n",
      "90:\tlearn: 0.3907137\ttotal: 1.92s\tremaining: 12.9s\n",
      "91:\tlearn: 0.3900854\ttotal: 1.94s\tremaining: 12.8s\n",
      "92:\tlearn: 0.3892869\ttotal: 1.96s\tremaining: 12.8s\n",
      "93:\tlearn: 0.3887001\ttotal: 1.98s\tremaining: 12.8s\n",
      "94:\tlearn: 0.3877973\ttotal: 2s\tremaining: 12.8s\n",
      "95:\tlearn: 0.3869668\ttotal: 2.03s\tremaining: 12.7s\n",
      "96:\tlearn: 0.3859967\ttotal: 2.05s\tremaining: 12.7s\n",
      "97:\tlearn: 0.3848411\ttotal: 2.07s\tremaining: 12.7s\n",
      "98:\tlearn: 0.3838293\ttotal: 2.09s\tremaining: 12.7s\n",
      "99:\tlearn: 0.3826762\ttotal: 2.11s\tremaining: 12.7s\n",
      "100:\tlearn: 0.3819125\ttotal: 2.13s\tremaining: 12.6s\n",
      "101:\tlearn: 0.3810022\ttotal: 2.15s\tremaining: 12.6s\n",
      "102:\tlearn: 0.3800977\ttotal: 2.17s\tremaining: 12.6s\n",
      "103:\tlearn: 0.3792165\ttotal: 2.19s\tremaining: 12.6s\n",
      "104:\tlearn: 0.3783921\ttotal: 2.21s\tremaining: 12.5s\n",
      "105:\tlearn: 0.3773797\ttotal: 2.23s\tremaining: 12.5s\n",
      "106:\tlearn: 0.3768185\ttotal: 2.25s\tremaining: 12.5s\n",
      "107:\tlearn: 0.3758830\ttotal: 2.27s\tremaining: 12.5s\n",
      "108:\tlearn: 0.3750261\ttotal: 2.29s\tremaining: 12.4s\n",
      "109:\tlearn: 0.3741958\ttotal: 2.31s\tremaining: 12.4s\n",
      "110:\tlearn: 0.3737028\ttotal: 2.33s\tremaining: 12.4s\n",
      "111:\tlearn: 0.3733129\ttotal: 2.35s\tremaining: 12.4s\n",
      "112:\tlearn: 0.3723398\ttotal: 2.37s\tremaining: 12.3s\n",
      "113:\tlearn: 0.3717767\ttotal: 2.39s\tremaining: 12.3s\n",
      "114:\tlearn: 0.3708796\ttotal: 2.41s\tremaining: 12.3s\n",
      "115:\tlearn: 0.3700782\ttotal: 2.44s\tremaining: 12.3s\n",
      "116:\tlearn: 0.3693553\ttotal: 2.46s\tremaining: 12.2s\n",
      "117:\tlearn: 0.3687730\ttotal: 2.48s\tremaining: 12.2s\n",
      "118:\tlearn: 0.3683750\ttotal: 2.5s\tremaining: 12.2s\n",
      "119:\tlearn: 0.3676107\ttotal: 2.52s\tremaining: 12.2s\n",
      "120:\tlearn: 0.3664734\ttotal: 2.55s\tremaining: 12.2s\n",
      "121:\tlearn: 0.3659384\ttotal: 2.57s\tremaining: 12.2s\n",
      "122:\tlearn: 0.3653855\ttotal: 2.59s\tremaining: 12.1s\n",
      "123:\tlearn: 0.3643704\ttotal: 2.61s\tremaining: 12.1s\n",
      "124:\tlearn: 0.3632383\ttotal: 2.63s\tremaining: 12.1s\n",
      "125:\tlearn: 0.3625364\ttotal: 2.65s\tremaining: 12.1s\n",
      "126:\tlearn: 0.3618371\ttotal: 2.67s\tremaining: 12s\n",
      "127:\tlearn: 0.3611869\ttotal: 2.69s\tremaining: 12s\n",
      "128:\tlearn: 0.3604762\ttotal: 2.71s\tremaining: 12s\n",
      "129:\tlearn: 0.3595874\ttotal: 2.73s\tremaining: 12s\n",
      "130:\tlearn: 0.3588969\ttotal: 2.75s\tremaining: 12s\n",
      "131:\tlearn: 0.3582081\ttotal: 2.77s\tremaining: 11.9s\n",
      "132:\tlearn: 0.3576231\ttotal: 2.79s\tremaining: 11.9s\n",
      "133:\tlearn: 0.3567104\ttotal: 2.81s\tremaining: 11.9s\n",
      "134:\tlearn: 0.3560416\ttotal: 2.83s\tremaining: 11.9s\n",
      "135:\tlearn: 0.3556042\ttotal: 2.85s\tremaining: 11.8s\n",
      "136:\tlearn: 0.3551118\ttotal: 2.87s\tremaining: 11.8s\n",
      "137:\tlearn: 0.3545553\ttotal: 2.89s\tremaining: 11.8s\n",
      "138:\tlearn: 0.3537908\ttotal: 2.91s\tremaining: 11.8s\n",
      "139:\tlearn: 0.3532624\ttotal: 2.93s\tremaining: 11.7s\n",
      "140:\tlearn: 0.3528806\ttotal: 2.96s\tremaining: 11.7s\n",
      "141:\tlearn: 0.3522529\ttotal: 2.98s\tremaining: 11.7s\n",
      "142:\tlearn: 0.3516768\ttotal: 3s\tremaining: 11.7s\n",
      "143:\tlearn: 0.3516053\ttotal: 3.01s\tremaining: 11.6s\n",
      "144:\tlearn: 0.3512821\ttotal: 3.03s\tremaining: 11.6s\n",
      "145:\tlearn: 0.3507839\ttotal: 3.05s\tremaining: 11.6s\n",
      "146:\tlearn: 0.3501290\ttotal: 3.07s\tremaining: 11.5s\n",
      "147:\tlearn: 0.3497250\ttotal: 3.1s\tremaining: 11.5s\n",
      "148:\tlearn: 0.3488913\ttotal: 3.12s\tremaining: 11.5s\n",
      "149:\tlearn: 0.3479790\ttotal: 3.14s\tremaining: 11.5s\n",
      "150:\tlearn: 0.3471145\ttotal: 3.16s\tremaining: 11.5s\n",
      "151:\tlearn: 0.3464753\ttotal: 3.18s\tremaining: 11.5s\n",
      "152:\tlearn: 0.3464430\ttotal: 3.19s\tremaining: 11.4s\n",
      "153:\tlearn: 0.3457805\ttotal: 3.21s\tremaining: 11.4s\n",
      "154:\tlearn: 0.3453485\ttotal: 3.23s\tremaining: 11.4s\n",
      "155:\tlearn: 0.3446591\ttotal: 3.25s\tremaining: 11.3s\n",
      "156:\tlearn: 0.3440651\ttotal: 3.27s\tremaining: 11.3s\n",
      "157:\tlearn: 0.3436314\ttotal: 3.29s\tremaining: 11.3s\n",
      "158:\tlearn: 0.3432745\ttotal: 3.31s\tremaining: 11.3s\n",
      "159:\tlearn: 0.3425888\ttotal: 3.33s\tremaining: 11.3s\n",
      "160:\tlearn: 0.3421620\ttotal: 3.35s\tremaining: 11.2s\n",
      "161:\tlearn: 0.3415598\ttotal: 3.38s\tremaining: 11.2s\n",
      "162:\tlearn: 0.3411704\ttotal: 3.4s\tremaining: 11.2s\n",
      "163:\tlearn: 0.3407216\ttotal: 3.42s\tremaining: 11.2s\n",
      "164:\tlearn: 0.3401956\ttotal: 3.44s\tremaining: 11.1s\n",
      "165:\tlearn: 0.3396932\ttotal: 3.46s\tremaining: 11.1s\n",
      "166:\tlearn: 0.3392790\ttotal: 3.48s\tremaining: 11.1s\n",
      "167:\tlearn: 0.3389765\ttotal: 3.5s\tremaining: 11.1s\n",
      "168:\tlearn: 0.3386263\ttotal: 3.52s\tremaining: 11.1s\n",
      "169:\tlearn: 0.3380967\ttotal: 3.54s\tremaining: 11s\n",
      "170:\tlearn: 0.3374880\ttotal: 3.56s\tremaining: 11s\n",
      "171:\tlearn: 0.3369975\ttotal: 3.58s\tremaining: 11s\n",
      "172:\tlearn: 0.3365151\ttotal: 3.6s\tremaining: 11s\n",
      "173:\tlearn: 0.3361547\ttotal: 3.62s\tremaining: 11s\n",
      "174:\tlearn: 0.3354969\ttotal: 3.64s\tremaining: 10.9s\n",
      "175:\tlearn: 0.3350096\ttotal: 3.66s\tremaining: 10.9s\n",
      "176:\tlearn: 0.3345658\ttotal: 3.68s\tremaining: 10.9s\n",
      "177:\tlearn: 0.3342077\ttotal: 3.71s\tremaining: 10.9s\n",
      "178:\tlearn: 0.3333973\ttotal: 3.73s\tremaining: 10.8s\n",
      "179:\tlearn: 0.3328574\ttotal: 3.75s\tremaining: 10.8s\n",
      "180:\tlearn: 0.3323359\ttotal: 3.77s\tremaining: 10.8s\n",
      "181:\tlearn: 0.3317659\ttotal: 3.79s\tremaining: 10.8s\n",
      "182:\tlearn: 0.3312065\ttotal: 3.81s\tremaining: 10.8s\n",
      "183:\tlearn: 0.3306222\ttotal: 3.83s\tremaining: 10.7s\n",
      "184:\tlearn: 0.3302339\ttotal: 3.85s\tremaining: 10.7s\n",
      "185:\tlearn: 0.3297614\ttotal: 3.87s\tremaining: 10.7s\n",
      "186:\tlearn: 0.3294698\ttotal: 3.89s\tremaining: 10.7s\n",
      "187:\tlearn: 0.3287508\ttotal: 3.91s\tremaining: 10.7s\n",
      "188:\tlearn: 0.3283392\ttotal: 3.93s\tremaining: 10.6s\n",
      "189:\tlearn: 0.3277202\ttotal: 3.96s\tremaining: 10.6s\n",
      "190:\tlearn: 0.3271006\ttotal: 3.98s\tremaining: 10.6s\n",
      "191:\tlearn: 0.3267422\ttotal: 4s\tremaining: 10.6s\n",
      "192:\tlearn: 0.3263373\ttotal: 4.02s\tremaining: 10.6s\n",
      "193:\tlearn: 0.3257891\ttotal: 4.04s\tremaining: 10.6s\n",
      "194:\tlearn: 0.3252719\ttotal: 4.07s\tremaining: 10.5s\n",
      "195:\tlearn: 0.3246827\ttotal: 4.09s\tremaining: 10.5s\n",
      "196:\tlearn: 0.3239124\ttotal: 4.11s\tremaining: 10.5s\n",
      "197:\tlearn: 0.3232148\ttotal: 4.13s\tremaining: 10.5s\n",
      "198:\tlearn: 0.3228326\ttotal: 4.15s\tremaining: 10.4s\n",
      "199:\tlearn: 0.3221357\ttotal: 4.17s\tremaining: 10.4s\n",
      "200:\tlearn: 0.3214407\ttotal: 4.19s\tremaining: 10.4s\n",
      "201:\tlearn: 0.3207533\ttotal: 4.21s\tremaining: 10.4s\n",
      "202:\tlearn: 0.3202186\ttotal: 4.23s\tremaining: 10.4s\n",
      "203:\tlearn: 0.3196453\ttotal: 4.25s\tremaining: 10.3s\n",
      "204:\tlearn: 0.3192152\ttotal: 4.27s\tremaining: 10.3s\n",
      "205:\tlearn: 0.3187559\ttotal: 4.29s\tremaining: 10.3s\n",
      "206:\tlearn: 0.3180720\ttotal: 4.31s\tremaining: 10.3s\n",
      "207:\tlearn: 0.3176923\ttotal: 4.33s\tremaining: 10.3s\n",
      "208:\tlearn: 0.3173774\ttotal: 4.35s\tremaining: 10.2s\n",
      "209:\tlearn: 0.3169843\ttotal: 4.37s\tremaining: 10.2s\n",
      "210:\tlearn: 0.3166061\ttotal: 4.39s\tremaining: 10.2s\n",
      "211:\tlearn: 0.3162439\ttotal: 4.42s\tremaining: 10.2s\n",
      "212:\tlearn: 0.3156480\ttotal: 4.44s\tremaining: 10.1s\n",
      "213:\tlearn: 0.3150548\ttotal: 4.46s\tremaining: 10.1s\n",
      "214:\tlearn: 0.3148837\ttotal: 4.48s\tremaining: 10.1s\n",
      "215:\tlearn: 0.3144964\ttotal: 4.5s\tremaining: 10.1s\n",
      "216:\tlearn: 0.3139474\ttotal: 4.52s\tremaining: 10.1s\n",
      "217:\tlearn: 0.3135059\ttotal: 4.54s\tremaining: 10s\n",
      "218:\tlearn: 0.3130591\ttotal: 4.56s\tremaining: 10s\n",
      "219:\tlearn: 0.3125556\ttotal: 4.58s\tremaining: 10s\n",
      "220:\tlearn: 0.3120769\ttotal: 4.6s\tremaining: 9.98s\n",
      "221:\tlearn: 0.3115347\ttotal: 4.62s\tremaining: 9.96s\n",
      "222:\tlearn: 0.3112124\ttotal: 4.64s\tremaining: 9.94s\n",
      "223:\tlearn: 0.3108070\ttotal: 4.67s\tremaining: 9.91s\n",
      "224:\tlearn: 0.3104919\ttotal: 4.68s\tremaining: 9.89s\n",
      "225:\tlearn: 0.3104011\ttotal: 4.7s\tremaining: 9.86s\n",
      "226:\tlearn: 0.3095717\ttotal: 4.72s\tremaining: 9.84s\n",
      "227:\tlearn: 0.3091793\ttotal: 4.74s\tremaining: 9.81s\n",
      "228:\tlearn: 0.3085508\ttotal: 4.76s\tremaining: 9.79s\n",
      "229:\tlearn: 0.3078211\ttotal: 4.78s\tremaining: 9.77s\n",
      "230:\tlearn: 0.3074051\ttotal: 4.8s\tremaining: 9.75s\n",
      "231:\tlearn: 0.3066613\ttotal: 4.82s\tremaining: 9.73s\n",
      "232:\tlearn: 0.3063315\ttotal: 4.84s\tremaining: 9.71s\n",
      "233:\tlearn: 0.3057249\ttotal: 4.87s\tremaining: 9.69s\n",
      "234:\tlearn: 0.3053775\ttotal: 4.89s\tremaining: 9.67s\n",
      "235:\tlearn: 0.3049474\ttotal: 4.91s\tremaining: 9.65s\n",
      "236:\tlearn: 0.3043592\ttotal: 4.93s\tremaining: 9.63s\n",
      "237:\tlearn: 0.3042206\ttotal: 4.95s\tremaining: 9.6s\n",
      "238:\tlearn: 0.3035798\ttotal: 4.97s\tremaining: 9.59s\n",
      "239:\tlearn: 0.3033219\ttotal: 4.99s\tremaining: 9.57s\n",
      "240:\tlearn: 0.3031872\ttotal: 5.01s\tremaining: 9.54s\n",
      "241:\tlearn: 0.3026959\ttotal: 5.03s\tremaining: 9.52s\n",
      "242:\tlearn: 0.3024145\ttotal: 5.05s\tremaining: 9.5s\n",
      "243:\tlearn: 0.3018361\ttotal: 5.07s\tremaining: 9.48s\n",
      "244:\tlearn: 0.3014883\ttotal: 5.09s\tremaining: 9.46s\n",
      "245:\tlearn: 0.3009770\ttotal: 5.11s\tremaining: 9.44s\n",
      "246:\tlearn: 0.3009206\ttotal: 5.12s\tremaining: 9.4s\n",
      "247:\tlearn: 0.3003596\ttotal: 5.14s\tremaining: 9.38s\n",
      "248:\tlearn: 0.2998788\ttotal: 5.17s\tremaining: 9.36s\n",
      "249:\tlearn: 0.2995085\ttotal: 5.19s\tremaining: 9.34s\n",
      "250:\tlearn: 0.2993544\ttotal: 5.21s\tremaining: 9.31s\n",
      "251:\tlearn: 0.2990299\ttotal: 5.23s\tremaining: 9.29s\n",
      "252:\tlearn: 0.2985080\ttotal: 5.25s\tremaining: 9.27s\n",
      "253:\tlearn: 0.2983007\ttotal: 5.27s\tremaining: 9.25s\n",
      "254:\tlearn: 0.2980166\ttotal: 5.29s\tremaining: 9.23s\n",
      "255:\tlearn: 0.2976892\ttotal: 5.31s\tremaining: 9.21s\n",
      "256:\tlearn: 0.2972125\ttotal: 5.33s\tremaining: 9.19s\n",
      "257:\tlearn: 0.2969842\ttotal: 5.35s\tremaining: 9.16s\n",
      "258:\tlearn: 0.2965605\ttotal: 5.37s\tremaining: 9.14s\n",
      "259:\tlearn: 0.2960201\ttotal: 5.39s\tremaining: 9.12s\n",
      "260:\tlearn: 0.2956427\ttotal: 5.41s\tremaining: 9.1s\n",
      "261:\tlearn: 0.2952403\ttotal: 5.43s\tremaining: 9.08s\n",
      "262:\tlearn: 0.2950676\ttotal: 5.45s\tremaining: 9.06s\n",
      "263:\tlearn: 0.2946895\ttotal: 5.47s\tremaining: 9.04s\n",
      "264:\tlearn: 0.2940452\ttotal: 5.5s\tremaining: 9.03s\n",
      "265:\tlearn: 0.2934864\ttotal: 5.52s\tremaining: 9.01s\n",
      "266:\tlearn: 0.2929397\ttotal: 5.54s\tremaining: 8.99s\n",
      "267:\tlearn: 0.2924912\ttotal: 5.57s\tremaining: 8.97s\n",
      "268:\tlearn: 0.2920783\ttotal: 5.59s\tremaining: 8.95s\n",
      "269:\tlearn: 0.2914778\ttotal: 5.61s\tremaining: 8.93s\n",
      "270:\tlearn: 0.2910447\ttotal: 5.63s\tremaining: 8.91s\n",
      "271:\tlearn: 0.2907056\ttotal: 5.65s\tremaining: 8.89s\n",
      "272:\tlearn: 0.2904756\ttotal: 5.67s\tremaining: 8.87s\n",
      "273:\tlearn: 0.2902299\ttotal: 5.69s\tremaining: 8.85s\n",
      "274:\tlearn: 0.2897736\ttotal: 5.71s\tremaining: 8.82s\n",
      "275:\tlearn: 0.2894539\ttotal: 5.73s\tremaining: 8.8s\n",
      "276:\tlearn: 0.2889945\ttotal: 5.75s\tremaining: 8.78s\n",
      "277:\tlearn: 0.2887235\ttotal: 5.77s\tremaining: 8.76s\n",
      "278:\tlearn: 0.2881576\ttotal: 5.79s\tremaining: 8.74s\n",
      "279:\tlearn: 0.2878500\ttotal: 5.81s\tremaining: 8.72s\n",
      "280:\tlearn: 0.2878229\ttotal: 5.82s\tremaining: 8.68s\n",
      "281:\tlearn: 0.2874979\ttotal: 5.84s\tremaining: 8.66s\n",
      "282:\tlearn: 0.2871010\ttotal: 5.86s\tremaining: 8.64s\n",
      "283:\tlearn: 0.2870869\ttotal: 5.87s\tremaining: 8.6s\n",
      "284:\tlearn: 0.2868294\ttotal: 5.89s\tremaining: 8.58s\n",
      "285:\tlearn: 0.2865180\ttotal: 5.91s\tremaining: 8.56s\n",
      "286:\tlearn: 0.2862772\ttotal: 5.93s\tremaining: 8.54s\n",
      "287:\tlearn: 0.2859116\ttotal: 5.96s\tremaining: 8.52s\n",
      "288:\tlearn: 0.2855763\ttotal: 5.98s\tremaining: 8.5s\n",
      "289:\tlearn: 0.2851194\ttotal: 6s\tremaining: 8.48s\n",
      "290:\tlearn: 0.2848796\ttotal: 6.02s\tremaining: 8.46s\n",
      "291:\tlearn: 0.2846032\ttotal: 6.04s\tremaining: 8.44s\n",
      "292:\tlearn: 0.2842301\ttotal: 6.06s\tremaining: 8.42s\n",
      "293:\tlearn: 0.2837953\ttotal: 6.08s\tremaining: 8.4s\n",
      "294:\tlearn: 0.2836113\ttotal: 6.1s\tremaining: 8.38s\n",
      "295:\tlearn: 0.2832912\ttotal: 6.12s\tremaining: 8.36s\n",
      "296:\tlearn: 0.2829937\ttotal: 6.14s\tremaining: 8.34s\n",
      "297:\tlearn: 0.2824661\ttotal: 6.16s\tremaining: 8.32s\n",
      "298:\tlearn: 0.2821069\ttotal: 6.18s\tremaining: 8.29s\n",
      "299:\tlearn: 0.2818277\ttotal: 6.2s\tremaining: 8.27s\n",
      "300:\tlearn: 0.2815863\ttotal: 6.22s\tremaining: 8.25s\n",
      "301:\tlearn: 0.2809679\ttotal: 6.25s\tremaining: 8.23s\n",
      "302:\tlearn: 0.2803635\ttotal: 6.27s\tremaining: 8.21s\n",
      "303:\tlearn: 0.2801390\ttotal: 6.29s\tremaining: 8.19s\n",
      "304:\tlearn: 0.2796527\ttotal: 6.31s\tremaining: 8.17s\n",
      "305:\tlearn: 0.2789472\ttotal: 6.33s\tremaining: 8.15s\n",
      "306:\tlearn: 0.2782913\ttotal: 6.35s\tremaining: 8.13s\n",
      "307:\tlearn: 0.2779715\ttotal: 6.37s\tremaining: 8.11s\n",
      "308:\tlearn: 0.2777630\ttotal: 6.39s\tremaining: 8.09s\n",
      "309:\tlearn: 0.2774724\ttotal: 6.41s\tremaining: 8.07s\n",
      "310:\tlearn: 0.2770606\ttotal: 6.43s\tremaining: 8.05s\n",
      "311:\tlearn: 0.2766981\ttotal: 6.46s\tremaining: 8.03s\n",
      "312:\tlearn: 0.2764706\ttotal: 6.48s\tremaining: 8.01s\n",
      "313:\tlearn: 0.2761680\ttotal: 6.5s\tremaining: 7.99s\n",
      "314:\tlearn: 0.2758028\ttotal: 6.52s\tremaining: 7.97s\n",
      "315:\tlearn: 0.2753446\ttotal: 6.54s\tremaining: 7.95s\n",
      "316:\tlearn: 0.2751672\ttotal: 6.56s\tremaining: 7.93s\n",
      "317:\tlearn: 0.2747830\ttotal: 6.58s\tremaining: 7.91s\n",
      "318:\tlearn: 0.2745178\ttotal: 6.6s\tremaining: 7.88s\n",
      "319:\tlearn: 0.2743006\ttotal: 6.62s\tremaining: 7.86s\n",
      "320:\tlearn: 0.2740452\ttotal: 6.64s\tremaining: 7.84s\n",
      "321:\tlearn: 0.2736800\ttotal: 6.66s\tremaining: 7.82s\n",
      "322:\tlearn: 0.2732696\ttotal: 6.68s\tremaining: 7.8s\n",
      "323:\tlearn: 0.2728717\ttotal: 6.7s\tremaining: 7.78s\n",
      "324:\tlearn: 0.2725141\ttotal: 6.72s\tremaining: 7.76s\n",
      "325:\tlearn: 0.2722457\ttotal: 6.75s\tremaining: 7.74s\n",
      "326:\tlearn: 0.2718993\ttotal: 6.77s\tremaining: 7.72s\n",
      "327:\tlearn: 0.2712960\ttotal: 6.79s\tremaining: 7.7s\n",
      "328:\tlearn: 0.2710305\ttotal: 6.81s\tremaining: 7.68s\n",
      "329:\tlearn: 0.2707544\ttotal: 6.83s\tremaining: 7.66s\n",
      "330:\tlearn: 0.2702277\ttotal: 6.85s\tremaining: 7.63s\n",
      "331:\tlearn: 0.2699021\ttotal: 6.87s\tremaining: 7.61s\n",
      "332:\tlearn: 0.2694707\ttotal: 6.89s\tremaining: 7.59s\n",
      "333:\tlearn: 0.2690401\ttotal: 6.91s\tremaining: 7.57s\n",
      "334:\tlearn: 0.2686476\ttotal: 6.93s\tremaining: 7.55s\n",
      "335:\tlearn: 0.2683587\ttotal: 6.96s\tremaining: 7.54s\n",
      "336:\tlearn: 0.2681742\ttotal: 6.99s\tremaining: 7.53s\n",
      "337:\tlearn: 0.2678105\ttotal: 7.01s\tremaining: 7.51s\n",
      "338:\tlearn: 0.2676680\ttotal: 7.03s\tremaining: 7.49s\n",
      "339:\tlearn: 0.2673691\ttotal: 7.05s\tremaining: 7.47s\n",
      "340:\tlearn: 0.2670232\ttotal: 7.07s\tremaining: 7.45s\n",
      "341:\tlearn: 0.2668007\ttotal: 7.09s\tremaining: 7.42s\n",
      "342:\tlearn: 0.2664259\ttotal: 7.11s\tremaining: 7.4s\n",
      "343:\tlearn: 0.2659576\ttotal: 7.13s\tremaining: 7.38s\n",
      "344:\tlearn: 0.2655052\ttotal: 7.15s\tremaining: 7.36s\n",
      "345:\tlearn: 0.2651203\ttotal: 7.17s\tremaining: 7.34s\n",
      "346:\tlearn: 0.2647325\ttotal: 7.2s\tremaining: 7.32s\n",
      "347:\tlearn: 0.2644428\ttotal: 7.22s\tremaining: 7.3s\n",
      "348:\tlearn: 0.2640371\ttotal: 7.24s\tremaining: 7.28s\n",
      "349:\tlearn: 0.2639229\ttotal: 7.26s\tremaining: 7.26s\n",
      "350:\tlearn: 0.2635410\ttotal: 7.28s\tremaining: 7.24s\n",
      "351:\tlearn: 0.2633273\ttotal: 7.3s\tremaining: 7.21s\n",
      "352:\tlearn: 0.2630233\ttotal: 7.32s\tremaining: 7.19s\n",
      "353:\tlearn: 0.2626148\ttotal: 7.34s\tremaining: 7.17s\n",
      "354:\tlearn: 0.2623042\ttotal: 7.36s\tremaining: 7.15s\n",
      "355:\tlearn: 0.2619557\ttotal: 7.38s\tremaining: 7.13s\n",
      "356:\tlearn: 0.2615117\ttotal: 7.4s\tremaining: 7.11s\n",
      "357:\tlearn: 0.2611760\ttotal: 7.42s\tremaining: 7.09s\n",
      "358:\tlearn: 0.2608472\ttotal: 7.44s\tremaining: 7.07s\n",
      "359:\tlearn: 0.2604313\ttotal: 7.46s\tremaining: 7.05s\n",
      "360:\tlearn: 0.2602558\ttotal: 7.49s\tremaining: 7.03s\n",
      "361:\tlearn: 0.2599457\ttotal: 7.51s\tremaining: 7.01s\n",
      "362:\tlearn: 0.2592854\ttotal: 7.53s\tremaining: 6.99s\n",
      "363:\tlearn: 0.2590069\ttotal: 7.55s\tremaining: 6.97s\n",
      "364:\tlearn: 0.2587068\ttotal: 7.57s\tremaining: 6.95s\n",
      "365:\tlearn: 0.2583541\ttotal: 7.59s\tremaining: 6.92s\n",
      "366:\tlearn: 0.2579217\ttotal: 7.61s\tremaining: 6.9s\n",
      "367:\tlearn: 0.2576239\ttotal: 7.63s\tremaining: 6.88s\n",
      "368:\tlearn: 0.2571680\ttotal: 7.65s\tremaining: 6.86s\n",
      "369:\tlearn: 0.2568475\ttotal: 7.67s\tremaining: 6.84s\n",
      "370:\tlearn: 0.2566164\ttotal: 7.69s\tremaining: 6.82s\n",
      "371:\tlearn: 0.2563163\ttotal: 7.71s\tremaining: 6.8s\n",
      "372:\tlearn: 0.2559829\ttotal: 7.73s\tremaining: 6.78s\n",
      "373:\tlearn: 0.2556875\ttotal: 7.75s\tremaining: 6.76s\n",
      "374:\tlearn: 0.2552337\ttotal: 7.77s\tremaining: 6.74s\n",
      "375:\tlearn: 0.2547884\ttotal: 7.79s\tremaining: 6.72s\n",
      "376:\tlearn: 0.2545085\ttotal: 7.81s\tremaining: 6.7s\n",
      "377:\tlearn: 0.2538856\ttotal: 7.83s\tremaining: 6.67s\n",
      "378:\tlearn: 0.2534811\ttotal: 7.86s\tremaining: 6.65s\n",
      "379:\tlearn: 0.2531358\ttotal: 7.88s\tremaining: 6.63s\n",
      "380:\tlearn: 0.2529229\ttotal: 7.9s\tremaining: 6.61s\n",
      "381:\tlearn: 0.2527131\ttotal: 7.92s\tremaining: 6.59s\n",
      "382:\tlearn: 0.2523729\ttotal: 7.94s\tremaining: 6.57s\n",
      "383:\tlearn: 0.2521659\ttotal: 7.96s\tremaining: 6.55s\n",
      "384:\tlearn: 0.2518756\ttotal: 7.98s\tremaining: 6.53s\n",
      "385:\tlearn: 0.2514734\ttotal: 8.01s\tremaining: 6.51s\n",
      "386:\tlearn: 0.2512079\ttotal: 8.03s\tremaining: 6.49s\n",
      "387:\tlearn: 0.2510459\ttotal: 8.05s\tremaining: 6.47s\n",
      "388:\tlearn: 0.2507908\ttotal: 8.07s\tremaining: 6.45s\n",
      "389:\tlearn: 0.2504194\ttotal: 8.09s\tremaining: 6.43s\n",
      "390:\tlearn: 0.2501399\ttotal: 8.11s\tremaining: 6.41s\n",
      "391:\tlearn: 0.2498694\ttotal: 8.13s\tremaining: 6.39s\n",
      "392:\tlearn: 0.2496755\ttotal: 8.15s\tremaining: 6.37s\n",
      "393:\tlearn: 0.2492787\ttotal: 8.17s\tremaining: 6.35s\n",
      "394:\tlearn: 0.2490195\ttotal: 8.19s\tremaining: 6.33s\n",
      "395:\tlearn: 0.2487389\ttotal: 8.21s\tremaining: 6.3s\n",
      "396:\tlearn: 0.2484193\ttotal: 8.23s\tremaining: 6.28s\n",
      "397:\tlearn: 0.2481142\ttotal: 8.25s\tremaining: 6.26s\n",
      "398:\tlearn: 0.2479580\ttotal: 8.27s\tremaining: 6.24s\n",
      "399:\tlearn: 0.2479207\ttotal: 8.29s\tremaining: 6.21s\n",
      "400:\tlearn: 0.2476599\ttotal: 8.31s\tremaining: 6.19s\n",
      "401:\tlearn: 0.2473405\ttotal: 8.33s\tremaining: 6.17s\n",
      "402:\tlearn: 0.2469445\ttotal: 8.35s\tremaining: 6.15s\n",
      "403:\tlearn: 0.2466099\ttotal: 8.37s\tremaining: 6.13s\n",
      "404:\tlearn: 0.2464045\ttotal: 8.39s\tremaining: 6.11s\n",
      "405:\tlearn: 0.2458839\ttotal: 8.41s\tremaining: 6.09s\n",
      "406:\tlearn: 0.2456687\ttotal: 8.43s\tremaining: 6.07s\n",
      "407:\tlearn: 0.2454414\ttotal: 8.45s\tremaining: 6.05s\n",
      "408:\tlearn: 0.2450101\ttotal: 8.48s\tremaining: 6.03s\n",
      "409:\tlearn: 0.2447256\ttotal: 8.5s\tremaining: 6.01s\n",
      "410:\tlearn: 0.2444283\ttotal: 8.52s\tremaining: 5.99s\n",
      "411:\tlearn: 0.2441935\ttotal: 8.54s\tremaining: 5.97s\n",
      "412:\tlearn: 0.2440032\ttotal: 8.56s\tremaining: 5.95s\n",
      "413:\tlearn: 0.2436768\ttotal: 8.58s\tremaining: 5.93s\n",
      "414:\tlearn: 0.2432197\ttotal: 8.6s\tremaining: 5.91s\n",
      "415:\tlearn: 0.2430405\ttotal: 8.62s\tremaining: 5.89s\n",
      "416:\tlearn: 0.2427317\ttotal: 8.64s\tremaining: 5.87s\n",
      "417:\tlearn: 0.2425334\ttotal: 8.66s\tremaining: 5.84s\n",
      "418:\tlearn: 0.2423774\ttotal: 8.68s\tremaining: 5.82s\n",
      "419:\tlearn: 0.2420912\ttotal: 8.7s\tremaining: 5.8s\n",
      "420:\tlearn: 0.2419060\ttotal: 8.72s\tremaining: 5.78s\n",
      "421:\tlearn: 0.2416710\ttotal: 8.74s\tremaining: 5.76s\n",
      "422:\tlearn: 0.2413749\ttotal: 8.77s\tremaining: 5.74s\n",
      "423:\tlearn: 0.2412062\ttotal: 8.79s\tremaining: 5.72s\n",
      "424:\tlearn: 0.2409585\ttotal: 8.81s\tremaining: 5.7s\n",
      "425:\tlearn: 0.2404987\ttotal: 8.83s\tremaining: 5.68s\n",
      "426:\tlearn: 0.2401799\ttotal: 8.85s\tremaining: 5.66s\n",
      "427:\tlearn: 0.2398903\ttotal: 8.87s\tremaining: 5.64s\n",
      "428:\tlearn: 0.2396534\ttotal: 8.89s\tremaining: 5.62s\n",
      "429:\tlearn: 0.2393230\ttotal: 8.91s\tremaining: 5.59s\n",
      "430:\tlearn: 0.2390296\ttotal: 8.93s\tremaining: 5.57s\n",
      "431:\tlearn: 0.2387391\ttotal: 8.95s\tremaining: 5.55s\n",
      "432:\tlearn: 0.2383841\ttotal: 8.97s\tremaining: 5.53s\n",
      "433:\tlearn: 0.2383670\ttotal: 8.99s\tremaining: 5.51s\n",
      "434:\tlearn: 0.2380287\ttotal: 9.01s\tremaining: 5.49s\n",
      "435:\tlearn: 0.2377965\ttotal: 9.02s\tremaining: 5.46s\n",
      "436:\tlearn: 0.2374316\ttotal: 9.04s\tremaining: 5.44s\n",
      "437:\tlearn: 0.2372716\ttotal: 9.06s\tremaining: 5.42s\n",
      "438:\tlearn: 0.2369792\ttotal: 9.09s\tremaining: 5.4s\n",
      "439:\tlearn: 0.2368333\ttotal: 9.11s\tremaining: 5.38s\n",
      "440:\tlearn: 0.2364079\ttotal: 9.13s\tremaining: 5.36s\n",
      "441:\tlearn: 0.2362764\ttotal: 9.15s\tremaining: 5.34s\n",
      "442:\tlearn: 0.2360670\ttotal: 9.17s\tremaining: 5.32s\n",
      "443:\tlearn: 0.2358168\ttotal: 9.19s\tremaining: 5.3s\n",
      "444:\tlearn: 0.2355453\ttotal: 9.21s\tremaining: 5.28s\n",
      "445:\tlearn: 0.2352556\ttotal: 9.23s\tremaining: 5.25s\n",
      "446:\tlearn: 0.2348051\ttotal: 9.25s\tremaining: 5.23s\n",
      "447:\tlearn: 0.2344766\ttotal: 9.27s\tremaining: 5.21s\n",
      "448:\tlearn: 0.2342088\ttotal: 9.29s\tremaining: 5.19s\n",
      "449:\tlearn: 0.2338992\ttotal: 9.31s\tremaining: 5.17s\n",
      "450:\tlearn: 0.2335316\ttotal: 9.33s\tremaining: 5.15s\n",
      "451:\tlearn: 0.2332181\ttotal: 9.35s\tremaining: 5.13s\n",
      "452:\tlearn: 0.2330307\ttotal: 9.37s\tremaining: 5.11s\n",
      "453:\tlearn: 0.2326718\ttotal: 9.39s\tremaining: 5.09s\n",
      "454:\tlearn: 0.2324131\ttotal: 9.41s\tremaining: 5.07s\n",
      "455:\tlearn: 0.2319666\ttotal: 9.44s\tremaining: 5.05s\n",
      "456:\tlearn: 0.2315602\ttotal: 9.46s\tremaining: 5.03s\n",
      "457:\tlearn: 0.2312364\ttotal: 9.48s\tremaining: 5.01s\n",
      "458:\tlearn: 0.2308271\ttotal: 9.5s\tremaining: 4.99s\n",
      "459:\tlearn: 0.2305057\ttotal: 9.52s\tremaining: 4.97s\n",
      "460:\tlearn: 0.2303174\ttotal: 9.54s\tremaining: 4.95s\n",
      "461:\tlearn: 0.2301316\ttotal: 9.56s\tremaining: 4.93s\n",
      "462:\tlearn: 0.2298851\ttotal: 9.58s\tremaining: 4.91s\n",
      "463:\tlearn: 0.2295158\ttotal: 9.6s\tremaining: 4.88s\n",
      "464:\tlearn: 0.2293298\ttotal: 9.62s\tremaining: 4.86s\n",
      "465:\tlearn: 0.2290704\ttotal: 9.64s\tremaining: 4.84s\n",
      "466:\tlearn: 0.2286874\ttotal: 9.66s\tremaining: 4.82s\n",
      "467:\tlearn: 0.2283845\ttotal: 9.69s\tremaining: 4.8s\n",
      "468:\tlearn: 0.2279456\ttotal: 9.71s\tremaining: 4.78s\n",
      "469:\tlearn: 0.2277110\ttotal: 9.73s\tremaining: 4.76s\n",
      "470:\tlearn: 0.2272330\ttotal: 9.75s\tremaining: 4.74s\n",
      "471:\tlearn: 0.2266961\ttotal: 9.77s\tremaining: 4.72s\n",
      "472:\tlearn: 0.2264171\ttotal: 9.79s\tremaining: 4.7s\n",
      "473:\tlearn: 0.2261518\ttotal: 9.81s\tremaining: 4.68s\n",
      "474:\tlearn: 0.2258268\ttotal: 9.83s\tremaining: 4.66s\n",
      "475:\tlearn: 0.2254002\ttotal: 9.85s\tremaining: 4.64s\n",
      "476:\tlearn: 0.2250549\ttotal: 9.87s\tremaining: 4.62s\n",
      "477:\tlearn: 0.2248375\ttotal: 9.89s\tremaining: 4.59s\n",
      "478:\tlearn: 0.2246251\ttotal: 9.91s\tremaining: 4.57s\n",
      "479:\tlearn: 0.2244688\ttotal: 9.94s\tremaining: 4.55s\n",
      "480:\tlearn: 0.2242737\ttotal: 9.96s\tremaining: 4.53s\n",
      "481:\tlearn: 0.2240889\ttotal: 9.98s\tremaining: 4.51s\n",
      "482:\tlearn: 0.2240548\ttotal: 9.99s\tremaining: 4.49s\n",
      "483:\tlearn: 0.2237136\ttotal: 10s\tremaining: 4.47s\n",
      "484:\tlearn: 0.2233300\ttotal: 10s\tremaining: 4.45s\n",
      "485:\tlearn: 0.2229842\ttotal: 10.1s\tremaining: 4.43s\n",
      "486:\tlearn: 0.2227234\ttotal: 10.1s\tremaining: 4.41s\n",
      "487:\tlearn: 0.2223618\ttotal: 10.1s\tremaining: 4.39s\n",
      "488:\tlearn: 0.2222157\ttotal: 10.1s\tremaining: 4.37s\n",
      "489:\tlearn: 0.2219965\ttotal: 10.1s\tremaining: 4.34s\n",
      "490:\tlearn: 0.2215989\ttotal: 10.2s\tremaining: 4.32s\n",
      "491:\tlearn: 0.2212302\ttotal: 10.2s\tremaining: 4.3s\n",
      "492:\tlearn: 0.2210655\ttotal: 10.2s\tremaining: 4.28s\n",
      "493:\tlearn: 0.2209021\ttotal: 10.2s\tremaining: 4.26s\n",
      "494:\tlearn: 0.2206938\ttotal: 10.2s\tremaining: 4.24s\n",
      "495:\tlearn: 0.2204909\ttotal: 10.3s\tremaining: 4.22s\n",
      "496:\tlearn: 0.2202502\ttotal: 10.3s\tremaining: 4.2s\n",
      "497:\tlearn: 0.2200022\ttotal: 10.3s\tremaining: 4.18s\n",
      "498:\tlearn: 0.2197035\ttotal: 10.3s\tremaining: 4.16s\n",
      "499:\tlearn: 0.2192605\ttotal: 10.3s\tremaining: 4.14s\n",
      "500:\tlearn: 0.2190034\ttotal: 10.4s\tremaining: 4.12s\n",
      "501:\tlearn: 0.2188098\ttotal: 10.4s\tremaining: 4.1s\n",
      "502:\tlearn: 0.2185234\ttotal: 10.4s\tremaining: 4.08s\n",
      "503:\tlearn: 0.2181061\ttotal: 10.4s\tremaining: 4.06s\n",
      "504:\tlearn: 0.2179263\ttotal: 10.5s\tremaining: 4.04s\n",
      "505:\tlearn: 0.2176277\ttotal: 10.5s\tremaining: 4.01s\n",
      "506:\tlearn: 0.2174675\ttotal: 10.5s\tremaining: 4s\n",
      "507:\tlearn: 0.2172436\ttotal: 10.5s\tremaining: 3.97s\n",
      "508:\tlearn: 0.2170225\ttotal: 10.5s\tremaining: 3.95s\n",
      "509:\tlearn: 0.2167623\ttotal: 10.6s\tremaining: 3.93s\n",
      "510:\tlearn: 0.2163535\ttotal: 10.6s\tremaining: 3.91s\n",
      "511:\tlearn: 0.2161016\ttotal: 10.6s\tremaining: 3.89s\n",
      "512:\tlearn: 0.2155397\ttotal: 10.6s\tremaining: 3.87s\n",
      "513:\tlearn: 0.2150236\ttotal: 10.6s\tremaining: 3.85s\n",
      "514:\tlearn: 0.2147499\ttotal: 10.7s\tremaining: 3.83s\n",
      "515:\tlearn: 0.2143951\ttotal: 10.7s\tremaining: 3.81s\n",
      "516:\tlearn: 0.2139827\ttotal: 10.7s\tremaining: 3.79s\n",
      "517:\tlearn: 0.2137098\ttotal: 10.7s\tremaining: 3.77s\n",
      "518:\tlearn: 0.2132085\ttotal: 10.8s\tremaining: 3.75s\n",
      "519:\tlearn: 0.2128696\ttotal: 10.8s\tremaining: 3.73s\n",
      "520:\tlearn: 0.2125973\ttotal: 10.8s\tremaining: 3.71s\n",
      "521:\tlearn: 0.2123403\ttotal: 10.8s\tremaining: 3.69s\n",
      "522:\tlearn: 0.2121597\ttotal: 10.8s\tremaining: 3.67s\n",
      "523:\tlearn: 0.2118840\ttotal: 10.9s\tremaining: 3.65s\n",
      "524:\tlearn: 0.2112659\ttotal: 10.9s\tremaining: 3.63s\n",
      "525:\tlearn: 0.2111491\ttotal: 10.9s\tremaining: 3.6s\n",
      "526:\tlearn: 0.2108224\ttotal: 10.9s\tremaining: 3.58s\n",
      "527:\tlearn: 0.2105211\ttotal: 10.9s\tremaining: 3.56s\n",
      "528:\tlearn: 0.2101760\ttotal: 11s\tremaining: 3.54s\n",
      "529:\tlearn: 0.2098140\ttotal: 11s\tremaining: 3.52s\n",
      "530:\tlearn: 0.2093733\ttotal: 11s\tremaining: 3.5s\n",
      "531:\tlearn: 0.2091854\ttotal: 11s\tremaining: 3.48s\n",
      "532:\tlearn: 0.2088230\ttotal: 11s\tremaining: 3.46s\n",
      "533:\tlearn: 0.2085090\ttotal: 11.1s\tremaining: 3.44s\n",
      "534:\tlearn: 0.2082249\ttotal: 11.1s\tremaining: 3.42s\n",
      "535:\tlearn: 0.2079005\ttotal: 11.1s\tremaining: 3.4s\n",
      "536:\tlearn: 0.2073131\ttotal: 11.1s\tremaining: 3.38s\n",
      "537:\tlearn: 0.2070466\ttotal: 11.2s\tremaining: 3.36s\n",
      "538:\tlearn: 0.2067873\ttotal: 11.2s\tremaining: 3.34s\n",
      "539:\tlearn: 0.2064885\ttotal: 11.2s\tremaining: 3.32s\n",
      "540:\tlearn: 0.2062447\ttotal: 11.2s\tremaining: 3.29s\n",
      "541:\tlearn: 0.2058406\ttotal: 11.2s\tremaining: 3.27s\n",
      "542:\tlearn: 0.2055626\ttotal: 11.3s\tremaining: 3.25s\n",
      "543:\tlearn: 0.2053706\ttotal: 11.3s\tremaining: 3.23s\n",
      "544:\tlearn: 0.2049680\ttotal: 11.3s\tremaining: 3.21s\n",
      "545:\tlearn: 0.2046476\ttotal: 11.3s\tremaining: 3.19s\n",
      "546:\tlearn: 0.2042836\ttotal: 11.3s\tremaining: 3.17s\n",
      "547:\tlearn: 0.2040630\ttotal: 11.4s\tremaining: 3.15s\n",
      "548:\tlearn: 0.2038613\ttotal: 11.4s\tremaining: 3.13s\n",
      "549:\tlearn: 0.2035972\ttotal: 11.4s\tremaining: 3.11s\n",
      "550:\tlearn: 0.2034417\ttotal: 11.4s\tremaining: 3.09s\n",
      "551:\tlearn: 0.2030291\ttotal: 11.4s\tremaining: 3.07s\n",
      "552:\tlearn: 0.2028534\ttotal: 11.5s\tremaining: 3.05s\n",
      "553:\tlearn: 0.2025620\ttotal: 11.5s\tremaining: 3.03s\n",
      "554:\tlearn: 0.2021849\ttotal: 11.5s\tremaining: 3.01s\n",
      "555:\tlearn: 0.2019953\ttotal: 11.5s\tremaining: 2.99s\n",
      "556:\tlearn: 0.2017569\ttotal: 11.6s\tremaining: 2.96s\n",
      "557:\tlearn: 0.2014626\ttotal: 11.6s\tremaining: 2.94s\n",
      "558:\tlearn: 0.2011296\ttotal: 11.6s\tremaining: 2.92s\n",
      "559:\tlearn: 0.2009717\ttotal: 11.6s\tremaining: 2.9s\n",
      "560:\tlearn: 0.2006559\ttotal: 11.6s\tremaining: 2.88s\n",
      "561:\tlearn: 0.2002807\ttotal: 11.7s\tremaining: 2.86s\n",
      "562:\tlearn: 0.1999134\ttotal: 11.7s\tremaining: 2.84s\n",
      "563:\tlearn: 0.1997340\ttotal: 11.7s\tremaining: 2.82s\n",
      "564:\tlearn: 0.1994071\ttotal: 11.7s\tremaining: 2.8s\n",
      "565:\tlearn: 0.1990685\ttotal: 11.7s\tremaining: 2.78s\n",
      "566:\tlearn: 0.1986320\ttotal: 11.8s\tremaining: 2.76s\n",
      "567:\tlearn: 0.1984629\ttotal: 11.8s\tremaining: 2.74s\n",
      "568:\tlearn: 0.1983018\ttotal: 11.8s\tremaining: 2.72s\n",
      "569:\tlearn: 0.1976280\ttotal: 11.8s\tremaining: 2.69s\n",
      "570:\tlearn: 0.1973232\ttotal: 11.8s\tremaining: 2.67s\n",
      "571:\tlearn: 0.1968851\ttotal: 11.9s\tremaining: 2.65s\n",
      "572:\tlearn: 0.1964785\ttotal: 11.9s\tremaining: 2.63s\n",
      "573:\tlearn: 0.1962227\ttotal: 11.9s\tremaining: 2.61s\n",
      "574:\tlearn: 0.1960253\ttotal: 11.9s\tremaining: 2.59s\n",
      "575:\tlearn: 0.1957404\ttotal: 11.9s\tremaining: 2.57s\n",
      "576:\tlearn: 0.1953202\ttotal: 12s\tremaining: 2.55s\n",
      "577:\tlearn: 0.1951033\ttotal: 12s\tremaining: 2.53s\n",
      "578:\tlearn: 0.1949448\ttotal: 12s\tremaining: 2.51s\n",
      "579:\tlearn: 0.1948132\ttotal: 12s\tremaining: 2.49s\n",
      "580:\tlearn: 0.1945522\ttotal: 12s\tremaining: 2.47s\n",
      "581:\tlearn: 0.1943179\ttotal: 12.1s\tremaining: 2.45s\n",
      "582:\tlearn: 0.1940105\ttotal: 12.1s\tremaining: 2.42s\n",
      "583:\tlearn: 0.1938337\ttotal: 12.1s\tremaining: 2.4s\n",
      "584:\tlearn: 0.1935137\ttotal: 12.1s\tremaining: 2.38s\n",
      "585:\tlearn: 0.1934118\ttotal: 12.1s\tremaining: 2.36s\n",
      "586:\tlearn: 0.1930143\ttotal: 12.2s\tremaining: 2.34s\n",
      "587:\tlearn: 0.1928877\ttotal: 12.2s\tremaining: 2.32s\n",
      "588:\tlearn: 0.1925530\ttotal: 12.2s\tremaining: 2.3s\n",
      "589:\tlearn: 0.1922172\ttotal: 12.2s\tremaining: 2.28s\n",
      "590:\tlearn: 0.1919475\ttotal: 12.3s\tremaining: 2.26s\n",
      "591:\tlearn: 0.1917459\ttotal: 12.3s\tremaining: 2.24s\n",
      "592:\tlearn: 0.1914670\ttotal: 12.3s\tremaining: 2.22s\n",
      "593:\tlearn: 0.1911484\ttotal: 12.3s\tremaining: 2.2s\n",
      "594:\tlearn: 0.1909929\ttotal: 12.3s\tremaining: 2.18s\n",
      "595:\tlearn: 0.1908274\ttotal: 12.4s\tremaining: 2.15s\n",
      "596:\tlearn: 0.1905299\ttotal: 12.4s\tremaining: 2.13s\n",
      "597:\tlearn: 0.1902959\ttotal: 12.4s\tremaining: 2.11s\n",
      "598:\tlearn: 0.1900567\ttotal: 12.4s\tremaining: 2.09s\n",
      "599:\tlearn: 0.1897727\ttotal: 12.4s\tremaining: 2.07s\n",
      "600:\tlearn: 0.1895718\ttotal: 12.5s\tremaining: 2.05s\n",
      "601:\tlearn: 0.1893353\ttotal: 12.5s\tremaining: 2.03s\n",
      "602:\tlearn: 0.1891302\ttotal: 12.5s\tremaining: 2.01s\n",
      "603:\tlearn: 0.1887776\ttotal: 12.5s\tremaining: 1.99s\n",
      "604:\tlearn: 0.1885225\ttotal: 12.5s\tremaining: 1.97s\n",
      "605:\tlearn: 0.1882310\ttotal: 12.6s\tremaining: 1.95s\n",
      "606:\tlearn: 0.1880097\ttotal: 12.6s\tremaining: 1.93s\n",
      "607:\tlearn: 0.1878498\ttotal: 12.6s\tremaining: 1.91s\n",
      "608:\tlearn: 0.1874558\ttotal: 12.6s\tremaining: 1.89s\n",
      "609:\tlearn: 0.1871581\ttotal: 12.6s\tremaining: 1.86s\n",
      "610:\tlearn: 0.1870262\ttotal: 12.7s\tremaining: 1.84s\n",
      "611:\tlearn: 0.1868003\ttotal: 12.7s\tremaining: 1.82s\n",
      "612:\tlearn: 0.1865674\ttotal: 12.7s\tremaining: 1.8s\n",
      "613:\tlearn: 0.1865120\ttotal: 12.7s\tremaining: 1.78s\n",
      "614:\tlearn: 0.1862574\ttotal: 12.7s\tremaining: 1.76s\n",
      "615:\tlearn: 0.1860707\ttotal: 12.8s\tremaining: 1.74s\n",
      "616:\tlearn: 0.1859134\ttotal: 12.8s\tremaining: 1.72s\n",
      "617:\tlearn: 0.1855797\ttotal: 12.8s\tremaining: 1.7s\n",
      "618:\tlearn: 0.1853004\ttotal: 12.8s\tremaining: 1.68s\n",
      "619:\tlearn: 0.1849416\ttotal: 12.8s\tremaining: 1.66s\n",
      "620:\tlearn: 0.1846218\ttotal: 12.9s\tremaining: 1.64s\n",
      "621:\tlearn: 0.1844772\ttotal: 12.9s\tremaining: 1.61s\n",
      "622:\tlearn: 0.1841815\ttotal: 12.9s\tremaining: 1.59s\n",
      "623:\tlearn: 0.1840035\ttotal: 12.9s\tremaining: 1.57s\n",
      "624:\tlearn: 0.1836418\ttotal: 12.9s\tremaining: 1.55s\n",
      "625:\tlearn: 0.1833171\ttotal: 13s\tremaining: 1.53s\n",
      "626:\tlearn: 0.1830961\ttotal: 13s\tremaining: 1.51s\n",
      "627:\tlearn: 0.1827470\ttotal: 13s\tremaining: 1.49s\n",
      "628:\tlearn: 0.1825666\ttotal: 13s\tremaining: 1.47s\n",
      "629:\tlearn: 0.1823272\ttotal: 13.1s\tremaining: 1.45s\n",
      "630:\tlearn: 0.1820690\ttotal: 13.1s\tremaining: 1.43s\n",
      "631:\tlearn: 0.1819128\ttotal: 13.1s\tremaining: 1.41s\n",
      "632:\tlearn: 0.1816804\ttotal: 13.1s\tremaining: 1.39s\n",
      "633:\tlearn: 0.1815096\ttotal: 13.1s\tremaining: 1.37s\n",
      "634:\tlearn: 0.1813254\ttotal: 13.2s\tremaining: 1.35s\n",
      "635:\tlearn: 0.1811327\ttotal: 13.2s\tremaining: 1.32s\n",
      "636:\tlearn: 0.1809822\ttotal: 13.2s\tremaining: 1.3s\n",
      "637:\tlearn: 0.1807296\ttotal: 13.2s\tremaining: 1.28s\n",
      "638:\tlearn: 0.1805221\ttotal: 13.2s\tremaining: 1.26s\n",
      "639:\tlearn: 0.1802992\ttotal: 13.3s\tremaining: 1.24s\n",
      "640:\tlearn: 0.1799674\ttotal: 13.3s\tremaining: 1.22s\n",
      "641:\tlearn: 0.1798624\ttotal: 13.3s\tremaining: 1.2s\n",
      "642:\tlearn: 0.1796697\ttotal: 13.3s\tremaining: 1.18s\n",
      "643:\tlearn: 0.1793231\ttotal: 13.3s\tremaining: 1.16s\n",
      "644:\tlearn: 0.1791315\ttotal: 13.4s\tremaining: 1.14s\n",
      "645:\tlearn: 0.1787295\ttotal: 13.4s\tremaining: 1.12s\n",
      "646:\tlearn: 0.1785975\ttotal: 13.4s\tremaining: 1.1s\n",
      "647:\tlearn: 0.1783451\ttotal: 13.4s\tremaining: 1.08s\n",
      "648:\tlearn: 0.1780179\ttotal: 13.4s\tremaining: 1.06s\n",
      "649:\tlearn: 0.1778993\ttotal: 13.5s\tremaining: 1.03s\n",
      "650:\tlearn: 0.1775314\ttotal: 13.5s\tremaining: 1.01s\n",
      "651:\tlearn: 0.1773517\ttotal: 13.5s\tremaining: 994ms\n",
      "652:\tlearn: 0.1771300\ttotal: 13.5s\tremaining: 973ms\n",
      "653:\tlearn: 0.1768567\ttotal: 13.5s\tremaining: 953ms\n",
      "654:\tlearn: 0.1764824\ttotal: 13.6s\tremaining: 932ms\n",
      "655:\tlearn: 0.1762273\ttotal: 13.6s\tremaining: 911ms\n",
      "656:\tlearn: 0.1760272\ttotal: 13.6s\tremaining: 890ms\n",
      "657:\tlearn: 0.1756709\ttotal: 13.6s\tremaining: 870ms\n",
      "658:\tlearn: 0.1755283\ttotal: 13.6s\tremaining: 849ms\n",
      "659:\tlearn: 0.1752406\ttotal: 13.7s\tremaining: 828ms\n",
      "660:\tlearn: 0.1749958\ttotal: 13.7s\tremaining: 807ms\n",
      "661:\tlearn: 0.1747507\ttotal: 13.7s\tremaining: 787ms\n",
      "662:\tlearn: 0.1744559\ttotal: 13.7s\tremaining: 766ms\n",
      "663:\tlearn: 0.1741898\ttotal: 13.7s\tremaining: 745ms\n",
      "664:\tlearn: 0.1740195\ttotal: 13.8s\tremaining: 725ms\n",
      "665:\tlearn: 0.1737168\ttotal: 13.8s\tremaining: 704ms\n",
      "666:\tlearn: 0.1734221\ttotal: 13.8s\tremaining: 683ms\n",
      "667:\tlearn: 0.1731687\ttotal: 13.8s\tremaining: 663ms\n",
      "668:\tlearn: 0.1729328\ttotal: 13.8s\tremaining: 642ms\n",
      "669:\tlearn: 0.1727912\ttotal: 13.9s\tremaining: 621ms\n",
      "670:\tlearn: 0.1726294\ttotal: 13.9s\tremaining: 600ms\n",
      "671:\tlearn: 0.1723201\ttotal: 13.9s\tremaining: 580ms\n",
      "672:\tlearn: 0.1720558\ttotal: 13.9s\tremaining: 559ms\n",
      "673:\tlearn: 0.1717946\ttotal: 14s\tremaining: 538ms\n",
      "674:\tlearn: 0.1715633\ttotal: 14s\tremaining: 518ms\n",
      "675:\tlearn: 0.1712907\ttotal: 14s\tremaining: 497ms\n",
      "676:\tlearn: 0.1710414\ttotal: 14s\tremaining: 476ms\n",
      "677:\tlearn: 0.1707077\ttotal: 14s\tremaining: 456ms\n",
      "678:\tlearn: 0.1705459\ttotal: 14.1s\tremaining: 435ms\n",
      "679:\tlearn: 0.1702068\ttotal: 14.1s\tremaining: 414ms\n",
      "680:\tlearn: 0.1699077\ttotal: 14.1s\tremaining: 393ms\n",
      "681:\tlearn: 0.1696842\ttotal: 14.1s\tremaining: 373ms\n",
      "682:\tlearn: 0.1693547\ttotal: 14.1s\tremaining: 352ms\n",
      "683:\tlearn: 0.1690999\ttotal: 14.2s\tremaining: 331ms\n",
      "684:\tlearn: 0.1688345\ttotal: 14.2s\tremaining: 311ms\n",
      "685:\tlearn: 0.1685532\ttotal: 14.2s\tremaining: 290ms\n",
      "686:\tlearn: 0.1684172\ttotal: 14.2s\tremaining: 269ms\n",
      "687:\tlearn: 0.1682252\ttotal: 14.2s\tremaining: 248ms\n",
      "688:\tlearn: 0.1680345\ttotal: 14.3s\tremaining: 228ms\n",
      "689:\tlearn: 0.1678522\ttotal: 14.3s\tremaining: 207ms\n",
      "690:\tlearn: 0.1677260\ttotal: 14.3s\tremaining: 186ms\n",
      "691:\tlearn: 0.1676276\ttotal: 14.3s\tremaining: 166ms\n",
      "692:\tlearn: 0.1673847\ttotal: 14.3s\tremaining: 145ms\n",
      "693:\tlearn: 0.1671692\ttotal: 14.4s\tremaining: 124ms\n",
      "694:\tlearn: 0.1668499\ttotal: 14.4s\tremaining: 104ms\n",
      "695:\tlearn: 0.1667146\ttotal: 14.4s\tremaining: 82.9ms\n",
      "696:\tlearn: 0.1664723\ttotal: 14.4s\tremaining: 62.1ms\n",
      "697:\tlearn: 0.1662145\ttotal: 14.5s\tremaining: 41.4ms\n",
      "698:\tlearn: 0.1660664\ttotal: 14.5s\tremaining: 20.7ms\n",
      "699:\tlearn: 0.1657431\ttotal: 14.5s\tremaining: 0us\n",
      "0:\tlearn: 0.6817995\ttotal: 21.4ms\tremaining: 14.9s\n",
      "1:\tlearn: 0.6720624\ttotal: 41.3ms\tremaining: 14.4s\n",
      "2:\tlearn: 0.6615563\ttotal: 62.1ms\tremaining: 14.4s\n",
      "3:\tlearn: 0.6546564\ttotal: 71.5ms\tremaining: 12.4s\n",
      "4:\tlearn: 0.6454797\ttotal: 91.4ms\tremaining: 12.7s\n",
      "5:\tlearn: 0.6369509\ttotal: 112ms\tremaining: 12.9s\n",
      "6:\tlearn: 0.6284718\ttotal: 132ms\tremaining: 13s\n",
      "7:\tlearn: 0.6195702\ttotal: 152ms\tremaining: 13.1s\n",
      "8:\tlearn: 0.6133865\ttotal: 172ms\tremaining: 13.2s\n",
      "9:\tlearn: 0.6060533\ttotal: 192ms\tremaining: 13.3s\n",
      "10:\tlearn: 0.5988317\ttotal: 212ms\tremaining: 13.3s\n",
      "11:\tlearn: 0.5910252\ttotal: 232ms\tremaining: 13.3s\n",
      "12:\tlearn: 0.5843475\ttotal: 254ms\tremaining: 13.4s\n",
      "13:\tlearn: 0.5778689\ttotal: 275ms\tremaining: 13.5s\n",
      "14:\tlearn: 0.5714252\ttotal: 298ms\tremaining: 13.6s\n",
      "15:\tlearn: 0.5652523\ttotal: 318ms\tremaining: 13.6s\n",
      "16:\tlearn: 0.5588527\ttotal: 338ms\tremaining: 13.6s\n",
      "17:\tlearn: 0.5535909\ttotal: 358ms\tremaining: 13.6s\n",
      "18:\tlearn: 0.5494889\ttotal: 378ms\tremaining: 13.5s\n",
      "19:\tlearn: 0.5439436\ttotal: 398ms\tremaining: 13.5s\n",
      "20:\tlearn: 0.5381656\ttotal: 418ms\tremaining: 13.5s\n",
      "21:\tlearn: 0.5347710\ttotal: 438ms\tremaining: 13.5s\n",
      "22:\tlearn: 0.5310868\ttotal: 454ms\tremaining: 13.4s\n",
      "23:\tlearn: 0.5262020\ttotal: 474ms\tremaining: 13.3s\n",
      "24:\tlearn: 0.5222417\ttotal: 493ms\tremaining: 13.3s\n",
      "25:\tlearn: 0.5195908\ttotal: 505ms\tremaining: 13.1s\n",
      "26:\tlearn: 0.5153959\ttotal: 525ms\tremaining: 13.1s\n",
      "27:\tlearn: 0.5117568\ttotal: 545ms\tremaining: 13.1s\n",
      "28:\tlearn: 0.5078248\ttotal: 565ms\tremaining: 13.1s\n",
      "29:\tlearn: 0.5040916\ttotal: 585ms\tremaining: 13.1s\n",
      "30:\tlearn: 0.5004959\ttotal: 605ms\tremaining: 13.1s\n",
      "31:\tlearn: 0.4979769\ttotal: 616ms\tremaining: 12.9s\n",
      "32:\tlearn: 0.4942601\ttotal: 636ms\tremaining: 12.9s\n",
      "33:\tlearn: 0.4917858\ttotal: 658ms\tremaining: 12.9s\n",
      "34:\tlearn: 0.4885400\ttotal: 678ms\tremaining: 12.9s\n",
      "35:\tlearn: 0.4847629\ttotal: 698ms\tremaining: 12.9s\n",
      "36:\tlearn: 0.4819548\ttotal: 719ms\tremaining: 12.9s\n",
      "37:\tlearn: 0.4794932\ttotal: 739ms\tremaining: 12.9s\n",
      "38:\tlearn: 0.4773682\ttotal: 759ms\tremaining: 12.9s\n",
      "39:\tlearn: 0.4743721\ttotal: 781ms\tremaining: 12.9s\n",
      "40:\tlearn: 0.4713523\ttotal: 804ms\tremaining: 12.9s\n",
      "41:\tlearn: 0.4681573\ttotal: 825ms\tremaining: 12.9s\n",
      "42:\tlearn: 0.4659394\ttotal: 845ms\tremaining: 12.9s\n",
      "43:\tlearn: 0.4639626\ttotal: 865ms\tremaining: 12.9s\n",
      "44:\tlearn: 0.4620102\ttotal: 886ms\tremaining: 12.9s\n",
      "45:\tlearn: 0.4597740\ttotal: 906ms\tremaining: 12.9s\n",
      "46:\tlearn: 0.4572523\ttotal: 926ms\tremaining: 12.9s\n",
      "47:\tlearn: 0.4552282\ttotal: 946ms\tremaining: 12.8s\n",
      "48:\tlearn: 0.4531466\ttotal: 967ms\tremaining: 12.8s\n",
      "49:\tlearn: 0.4505863\ttotal: 987ms\tremaining: 12.8s\n",
      "50:\tlearn: 0.4486452\ttotal: 1.01s\tremaining: 12.8s\n",
      "51:\tlearn: 0.4470079\ttotal: 1.03s\tremaining: 12.8s\n",
      "52:\tlearn: 0.4452638\ttotal: 1.05s\tremaining: 12.8s\n",
      "53:\tlearn: 0.4435697\ttotal: 1.07s\tremaining: 12.8s\n",
      "54:\tlearn: 0.4416208\ttotal: 1.09s\tremaining: 12.8s\n",
      "55:\tlearn: 0.4397060\ttotal: 1.11s\tremaining: 12.8s\n",
      "56:\tlearn: 0.4378653\ttotal: 1.13s\tremaining: 12.7s\n",
      "57:\tlearn: 0.4364287\ttotal: 1.15s\tremaining: 12.7s\n",
      "58:\tlearn: 0.4343322\ttotal: 1.17s\tremaining: 12.7s\n",
      "59:\tlearn: 0.4331662\ttotal: 1.19s\tremaining: 12.7s\n",
      "60:\tlearn: 0.4316900\ttotal: 1.21s\tremaining: 12.7s\n",
      "61:\tlearn: 0.4302903\ttotal: 1.23s\tremaining: 12.7s\n",
      "62:\tlearn: 0.4281908\ttotal: 1.25s\tremaining: 12.6s\n",
      "63:\tlearn: 0.4267287\ttotal: 1.27s\tremaining: 12.6s\n",
      "64:\tlearn: 0.4252216\ttotal: 1.29s\tremaining: 12.6s\n",
      "65:\tlearn: 0.4236871\ttotal: 1.32s\tremaining: 12.7s\n",
      "66:\tlearn: 0.4226329\ttotal: 1.34s\tremaining: 12.7s\n",
      "67:\tlearn: 0.4213158\ttotal: 1.36s\tremaining: 12.7s\n",
      "68:\tlearn: 0.4201422\ttotal: 1.38s\tremaining: 12.6s\n",
      "69:\tlearn: 0.4182654\ttotal: 1.4s\tremaining: 12.6s\n",
      "70:\tlearn: 0.4168968\ttotal: 1.42s\tremaining: 12.6s\n",
      "71:\tlearn: 0.4156002\ttotal: 1.45s\tremaining: 12.6s\n",
      "72:\tlearn: 0.4140809\ttotal: 1.47s\tremaining: 12.6s\n",
      "73:\tlearn: 0.4127694\ttotal: 1.49s\tremaining: 12.6s\n",
      "74:\tlearn: 0.4112305\ttotal: 1.51s\tremaining: 12.6s\n",
      "75:\tlearn: 0.4097484\ttotal: 1.53s\tremaining: 12.6s\n",
      "76:\tlearn: 0.4084704\ttotal: 1.55s\tremaining: 12.5s\n",
      "77:\tlearn: 0.4076871\ttotal: 1.57s\tremaining: 12.5s\n",
      "78:\tlearn: 0.4066225\ttotal: 1.59s\tremaining: 12.5s\n",
      "79:\tlearn: 0.4053398\ttotal: 1.61s\tremaining: 12.5s\n",
      "80:\tlearn: 0.4043454\ttotal: 1.63s\tremaining: 12.5s\n",
      "81:\tlearn: 0.4029802\ttotal: 1.65s\tremaining: 12.4s\n",
      "82:\tlearn: 0.4017760\ttotal: 1.67s\tremaining: 12.4s\n",
      "83:\tlearn: 0.4003789\ttotal: 1.69s\tremaining: 12.4s\n",
      "84:\tlearn: 0.3996583\ttotal: 1.71s\tremaining: 12.4s\n",
      "85:\tlearn: 0.3986746\ttotal: 1.73s\tremaining: 12.4s\n",
      "86:\tlearn: 0.3979454\ttotal: 1.75s\tremaining: 12.4s\n",
      "87:\tlearn: 0.3973451\ttotal: 1.78s\tremaining: 12.4s\n",
      "88:\tlearn: 0.3965253\ttotal: 1.8s\tremaining: 12.3s\n",
      "89:\tlearn: 0.3955547\ttotal: 1.82s\tremaining: 12.3s\n",
      "90:\tlearn: 0.3942530\ttotal: 1.84s\tremaining: 12.3s\n",
      "91:\tlearn: 0.3935268\ttotal: 1.86s\tremaining: 12.3s\n",
      "92:\tlearn: 0.3927765\ttotal: 1.88s\tremaining: 12.3s\n",
      "93:\tlearn: 0.3916801\ttotal: 1.9s\tremaining: 12.3s\n",
      "94:\tlearn: 0.3905773\ttotal: 1.92s\tremaining: 12.2s\n",
      "95:\tlearn: 0.3898506\ttotal: 1.94s\tremaining: 12.2s\n",
      "96:\tlearn: 0.3888911\ttotal: 1.96s\tremaining: 12.2s\n",
      "97:\tlearn: 0.3881167\ttotal: 1.98s\tremaining: 12.2s\n",
      "98:\tlearn: 0.3874575\ttotal: 2s\tremaining: 12.2s\n",
      "99:\tlearn: 0.3868808\ttotal: 2.03s\tremaining: 12.2s\n",
      "100:\tlearn: 0.3855089\ttotal: 2.05s\tremaining: 12.1s\n",
      "101:\tlearn: 0.3847582\ttotal: 2.07s\tremaining: 12.1s\n",
      "102:\tlearn: 0.3841368\ttotal: 2.09s\tremaining: 12.1s\n",
      "103:\tlearn: 0.3832790\ttotal: 2.11s\tremaining: 12.1s\n",
      "104:\tlearn: 0.3824597\ttotal: 2.13s\tremaining: 12.1s\n",
      "105:\tlearn: 0.3811434\ttotal: 2.15s\tremaining: 12s\n",
      "106:\tlearn: 0.3804803\ttotal: 2.17s\tremaining: 12s\n",
      "107:\tlearn: 0.3797375\ttotal: 2.19s\tremaining: 12s\n",
      "108:\tlearn: 0.3788847\ttotal: 2.21s\tremaining: 12s\n",
      "109:\tlearn: 0.3780425\ttotal: 2.23s\tremaining: 12s\n",
      "110:\tlearn: 0.3773745\ttotal: 2.25s\tremaining: 11.9s\n",
      "111:\tlearn: 0.3766953\ttotal: 2.27s\tremaining: 11.9s\n",
      "112:\tlearn: 0.3760046\ttotal: 2.29s\tremaining: 11.9s\n",
      "113:\tlearn: 0.3750987\ttotal: 2.32s\tremaining: 11.9s\n",
      "114:\tlearn: 0.3744674\ttotal: 2.34s\tremaining: 11.9s\n",
      "115:\tlearn: 0.3735486\ttotal: 2.36s\tremaining: 11.9s\n",
      "116:\tlearn: 0.3729302\ttotal: 2.38s\tremaining: 11.8s\n",
      "117:\tlearn: 0.3722090\ttotal: 2.4s\tremaining: 11.8s\n",
      "118:\tlearn: 0.3716935\ttotal: 2.42s\tremaining: 11.8s\n",
      "119:\tlearn: 0.3712238\ttotal: 2.44s\tremaining: 11.8s\n",
      "120:\tlearn: 0.3704278\ttotal: 2.46s\tremaining: 11.8s\n",
      "121:\tlearn: 0.3699725\ttotal: 2.48s\tremaining: 11.7s\n",
      "122:\tlearn: 0.3693608\ttotal: 2.5s\tremaining: 11.7s\n",
      "123:\tlearn: 0.3686719\ttotal: 2.52s\tremaining: 11.7s\n",
      "124:\tlearn: 0.3682445\ttotal: 2.54s\tremaining: 11.7s\n",
      "125:\tlearn: 0.3672907\ttotal: 2.56s\tremaining: 11.7s\n",
      "126:\tlearn: 0.3667715\ttotal: 2.58s\tremaining: 11.6s\n",
      "127:\tlearn: 0.3658527\ttotal: 2.6s\tremaining: 11.6s\n",
      "128:\tlearn: 0.3651771\ttotal: 2.62s\tremaining: 11.6s\n",
      "129:\tlearn: 0.3646322\ttotal: 2.64s\tremaining: 11.6s\n",
      "130:\tlearn: 0.3637460\ttotal: 2.66s\tremaining: 11.6s\n",
      "131:\tlearn: 0.3630444\ttotal: 2.68s\tremaining: 11.5s\n",
      "132:\tlearn: 0.3625798\ttotal: 2.7s\tremaining: 11.5s\n",
      "133:\tlearn: 0.3619684\ttotal: 2.72s\tremaining: 11.5s\n",
      "134:\tlearn: 0.3613115\ttotal: 2.74s\tremaining: 11.5s\n",
      "135:\tlearn: 0.3608655\ttotal: 2.76s\tremaining: 11.5s\n",
      "136:\tlearn: 0.3599803\ttotal: 2.78s\tremaining: 11.4s\n",
      "137:\tlearn: 0.3598678\ttotal: 2.79s\tremaining: 11.4s\n",
      "138:\tlearn: 0.3591413\ttotal: 2.82s\tremaining: 11.4s\n",
      "139:\tlearn: 0.3586286\ttotal: 2.84s\tremaining: 11.4s\n",
      "140:\tlearn: 0.3579493\ttotal: 2.86s\tremaining: 11.3s\n",
      "141:\tlearn: 0.3572655\ttotal: 2.88s\tremaining: 11.3s\n",
      "142:\tlearn: 0.3564396\ttotal: 2.9s\tremaining: 11.3s\n",
      "143:\tlearn: 0.3558070\ttotal: 2.92s\tremaining: 11.3s\n",
      "144:\tlearn: 0.3554178\ttotal: 2.94s\tremaining: 11.3s\n",
      "145:\tlearn: 0.3548662\ttotal: 2.96s\tremaining: 11.2s\n",
      "146:\tlearn: 0.3542295\ttotal: 2.98s\tremaining: 11.2s\n",
      "147:\tlearn: 0.3533944\ttotal: 3s\tremaining: 11.2s\n",
      "148:\tlearn: 0.3528522\ttotal: 3.02s\tremaining: 11.2s\n",
      "149:\tlearn: 0.3525431\ttotal: 3.04s\tremaining: 11.1s\n",
      "150:\tlearn: 0.3518812\ttotal: 3.06s\tremaining: 11.1s\n",
      "151:\tlearn: 0.3513625\ttotal: 3.08s\tremaining: 11.1s\n",
      "152:\tlearn: 0.3513195\ttotal: 3.09s\tremaining: 11s\n",
      "153:\tlearn: 0.3506690\ttotal: 3.11s\tremaining: 11s\n",
      "154:\tlearn: 0.3501757\ttotal: 3.13s\tremaining: 11s\n",
      "155:\tlearn: 0.3494990\ttotal: 3.15s\tremaining: 11s\n",
      "156:\tlearn: 0.3487941\ttotal: 3.17s\tremaining: 11s\n",
      "157:\tlearn: 0.3484701\ttotal: 3.19s\tremaining: 10.9s\n",
      "158:\tlearn: 0.3481480\ttotal: 3.21s\tremaining: 10.9s\n",
      "159:\tlearn: 0.3473713\ttotal: 3.23s\tremaining: 10.9s\n",
      "160:\tlearn: 0.3468800\ttotal: 3.25s\tremaining: 10.9s\n",
      "161:\tlearn: 0.3460396\ttotal: 3.27s\tremaining: 10.9s\n",
      "162:\tlearn: 0.3456124\ttotal: 3.29s\tremaining: 10.9s\n",
      "163:\tlearn: 0.3451665\ttotal: 3.31s\tremaining: 10.8s\n",
      "164:\tlearn: 0.3446416\ttotal: 3.33s\tremaining: 10.8s\n",
      "165:\tlearn: 0.3441460\ttotal: 3.35s\tremaining: 10.8s\n",
      "166:\tlearn: 0.3437398\ttotal: 3.38s\tremaining: 10.8s\n",
      "167:\tlearn: 0.3433751\ttotal: 3.39s\tremaining: 10.7s\n",
      "168:\tlearn: 0.3431161\ttotal: 3.41s\tremaining: 10.7s\n",
      "169:\tlearn: 0.3425088\ttotal: 3.43s\tremaining: 10.7s\n",
      "170:\tlearn: 0.3418939\ttotal: 3.45s\tremaining: 10.7s\n",
      "171:\tlearn: 0.3414149\ttotal: 3.47s\tremaining: 10.7s\n",
      "172:\tlearn: 0.3408637\ttotal: 3.49s\tremaining: 10.6s\n",
      "173:\tlearn: 0.3404720\ttotal: 3.52s\tremaining: 10.7s\n",
      "174:\tlearn: 0.3398219\ttotal: 3.54s\tremaining: 10.6s\n",
      "175:\tlearn: 0.3394286\ttotal: 3.56s\tremaining: 10.6s\n",
      "176:\tlearn: 0.3390153\ttotal: 3.58s\tremaining: 10.6s\n",
      "177:\tlearn: 0.3387086\ttotal: 3.6s\tremaining: 10.6s\n",
      "178:\tlearn: 0.3379955\ttotal: 3.63s\tremaining: 10.6s\n",
      "179:\tlearn: 0.3372898\ttotal: 3.65s\tremaining: 10.5s\n",
      "180:\tlearn: 0.3367297\ttotal: 3.67s\tremaining: 10.5s\n",
      "181:\tlearn: 0.3362431\ttotal: 3.69s\tremaining: 10.5s\n",
      "182:\tlearn: 0.3357540\ttotal: 3.71s\tremaining: 10.5s\n",
      "183:\tlearn: 0.3352095\ttotal: 3.73s\tremaining: 10.4s\n",
      "184:\tlearn: 0.3348184\ttotal: 3.75s\tremaining: 10.4s\n",
      "185:\tlearn: 0.3345272\ttotal: 3.77s\tremaining: 10.4s\n",
      "186:\tlearn: 0.3341859\ttotal: 3.79s\tremaining: 10.4s\n",
      "187:\tlearn: 0.3339826\ttotal: 3.81s\tremaining: 10.4s\n",
      "188:\tlearn: 0.3336133\ttotal: 3.83s\tremaining: 10.4s\n",
      "189:\tlearn: 0.3329841\ttotal: 3.85s\tremaining: 10.3s\n",
      "190:\tlearn: 0.3323901\ttotal: 3.87s\tremaining: 10.3s\n",
      "191:\tlearn: 0.3318528\ttotal: 3.89s\tremaining: 10.3s\n",
      "192:\tlearn: 0.3313197\ttotal: 3.91s\tremaining: 10.3s\n",
      "193:\tlearn: 0.3309093\ttotal: 3.93s\tremaining: 10.3s\n",
      "194:\tlearn: 0.3303592\ttotal: 3.95s\tremaining: 10.2s\n",
      "195:\tlearn: 0.3297076\ttotal: 3.97s\tremaining: 10.2s\n",
      "196:\tlearn: 0.3290365\ttotal: 3.99s\tremaining: 10.2s\n",
      "197:\tlearn: 0.3283200\ttotal: 4.01s\tremaining: 10.2s\n",
      "198:\tlearn: 0.3279393\ttotal: 4.03s\tremaining: 10.2s\n",
      "199:\tlearn: 0.3272014\ttotal: 4.05s\tremaining: 10.1s\n",
      "200:\tlearn: 0.3266703\ttotal: 4.07s\tremaining: 10.1s\n",
      "201:\tlearn: 0.3260543\ttotal: 4.09s\tremaining: 10.1s\n",
      "202:\tlearn: 0.3255583\ttotal: 4.12s\tremaining: 10.1s\n",
      "203:\tlearn: 0.3249446\ttotal: 4.14s\tremaining: 10.1s\n",
      "204:\tlearn: 0.3245172\ttotal: 4.16s\tremaining: 10s\n",
      "205:\tlearn: 0.3241618\ttotal: 4.18s\tremaining: 10s\n",
      "206:\tlearn: 0.3235057\ttotal: 4.2s\tremaining: 9.99s\n",
      "207:\tlearn: 0.3230121\ttotal: 4.22s\tremaining: 9.97s\n",
      "208:\tlearn: 0.3227363\ttotal: 4.24s\tremaining: 9.95s\n",
      "209:\tlearn: 0.3224596\ttotal: 4.26s\tremaining: 9.93s\n",
      "210:\tlearn: 0.3221338\ttotal: 4.28s\tremaining: 9.91s\n",
      "211:\tlearn: 0.3217100\ttotal: 4.3s\tremaining: 9.9s\n",
      "212:\tlearn: 0.3210775\ttotal: 4.32s\tremaining: 9.88s\n",
      "213:\tlearn: 0.3205158\ttotal: 4.34s\tremaining: 9.86s\n",
      "214:\tlearn: 0.3203391\ttotal: 4.36s\tremaining: 9.84s\n",
      "215:\tlearn: 0.3200162\ttotal: 4.38s\tremaining: 9.82s\n",
      "216:\tlearn: 0.3197463\ttotal: 4.4s\tremaining: 9.8s\n",
      "217:\tlearn: 0.3192037\ttotal: 4.42s\tremaining: 9.78s\n",
      "218:\tlearn: 0.3187416\ttotal: 4.44s\tremaining: 9.76s\n",
      "219:\tlearn: 0.3182120\ttotal: 4.46s\tremaining: 9.74s\n",
      "220:\tlearn: 0.3178933\ttotal: 4.48s\tremaining: 9.72s\n",
      "221:\tlearn: 0.3173704\ttotal: 4.5s\tremaining: 9.7s\n",
      "222:\tlearn: 0.3169651\ttotal: 4.52s\tremaining: 9.68s\n",
      "223:\tlearn: 0.3165142\ttotal: 4.54s\tremaining: 9.66s\n",
      "224:\tlearn: 0.3159903\ttotal: 4.57s\tremaining: 9.64s\n",
      "225:\tlearn: 0.3159072\ttotal: 4.58s\tremaining: 9.6s\n",
      "226:\tlearn: 0.3152239\ttotal: 4.6s\tremaining: 9.58s\n",
      "227:\tlearn: 0.3147026\ttotal: 4.62s\tremaining: 9.56s\n",
      "228:\tlearn: 0.3140095\ttotal: 4.64s\tremaining: 9.54s\n",
      "229:\tlearn: 0.3132735\ttotal: 4.66s\tremaining: 9.52s\n",
      "230:\tlearn: 0.3127900\ttotal: 4.68s\tremaining: 9.5s\n",
      "231:\tlearn: 0.3120352\ttotal: 4.7s\tremaining: 9.48s\n",
      "232:\tlearn: 0.3115580\ttotal: 4.72s\tremaining: 9.46s\n",
      "233:\tlearn: 0.3109829\ttotal: 4.74s\tremaining: 9.44s\n",
      "234:\tlearn: 0.3107896\ttotal: 4.76s\tremaining: 9.42s\n",
      "235:\tlearn: 0.3101706\ttotal: 4.78s\tremaining: 9.41s\n",
      "236:\tlearn: 0.3099120\ttotal: 4.8s\tremaining: 9.39s\n",
      "237:\tlearn: 0.3097234\ttotal: 4.82s\tremaining: 9.36s\n",
      "238:\tlearn: 0.3091804\ttotal: 4.84s\tremaining: 9.34s\n",
      "239:\tlearn: 0.3089812\ttotal: 4.86s\tremaining: 9.32s\n",
      "240:\tlearn: 0.3088006\ttotal: 4.88s\tremaining: 9.3s\n",
      "241:\tlearn: 0.3085217\ttotal: 4.9s\tremaining: 9.28s\n",
      "242:\tlearn: 0.3082069\ttotal: 4.92s\tremaining: 9.26s\n",
      "243:\tlearn: 0.3076055\ttotal: 4.95s\tremaining: 9.24s\n",
      "244:\tlearn: 0.3072629\ttotal: 4.96s\tremaining: 9.22s\n",
      "245:\tlearn: 0.3067302\ttotal: 4.99s\tremaining: 9.2s\n",
      "246:\tlearn: 0.3064458\ttotal: 5.01s\tremaining: 9.18s\n",
      "247:\tlearn: 0.3060442\ttotal: 5.03s\tremaining: 9.16s\n",
      "248:\tlearn: 0.3052484\ttotal: 5.05s\tremaining: 9.14s\n",
      "249:\tlearn: 0.3045766\ttotal: 5.07s\tremaining: 9.13s\n",
      "250:\tlearn: 0.3037782\ttotal: 5.09s\tremaining: 9.11s\n",
      "251:\tlearn: 0.3032755\ttotal: 5.11s\tremaining: 9.09s\n",
      "252:\tlearn: 0.3027839\ttotal: 5.13s\tremaining: 9.06s\n",
      "253:\tlearn: 0.3025402\ttotal: 5.15s\tremaining: 9.04s\n",
      "254:\tlearn: 0.3022175\ttotal: 5.17s\tremaining: 9.02s\n",
      "255:\tlearn: 0.3018808\ttotal: 5.19s\tremaining: 9s\n",
      "256:\tlearn: 0.3015787\ttotal: 5.21s\tremaining: 8.98s\n",
      "257:\tlearn: 0.3012519\ttotal: 5.23s\tremaining: 8.96s\n",
      "258:\tlearn: 0.3011112\ttotal: 5.25s\tremaining: 8.94s\n",
      "259:\tlearn: 0.3007073\ttotal: 5.27s\tremaining: 8.92s\n",
      "260:\tlearn: 0.3001403\ttotal: 5.29s\tremaining: 8.91s\n",
      "261:\tlearn: 0.2999259\ttotal: 5.32s\tremaining: 8.88s\n",
      "262:\tlearn: 0.2996206\ttotal: 5.33s\tremaining: 8.87s\n",
      "263:\tlearn: 0.2992590\ttotal: 5.36s\tremaining: 8.85s\n",
      "264:\tlearn: 0.2989081\ttotal: 5.38s\tremaining: 8.82s\n",
      "265:\tlearn: 0.2982492\ttotal: 5.4s\tremaining: 8.8s\n",
      "266:\tlearn: 0.2975657\ttotal: 5.42s\tremaining: 8.78s\n",
      "267:\tlearn: 0.2971388\ttotal: 5.44s\tremaining: 8.77s\n",
      "268:\tlearn: 0.2968589\ttotal: 5.46s\tremaining: 8.74s\n",
      "269:\tlearn: 0.2965497\ttotal: 5.48s\tremaining: 8.72s\n",
      "270:\tlearn: 0.2961159\ttotal: 5.5s\tremaining: 8.71s\n",
      "271:\tlearn: 0.2957518\ttotal: 5.52s\tremaining: 8.68s\n",
      "272:\tlearn: 0.2954258\ttotal: 5.54s\tremaining: 8.66s\n",
      "273:\tlearn: 0.2947818\ttotal: 5.56s\tremaining: 8.64s\n",
      "274:\tlearn: 0.2943819\ttotal: 5.58s\tremaining: 8.62s\n",
      "275:\tlearn: 0.2936095\ttotal: 5.6s\tremaining: 8.6s\n",
      "276:\tlearn: 0.2933863\ttotal: 5.62s\tremaining: 8.58s\n",
      "277:\tlearn: 0.2928045\ttotal: 5.64s\tremaining: 8.56s\n",
      "278:\tlearn: 0.2922317\ttotal: 5.66s\tremaining: 8.54s\n",
      "279:\tlearn: 0.2917591\ttotal: 5.68s\tremaining: 8.52s\n",
      "280:\tlearn: 0.2913949\ttotal: 5.7s\tremaining: 8.5s\n",
      "281:\tlearn: 0.2908864\ttotal: 5.72s\tremaining: 8.48s\n",
      "282:\tlearn: 0.2905746\ttotal: 5.74s\tremaining: 8.46s\n",
      "283:\tlearn: 0.2904325\ttotal: 5.76s\tremaining: 8.44s\n",
      "284:\tlearn: 0.2901840\ttotal: 5.79s\tremaining: 8.43s\n",
      "285:\tlearn: 0.2896928\ttotal: 5.81s\tremaining: 8.41s\n",
      "286:\tlearn: 0.2890110\ttotal: 5.83s\tremaining: 8.39s\n",
      "287:\tlearn: 0.2886058\ttotal: 5.85s\tremaining: 8.37s\n",
      "288:\tlearn: 0.2880213\ttotal: 5.87s\tremaining: 8.35s\n",
      "289:\tlearn: 0.2876132\ttotal: 5.89s\tremaining: 8.33s\n",
      "290:\tlearn: 0.2870745\ttotal: 5.91s\tremaining: 8.31s\n",
      "291:\tlearn: 0.2867592\ttotal: 5.93s\tremaining: 8.29s\n",
      "292:\tlearn: 0.2863729\ttotal: 5.95s\tremaining: 8.27s\n",
      "293:\tlearn: 0.2863711\ttotal: 5.96s\tremaining: 8.23s\n",
      "294:\tlearn: 0.2858231\ttotal: 5.98s\tremaining: 8.21s\n",
      "295:\tlearn: 0.2852395\ttotal: 6s\tremaining: 8.19s\n",
      "296:\tlearn: 0.2850407\ttotal: 6.02s\tremaining: 8.17s\n",
      "297:\tlearn: 0.2845798\ttotal: 6.04s\tremaining: 8.15s\n",
      "298:\tlearn: 0.2844115\ttotal: 6.06s\tremaining: 8.13s\n",
      "299:\tlearn: 0.2839807\ttotal: 6.08s\tremaining: 8.11s\n",
      "300:\tlearn: 0.2836248\ttotal: 6.1s\tremaining: 8.09s\n",
      "301:\tlearn: 0.2831148\ttotal: 6.12s\tremaining: 8.07s\n",
      "302:\tlearn: 0.2829551\ttotal: 6.14s\tremaining: 8.05s\n",
      "303:\tlearn: 0.2827480\ttotal: 6.16s\tremaining: 8.03s\n",
      "304:\tlearn: 0.2826245\ttotal: 6.18s\tremaining: 8.01s\n",
      "305:\tlearn: 0.2821617\ttotal: 6.2s\tremaining: 7.99s\n",
      "306:\tlearn: 0.2818737\ttotal: 6.22s\tremaining: 7.97s\n",
      "307:\tlearn: 0.2814490\ttotal: 6.24s\tremaining: 7.95s\n",
      "308:\tlearn: 0.2811688\ttotal: 6.26s\tremaining: 7.93s\n",
      "309:\tlearn: 0.2809770\ttotal: 6.29s\tremaining: 7.91s\n",
      "310:\tlearn: 0.2805624\ttotal: 6.31s\tremaining: 7.89s\n",
      "311:\tlearn: 0.2801641\ttotal: 6.33s\tremaining: 7.87s\n",
      "312:\tlearn: 0.2798619\ttotal: 6.35s\tremaining: 7.85s\n",
      "313:\tlearn: 0.2795795\ttotal: 6.37s\tremaining: 7.83s\n",
      "314:\tlearn: 0.2792094\ttotal: 6.39s\tremaining: 7.81s\n",
      "315:\tlearn: 0.2788025\ttotal: 6.41s\tremaining: 7.79s\n",
      "316:\tlearn: 0.2783161\ttotal: 6.43s\tremaining: 7.77s\n",
      "317:\tlearn: 0.2778711\ttotal: 6.45s\tremaining: 7.75s\n",
      "318:\tlearn: 0.2774964\ttotal: 6.47s\tremaining: 7.73s\n",
      "319:\tlearn: 0.2770581\ttotal: 6.49s\tremaining: 7.71s\n",
      "320:\tlearn: 0.2766619\ttotal: 6.51s\tremaining: 7.69s\n",
      "321:\tlearn: 0.2762423\ttotal: 6.53s\tremaining: 7.67s\n",
      "322:\tlearn: 0.2760783\ttotal: 6.55s\tremaining: 7.65s\n",
      "323:\tlearn: 0.2756566\ttotal: 6.57s\tremaining: 7.63s\n",
      "324:\tlearn: 0.2756046\ttotal: 6.59s\tremaining: 7.61s\n",
      "325:\tlearn: 0.2753201\ttotal: 6.61s\tremaining: 7.58s\n",
      "326:\tlearn: 0.2748940\ttotal: 6.63s\tremaining: 7.56s\n",
      "327:\tlearn: 0.2742601\ttotal: 6.65s\tremaining: 7.54s\n",
      "328:\tlearn: 0.2739954\ttotal: 6.67s\tremaining: 7.52s\n",
      "329:\tlearn: 0.2737516\ttotal: 6.69s\tremaining: 7.5s\n",
      "330:\tlearn: 0.2736277\ttotal: 6.71s\tremaining: 7.48s\n",
      "331:\tlearn: 0.2731485\ttotal: 6.73s\tremaining: 7.46s\n",
      "332:\tlearn: 0.2727435\ttotal: 6.75s\tremaining: 7.45s\n",
      "333:\tlearn: 0.2725458\ttotal: 6.78s\tremaining: 7.42s\n",
      "334:\tlearn: 0.2722964\ttotal: 6.8s\tremaining: 7.41s\n",
      "335:\tlearn: 0.2721426\ttotal: 6.82s\tremaining: 7.38s\n",
      "336:\tlearn: 0.2719214\ttotal: 6.84s\tremaining: 7.37s\n",
      "337:\tlearn: 0.2714740\ttotal: 6.86s\tremaining: 7.34s\n",
      "338:\tlearn: 0.2711692\ttotal: 6.88s\tremaining: 7.32s\n",
      "339:\tlearn: 0.2708556\ttotal: 6.9s\tremaining: 7.3s\n",
      "340:\tlearn: 0.2703848\ttotal: 6.92s\tremaining: 7.28s\n",
      "341:\tlearn: 0.2699903\ttotal: 6.94s\tremaining: 7.26s\n",
      "342:\tlearn: 0.2696289\ttotal: 6.96s\tremaining: 7.24s\n",
      "343:\tlearn: 0.2691858\ttotal: 6.98s\tremaining: 7.22s\n",
      "344:\tlearn: 0.2688671\ttotal: 7s\tremaining: 7.2s\n",
      "345:\tlearn: 0.2684958\ttotal: 7.02s\tremaining: 7.18s\n",
      "346:\tlearn: 0.2681405\ttotal: 7.04s\tremaining: 7.16s\n",
      "347:\tlearn: 0.2678128\ttotal: 7.06s\tremaining: 7.14s\n",
      "348:\tlearn: 0.2676969\ttotal: 7.08s\tremaining: 7.12s\n",
      "349:\tlearn: 0.2674442\ttotal: 7.1s\tremaining: 7.1s\n",
      "350:\tlearn: 0.2667624\ttotal: 7.12s\tremaining: 7.08s\n",
      "351:\tlearn: 0.2664984\ttotal: 7.14s\tremaining: 7.06s\n",
      "352:\tlearn: 0.2663046\ttotal: 7.16s\tremaining: 7.04s\n",
      "353:\tlearn: 0.2660538\ttotal: 7.19s\tremaining: 7.03s\n",
      "354:\tlearn: 0.2655737\ttotal: 7.21s\tremaining: 7.01s\n",
      "355:\tlearn: 0.2654728\ttotal: 7.23s\tremaining: 6.99s\n",
      "356:\tlearn: 0.2651535\ttotal: 7.25s\tremaining: 6.97s\n",
      "357:\tlearn: 0.2647957\ttotal: 7.28s\tremaining: 6.95s\n",
      "358:\tlearn: 0.2644670\ttotal: 7.3s\tremaining: 6.93s\n",
      "359:\tlearn: 0.2641577\ttotal: 7.32s\tremaining: 6.91s\n",
      "360:\tlearn: 0.2638592\ttotal: 7.34s\tremaining: 6.89s\n",
      "361:\tlearn: 0.2636127\ttotal: 7.36s\tremaining: 6.87s\n",
      "362:\tlearn: 0.2632747\ttotal: 7.38s\tremaining: 6.85s\n",
      "363:\tlearn: 0.2628821\ttotal: 7.4s\tremaining: 6.83s\n",
      "364:\tlearn: 0.2626300\ttotal: 7.42s\tremaining: 6.81s\n",
      "365:\tlearn: 0.2622803\ttotal: 7.44s\tremaining: 6.79s\n",
      "366:\tlearn: 0.2618837\ttotal: 7.46s\tremaining: 6.77s\n",
      "367:\tlearn: 0.2615602\ttotal: 7.48s\tremaining: 6.75s\n",
      "368:\tlearn: 0.2612988\ttotal: 7.5s\tremaining: 6.73s\n",
      "369:\tlearn: 0.2609889\ttotal: 7.52s\tremaining: 6.71s\n",
      "370:\tlearn: 0.2606080\ttotal: 7.54s\tremaining: 6.69s\n",
      "371:\tlearn: 0.2604333\ttotal: 7.56s\tremaining: 6.67s\n",
      "372:\tlearn: 0.2601797\ttotal: 7.58s\tremaining: 6.65s\n",
      "373:\tlearn: 0.2599020\ttotal: 7.61s\tremaining: 6.63s\n",
      "374:\tlearn: 0.2593620\ttotal: 7.63s\tremaining: 6.61s\n",
      "375:\tlearn: 0.2588625\ttotal: 7.65s\tremaining: 6.59s\n",
      "376:\tlearn: 0.2587041\ttotal: 7.67s\tremaining: 6.57s\n",
      "377:\tlearn: 0.2584163\ttotal: 7.69s\tremaining: 6.55s\n",
      "378:\tlearn: 0.2580961\ttotal: 7.71s\tremaining: 6.53s\n",
      "379:\tlearn: 0.2576424\ttotal: 7.73s\tremaining: 6.51s\n",
      "380:\tlearn: 0.2572867\ttotal: 7.75s\tremaining: 6.49s\n",
      "381:\tlearn: 0.2569780\ttotal: 7.77s\tremaining: 6.47s\n",
      "382:\tlearn: 0.2566058\ttotal: 7.79s\tremaining: 6.45s\n",
      "383:\tlearn: 0.2563421\ttotal: 7.81s\tremaining: 6.43s\n",
      "384:\tlearn: 0.2561057\ttotal: 7.83s\tremaining: 6.41s\n",
      "385:\tlearn: 0.2558337\ttotal: 7.85s\tremaining: 6.39s\n",
      "386:\tlearn: 0.2555179\ttotal: 7.87s\tremaining: 6.37s\n",
      "387:\tlearn: 0.2550371\ttotal: 7.89s\tremaining: 6.35s\n",
      "388:\tlearn: 0.2546212\ttotal: 7.91s\tremaining: 6.33s\n",
      "389:\tlearn: 0.2544957\ttotal: 7.93s\tremaining: 6.31s\n",
      "390:\tlearn: 0.2541423\ttotal: 7.96s\tremaining: 6.29s\n",
      "391:\tlearn: 0.2538888\ttotal: 7.97s\tremaining: 6.26s\n",
      "392:\tlearn: 0.2536459\ttotal: 7.99s\tremaining: 6.25s\n",
      "393:\tlearn: 0.2534845\ttotal: 8.01s\tremaining: 6.22s\n",
      "394:\tlearn: 0.2529765\ttotal: 8.04s\tremaining: 6.2s\n",
      "395:\tlearn: 0.2526000\ttotal: 8.06s\tremaining: 6.18s\n",
      "396:\tlearn: 0.2520398\ttotal: 8.08s\tremaining: 6.16s\n",
      "397:\tlearn: 0.2516583\ttotal: 8.1s\tremaining: 6.14s\n",
      "398:\tlearn: 0.2513292\ttotal: 8.12s\tremaining: 6.12s\n",
      "399:\tlearn: 0.2509276\ttotal: 8.14s\tremaining: 6.1s\n",
      "400:\tlearn: 0.2506427\ttotal: 8.16s\tremaining: 6.08s\n",
      "401:\tlearn: 0.2501566\ttotal: 8.18s\tremaining: 6.06s\n",
      "402:\tlearn: 0.2497517\ttotal: 8.2s\tremaining: 6.04s\n",
      "403:\tlearn: 0.2493867\ttotal: 8.22s\tremaining: 6.02s\n",
      "404:\tlearn: 0.2490869\ttotal: 8.24s\tremaining: 6s\n",
      "405:\tlearn: 0.2486067\ttotal: 8.27s\tremaining: 5.99s\n",
      "406:\tlearn: 0.2484227\ttotal: 8.29s\tremaining: 5.96s\n",
      "407:\tlearn: 0.2483207\ttotal: 8.3s\tremaining: 5.94s\n",
      "408:\tlearn: 0.2481331\ttotal: 8.32s\tremaining: 5.92s\n",
      "409:\tlearn: 0.2476443\ttotal: 8.35s\tremaining: 5.9s\n",
      "410:\tlearn: 0.2474326\ttotal: 8.37s\tremaining: 5.88s\n",
      "411:\tlearn: 0.2471980\ttotal: 8.39s\tremaining: 5.86s\n",
      "412:\tlearn: 0.2468407\ttotal: 8.41s\tremaining: 5.84s\n",
      "413:\tlearn: 0.2467079\ttotal: 8.43s\tremaining: 5.82s\n",
      "414:\tlearn: 0.2463616\ttotal: 8.45s\tremaining: 5.8s\n",
      "415:\tlearn: 0.2460913\ttotal: 8.47s\tremaining: 5.78s\n",
      "416:\tlearn: 0.2459051\ttotal: 8.49s\tremaining: 5.76s\n",
      "417:\tlearn: 0.2457493\ttotal: 8.51s\tremaining: 5.74s\n",
      "418:\tlearn: 0.2452950\ttotal: 8.53s\tremaining: 5.72s\n",
      "419:\tlearn: 0.2450123\ttotal: 8.55s\tremaining: 5.7s\n",
      "420:\tlearn: 0.2448325\ttotal: 8.57s\tremaining: 5.68s\n",
      "421:\tlearn: 0.2445100\ttotal: 8.59s\tremaining: 5.66s\n",
      "422:\tlearn: 0.2441717\ttotal: 8.61s\tremaining: 5.64s\n",
      "423:\tlearn: 0.2439124\ttotal: 8.63s\tremaining: 5.62s\n",
      "424:\tlearn: 0.2437097\ttotal: 8.65s\tremaining: 5.6s\n",
      "425:\tlearn: 0.2434435\ttotal: 8.67s\tremaining: 5.58s\n",
      "426:\tlearn: 0.2431326\ttotal: 8.69s\tremaining: 5.56s\n",
      "427:\tlearn: 0.2428599\ttotal: 8.71s\tremaining: 5.54s\n",
      "428:\tlearn: 0.2424631\ttotal: 8.73s\tremaining: 5.52s\n",
      "429:\tlearn: 0.2422342\ttotal: 8.75s\tremaining: 5.5s\n",
      "430:\tlearn: 0.2416451\ttotal: 8.78s\tremaining: 5.48s\n",
      "431:\tlearn: 0.2414712\ttotal: 8.8s\tremaining: 5.46s\n",
      "432:\tlearn: 0.2411020\ttotal: 8.82s\tremaining: 5.44s\n",
      "433:\tlearn: 0.2409697\ttotal: 8.84s\tremaining: 5.42s\n",
      "434:\tlearn: 0.2406501\ttotal: 8.86s\tremaining: 5.4s\n",
      "435:\tlearn: 0.2402315\ttotal: 8.88s\tremaining: 5.38s\n",
      "436:\tlearn: 0.2398371\ttotal: 8.9s\tremaining: 5.36s\n",
      "437:\tlearn: 0.2396886\ttotal: 8.92s\tremaining: 5.34s\n",
      "438:\tlearn: 0.2394854\ttotal: 8.94s\tremaining: 5.32s\n",
      "439:\tlearn: 0.2391437\ttotal: 8.96s\tremaining: 5.3s\n",
      "440:\tlearn: 0.2387476\ttotal: 8.98s\tremaining: 5.28s\n",
      "441:\tlearn: 0.2386076\ttotal: 9s\tremaining: 5.25s\n",
      "442:\tlearn: 0.2382677\ttotal: 9.02s\tremaining: 5.23s\n",
      "443:\tlearn: 0.2378155\ttotal: 9.04s\tremaining: 5.21s\n",
      "444:\tlearn: 0.2376242\ttotal: 9.06s\tremaining: 5.19s\n",
      "445:\tlearn: 0.2373886\ttotal: 9.08s\tremaining: 5.17s\n",
      "446:\tlearn: 0.2371208\ttotal: 9.11s\tremaining: 5.15s\n",
      "447:\tlearn: 0.2369436\ttotal: 9.13s\tremaining: 5.13s\n",
      "448:\tlearn: 0.2367411\ttotal: 9.14s\tremaining: 5.11s\n",
      "449:\tlearn: 0.2364143\ttotal: 9.17s\tremaining: 5.09s\n",
      "450:\tlearn: 0.2362822\ttotal: 9.19s\tremaining: 5.07s\n",
      "451:\tlearn: 0.2361220\ttotal: 9.21s\tremaining: 5.05s\n",
      "452:\tlearn: 0.2354898\ttotal: 9.23s\tremaining: 5.03s\n",
      "453:\tlearn: 0.2353026\ttotal: 9.25s\tremaining: 5.01s\n",
      "454:\tlearn: 0.2348903\ttotal: 9.27s\tremaining: 4.99s\n",
      "455:\tlearn: 0.2346980\ttotal: 9.29s\tremaining: 4.97s\n",
      "456:\tlearn: 0.2344663\ttotal: 9.31s\tremaining: 4.95s\n",
      "457:\tlearn: 0.2341282\ttotal: 9.33s\tremaining: 4.93s\n",
      "458:\tlearn: 0.2338109\ttotal: 9.35s\tremaining: 4.91s\n",
      "459:\tlearn: 0.2335308\ttotal: 9.37s\tremaining: 4.89s\n",
      "460:\tlearn: 0.2333301\ttotal: 9.39s\tremaining: 4.87s\n",
      "461:\tlearn: 0.2330708\ttotal: 9.41s\tremaining: 4.85s\n",
      "462:\tlearn: 0.2327820\ttotal: 9.43s\tremaining: 4.83s\n",
      "463:\tlearn: 0.2321378\ttotal: 9.46s\tremaining: 4.81s\n",
      "464:\tlearn: 0.2316635\ttotal: 9.47s\tremaining: 4.79s\n",
      "465:\tlearn: 0.2313921\ttotal: 9.5s\tremaining: 4.77s\n",
      "466:\tlearn: 0.2309629\ttotal: 9.52s\tremaining: 4.75s\n",
      "467:\tlearn: 0.2305586\ttotal: 9.54s\tremaining: 4.73s\n",
      "468:\tlearn: 0.2302481\ttotal: 9.56s\tremaining: 4.71s\n",
      "469:\tlearn: 0.2300771\ttotal: 9.58s\tremaining: 4.69s\n",
      "470:\tlearn: 0.2298335\ttotal: 9.6s\tremaining: 4.67s\n",
      "471:\tlearn: 0.2293458\ttotal: 9.62s\tremaining: 4.65s\n",
      "472:\tlearn: 0.2290025\ttotal: 9.64s\tremaining: 4.63s\n",
      "473:\tlearn: 0.2288215\ttotal: 9.66s\tremaining: 4.61s\n",
      "474:\tlearn: 0.2283762\ttotal: 9.68s\tremaining: 4.58s\n",
      "475:\tlearn: 0.2280935\ttotal: 9.7s\tremaining: 4.57s\n",
      "476:\tlearn: 0.2279324\ttotal: 9.72s\tremaining: 4.54s\n",
      "477:\tlearn: 0.2276588\ttotal: 9.74s\tremaining: 4.52s\n",
      "478:\tlearn: 0.2274926\ttotal: 9.77s\tremaining: 4.5s\n",
      "479:\tlearn: 0.2272743\ttotal: 9.79s\tremaining: 4.49s\n",
      "480:\tlearn: 0.2270632\ttotal: 9.81s\tremaining: 4.46s\n",
      "481:\tlearn: 0.2268170\ttotal: 9.83s\tremaining: 4.44s\n",
      "482:\tlearn: 0.2265063\ttotal: 9.85s\tremaining: 4.42s\n",
      "483:\tlearn: 0.2258343\ttotal: 9.87s\tremaining: 4.4s\n",
      "484:\tlearn: 0.2256282\ttotal: 9.89s\tremaining: 4.38s\n",
      "485:\tlearn: 0.2253844\ttotal: 9.91s\tremaining: 4.36s\n",
      "486:\tlearn: 0.2251618\ttotal: 9.93s\tremaining: 4.34s\n",
      "487:\tlearn: 0.2248938\ttotal: 9.95s\tremaining: 4.32s\n",
      "488:\tlearn: 0.2247529\ttotal: 9.97s\tremaining: 4.3s\n",
      "489:\tlearn: 0.2245322\ttotal: 9.99s\tremaining: 4.28s\n",
      "490:\tlearn: 0.2242500\ttotal: 10s\tremaining: 4.26s\n",
      "491:\tlearn: 0.2240460\ttotal: 10s\tremaining: 4.24s\n",
      "492:\tlearn: 0.2233256\ttotal: 10.1s\tremaining: 4.22s\n",
      "493:\tlearn: 0.2229103\ttotal: 10.1s\tremaining: 4.2s\n",
      "494:\tlearn: 0.2223785\ttotal: 10.1s\tremaining: 4.18s\n",
      "495:\tlearn: 0.2221776\ttotal: 10.1s\tremaining: 4.16s\n",
      "496:\tlearn: 0.2216007\ttotal: 10.1s\tremaining: 4.14s\n",
      "497:\tlearn: 0.2214260\ttotal: 10.2s\tremaining: 4.12s\n",
      "498:\tlearn: 0.2208932\ttotal: 10.2s\tremaining: 4.1s\n",
      "499:\tlearn: 0.2204987\ttotal: 10.2s\tremaining: 4.08s\n",
      "500:\tlearn: 0.2203142\ttotal: 10.2s\tremaining: 4.06s\n",
      "501:\tlearn: 0.2198866\ttotal: 10.2s\tremaining: 4.04s\n",
      "502:\tlearn: 0.2193900\ttotal: 10.3s\tremaining: 4.02s\n",
      "503:\tlearn: 0.2191530\ttotal: 10.3s\tremaining: 4s\n",
      "504:\tlearn: 0.2188610\ttotal: 10.3s\tremaining: 3.98s\n",
      "505:\tlearn: 0.2186007\ttotal: 10.3s\tremaining: 3.96s\n",
      "506:\tlearn: 0.2182988\ttotal: 10.3s\tremaining: 3.94s\n",
      "507:\tlearn: 0.2178563\ttotal: 10.4s\tremaining: 3.92s\n",
      "508:\tlearn: 0.2176777\ttotal: 10.4s\tremaining: 3.9s\n",
      "509:\tlearn: 0.2171434\ttotal: 10.4s\tremaining: 3.88s\n",
      "510:\tlearn: 0.2168754\ttotal: 10.4s\tremaining: 3.86s\n",
      "511:\tlearn: 0.2165053\ttotal: 10.4s\tremaining: 3.84s\n",
      "512:\tlearn: 0.2163175\ttotal: 10.5s\tremaining: 3.82s\n",
      "513:\tlearn: 0.2160778\ttotal: 10.5s\tremaining: 3.79s\n",
      "514:\tlearn: 0.2155108\ttotal: 10.5s\tremaining: 3.77s\n",
      "515:\tlearn: 0.2151733\ttotal: 10.5s\tremaining: 3.75s\n",
      "516:\tlearn: 0.2147772\ttotal: 10.6s\tremaining: 3.73s\n",
      "517:\tlearn: 0.2144812\ttotal: 10.6s\tremaining: 3.71s\n",
      "518:\tlearn: 0.2141116\ttotal: 10.6s\tremaining: 3.69s\n",
      "519:\tlearn: 0.2138418\ttotal: 10.6s\tremaining: 3.67s\n",
      "520:\tlearn: 0.2133191\ttotal: 10.6s\tremaining: 3.65s\n",
      "521:\tlearn: 0.2131105\ttotal: 10.7s\tremaining: 3.63s\n",
      "522:\tlearn: 0.2126418\ttotal: 10.7s\tremaining: 3.61s\n",
      "523:\tlearn: 0.2122818\ttotal: 10.7s\tremaining: 3.59s\n",
      "524:\tlearn: 0.2120173\ttotal: 10.7s\tremaining: 3.57s\n",
      "525:\tlearn: 0.2118691\ttotal: 10.7s\tremaining: 3.55s\n",
      "526:\tlearn: 0.2115341\ttotal: 10.8s\tremaining: 3.53s\n",
      "527:\tlearn: 0.2112464\ttotal: 10.8s\tremaining: 3.51s\n",
      "528:\tlearn: 0.2108339\ttotal: 10.8s\tremaining: 3.49s\n",
      "529:\tlearn: 0.2106812\ttotal: 10.8s\tremaining: 3.47s\n",
      "530:\tlearn: 0.2104447\ttotal: 10.8s\tremaining: 3.45s\n",
      "531:\tlearn: 0.2101635\ttotal: 10.9s\tremaining: 3.43s\n",
      "532:\tlearn: 0.2099778\ttotal: 10.9s\tremaining: 3.41s\n",
      "533:\tlearn: 0.2093965\ttotal: 10.9s\tremaining: 3.39s\n",
      "534:\tlearn: 0.2092782\ttotal: 10.9s\tremaining: 3.37s\n",
      "535:\tlearn: 0.2088829\ttotal: 11s\tremaining: 3.35s\n",
      "536:\tlearn: 0.2086814\ttotal: 11s\tremaining: 3.33s\n",
      "537:\tlearn: 0.2083931\ttotal: 11s\tremaining: 3.31s\n",
      "538:\tlearn: 0.2080766\ttotal: 11s\tremaining: 3.29s\n",
      "539:\tlearn: 0.2078413\ttotal: 11s\tremaining: 3.27s\n",
      "540:\tlearn: 0.2075352\ttotal: 11.1s\tremaining: 3.25s\n",
      "541:\tlearn: 0.2070290\ttotal: 11.1s\tremaining: 3.23s\n",
      "542:\tlearn: 0.2067054\ttotal: 11.1s\tremaining: 3.21s\n",
      "543:\tlearn: 0.2063503\ttotal: 11.1s\tremaining: 3.19s\n",
      "544:\tlearn: 0.2056860\ttotal: 11.1s\tremaining: 3.17s\n",
      "545:\tlearn: 0.2054506\ttotal: 11.2s\tremaining: 3.15s\n",
      "546:\tlearn: 0.2051009\ttotal: 11.2s\tremaining: 3.13s\n",
      "547:\tlearn: 0.2048631\ttotal: 11.2s\tremaining: 3.1s\n",
      "548:\tlearn: 0.2044647\ttotal: 11.2s\tremaining: 3.08s\n",
      "549:\tlearn: 0.2042222\ttotal: 11.2s\tremaining: 3.06s\n",
      "550:\tlearn: 0.2040517\ttotal: 11.3s\tremaining: 3.04s\n",
      "551:\tlearn: 0.2037995\ttotal: 11.3s\tremaining: 3.02s\n",
      "552:\tlearn: 0.2035129\ttotal: 11.3s\tremaining: 3s\n",
      "553:\tlearn: 0.2030577\ttotal: 11.3s\tremaining: 2.98s\n",
      "554:\tlearn: 0.2028885\ttotal: 11.3s\tremaining: 2.96s\n",
      "555:\tlearn: 0.2026821\ttotal: 11.4s\tremaining: 2.94s\n",
      "556:\tlearn: 0.2024353\ttotal: 11.4s\tremaining: 2.92s\n",
      "557:\tlearn: 0.2022202\ttotal: 11.4s\tremaining: 2.9s\n",
      "558:\tlearn: 0.2019887\ttotal: 11.4s\tremaining: 2.88s\n",
      "559:\tlearn: 0.2018134\ttotal: 11.4s\tremaining: 2.86s\n",
      "560:\tlearn: 0.2015056\ttotal: 11.5s\tremaining: 2.84s\n",
      "561:\tlearn: 0.2012706\ttotal: 11.5s\tremaining: 2.82s\n",
      "562:\tlearn: 0.2010304\ttotal: 11.5s\tremaining: 2.8s\n",
      "563:\tlearn: 0.2007411\ttotal: 11.5s\tremaining: 2.78s\n",
      "564:\tlearn: 0.2005578\ttotal: 11.5s\tremaining: 2.76s\n",
      "565:\tlearn: 0.2002264\ttotal: 11.6s\tremaining: 2.74s\n",
      "566:\tlearn: 0.1997149\ttotal: 11.6s\tremaining: 2.72s\n",
      "567:\tlearn: 0.1993894\ttotal: 11.6s\tremaining: 2.7s\n",
      "568:\tlearn: 0.1990271\ttotal: 11.6s\tremaining: 2.68s\n",
      "569:\tlearn: 0.1988759\ttotal: 11.6s\tremaining: 2.66s\n",
      "570:\tlearn: 0.1987163\ttotal: 11.7s\tremaining: 2.63s\n",
      "571:\tlearn: 0.1983632\ttotal: 11.7s\tremaining: 2.61s\n",
      "572:\tlearn: 0.1981529\ttotal: 11.7s\tremaining: 2.59s\n",
      "573:\tlearn: 0.1979468\ttotal: 11.7s\tremaining: 2.57s\n",
      "574:\tlearn: 0.1977164\ttotal: 11.7s\tremaining: 2.55s\n",
      "575:\tlearn: 0.1975382\ttotal: 11.8s\tremaining: 2.53s\n",
      "576:\tlearn: 0.1972459\ttotal: 11.8s\tremaining: 2.51s\n",
      "577:\tlearn: 0.1970096\ttotal: 11.8s\tremaining: 2.49s\n",
      "578:\tlearn: 0.1966226\ttotal: 11.8s\tremaining: 2.47s\n",
      "579:\tlearn: 0.1963855\ttotal: 11.9s\tremaining: 2.45s\n",
      "580:\tlearn: 0.1961877\ttotal: 11.9s\tremaining: 2.43s\n",
      "581:\tlearn: 0.1959587\ttotal: 11.9s\tremaining: 2.41s\n",
      "582:\tlearn: 0.1957992\ttotal: 11.9s\tremaining: 2.39s\n",
      "583:\tlearn: 0.1954352\ttotal: 11.9s\tremaining: 2.37s\n",
      "584:\tlearn: 0.1950927\ttotal: 12s\tremaining: 2.35s\n",
      "585:\tlearn: 0.1949124\ttotal: 12s\tremaining: 2.33s\n",
      "586:\tlearn: 0.1947144\ttotal: 12s\tremaining: 2.31s\n",
      "587:\tlearn: 0.1944521\ttotal: 12s\tremaining: 2.29s\n",
      "588:\tlearn: 0.1940927\ttotal: 12s\tremaining: 2.27s\n",
      "589:\tlearn: 0.1938529\ttotal: 12.1s\tremaining: 2.25s\n",
      "590:\tlearn: 0.1933552\ttotal: 12.1s\tremaining: 2.23s\n",
      "591:\tlearn: 0.1931895\ttotal: 12.1s\tremaining: 2.21s\n",
      "592:\tlearn: 0.1928109\ttotal: 12.1s\tremaining: 2.19s\n",
      "593:\tlearn: 0.1925975\ttotal: 12.1s\tremaining: 2.17s\n",
      "594:\tlearn: 0.1923907\ttotal: 12.2s\tremaining: 2.15s\n",
      "595:\tlearn: 0.1921490\ttotal: 12.2s\tremaining: 2.12s\n",
      "596:\tlearn: 0.1920049\ttotal: 12.2s\tremaining: 2.1s\n",
      "597:\tlearn: 0.1918657\ttotal: 12.2s\tremaining: 2.08s\n",
      "598:\tlearn: 0.1915490\ttotal: 12.2s\tremaining: 2.06s\n",
      "599:\tlearn: 0.1912544\ttotal: 12.3s\tremaining: 2.04s\n",
      "600:\tlearn: 0.1909228\ttotal: 12.3s\tremaining: 2.02s\n",
      "601:\tlearn: 0.1906848\ttotal: 12.3s\tremaining: 2s\n",
      "602:\tlearn: 0.1903882\ttotal: 12.3s\tremaining: 1.98s\n",
      "603:\tlearn: 0.1901280\ttotal: 12.3s\tremaining: 1.96s\n",
      "604:\tlearn: 0.1899585\ttotal: 12.4s\tremaining: 1.94s\n",
      "605:\tlearn: 0.1896728\ttotal: 12.4s\tremaining: 1.92s\n",
      "606:\tlearn: 0.1893409\ttotal: 12.4s\tremaining: 1.9s\n",
      "607:\tlearn: 0.1891275\ttotal: 12.4s\tremaining: 1.88s\n",
      "608:\tlearn: 0.1889709\ttotal: 12.4s\tremaining: 1.86s\n",
      "609:\tlearn: 0.1887716\ttotal: 12.5s\tremaining: 1.84s\n",
      "610:\tlearn: 0.1884405\ttotal: 12.5s\tremaining: 1.82s\n",
      "611:\tlearn: 0.1881487\ttotal: 12.5s\tremaining: 1.8s\n",
      "612:\tlearn: 0.1878383\ttotal: 12.5s\tremaining: 1.78s\n",
      "613:\tlearn: 0.1876050\ttotal: 12.5s\tremaining: 1.76s\n",
      "614:\tlearn: 0.1873520\ttotal: 12.6s\tremaining: 1.74s\n",
      "615:\tlearn: 0.1871239\ttotal: 12.6s\tremaining: 1.72s\n",
      "616:\tlearn: 0.1869172\ttotal: 12.6s\tremaining: 1.7s\n",
      "617:\tlearn: 0.1867451\ttotal: 12.6s\tremaining: 1.67s\n",
      "618:\tlearn: 0.1864230\ttotal: 12.6s\tremaining: 1.65s\n",
      "619:\tlearn: 0.1861628\ttotal: 12.7s\tremaining: 1.63s\n",
      "620:\tlearn: 0.1859937\ttotal: 12.7s\tremaining: 1.61s\n",
      "621:\tlearn: 0.1857625\ttotal: 12.7s\tremaining: 1.59s\n",
      "622:\tlearn: 0.1855951\ttotal: 12.7s\tremaining: 1.57s\n",
      "623:\tlearn: 0.1854657\ttotal: 12.7s\tremaining: 1.55s\n",
      "624:\tlearn: 0.1852422\ttotal: 12.8s\tremaining: 1.53s\n",
      "625:\tlearn: 0.1847602\ttotal: 12.8s\tremaining: 1.51s\n",
      "626:\tlearn: 0.1845417\ttotal: 12.8s\tremaining: 1.49s\n",
      "627:\tlearn: 0.1843384\ttotal: 12.8s\tremaining: 1.47s\n",
      "628:\tlearn: 0.1839481\ttotal: 12.9s\tremaining: 1.45s\n",
      "629:\tlearn: 0.1837021\ttotal: 12.9s\tremaining: 1.43s\n",
      "630:\tlearn: 0.1835743\ttotal: 12.9s\tremaining: 1.41s\n",
      "631:\tlearn: 0.1833769\ttotal: 12.9s\tremaining: 1.39s\n",
      "632:\tlearn: 0.1831430\ttotal: 12.9s\tremaining: 1.37s\n",
      "633:\tlearn: 0.1830050\ttotal: 13s\tremaining: 1.35s\n",
      "634:\tlearn: 0.1826664\ttotal: 13s\tremaining: 1.33s\n",
      "635:\tlearn: 0.1824893\ttotal: 13s\tremaining: 1.31s\n",
      "636:\tlearn: 0.1822053\ttotal: 13s\tremaining: 1.29s\n",
      "637:\tlearn: 0.1819754\ttotal: 13s\tremaining: 1.27s\n",
      "638:\tlearn: 0.1817887\ttotal: 13.1s\tremaining: 1.25s\n",
      "639:\tlearn: 0.1815271\ttotal: 13.1s\tremaining: 1.23s\n",
      "640:\tlearn: 0.1812121\ttotal: 13.1s\tremaining: 1.21s\n",
      "641:\tlearn: 0.1809074\ttotal: 13.1s\tremaining: 1.19s\n",
      "642:\tlearn: 0.1805828\ttotal: 13.1s\tremaining: 1.16s\n",
      "643:\tlearn: 0.1804950\ttotal: 13.2s\tremaining: 1.14s\n",
      "644:\tlearn: 0.1802117\ttotal: 13.2s\tremaining: 1.12s\n",
      "645:\tlearn: 0.1799695\ttotal: 13.2s\tremaining: 1.1s\n",
      "646:\tlearn: 0.1797505\ttotal: 13.2s\tremaining: 1.08s\n",
      "647:\tlearn: 0.1795510\ttotal: 13.2s\tremaining: 1.06s\n",
      "648:\tlearn: 0.1793159\ttotal: 13.3s\tremaining: 1.04s\n",
      "649:\tlearn: 0.1791045\ttotal: 13.3s\tremaining: 1.02s\n",
      "650:\tlearn: 0.1787931\ttotal: 13.3s\tremaining: 1s\n",
      "651:\tlearn: 0.1785383\ttotal: 13.3s\tremaining: 981ms\n",
      "652:\tlearn: 0.1783136\ttotal: 13.3s\tremaining: 961ms\n",
      "653:\tlearn: 0.1778739\ttotal: 13.4s\tremaining: 940ms\n",
      "654:\tlearn: 0.1777285\ttotal: 13.4s\tremaining: 920ms\n",
      "655:\tlearn: 0.1775673\ttotal: 13.4s\tremaining: 899ms\n",
      "656:\tlearn: 0.1772467\ttotal: 13.4s\tremaining: 879ms\n",
      "657:\tlearn: 0.1770915\ttotal: 13.5s\tremaining: 859ms\n",
      "658:\tlearn: 0.1767874\ttotal: 13.5s\tremaining: 838ms\n",
      "659:\tlearn: 0.1765556\ttotal: 13.5s\tremaining: 818ms\n",
      "660:\tlearn: 0.1763105\ttotal: 13.5s\tremaining: 797ms\n",
      "661:\tlearn: 0.1760461\ttotal: 13.5s\tremaining: 777ms\n",
      "662:\tlearn: 0.1757379\ttotal: 13.6s\tremaining: 756ms\n",
      "663:\tlearn: 0.1755530\ttotal: 13.6s\tremaining: 736ms\n",
      "664:\tlearn: 0.1752919\ttotal: 13.6s\tremaining: 716ms\n",
      "665:\tlearn: 0.1750505\ttotal: 13.6s\tremaining: 695ms\n",
      "666:\tlearn: 0.1746179\ttotal: 13.6s\tremaining: 675ms\n",
      "667:\tlearn: 0.1744000\ttotal: 13.7s\tremaining: 654ms\n",
      "668:\tlearn: 0.1741792\ttotal: 13.7s\tremaining: 634ms\n",
      "669:\tlearn: 0.1740031\ttotal: 13.7s\tremaining: 613ms\n",
      "670:\tlearn: 0.1736994\ttotal: 13.7s\tremaining: 593ms\n",
      "671:\tlearn: 0.1732891\ttotal: 13.7s\tremaining: 573ms\n",
      "672:\tlearn: 0.1731246\ttotal: 13.8s\tremaining: 552ms\n",
      "673:\tlearn: 0.1729448\ttotal: 13.8s\tremaining: 532ms\n",
      "674:\tlearn: 0.1726941\ttotal: 13.8s\tremaining: 511ms\n",
      "675:\tlearn: 0.1725704\ttotal: 13.8s\tremaining: 491ms\n",
      "676:\tlearn: 0.1723579\ttotal: 13.8s\tremaining: 470ms\n",
      "677:\tlearn: 0.1720793\ttotal: 13.9s\tremaining: 450ms\n",
      "678:\tlearn: 0.1717614\ttotal: 13.9s\tremaining: 429ms\n",
      "679:\tlearn: 0.1713801\ttotal: 13.9s\tremaining: 409ms\n",
      "680:\tlearn: 0.1711849\ttotal: 13.9s\tremaining: 389ms\n",
      "681:\tlearn: 0.1709544\ttotal: 13.9s\tremaining: 368ms\n",
      "682:\tlearn: 0.1707654\ttotal: 14s\tremaining: 348ms\n",
      "683:\tlearn: 0.1706020\ttotal: 14s\tremaining: 327ms\n",
      "684:\tlearn: 0.1703891\ttotal: 14s\tremaining: 307ms\n",
      "685:\tlearn: 0.1701301\ttotal: 14s\tremaining: 286ms\n",
      "686:\tlearn: 0.1698646\ttotal: 14.1s\tremaining: 266ms\n",
      "687:\tlearn: 0.1696775\ttotal: 14.1s\tremaining: 245ms\n",
      "688:\tlearn: 0.1694392\ttotal: 14.1s\tremaining: 225ms\n",
      "689:\tlearn: 0.1692393\ttotal: 14.1s\tremaining: 205ms\n",
      "690:\tlearn: 0.1690294\ttotal: 14.1s\tremaining: 184ms\n",
      "691:\tlearn: 0.1687109\ttotal: 14.2s\tremaining: 164ms\n",
      "692:\tlearn: 0.1684541\ttotal: 14.2s\tremaining: 143ms\n",
      "693:\tlearn: 0.1682769\ttotal: 14.2s\tremaining: 123ms\n",
      "694:\tlearn: 0.1679732\ttotal: 14.2s\tremaining: 102ms\n",
      "695:\tlearn: 0.1677091\ttotal: 14.2s\tremaining: 81.8ms\n",
      "696:\tlearn: 0.1674552\ttotal: 14.3s\tremaining: 61.4ms\n",
      "697:\tlearn: 0.1672451\ttotal: 14.3s\tremaining: 40.9ms\n",
      "698:\tlearn: 0.1669937\ttotal: 14.3s\tremaining: 20.5ms\n",
      "699:\tlearn: 0.1668140\ttotal: 14.3s\tremaining: 0us\n",
      "0:\tlearn: 0.6819459\ttotal: 21.2ms\tremaining: 14.8s\n",
      "1:\tlearn: 0.6720410\ttotal: 41.3ms\tremaining: 14.4s\n",
      "2:\tlearn: 0.6616339\ttotal: 62.4ms\tremaining: 14.5s\n",
      "3:\tlearn: 0.6545574\ttotal: 72ms\tremaining: 12.5s\n",
      "4:\tlearn: 0.6444278\ttotal: 92.4ms\tremaining: 12.8s\n",
      "5:\tlearn: 0.6341527\ttotal: 113ms\tremaining: 13.1s\n",
      "6:\tlearn: 0.6256320\ttotal: 135ms\tremaining: 13.4s\n",
      "7:\tlearn: 0.6168523\ttotal: 156ms\tremaining: 13.5s\n",
      "8:\tlearn: 0.6106962\ttotal: 176ms\tremaining: 13.5s\n",
      "9:\tlearn: 0.6033690\ttotal: 196ms\tremaining: 13.6s\n",
      "10:\tlearn: 0.5959732\ttotal: 216ms\tremaining: 13.5s\n",
      "11:\tlearn: 0.5882037\ttotal: 237ms\tremaining: 13.6s\n",
      "12:\tlearn: 0.5814163\ttotal: 260ms\tremaining: 13.7s\n",
      "13:\tlearn: 0.5755966\ttotal: 282ms\tremaining: 13.8s\n",
      "14:\tlearn: 0.5689408\ttotal: 307ms\tremaining: 14s\n",
      "15:\tlearn: 0.5621836\ttotal: 328ms\tremaining: 14s\n",
      "16:\tlearn: 0.5560233\ttotal: 349ms\tremaining: 14s\n",
      "17:\tlearn: 0.5507010\ttotal: 369ms\tremaining: 14s\n",
      "18:\tlearn: 0.5465033\ttotal: 389ms\tremaining: 13.9s\n",
      "19:\tlearn: 0.5411702\ttotal: 410ms\tremaining: 13.9s\n",
      "20:\tlearn: 0.5355895\ttotal: 430ms\tremaining: 13.9s\n",
      "21:\tlearn: 0.5312821\ttotal: 452ms\tremaining: 13.9s\n",
      "22:\tlearn: 0.5270256\ttotal: 468ms\tremaining: 13.8s\n",
      "23:\tlearn: 0.5243809\ttotal: 477ms\tremaining: 13.4s\n",
      "24:\tlearn: 0.5199080\ttotal: 497ms\tremaining: 13.4s\n",
      "25:\tlearn: 0.5156547\ttotal: 518ms\tremaining: 13.4s\n",
      "26:\tlearn: 0.5119723\ttotal: 538ms\tremaining: 13.4s\n",
      "27:\tlearn: 0.5070203\ttotal: 559ms\tremaining: 13.4s\n",
      "28:\tlearn: 0.5037614\ttotal: 579ms\tremaining: 13.4s\n",
      "29:\tlearn: 0.4995086\ttotal: 600ms\tremaining: 13.4s\n",
      "30:\tlearn: 0.4966093\ttotal: 620ms\tremaining: 13.4s\n",
      "31:\tlearn: 0.4936703\ttotal: 641ms\tremaining: 13.4s\n",
      "32:\tlearn: 0.4902333\ttotal: 662ms\tremaining: 13.4s\n",
      "33:\tlearn: 0.4869947\ttotal: 683ms\tremaining: 13.4s\n",
      "34:\tlearn: 0.4836914\ttotal: 704ms\tremaining: 13.4s\n",
      "35:\tlearn: 0.4810284\ttotal: 724ms\tremaining: 13.4s\n",
      "36:\tlearn: 0.4780873\ttotal: 746ms\tremaining: 13.4s\n",
      "37:\tlearn: 0.4750688\ttotal: 768ms\tremaining: 13.4s\n",
      "38:\tlearn: 0.4721424\ttotal: 790ms\tremaining: 13.4s\n",
      "39:\tlearn: 0.4696433\ttotal: 810ms\tremaining: 13.4s\n",
      "40:\tlearn: 0.4670140\ttotal: 831ms\tremaining: 13.4s\n",
      "41:\tlearn: 0.4644944\ttotal: 851ms\tremaining: 13.3s\n",
      "42:\tlearn: 0.4617969\ttotal: 873ms\tremaining: 13.3s\n",
      "43:\tlearn: 0.4598850\ttotal: 894ms\tremaining: 13.3s\n",
      "44:\tlearn: 0.4576467\ttotal: 914ms\tremaining: 13.3s\n",
      "45:\tlearn: 0.4559087\ttotal: 934ms\tremaining: 13.3s\n",
      "46:\tlearn: 0.4544024\ttotal: 954ms\tremaining: 13.3s\n",
      "47:\tlearn: 0.4523666\ttotal: 975ms\tremaining: 13.2s\n",
      "48:\tlearn: 0.4498430\ttotal: 995ms\tremaining: 13.2s\n",
      "49:\tlearn: 0.4481250\ttotal: 1.01s\tremaining: 13.2s\n",
      "50:\tlearn: 0.4462051\ttotal: 1.03s\tremaining: 13.2s\n",
      "51:\tlearn: 0.4443104\ttotal: 1.06s\tremaining: 13.2s\n",
      "52:\tlearn: 0.4428202\ttotal: 1.08s\tremaining: 13.1s\n",
      "53:\tlearn: 0.4407037\ttotal: 1.1s\tremaining: 13.1s\n",
      "54:\tlearn: 0.4382213\ttotal: 1.12s\tremaining: 13.1s\n",
      "55:\tlearn: 0.4366636\ttotal: 1.14s\tremaining: 13.1s\n",
      "56:\tlearn: 0.4350665\ttotal: 1.16s\tremaining: 13.1s\n",
      "57:\tlearn: 0.4339488\ttotal: 1.18s\tremaining: 13.1s\n",
      "58:\tlearn: 0.4322011\ttotal: 1.2s\tremaining: 13s\n",
      "59:\tlearn: 0.4309608\ttotal: 1.22s\tremaining: 13s\n",
      "60:\tlearn: 0.4291991\ttotal: 1.24s\tremaining: 13s\n",
      "61:\tlearn: 0.4266931\ttotal: 1.27s\tremaining: 13s\n",
      "62:\tlearn: 0.4248104\ttotal: 1.29s\tremaining: 13s\n",
      "63:\tlearn: 0.4238029\ttotal: 1.31s\tremaining: 13s\n",
      "64:\tlearn: 0.4224410\ttotal: 1.34s\tremaining: 13.1s\n",
      "65:\tlearn: 0.4208565\ttotal: 1.37s\tremaining: 13.1s\n",
      "66:\tlearn: 0.4191111\ttotal: 1.39s\tremaining: 13.1s\n",
      "67:\tlearn: 0.4176344\ttotal: 1.41s\tremaining: 13.1s\n",
      "68:\tlearn: 0.4163547\ttotal: 1.44s\tremaining: 13.1s\n",
      "69:\tlearn: 0.4153078\ttotal: 1.46s\tremaining: 13.1s\n",
      "70:\tlearn: 0.4140026\ttotal: 1.48s\tremaining: 13.1s\n",
      "71:\tlearn: 0.4126665\ttotal: 1.5s\tremaining: 13.1s\n",
      "72:\tlearn: 0.4116919\ttotal: 1.52s\tremaining: 13.1s\n",
      "73:\tlearn: 0.4100501\ttotal: 1.55s\tremaining: 13.1s\n",
      "74:\tlearn: 0.4088265\ttotal: 1.57s\tremaining: 13.1s\n",
      "75:\tlearn: 0.4078692\ttotal: 1.59s\tremaining: 13s\n",
      "76:\tlearn: 0.4066821\ttotal: 1.61s\tremaining: 13s\n",
      "77:\tlearn: 0.4053330\ttotal: 1.63s\tremaining: 13s\n",
      "78:\tlearn: 0.4039774\ttotal: 1.65s\tremaining: 13s\n",
      "79:\tlearn: 0.4029711\ttotal: 1.67s\tremaining: 13s\n",
      "80:\tlearn: 0.4019723\ttotal: 1.69s\tremaining: 12.9s\n",
      "81:\tlearn: 0.4010196\ttotal: 1.71s\tremaining: 12.9s\n",
      "82:\tlearn: 0.3999144\ttotal: 1.73s\tremaining: 12.9s\n",
      "83:\tlearn: 0.3985602\ttotal: 1.76s\tremaining: 12.9s\n",
      "84:\tlearn: 0.3977073\ttotal: 1.78s\tremaining: 12.9s\n",
      "85:\tlearn: 0.3968327\ttotal: 1.8s\tremaining: 12.9s\n",
      "86:\tlearn: 0.3956060\ttotal: 1.83s\tremaining: 12.9s\n",
      "87:\tlearn: 0.3942847\ttotal: 1.85s\tremaining: 12.9s\n",
      "88:\tlearn: 0.3933138\ttotal: 1.87s\tremaining: 12.8s\n",
      "89:\tlearn: 0.3921706\ttotal: 1.89s\tremaining: 12.8s\n",
      "90:\tlearn: 0.3910751\ttotal: 1.91s\tremaining: 12.8s\n",
      "91:\tlearn: 0.3903258\ttotal: 1.93s\tremaining: 12.8s\n",
      "92:\tlearn: 0.3893101\ttotal: 1.95s\tremaining: 12.8s\n",
      "93:\tlearn: 0.3887326\ttotal: 1.98s\tremaining: 12.7s\n",
      "94:\tlearn: 0.3882604\ttotal: 2s\tremaining: 12.7s\n",
      "95:\tlearn: 0.3874466\ttotal: 2.02s\tremaining: 12.7s\n",
      "96:\tlearn: 0.3864565\ttotal: 2.04s\tremaining: 12.7s\n",
      "97:\tlearn: 0.3853040\ttotal: 2.06s\tremaining: 12.7s\n",
      "98:\tlearn: 0.3846148\ttotal: 2.08s\tremaining: 12.6s\n",
      "99:\tlearn: 0.3833956\ttotal: 2.1s\tremaining: 12.6s\n",
      "100:\tlearn: 0.3826452\ttotal: 2.12s\tremaining: 12.6s\n",
      "101:\tlearn: 0.3818269\ttotal: 2.15s\tremaining: 12.6s\n",
      "102:\tlearn: 0.3809912\ttotal: 2.17s\tremaining: 12.6s\n",
      "103:\tlearn: 0.3801405\ttotal: 2.19s\tremaining: 12.5s\n",
      "104:\tlearn: 0.3793487\ttotal: 2.21s\tremaining: 12.5s\n",
      "105:\tlearn: 0.3783906\ttotal: 2.23s\tremaining: 12.5s\n",
      "106:\tlearn: 0.3778196\ttotal: 2.25s\tremaining: 12.5s\n",
      "107:\tlearn: 0.3771663\ttotal: 2.28s\tremaining: 12.5s\n",
      "108:\tlearn: 0.3763071\ttotal: 2.3s\tremaining: 12.5s\n",
      "109:\tlearn: 0.3758256\ttotal: 2.32s\tremaining: 12.4s\n",
      "110:\tlearn: 0.3753460\ttotal: 2.34s\tremaining: 12.4s\n",
      "111:\tlearn: 0.3749053\ttotal: 2.36s\tremaining: 12.4s\n",
      "112:\tlearn: 0.3738159\ttotal: 2.38s\tremaining: 12.4s\n",
      "113:\tlearn: 0.3731374\ttotal: 2.4s\tremaining: 12.4s\n",
      "114:\tlearn: 0.3721930\ttotal: 2.43s\tremaining: 12.4s\n",
      "115:\tlearn: 0.3714407\ttotal: 2.45s\tremaining: 12.3s\n",
      "116:\tlearn: 0.3706840\ttotal: 2.47s\tremaining: 12.3s\n",
      "117:\tlearn: 0.3701192\ttotal: 2.5s\tremaining: 12.3s\n",
      "118:\tlearn: 0.3694958\ttotal: 2.52s\tremaining: 12.3s\n",
      "119:\tlearn: 0.3688019\ttotal: 2.54s\tremaining: 12.3s\n",
      "120:\tlearn: 0.3676891\ttotal: 2.56s\tremaining: 12.3s\n",
      "121:\tlearn: 0.3669881\ttotal: 2.58s\tremaining: 12.2s\n",
      "122:\tlearn: 0.3664383\ttotal: 2.6s\tremaining: 12.2s\n",
      "123:\tlearn: 0.3653935\ttotal: 2.63s\tremaining: 12.2s\n",
      "124:\tlearn: 0.3643668\ttotal: 2.65s\tremaining: 12.2s\n",
      "125:\tlearn: 0.3636693\ttotal: 2.67s\tremaining: 12.2s\n",
      "126:\tlearn: 0.3629067\ttotal: 2.69s\tremaining: 12.1s\n",
      "127:\tlearn: 0.3625155\ttotal: 2.71s\tremaining: 12.1s\n",
      "128:\tlearn: 0.3612211\ttotal: 2.73s\tremaining: 12.1s\n",
      "129:\tlearn: 0.3605220\ttotal: 2.76s\tremaining: 12.1s\n",
      "130:\tlearn: 0.3598225\ttotal: 2.78s\tremaining: 12.1s\n",
      "131:\tlearn: 0.3592769\ttotal: 2.8s\tremaining: 12.1s\n",
      "132:\tlearn: 0.3587779\ttotal: 2.82s\tremaining: 12s\n",
      "133:\tlearn: 0.3578099\ttotal: 2.85s\tremaining: 12s\n",
      "134:\tlearn: 0.3570995\ttotal: 2.87s\tremaining: 12s\n",
      "135:\tlearn: 0.3566144\ttotal: 2.89s\tremaining: 12s\n",
      "136:\tlearn: 0.3561896\ttotal: 2.91s\tremaining: 12s\n",
      "137:\tlearn: 0.3556056\ttotal: 2.93s\tremaining: 11.9s\n",
      "138:\tlearn: 0.3548725\ttotal: 2.95s\tremaining: 11.9s\n",
      "139:\tlearn: 0.3543295\ttotal: 2.97s\tremaining: 11.9s\n",
      "140:\tlearn: 0.3539344\ttotal: 2.99s\tremaining: 11.9s\n",
      "141:\tlearn: 0.3534600\ttotal: 3.01s\tremaining: 11.8s\n",
      "142:\tlearn: 0.3529133\ttotal: 3.03s\tremaining: 11.8s\n",
      "143:\tlearn: 0.3519562\ttotal: 3.06s\tremaining: 11.8s\n",
      "144:\tlearn: 0.3515386\ttotal: 3.08s\tremaining: 11.8s\n",
      "145:\tlearn: 0.3510379\ttotal: 3.1s\tremaining: 11.8s\n",
      "146:\tlearn: 0.3503521\ttotal: 3.12s\tremaining: 11.7s\n",
      "147:\tlearn: 0.3498261\ttotal: 3.14s\tremaining: 11.7s\n",
      "148:\tlearn: 0.3492895\ttotal: 3.16s\tremaining: 11.7s\n",
      "149:\tlearn: 0.3486720\ttotal: 3.18s\tremaining: 11.7s\n",
      "150:\tlearn: 0.3479954\ttotal: 3.21s\tremaining: 11.7s\n",
      "151:\tlearn: 0.3474764\ttotal: 3.23s\tremaining: 11.6s\n",
      "152:\tlearn: 0.3474567\ttotal: 3.23s\tremaining: 11.6s\n",
      "153:\tlearn: 0.3465941\ttotal: 3.26s\tremaining: 11.6s\n",
      "154:\tlearn: 0.3462144\ttotal: 3.28s\tremaining: 11.5s\n",
      "155:\tlearn: 0.3457588\ttotal: 3.31s\tremaining: 11.5s\n",
      "156:\tlearn: 0.3451484\ttotal: 3.33s\tremaining: 11.5s\n",
      "157:\tlearn: 0.3445966\ttotal: 3.35s\tremaining: 11.5s\n",
      "158:\tlearn: 0.3441962\ttotal: 3.37s\tremaining: 11.5s\n",
      "159:\tlearn: 0.3435298\ttotal: 3.39s\tremaining: 11.4s\n",
      "160:\tlearn: 0.3429211\ttotal: 3.41s\tremaining: 11.4s\n",
      "161:\tlearn: 0.3424104\ttotal: 3.43s\tremaining: 11.4s\n",
      "162:\tlearn: 0.3417640\ttotal: 3.46s\tremaining: 11.4s\n",
      "163:\tlearn: 0.3411762\ttotal: 3.48s\tremaining: 11.4s\n",
      "164:\tlearn: 0.3407728\ttotal: 3.5s\tremaining: 11.3s\n",
      "165:\tlearn: 0.3402873\ttotal: 3.52s\tremaining: 11.3s\n",
      "166:\tlearn: 0.3393007\ttotal: 3.54s\tremaining: 11.3s\n",
      "167:\tlearn: 0.3388012\ttotal: 3.56s\tremaining: 11.3s\n",
      "168:\tlearn: 0.3379841\ttotal: 3.58s\tremaining: 11.3s\n",
      "169:\tlearn: 0.3374381\ttotal: 3.6s\tremaining: 11.2s\n",
      "170:\tlearn: 0.3367240\ttotal: 3.63s\tremaining: 11.2s\n",
      "171:\tlearn: 0.3362089\ttotal: 3.65s\tremaining: 11.2s\n",
      "172:\tlearn: 0.3356184\ttotal: 3.67s\tremaining: 11.2s\n",
      "173:\tlearn: 0.3350622\ttotal: 3.69s\tremaining: 11.2s\n",
      "174:\tlearn: 0.3344895\ttotal: 3.71s\tremaining: 11.1s\n",
      "175:\tlearn: 0.3342343\ttotal: 3.73s\tremaining: 11.1s\n",
      "176:\tlearn: 0.3338411\ttotal: 3.76s\tremaining: 11.1s\n",
      "177:\tlearn: 0.3335113\ttotal: 3.78s\tremaining: 11.1s\n",
      "178:\tlearn: 0.3331141\ttotal: 3.8s\tremaining: 11.1s\n",
      "179:\tlearn: 0.3325541\ttotal: 3.82s\tremaining: 11s\n",
      "180:\tlearn: 0.3319483\ttotal: 3.84s\tremaining: 11s\n",
      "181:\tlearn: 0.3314967\ttotal: 3.86s\tremaining: 11s\n",
      "182:\tlearn: 0.3307702\ttotal: 3.88s\tremaining: 11s\n",
      "183:\tlearn: 0.3301662\ttotal: 3.91s\tremaining: 11s\n",
      "184:\tlearn: 0.3296056\ttotal: 3.93s\tremaining: 10.9s\n",
      "185:\tlearn: 0.3293485\ttotal: 3.95s\tremaining: 10.9s\n",
      "186:\tlearn: 0.3288838\ttotal: 3.97s\tremaining: 10.9s\n",
      "187:\tlearn: 0.3284549\ttotal: 3.99s\tremaining: 10.9s\n",
      "188:\tlearn: 0.3280137\ttotal: 4.01s\tremaining: 10.8s\n",
      "189:\tlearn: 0.3277284\ttotal: 4.03s\tremaining: 10.8s\n",
      "190:\tlearn: 0.3271996\ttotal: 4.05s\tremaining: 10.8s\n",
      "191:\tlearn: 0.3269338\ttotal: 4.08s\tremaining: 10.8s\n",
      "192:\tlearn: 0.3264694\ttotal: 4.1s\tremaining: 10.8s\n",
      "193:\tlearn: 0.3260619\ttotal: 4.12s\tremaining: 10.7s\n",
      "194:\tlearn: 0.3255900\ttotal: 4.14s\tremaining: 10.7s\n",
      "195:\tlearn: 0.3251759\ttotal: 4.16s\tremaining: 10.7s\n",
      "196:\tlearn: 0.3245411\ttotal: 4.18s\tremaining: 10.7s\n",
      "197:\tlearn: 0.3238859\ttotal: 4.2s\tremaining: 10.7s\n",
      "198:\tlearn: 0.3234849\ttotal: 4.22s\tremaining: 10.6s\n",
      "199:\tlearn: 0.3231016\ttotal: 4.25s\tremaining: 10.6s\n",
      "200:\tlearn: 0.3229344\ttotal: 4.27s\tremaining: 10.6s\n",
      "201:\tlearn: 0.3225467\ttotal: 4.29s\tremaining: 10.6s\n",
      "202:\tlearn: 0.3222389\ttotal: 4.31s\tremaining: 10.6s\n",
      "203:\tlearn: 0.3217190\ttotal: 4.34s\tremaining: 10.5s\n",
      "204:\tlearn: 0.3212241\ttotal: 4.36s\tremaining: 10.5s\n",
      "205:\tlearn: 0.3206832\ttotal: 4.38s\tremaining: 10.5s\n",
      "206:\tlearn: 0.3202004\ttotal: 4.4s\tremaining: 10.5s\n",
      "207:\tlearn: 0.3197381\ttotal: 4.42s\tremaining: 10.5s\n",
      "208:\tlearn: 0.3192385\ttotal: 4.44s\tremaining: 10.4s\n",
      "209:\tlearn: 0.3188916\ttotal: 4.46s\tremaining: 10.4s\n",
      "210:\tlearn: 0.3182911\ttotal: 4.49s\tremaining: 10.4s\n",
      "211:\tlearn: 0.3175869\ttotal: 4.51s\tremaining: 10.4s\n",
      "212:\tlearn: 0.3171311\ttotal: 4.53s\tremaining: 10.4s\n",
      "213:\tlearn: 0.3168571\ttotal: 4.54s\tremaining: 10.3s\n",
      "214:\tlearn: 0.3164887\ttotal: 4.57s\tremaining: 10.3s\n",
      "215:\tlearn: 0.3159860\ttotal: 4.59s\tremaining: 10.3s\n",
      "216:\tlearn: 0.3154060\ttotal: 4.61s\tremaining: 10.3s\n",
      "217:\tlearn: 0.3148971\ttotal: 4.63s\tremaining: 10.2s\n",
      "218:\tlearn: 0.3146239\ttotal: 4.65s\tremaining: 10.2s\n",
      "219:\tlearn: 0.3143045\ttotal: 4.67s\tremaining: 10.2s\n",
      "220:\tlearn: 0.3138518\ttotal: 4.69s\tremaining: 10.2s\n",
      "221:\tlearn: 0.3129448\ttotal: 4.71s\tremaining: 10.2s\n",
      "222:\tlearn: 0.3125412\ttotal: 4.74s\tremaining: 10.1s\n",
      "223:\tlearn: 0.3121565\ttotal: 4.76s\tremaining: 10.1s\n",
      "224:\tlearn: 0.3115311\ttotal: 4.79s\tremaining: 10.1s\n",
      "225:\tlearn: 0.3112191\ttotal: 4.81s\tremaining: 10.1s\n",
      "226:\tlearn: 0.3107110\ttotal: 4.83s\tremaining: 10.1s\n",
      "227:\tlearn: 0.3101150\ttotal: 4.85s\tremaining: 10s\n",
      "228:\tlearn: 0.3095589\ttotal: 4.87s\tremaining: 10s\n",
      "229:\tlearn: 0.3090173\ttotal: 4.89s\tremaining: 10s\n",
      "230:\tlearn: 0.3084920\ttotal: 4.91s\tremaining: 9.98s\n",
      "231:\tlearn: 0.3079863\ttotal: 4.93s\tremaining: 9.96s\n",
      "232:\tlearn: 0.3075635\ttotal: 4.96s\tremaining: 9.94s\n",
      "233:\tlearn: 0.3072774\ttotal: 4.98s\tremaining: 9.91s\n",
      "234:\tlearn: 0.3066550\ttotal: 5s\tremaining: 9.89s\n",
      "235:\tlearn: 0.3062722\ttotal: 5.02s\tremaining: 9.87s\n",
      "236:\tlearn: 0.3058260\ttotal: 5.04s\tremaining: 9.85s\n",
      "237:\tlearn: 0.3056354\ttotal: 5.06s\tremaining: 9.83s\n",
      "238:\tlearn: 0.3053743\ttotal: 5.08s\tremaining: 9.81s\n",
      "239:\tlearn: 0.3050313\ttotal: 5.1s\tremaining: 9.78s\n",
      "240:\tlearn: 0.3045851\ttotal: 5.13s\tremaining: 9.76s\n",
      "241:\tlearn: 0.3043135\ttotal: 5.14s\tremaining: 9.74s\n",
      "242:\tlearn: 0.3040833\ttotal: 5.17s\tremaining: 9.71s\n",
      "243:\tlearn: 0.3038236\ttotal: 5.18s\tremaining: 9.69s\n",
      "244:\tlearn: 0.3033727\ttotal: 5.22s\tremaining: 9.69s\n",
      "245:\tlearn: 0.3030132\ttotal: 5.24s\tremaining: 9.67s\n",
      "246:\tlearn: 0.3024804\ttotal: 5.26s\tremaining: 9.65s\n",
      "247:\tlearn: 0.3020022\ttotal: 5.28s\tremaining: 9.63s\n",
      "248:\tlearn: 0.3015464\ttotal: 5.3s\tremaining: 9.6s\n",
      "249:\tlearn: 0.3010970\ttotal: 5.32s\tremaining: 9.58s\n",
      "250:\tlearn: 0.3010639\ttotal: 5.33s\tremaining: 9.54s\n",
      "251:\tlearn: 0.3006935\ttotal: 5.35s\tremaining: 9.52s\n",
      "252:\tlearn: 0.3002687\ttotal: 5.37s\tremaining: 9.49s\n",
      "253:\tlearn: 0.2995248\ttotal: 5.39s\tremaining: 9.47s\n",
      "254:\tlearn: 0.2991169\ttotal: 5.41s\tremaining: 9.45s\n",
      "255:\tlearn: 0.2987587\ttotal: 5.43s\tremaining: 9.43s\n",
      "256:\tlearn: 0.2986463\ttotal: 5.46s\tremaining: 9.4s\n",
      "257:\tlearn: 0.2982572\ttotal: 5.47s\tremaining: 9.38s\n",
      "258:\tlearn: 0.2977591\ttotal: 5.5s\tremaining: 9.36s\n",
      "259:\tlearn: 0.2974810\ttotal: 5.52s\tremaining: 9.34s\n",
      "260:\tlearn: 0.2970244\ttotal: 5.54s\tremaining: 9.31s\n",
      "261:\tlearn: 0.2967399\ttotal: 5.56s\tremaining: 9.29s\n",
      "262:\tlearn: 0.2964607\ttotal: 5.58s\tremaining: 9.27s\n",
      "263:\tlearn: 0.2958962\ttotal: 5.6s\tremaining: 9.24s\n",
      "264:\tlearn: 0.2954852\ttotal: 5.62s\tremaining: 9.22s\n",
      "265:\tlearn: 0.2951735\ttotal: 5.64s\tremaining: 9.2s\n",
      "266:\tlearn: 0.2948068\ttotal: 5.66s\tremaining: 9.18s\n",
      "267:\tlearn: 0.2944182\ttotal: 5.68s\tremaining: 9.15s\n",
      "268:\tlearn: 0.2939588\ttotal: 5.7s\tremaining: 9.13s\n",
      "269:\tlearn: 0.2935817\ttotal: 5.72s\tremaining: 9.11s\n",
      "270:\tlearn: 0.2932618\ttotal: 5.74s\tremaining: 9.09s\n",
      "271:\tlearn: 0.2929434\ttotal: 5.76s\tremaining: 9.07s\n",
      "272:\tlearn: 0.2924709\ttotal: 5.79s\tremaining: 9.05s\n",
      "273:\tlearn: 0.2920861\ttotal: 5.81s\tremaining: 9.03s\n",
      "274:\tlearn: 0.2913315\ttotal: 5.83s\tremaining: 9.01s\n",
      "275:\tlearn: 0.2908246\ttotal: 5.85s\tremaining: 8.98s\n",
      "276:\tlearn: 0.2904893\ttotal: 5.87s\tremaining: 8.96s\n",
      "277:\tlearn: 0.2900695\ttotal: 5.89s\tremaining: 8.94s\n",
      "278:\tlearn: 0.2896427\ttotal: 5.91s\tremaining: 8.92s\n",
      "279:\tlearn: 0.2891845\ttotal: 5.93s\tremaining: 8.9s\n",
      "280:\tlearn: 0.2889170\ttotal: 5.95s\tremaining: 8.87s\n",
      "281:\tlearn: 0.2884269\ttotal: 5.97s\tremaining: 8.85s\n",
      "282:\tlearn: 0.2877781\ttotal: 5.99s\tremaining: 8.83s\n",
      "283:\tlearn: 0.2874991\ttotal: 6.01s\tremaining: 8.81s\n",
      "284:\tlearn: 0.2872448\ttotal: 6.03s\tremaining: 8.79s\n",
      "285:\tlearn: 0.2868626\ttotal: 6.05s\tremaining: 8.76s\n",
      "286:\tlearn: 0.2861953\ttotal: 6.07s\tremaining: 8.74s\n",
      "287:\tlearn: 0.2859650\ttotal: 6.09s\tremaining: 8.72s\n",
      "288:\tlearn: 0.2856378\ttotal: 6.12s\tremaining: 8.7s\n",
      "289:\tlearn: 0.2852853\ttotal: 6.14s\tremaining: 8.68s\n",
      "290:\tlearn: 0.2851107\ttotal: 6.16s\tremaining: 8.65s\n",
      "291:\tlearn: 0.2845759\ttotal: 6.18s\tremaining: 8.63s\n",
      "292:\tlearn: 0.2841325\ttotal: 6.2s\tremaining: 8.61s\n",
      "293:\tlearn: 0.2838657\ttotal: 6.22s\tremaining: 8.59s\n",
      "294:\tlearn: 0.2835159\ttotal: 6.24s\tremaining: 8.57s\n",
      "295:\tlearn: 0.2832494\ttotal: 6.26s\tremaining: 8.55s\n",
      "296:\tlearn: 0.2829324\ttotal: 6.29s\tremaining: 8.53s\n",
      "297:\tlearn: 0.2821892\ttotal: 6.31s\tremaining: 8.51s\n",
      "298:\tlearn: 0.2816865\ttotal: 6.33s\tremaining: 8.49s\n",
      "299:\tlearn: 0.2814827\ttotal: 6.35s\tremaining: 8.47s\n",
      "300:\tlearn: 0.2813024\ttotal: 6.37s\tremaining: 8.45s\n",
      "301:\tlearn: 0.2807067\ttotal: 6.39s\tremaining: 8.42s\n",
      "302:\tlearn: 0.2803263\ttotal: 6.41s\tremaining: 8.4s\n",
      "303:\tlearn: 0.2799597\ttotal: 6.43s\tremaining: 8.38s\n",
      "304:\tlearn: 0.2795908\ttotal: 6.45s\tremaining: 8.36s\n",
      "305:\tlearn: 0.2791292\ttotal: 6.47s\tremaining: 8.34s\n",
      "306:\tlearn: 0.2789311\ttotal: 6.5s\tremaining: 8.31s\n",
      "307:\tlearn: 0.2784512\ttotal: 6.52s\tremaining: 8.29s\n",
      "308:\tlearn: 0.2780759\ttotal: 6.54s\tremaining: 8.27s\n",
      "309:\tlearn: 0.2780723\ttotal: 6.55s\tremaining: 8.23s\n",
      "310:\tlearn: 0.2777576\ttotal: 6.57s\tremaining: 8.21s\n",
      "311:\tlearn: 0.2774602\ttotal: 6.59s\tremaining: 8.19s\n",
      "312:\tlearn: 0.2770253\ttotal: 6.61s\tremaining: 8.17s\n",
      "313:\tlearn: 0.2766595\ttotal: 6.63s\tremaining: 8.15s\n",
      "314:\tlearn: 0.2761081\ttotal: 6.65s\tremaining: 8.13s\n",
      "315:\tlearn: 0.2757465\ttotal: 6.67s\tremaining: 8.1s\n",
      "316:\tlearn: 0.2753858\ttotal: 6.69s\tremaining: 8.08s\n",
      "317:\tlearn: 0.2751607\ttotal: 6.71s\tremaining: 8.06s\n",
      "318:\tlearn: 0.2751231\ttotal: 6.72s\tremaining: 8.03s\n",
      "319:\tlearn: 0.2747648\ttotal: 6.75s\tremaining: 8.01s\n",
      "320:\tlearn: 0.2745556\ttotal: 6.77s\tremaining: 7.99s\n",
      "321:\tlearn: 0.2741821\ttotal: 6.79s\tremaining: 7.97s\n",
      "322:\tlearn: 0.2738729\ttotal: 6.81s\tremaining: 7.95s\n",
      "323:\tlearn: 0.2736928\ttotal: 6.83s\tremaining: 7.92s\n",
      "324:\tlearn: 0.2734157\ttotal: 6.85s\tremaining: 7.9s\n",
      "325:\tlearn: 0.2728914\ttotal: 6.87s\tremaining: 7.88s\n",
      "326:\tlearn: 0.2724865\ttotal: 6.89s\tremaining: 7.86s\n",
      "327:\tlearn: 0.2722548\ttotal: 6.91s\tremaining: 7.84s\n",
      "328:\tlearn: 0.2718622\ttotal: 6.93s\tremaining: 7.82s\n",
      "329:\tlearn: 0.2711709\ttotal: 6.95s\tremaining: 7.8s\n",
      "330:\tlearn: 0.2710043\ttotal: 6.97s\tremaining: 7.78s\n",
      "331:\tlearn: 0.2705292\ttotal: 7s\tremaining: 7.75s\n",
      "332:\tlearn: 0.2702322\ttotal: 7.02s\tremaining: 7.73s\n",
      "333:\tlearn: 0.2699607\ttotal: 7.04s\tremaining: 7.71s\n",
      "334:\tlearn: 0.2696377\ttotal: 7.06s\tremaining: 7.69s\n",
      "335:\tlearn: 0.2692871\ttotal: 7.08s\tremaining: 7.67s\n",
      "336:\tlearn: 0.2689155\ttotal: 7.1s\tremaining: 7.65s\n",
      "337:\tlearn: 0.2686665\ttotal: 7.12s\tremaining: 7.62s\n",
      "338:\tlearn: 0.2683808\ttotal: 7.14s\tremaining: 7.6s\n",
      "339:\tlearn: 0.2682169\ttotal: 7.16s\tremaining: 7.58s\n",
      "340:\tlearn: 0.2678175\ttotal: 7.18s\tremaining: 7.56s\n",
      "341:\tlearn: 0.2675932\ttotal: 7.2s\tremaining: 7.54s\n",
      "342:\tlearn: 0.2672496\ttotal: 7.22s\tremaining: 7.52s\n",
      "343:\tlearn: 0.2670532\ttotal: 7.24s\tremaining: 7.5s\n",
      "344:\tlearn: 0.2666454\ttotal: 7.27s\tremaining: 7.48s\n",
      "345:\tlearn: 0.2662294\ttotal: 7.29s\tremaining: 7.46s\n",
      "346:\tlearn: 0.2658424\ttotal: 7.31s\tremaining: 7.43s\n",
      "347:\tlearn: 0.2654083\ttotal: 7.33s\tremaining: 7.41s\n",
      "348:\tlearn: 0.2650348\ttotal: 7.35s\tremaining: 7.39s\n",
      "349:\tlearn: 0.2647077\ttotal: 7.37s\tremaining: 7.37s\n",
      "350:\tlearn: 0.2643267\ttotal: 7.39s\tremaining: 7.35s\n",
      "351:\tlearn: 0.2639806\ttotal: 7.41s\tremaining: 7.33s\n",
      "352:\tlearn: 0.2635174\ttotal: 7.43s\tremaining: 7.31s\n",
      "353:\tlearn: 0.2630729\ttotal: 7.45s\tremaining: 7.29s\n",
      "354:\tlearn: 0.2626957\ttotal: 7.47s\tremaining: 7.26s\n",
      "355:\tlearn: 0.2623259\ttotal: 7.5s\tremaining: 7.24s\n",
      "356:\tlearn: 0.2620672\ttotal: 7.52s\tremaining: 7.22s\n",
      "357:\tlearn: 0.2620134\ttotal: 7.53s\tremaining: 7.19s\n",
      "358:\tlearn: 0.2616480\ttotal: 7.55s\tremaining: 7.17s\n",
      "359:\tlearn: 0.2616454\ttotal: 7.56s\tremaining: 7.14s\n",
      "360:\tlearn: 0.2614180\ttotal: 7.58s\tremaining: 7.12s\n",
      "361:\tlearn: 0.2613103\ttotal: 7.6s\tremaining: 7.1s\n",
      "362:\tlearn: 0.2608913\ttotal: 7.62s\tremaining: 7.08s\n",
      "363:\tlearn: 0.2606410\ttotal: 7.64s\tremaining: 7.05s\n",
      "364:\tlearn: 0.2605131\ttotal: 7.66s\tremaining: 7.03s\n",
      "365:\tlearn: 0.2601985\ttotal: 7.68s\tremaining: 7.01s\n",
      "366:\tlearn: 0.2598056\ttotal: 7.71s\tremaining: 6.99s\n",
      "367:\tlearn: 0.2595292\ttotal: 7.73s\tremaining: 6.97s\n",
      "368:\tlearn: 0.2592855\ttotal: 7.75s\tremaining: 6.95s\n",
      "369:\tlearn: 0.2590802\ttotal: 7.77s\tremaining: 6.93s\n",
      "370:\tlearn: 0.2587853\ttotal: 7.79s\tremaining: 6.91s\n",
      "371:\tlearn: 0.2584374\ttotal: 7.81s\tremaining: 6.89s\n",
      "372:\tlearn: 0.2581651\ttotal: 7.83s\tremaining: 6.87s\n",
      "373:\tlearn: 0.2579189\ttotal: 7.86s\tremaining: 6.85s\n",
      "374:\tlearn: 0.2576091\ttotal: 7.88s\tremaining: 6.83s\n",
      "375:\tlearn: 0.2571870\ttotal: 7.9s\tremaining: 6.8s\n",
      "376:\tlearn: 0.2568339\ttotal: 7.92s\tremaining: 6.78s\n",
      "377:\tlearn: 0.2564219\ttotal: 7.94s\tremaining: 6.76s\n",
      "378:\tlearn: 0.2560333\ttotal: 7.96s\tremaining: 6.74s\n",
      "379:\tlearn: 0.2558524\ttotal: 7.98s\tremaining: 6.72s\n",
      "380:\tlearn: 0.2554296\ttotal: 8s\tremaining: 6.7s\n",
      "381:\tlearn: 0.2550009\ttotal: 8.02s\tremaining: 6.68s\n",
      "382:\tlearn: 0.2545762\ttotal: 8.04s\tremaining: 6.66s\n",
      "383:\tlearn: 0.2543548\ttotal: 8.06s\tremaining: 6.63s\n",
      "384:\tlearn: 0.2536387\ttotal: 8.08s\tremaining: 6.61s\n",
      "385:\tlearn: 0.2532673\ttotal: 8.1s\tremaining: 6.59s\n",
      "386:\tlearn: 0.2530558\ttotal: 8.12s\tremaining: 6.57s\n",
      "387:\tlearn: 0.2526452\ttotal: 8.15s\tremaining: 6.55s\n",
      "388:\tlearn: 0.2523010\ttotal: 8.17s\tremaining: 6.53s\n",
      "389:\tlearn: 0.2518894\ttotal: 8.19s\tremaining: 6.51s\n",
      "390:\tlearn: 0.2516858\ttotal: 8.21s\tremaining: 6.49s\n",
      "391:\tlearn: 0.2514485\ttotal: 8.23s\tremaining: 6.46s\n",
      "392:\tlearn: 0.2513212\ttotal: 8.25s\tremaining: 6.44s\n",
      "393:\tlearn: 0.2510339\ttotal: 8.27s\tremaining: 6.42s\n",
      "394:\tlearn: 0.2507830\ttotal: 8.29s\tremaining: 6.4s\n",
      "395:\tlearn: 0.2505978\ttotal: 8.31s\tremaining: 6.38s\n",
      "396:\tlearn: 0.2499960\ttotal: 8.33s\tremaining: 6.36s\n",
      "397:\tlearn: 0.2496415\ttotal: 8.35s\tremaining: 6.34s\n",
      "398:\tlearn: 0.2491572\ttotal: 8.37s\tremaining: 6.32s\n",
      "399:\tlearn: 0.2487385\ttotal: 8.39s\tremaining: 6.3s\n",
      "400:\tlearn: 0.2486514\ttotal: 8.41s\tremaining: 6.27s\n",
      "401:\tlearn: 0.2482605\ttotal: 8.44s\tremaining: 6.25s\n",
      "402:\tlearn: 0.2480370\ttotal: 8.46s\tremaining: 6.23s\n",
      "403:\tlearn: 0.2476876\ttotal: 8.48s\tremaining: 6.21s\n",
      "404:\tlearn: 0.2474609\ttotal: 8.5s\tremaining: 6.19s\n",
      "405:\tlearn: 0.2471064\ttotal: 8.52s\tremaining: 6.17s\n",
      "406:\tlearn: 0.2467650\ttotal: 8.54s\tremaining: 6.15s\n",
      "407:\tlearn: 0.2465484\ttotal: 8.56s\tremaining: 6.13s\n",
      "408:\tlearn: 0.2463229\ttotal: 8.58s\tremaining: 6.11s\n",
      "409:\tlearn: 0.2459630\ttotal: 8.6s\tremaining: 6.08s\n",
      "410:\tlearn: 0.2458061\ttotal: 8.62s\tremaining: 6.06s\n",
      "411:\tlearn: 0.2456442\ttotal: 8.64s\tremaining: 6.04s\n",
      "412:\tlearn: 0.2456377\ttotal: 8.65s\tremaining: 6.01s\n",
      "413:\tlearn: 0.2454121\ttotal: 8.67s\tremaining: 5.99s\n",
      "414:\tlearn: 0.2450228\ttotal: 8.69s\tremaining: 5.97s\n",
      "415:\tlearn: 0.2447585\ttotal: 8.71s\tremaining: 5.95s\n",
      "416:\tlearn: 0.2444405\ttotal: 8.74s\tremaining: 5.93s\n",
      "417:\tlearn: 0.2441537\ttotal: 8.76s\tremaining: 5.91s\n",
      "418:\tlearn: 0.2439590\ttotal: 8.78s\tremaining: 5.89s\n",
      "419:\tlearn: 0.2435517\ttotal: 8.8s\tremaining: 5.87s\n",
      "420:\tlearn: 0.2433526\ttotal: 8.82s\tremaining: 5.84s\n",
      "421:\tlearn: 0.2431264\ttotal: 8.84s\tremaining: 5.82s\n",
      "422:\tlearn: 0.2428399\ttotal: 8.86s\tremaining: 5.8s\n",
      "423:\tlearn: 0.2425645\ttotal: 8.88s\tremaining: 5.78s\n",
      "424:\tlearn: 0.2423273\ttotal: 8.9s\tremaining: 5.76s\n",
      "425:\tlearn: 0.2419993\ttotal: 8.92s\tremaining: 5.74s\n",
      "426:\tlearn: 0.2416143\ttotal: 8.95s\tremaining: 5.72s\n",
      "427:\tlearn: 0.2414233\ttotal: 8.97s\tremaining: 5.7s\n",
      "428:\tlearn: 0.2411771\ttotal: 8.99s\tremaining: 5.68s\n",
      "429:\tlearn: 0.2408877\ttotal: 9.02s\tremaining: 5.66s\n",
      "430:\tlearn: 0.2405051\ttotal: 9.04s\tremaining: 5.64s\n",
      "431:\tlearn: 0.2402266\ttotal: 9.06s\tremaining: 5.62s\n",
      "432:\tlearn: 0.2398972\ttotal: 9.08s\tremaining: 5.6s\n",
      "433:\tlearn: 0.2398783\ttotal: 9.09s\tremaining: 5.57s\n",
      "434:\tlearn: 0.2396625\ttotal: 9.11s\tremaining: 5.55s\n",
      "435:\tlearn: 0.2394147\ttotal: 9.13s\tremaining: 5.53s\n",
      "436:\tlearn: 0.2390050\ttotal: 9.15s\tremaining: 5.51s\n",
      "437:\tlearn: 0.2387205\ttotal: 9.17s\tremaining: 5.49s\n",
      "438:\tlearn: 0.2384203\ttotal: 9.19s\tremaining: 5.46s\n",
      "439:\tlearn: 0.2382698\ttotal: 9.21s\tremaining: 5.44s\n",
      "440:\tlearn: 0.2380116\ttotal: 9.23s\tremaining: 5.42s\n",
      "441:\tlearn: 0.2378922\ttotal: 9.26s\tremaining: 5.4s\n",
      "442:\tlearn: 0.2375484\ttotal: 9.28s\tremaining: 5.38s\n",
      "443:\tlearn: 0.2372911\ttotal: 9.3s\tremaining: 5.36s\n",
      "444:\tlearn: 0.2370431\ttotal: 9.32s\tremaining: 5.34s\n",
      "445:\tlearn: 0.2367141\ttotal: 9.35s\tremaining: 5.32s\n",
      "446:\tlearn: 0.2362194\ttotal: 9.37s\tremaining: 5.3s\n",
      "447:\tlearn: 0.2358740\ttotal: 9.39s\tremaining: 5.28s\n",
      "448:\tlearn: 0.2354011\ttotal: 9.41s\tremaining: 5.26s\n",
      "449:\tlearn: 0.2350619\ttotal: 9.43s\tremaining: 5.24s\n",
      "450:\tlearn: 0.2347047\ttotal: 9.45s\tremaining: 5.22s\n",
      "451:\tlearn: 0.2345509\ttotal: 9.47s\tremaining: 5.2s\n",
      "452:\tlearn: 0.2342207\ttotal: 9.49s\tremaining: 5.18s\n",
      "453:\tlearn: 0.2338480\ttotal: 9.51s\tremaining: 5.15s\n",
      "454:\tlearn: 0.2336019\ttotal: 9.53s\tremaining: 5.13s\n",
      "455:\tlearn: 0.2334356\ttotal: 9.55s\tremaining: 5.11s\n",
      "456:\tlearn: 0.2329787\ttotal: 9.57s\tremaining: 5.09s\n",
      "457:\tlearn: 0.2326561\ttotal: 9.6s\tremaining: 5.07s\n",
      "458:\tlearn: 0.2323621\ttotal: 9.62s\tremaining: 5.05s\n",
      "459:\tlearn: 0.2320562\ttotal: 9.64s\tremaining: 5.03s\n",
      "460:\tlearn: 0.2318701\ttotal: 9.66s\tremaining: 5.01s\n",
      "461:\tlearn: 0.2314449\ttotal: 9.68s\tremaining: 4.99s\n",
      "462:\tlearn: 0.2312427\ttotal: 9.7s\tremaining: 4.96s\n",
      "463:\tlearn: 0.2308708\ttotal: 9.72s\tremaining: 4.94s\n",
      "464:\tlearn: 0.2306913\ttotal: 9.74s\tremaining: 4.92s\n",
      "465:\tlearn: 0.2304847\ttotal: 9.76s\tremaining: 4.9s\n",
      "466:\tlearn: 0.2302047\ttotal: 9.78s\tremaining: 4.88s\n",
      "467:\tlearn: 0.2299066\ttotal: 9.8s\tremaining: 4.86s\n",
      "468:\tlearn: 0.2295764\ttotal: 9.82s\tremaining: 4.84s\n",
      "469:\tlearn: 0.2293773\ttotal: 9.85s\tremaining: 4.82s\n",
      "470:\tlearn: 0.2289086\ttotal: 9.87s\tremaining: 4.8s\n",
      "471:\tlearn: 0.2285083\ttotal: 9.89s\tremaining: 4.78s\n",
      "472:\tlearn: 0.2283073\ttotal: 9.91s\tremaining: 4.75s\n",
      "473:\tlearn: 0.2280728\ttotal: 9.93s\tremaining: 4.73s\n",
      "474:\tlearn: 0.2276770\ttotal: 9.95s\tremaining: 4.71s\n",
      "475:\tlearn: 0.2271613\ttotal: 9.97s\tremaining: 4.69s\n",
      "476:\tlearn: 0.2268680\ttotal: 9.99s\tremaining: 4.67s\n",
      "477:\tlearn: 0.2264053\ttotal: 10s\tremaining: 4.65s\n",
      "478:\tlearn: 0.2262183\ttotal: 10s\tremaining: 4.63s\n",
      "479:\tlearn: 0.2261160\ttotal: 10.1s\tremaining: 4.61s\n",
      "480:\tlearn: 0.2259181\ttotal: 10.1s\tremaining: 4.58s\n",
      "481:\tlearn: 0.2256974\ttotal: 10.1s\tremaining: 4.56s\n",
      "482:\tlearn: 0.2255374\ttotal: 10.1s\tremaining: 4.54s\n",
      "483:\tlearn: 0.2252678\ttotal: 10.1s\tremaining: 4.52s\n",
      "484:\tlearn: 0.2249898\ttotal: 10.2s\tremaining: 4.5s\n",
      "485:\tlearn: 0.2247934\ttotal: 10.2s\tremaining: 4.48s\n",
      "486:\tlearn: 0.2245134\ttotal: 10.2s\tremaining: 4.46s\n",
      "487:\tlearn: 0.2241802\ttotal: 10.2s\tremaining: 4.44s\n",
      "488:\tlearn: 0.2237650\ttotal: 10.2s\tremaining: 4.42s\n",
      "489:\tlearn: 0.2234523\ttotal: 10.3s\tremaining: 4.4s\n",
      "490:\tlearn: 0.2231748\ttotal: 10.3s\tremaining: 4.38s\n",
      "491:\tlearn: 0.2229750\ttotal: 10.3s\tremaining: 4.36s\n",
      "492:\tlearn: 0.2228047\ttotal: 10.3s\tremaining: 4.33s\n",
      "493:\tlearn: 0.2224381\ttotal: 10.3s\tremaining: 4.31s\n",
      "494:\tlearn: 0.2221774\ttotal: 10.4s\tremaining: 4.29s\n",
      "495:\tlearn: 0.2219021\ttotal: 10.4s\tremaining: 4.27s\n",
      "496:\tlearn: 0.2215962\ttotal: 10.4s\tremaining: 4.25s\n",
      "497:\tlearn: 0.2213309\ttotal: 10.4s\tremaining: 4.23s\n",
      "498:\tlearn: 0.2210479\ttotal: 10.4s\tremaining: 4.21s\n",
      "499:\tlearn: 0.2207690\ttotal: 10.5s\tremaining: 4.19s\n",
      "500:\tlearn: 0.2204016\ttotal: 10.5s\tremaining: 4.17s\n",
      "501:\tlearn: 0.2201721\ttotal: 10.5s\tremaining: 4.14s\n",
      "502:\tlearn: 0.2195825\ttotal: 10.5s\tremaining: 4.12s\n",
      "503:\tlearn: 0.2193501\ttotal: 10.6s\tremaining: 4.1s\n",
      "504:\tlearn: 0.2191877\ttotal: 10.6s\tremaining: 4.08s\n",
      "505:\tlearn: 0.2189238\ttotal: 10.6s\tremaining: 4.06s\n",
      "506:\tlearn: 0.2185772\ttotal: 10.6s\tremaining: 4.04s\n",
      "507:\tlearn: 0.2182867\ttotal: 10.6s\tremaining: 4.02s\n",
      "508:\tlearn: 0.2179393\ttotal: 10.7s\tremaining: 4s\n",
      "509:\tlearn: 0.2177670\ttotal: 10.7s\tremaining: 3.98s\n",
      "510:\tlearn: 0.2175697\ttotal: 10.7s\tremaining: 3.96s\n",
      "511:\tlearn: 0.2172581\ttotal: 10.7s\tremaining: 3.94s\n",
      "512:\tlearn: 0.2169893\ttotal: 10.7s\tremaining: 3.92s\n",
      "513:\tlearn: 0.2166720\ttotal: 10.8s\tremaining: 3.9s\n",
      "514:\tlearn: 0.2163333\ttotal: 10.8s\tremaining: 3.87s\n",
      "515:\tlearn: 0.2156996\ttotal: 10.8s\tremaining: 3.85s\n",
      "516:\tlearn: 0.2152974\ttotal: 10.8s\tremaining: 3.83s\n",
      "517:\tlearn: 0.2150030\ttotal: 10.8s\tremaining: 3.81s\n",
      "518:\tlearn: 0.2146022\ttotal: 10.9s\tremaining: 3.79s\n",
      "519:\tlearn: 0.2142923\ttotal: 10.9s\tremaining: 3.77s\n",
      "520:\tlearn: 0.2141167\ttotal: 10.9s\tremaining: 3.75s\n",
      "521:\tlearn: 0.2139124\ttotal: 10.9s\tremaining: 3.73s\n",
      "522:\tlearn: 0.2136844\ttotal: 11s\tremaining: 3.71s\n",
      "523:\tlearn: 0.2134728\ttotal: 11s\tremaining: 3.69s\n",
      "524:\tlearn: 0.2131733\ttotal: 11s\tremaining: 3.66s\n",
      "525:\tlearn: 0.2128530\ttotal: 11s\tremaining: 3.64s\n",
      "526:\tlearn: 0.2127134\ttotal: 11s\tremaining: 3.62s\n",
      "527:\tlearn: 0.2123065\ttotal: 11.1s\tremaining: 3.6s\n",
      "528:\tlearn: 0.2120956\ttotal: 11.1s\tremaining: 3.58s\n",
      "529:\tlearn: 0.2118907\ttotal: 11.1s\tremaining: 3.56s\n",
      "530:\tlearn: 0.2114678\ttotal: 11.1s\tremaining: 3.54s\n",
      "531:\tlearn: 0.2112645\ttotal: 11.1s\tremaining: 3.52s\n",
      "532:\tlearn: 0.2111087\ttotal: 11.2s\tremaining: 3.5s\n",
      "533:\tlearn: 0.2108164\ttotal: 11.2s\tremaining: 3.48s\n",
      "534:\tlearn: 0.2104425\ttotal: 11.2s\tremaining: 3.45s\n",
      "535:\tlearn: 0.2101321\ttotal: 11.2s\tremaining: 3.43s\n",
      "536:\tlearn: 0.2098839\ttotal: 11.2s\tremaining: 3.41s\n",
      "537:\tlearn: 0.2096021\ttotal: 11.3s\tremaining: 3.39s\n",
      "538:\tlearn: 0.2089547\ttotal: 11.3s\tremaining: 3.37s\n",
      "539:\tlearn: 0.2086325\ttotal: 11.3s\tremaining: 3.35s\n",
      "540:\tlearn: 0.2082407\ttotal: 11.3s\tremaining: 3.33s\n",
      "541:\tlearn: 0.2079937\ttotal: 11.4s\tremaining: 3.31s\n",
      "542:\tlearn: 0.2077917\ttotal: 11.4s\tremaining: 3.29s\n",
      "543:\tlearn: 0.2073789\ttotal: 11.4s\tremaining: 3.27s\n",
      "544:\tlearn: 0.2068414\ttotal: 11.4s\tremaining: 3.25s\n",
      "545:\tlearn: 0.2065247\ttotal: 11.4s\tremaining: 3.23s\n",
      "546:\tlearn: 0.2060273\ttotal: 11.5s\tremaining: 3.2s\n",
      "547:\tlearn: 0.2057552\ttotal: 11.5s\tremaining: 3.18s\n",
      "548:\tlearn: 0.2054876\ttotal: 11.5s\tremaining: 3.16s\n",
      "549:\tlearn: 0.2051194\ttotal: 11.5s\tremaining: 3.14s\n",
      "550:\tlearn: 0.2048197\ttotal: 11.5s\tremaining: 3.12s\n",
      "551:\tlearn: 0.2045261\ttotal: 11.6s\tremaining: 3.1s\n",
      "552:\tlearn: 0.2041817\ttotal: 11.6s\tremaining: 3.08s\n",
      "553:\tlearn: 0.2036990\ttotal: 11.6s\tremaining: 3.06s\n",
      "554:\tlearn: 0.2034572\ttotal: 11.6s\tremaining: 3.04s\n",
      "555:\tlearn: 0.2031690\ttotal: 11.6s\tremaining: 3.02s\n",
      "556:\tlearn: 0.2029409\ttotal: 11.7s\tremaining: 2.99s\n",
      "557:\tlearn: 0.2023825\ttotal: 11.7s\tremaining: 2.97s\n",
      "558:\tlearn: 0.2017730\ttotal: 11.7s\tremaining: 2.95s\n",
      "559:\tlearn: 0.2015657\ttotal: 11.7s\tremaining: 2.93s\n",
      "560:\tlearn: 0.2013671\ttotal: 11.7s\tremaining: 2.91s\n",
      "561:\tlearn: 0.2012229\ttotal: 11.8s\tremaining: 2.89s\n",
      "562:\tlearn: 0.2009279\ttotal: 11.8s\tremaining: 2.87s\n",
      "563:\tlearn: 0.2007726\ttotal: 11.8s\tremaining: 2.85s\n",
      "564:\tlearn: 0.2006107\ttotal: 11.8s\tremaining: 2.83s\n",
      "565:\tlearn: 0.2002570\ttotal: 11.8s\tremaining: 2.81s\n",
      "566:\tlearn: 0.1997275\ttotal: 11.9s\tremaining: 2.78s\n",
      "567:\tlearn: 0.1993634\ttotal: 11.9s\tremaining: 2.76s\n",
      "568:\tlearn: 0.1991148\ttotal: 11.9s\tremaining: 2.74s\n",
      "569:\tlearn: 0.1987907\ttotal: 11.9s\tremaining: 2.72s\n",
      "570:\tlearn: 0.1985098\ttotal: 12s\tremaining: 2.7s\n",
      "571:\tlearn: 0.1981857\ttotal: 12s\tremaining: 2.68s\n",
      "572:\tlearn: 0.1978851\ttotal: 12s\tremaining: 2.66s\n",
      "573:\tlearn: 0.1975931\ttotal: 12s\tremaining: 2.64s\n",
      "574:\tlearn: 0.1972234\ttotal: 12s\tremaining: 2.62s\n",
      "575:\tlearn: 0.1970430\ttotal: 12.1s\tremaining: 2.6s\n",
      "576:\tlearn: 0.1968233\ttotal: 12.1s\tremaining: 2.57s\n",
      "577:\tlearn: 0.1964826\ttotal: 12.1s\tremaining: 2.55s\n",
      "578:\tlearn: 0.1962287\ttotal: 12.1s\tremaining: 2.53s\n",
      "579:\tlearn: 0.1959306\ttotal: 12.1s\tremaining: 2.51s\n",
      "580:\tlearn: 0.1954756\ttotal: 12.2s\tremaining: 2.49s\n",
      "581:\tlearn: 0.1952270\ttotal: 12.2s\tremaining: 2.47s\n",
      "582:\tlearn: 0.1948592\ttotal: 12.2s\tremaining: 2.45s\n",
      "583:\tlearn: 0.1947407\ttotal: 12.2s\tremaining: 2.43s\n",
      "584:\tlearn: 0.1944995\ttotal: 12.2s\tremaining: 2.41s\n",
      "585:\tlearn: 0.1942237\ttotal: 12.3s\tremaining: 2.39s\n",
      "586:\tlearn: 0.1940018\ttotal: 12.3s\tremaining: 2.37s\n",
      "587:\tlearn: 0.1937775\ttotal: 12.3s\tremaining: 2.35s\n",
      "588:\tlearn: 0.1933150\ttotal: 12.3s\tremaining: 2.32s\n",
      "589:\tlearn: 0.1928517\ttotal: 12.4s\tremaining: 2.3s\n",
      "590:\tlearn: 0.1925834\ttotal: 12.4s\tremaining: 2.28s\n",
      "591:\tlearn: 0.1923790\ttotal: 12.4s\tremaining: 2.26s\n",
      "592:\tlearn: 0.1921543\ttotal: 12.4s\tremaining: 2.24s\n",
      "593:\tlearn: 0.1916877\ttotal: 12.4s\tremaining: 2.22s\n",
      "594:\tlearn: 0.1913856\ttotal: 12.5s\tremaining: 2.2s\n",
      "595:\tlearn: 0.1911758\ttotal: 12.5s\tremaining: 2.18s\n",
      "596:\tlearn: 0.1908672\ttotal: 12.5s\tremaining: 2.16s\n",
      "597:\tlearn: 0.1904977\ttotal: 12.5s\tremaining: 2.13s\n",
      "598:\tlearn: 0.1902156\ttotal: 12.5s\tremaining: 2.11s\n",
      "599:\tlearn: 0.1898888\ttotal: 12.6s\tremaining: 2.09s\n",
      "600:\tlearn: 0.1895997\ttotal: 12.6s\tremaining: 2.07s\n",
      "601:\tlearn: 0.1894099\ttotal: 12.6s\tremaining: 2.05s\n",
      "602:\tlearn: 0.1891606\ttotal: 12.6s\tremaining: 2.03s\n",
      "603:\tlearn: 0.1888914\ttotal: 12.6s\tremaining: 2.01s\n",
      "604:\tlearn: 0.1886576\ttotal: 12.7s\tremaining: 1.99s\n",
      "605:\tlearn: 0.1885006\ttotal: 12.7s\tremaining: 1.97s\n",
      "606:\tlearn: 0.1882157\ttotal: 12.7s\tremaining: 1.95s\n",
      "607:\tlearn: 0.1878704\ttotal: 12.7s\tremaining: 1.93s\n",
      "608:\tlearn: 0.1876548\ttotal: 12.8s\tremaining: 1.91s\n",
      "609:\tlearn: 0.1873968\ttotal: 12.8s\tremaining: 1.88s\n",
      "610:\tlearn: 0.1871492\ttotal: 12.8s\tremaining: 1.86s\n",
      "611:\tlearn: 0.1868724\ttotal: 12.8s\tremaining: 1.84s\n",
      "612:\tlearn: 0.1867057\ttotal: 12.8s\tremaining: 1.82s\n",
      "613:\tlearn: 0.1864867\ttotal: 12.9s\tremaining: 1.8s\n",
      "614:\tlearn: 0.1860868\ttotal: 12.9s\tremaining: 1.78s\n",
      "615:\tlearn: 0.1858662\ttotal: 12.9s\tremaining: 1.76s\n",
      "616:\tlearn: 0.1856536\ttotal: 12.9s\tremaining: 1.74s\n",
      "617:\tlearn: 0.1853810\ttotal: 12.9s\tremaining: 1.72s\n",
      "618:\tlearn: 0.1851510\ttotal: 13s\tremaining: 1.7s\n",
      "619:\tlearn: 0.1848494\ttotal: 13s\tremaining: 1.67s\n",
      "620:\tlearn: 0.1845655\ttotal: 13s\tremaining: 1.65s\n",
      "621:\tlearn: 0.1842604\ttotal: 13s\tremaining: 1.63s\n",
      "622:\tlearn: 0.1840694\ttotal: 13s\tremaining: 1.61s\n",
      "623:\tlearn: 0.1837382\ttotal: 13.1s\tremaining: 1.59s\n",
      "624:\tlearn: 0.1834681\ttotal: 13.1s\tremaining: 1.57s\n",
      "625:\tlearn: 0.1832366\ttotal: 13.1s\tremaining: 1.55s\n",
      "626:\tlearn: 0.1828778\ttotal: 13.1s\tremaining: 1.53s\n",
      "627:\tlearn: 0.1825718\ttotal: 13.1s\tremaining: 1.51s\n",
      "628:\tlearn: 0.1823299\ttotal: 13.2s\tremaining: 1.49s\n",
      "629:\tlearn: 0.1819656\ttotal: 13.2s\tremaining: 1.47s\n",
      "630:\tlearn: 0.1817100\ttotal: 13.2s\tremaining: 1.44s\n",
      "631:\tlearn: 0.1815969\ttotal: 13.2s\tremaining: 1.42s\n",
      "632:\tlearn: 0.1812708\ttotal: 13.3s\tremaining: 1.4s\n",
      "633:\tlearn: 0.1809731\ttotal: 13.3s\tremaining: 1.38s\n",
      "634:\tlearn: 0.1807521\ttotal: 13.3s\tremaining: 1.36s\n",
      "635:\tlearn: 0.1805672\ttotal: 13.3s\tremaining: 1.34s\n",
      "636:\tlearn: 0.1802484\ttotal: 13.3s\tremaining: 1.32s\n",
      "637:\tlearn: 0.1800330\ttotal: 13.4s\tremaining: 1.3s\n",
      "638:\tlearn: 0.1797350\ttotal: 13.4s\tremaining: 1.28s\n",
      "639:\tlearn: 0.1793595\ttotal: 13.4s\tremaining: 1.26s\n",
      "640:\tlearn: 0.1791376\ttotal: 13.4s\tremaining: 1.24s\n",
      "641:\tlearn: 0.1788411\ttotal: 13.4s\tremaining: 1.21s\n",
      "642:\tlearn: 0.1786008\ttotal: 13.5s\tremaining: 1.19s\n",
      "643:\tlearn: 0.1784275\ttotal: 13.5s\tremaining: 1.17s\n",
      "644:\tlearn: 0.1782757\ttotal: 13.5s\tremaining: 1.15s\n",
      "645:\tlearn: 0.1780680\ttotal: 13.5s\tremaining: 1.13s\n",
      "646:\tlearn: 0.1778891\ttotal: 13.5s\tremaining: 1.11s\n",
      "647:\tlearn: 0.1775516\ttotal: 13.6s\tremaining: 1.09s\n",
      "648:\tlearn: 0.1773319\ttotal: 13.6s\tremaining: 1.07s\n",
      "649:\tlearn: 0.1770394\ttotal: 13.6s\tremaining: 1.05s\n",
      "650:\tlearn: 0.1768516\ttotal: 13.6s\tremaining: 1.02s\n",
      "651:\tlearn: 0.1766541\ttotal: 13.6s\tremaining: 1s\n",
      "652:\tlearn: 0.1764625\ttotal: 13.7s\tremaining: 984ms\n",
      "653:\tlearn: 0.1762942\ttotal: 13.7s\tremaining: 963ms\n",
      "654:\tlearn: 0.1761438\ttotal: 13.7s\tremaining: 942ms\n",
      "655:\tlearn: 0.1759120\ttotal: 13.7s\tremaining: 921ms\n",
      "656:\tlearn: 0.1756010\ttotal: 13.8s\tremaining: 900ms\n",
      "657:\tlearn: 0.1754123\ttotal: 13.8s\tremaining: 879ms\n",
      "658:\tlearn: 0.1751597\ttotal: 13.8s\tremaining: 858ms\n",
      "659:\tlearn: 0.1749436\ttotal: 13.8s\tremaining: 837ms\n",
      "660:\tlearn: 0.1747452\ttotal: 13.8s\tremaining: 817ms\n",
      "661:\tlearn: 0.1745672\ttotal: 13.9s\tremaining: 796ms\n",
      "662:\tlearn: 0.1742463\ttotal: 13.9s\tremaining: 775ms\n",
      "663:\tlearn: 0.1740020\ttotal: 13.9s\tremaining: 754ms\n",
      "664:\tlearn: 0.1737946\ttotal: 13.9s\tremaining: 733ms\n",
      "665:\tlearn: 0.1736176\ttotal: 13.9s\tremaining: 712ms\n",
      "666:\tlearn: 0.1732728\ttotal: 14s\tremaining: 691ms\n",
      "667:\tlearn: 0.1730930\ttotal: 14s\tremaining: 670ms\n",
      "668:\tlearn: 0.1728651\ttotal: 14s\tremaining: 649ms\n",
      "669:\tlearn: 0.1726899\ttotal: 14s\tremaining: 628ms\n",
      "670:\tlearn: 0.1724607\ttotal: 14s\tremaining: 607ms\n",
      "671:\tlearn: 0.1722369\ttotal: 14.1s\tremaining: 586ms\n",
      "672:\tlearn: 0.1717694\ttotal: 14.1s\tremaining: 565ms\n",
      "673:\tlearn: 0.1715466\ttotal: 14.1s\tremaining: 544ms\n",
      "674:\tlearn: 0.1714130\ttotal: 14.1s\tremaining: 523ms\n",
      "675:\tlearn: 0.1712332\ttotal: 14.1s\tremaining: 502ms\n",
      "676:\tlearn: 0.1708499\ttotal: 14.2s\tremaining: 481ms\n",
      "677:\tlearn: 0.1707147\ttotal: 14.2s\tremaining: 460ms\n",
      "678:\tlearn: 0.1705426\ttotal: 14.2s\tremaining: 439ms\n",
      "679:\tlearn: 0.1702290\ttotal: 14.2s\tremaining: 419ms\n",
      "680:\tlearn: 0.1700550\ttotal: 14.3s\tremaining: 398ms\n",
      "681:\tlearn: 0.1697296\ttotal: 14.3s\tremaining: 377ms\n",
      "682:\tlearn: 0.1694883\ttotal: 14.3s\tremaining: 356ms\n",
      "683:\tlearn: 0.1693561\ttotal: 14.3s\tremaining: 335ms\n",
      "684:\tlearn: 0.1691734\ttotal: 14.3s\tremaining: 314ms\n",
      "685:\tlearn: 0.1689580\ttotal: 14.4s\tremaining: 293ms\n",
      "686:\tlearn: 0.1686662\ttotal: 14.4s\tremaining: 272ms\n",
      "687:\tlearn: 0.1685009\ttotal: 14.4s\tremaining: 251ms\n",
      "688:\tlearn: 0.1682440\ttotal: 14.4s\tremaining: 230ms\n",
      "689:\tlearn: 0.1680329\ttotal: 14.4s\tremaining: 209ms\n",
      "690:\tlearn: 0.1678060\ttotal: 14.5s\tremaining: 188ms\n",
      "691:\tlearn: 0.1674600\ttotal: 14.5s\tremaining: 167ms\n",
      "692:\tlearn: 0.1671349\ttotal: 14.5s\tremaining: 146ms\n",
      "693:\tlearn: 0.1669044\ttotal: 14.5s\tremaining: 126ms\n",
      "694:\tlearn: 0.1667237\ttotal: 14.5s\tremaining: 105ms\n",
      "695:\tlearn: 0.1665084\ttotal: 14.6s\tremaining: 83.7ms\n",
      "696:\tlearn: 0.1662280\ttotal: 14.6s\tremaining: 62.8ms\n",
      "697:\tlearn: 0.1660572\ttotal: 14.6s\tremaining: 41.8ms\n",
      "698:\tlearn: 0.1658145\ttotal: 14.6s\tremaining: 20.9ms\n",
      "699:\tlearn: 0.1656110\ttotal: 14.6s\tremaining: 0us\n",
      "0:\tlearn: 0.6818003\ttotal: 21.5ms\tremaining: 15s\n",
      "1:\tlearn: 0.6724397\ttotal: 41.7ms\tremaining: 14.6s\n",
      "2:\tlearn: 0.6626818\ttotal: 62.5ms\tremaining: 14.5s\n",
      "3:\tlearn: 0.6555204\ttotal: 72.2ms\tremaining: 12.6s\n",
      "4:\tlearn: 0.6460467\ttotal: 92.1ms\tremaining: 12.8s\n",
      "5:\tlearn: 0.6362986\ttotal: 112ms\tremaining: 13s\n",
      "6:\tlearn: 0.6274797\ttotal: 132ms\tremaining: 13.1s\n",
      "7:\tlearn: 0.6186253\ttotal: 153ms\tremaining: 13.2s\n",
      "8:\tlearn: 0.6121067\ttotal: 173ms\tremaining: 13.3s\n",
      "9:\tlearn: 0.6043390\ttotal: 194ms\tremaining: 13.4s\n",
      "10:\tlearn: 0.5967586\ttotal: 214ms\tremaining: 13.4s\n",
      "11:\tlearn: 0.5889058\ttotal: 235ms\tremaining: 13.5s\n",
      "12:\tlearn: 0.5820906\ttotal: 257ms\tremaining: 13.6s\n",
      "13:\tlearn: 0.5760550\ttotal: 277ms\tremaining: 13.6s\n",
      "14:\tlearn: 0.5692198\ttotal: 298ms\tremaining: 13.6s\n",
      "15:\tlearn: 0.5618805\ttotal: 319ms\tremaining: 13.6s\n",
      "16:\tlearn: 0.5570343\ttotal: 341ms\tremaining: 13.7s\n",
      "17:\tlearn: 0.5515038\ttotal: 362ms\tremaining: 13.7s\n",
      "18:\tlearn: 0.5463745\ttotal: 383ms\tremaining: 13.7s\n",
      "19:\tlearn: 0.5410208\ttotal: 405ms\tremaining: 13.8s\n",
      "20:\tlearn: 0.5353338\ttotal: 427ms\tremaining: 13.8s\n",
      "21:\tlearn: 0.5309677\ttotal: 454ms\tremaining: 14s\n",
      "22:\tlearn: 0.5271103\ttotal: 472ms\tremaining: 13.9s\n",
      "23:\tlearn: 0.5245007\ttotal: 481ms\tremaining: 13.6s\n",
      "24:\tlearn: 0.5196308\ttotal: 502ms\tremaining: 13.6s\n",
      "25:\tlearn: 0.5155230\ttotal: 522ms\tremaining: 13.5s\n",
      "26:\tlearn: 0.5117909\ttotal: 542ms\tremaining: 13.5s\n",
      "27:\tlearn: 0.5067869\ttotal: 563ms\tremaining: 13.5s\n",
      "28:\tlearn: 0.5034378\ttotal: 583ms\tremaining: 13.5s\n",
      "29:\tlearn: 0.4989381\ttotal: 604ms\tremaining: 13.5s\n",
      "30:\tlearn: 0.4959794\ttotal: 624ms\tremaining: 13.5s\n",
      "31:\tlearn: 0.4927532\ttotal: 644ms\tremaining: 13.4s\n",
      "32:\tlearn: 0.4892433\ttotal: 665ms\tremaining: 13.4s\n",
      "33:\tlearn: 0.4860876\ttotal: 686ms\tremaining: 13.4s\n",
      "34:\tlearn: 0.4825555\ttotal: 707ms\tremaining: 13.4s\n",
      "35:\tlearn: 0.4798783\ttotal: 728ms\tremaining: 13.4s\n",
      "36:\tlearn: 0.4767424\ttotal: 749ms\tremaining: 13.4s\n",
      "37:\tlearn: 0.4743820\ttotal: 769ms\tremaining: 13.4s\n",
      "38:\tlearn: 0.4716984\ttotal: 790ms\tremaining: 13.4s\n",
      "39:\tlearn: 0.4693869\ttotal: 810ms\tremaining: 13.4s\n",
      "40:\tlearn: 0.4665338\ttotal: 830ms\tremaining: 13.3s\n",
      "41:\tlearn: 0.4638061\ttotal: 851ms\tremaining: 13.3s\n",
      "42:\tlearn: 0.4611357\ttotal: 872ms\tremaining: 13.3s\n",
      "43:\tlearn: 0.4591001\ttotal: 893ms\tremaining: 13.3s\n",
      "44:\tlearn: 0.4569148\ttotal: 915ms\tremaining: 13.3s\n",
      "45:\tlearn: 0.4553374\ttotal: 937ms\tremaining: 13.3s\n",
      "46:\tlearn: 0.4537973\ttotal: 958ms\tremaining: 13.3s\n",
      "47:\tlearn: 0.4518240\ttotal: 978ms\tremaining: 13.3s\n",
      "48:\tlearn: 0.4492710\ttotal: 998ms\tremaining: 13.3s\n",
      "49:\tlearn: 0.4475870\ttotal: 1.02s\tremaining: 13.2s\n",
      "50:\tlearn: 0.4455179\ttotal: 1.04s\tremaining: 13.2s\n",
      "51:\tlearn: 0.4431081\ttotal: 1.06s\tremaining: 13.2s\n",
      "52:\tlearn: 0.4413349\ttotal: 1.08s\tremaining: 13.2s\n",
      "53:\tlearn: 0.4392532\ttotal: 1.1s\tremaining: 13.2s\n",
      "54:\tlearn: 0.4386210\ttotal: 1.11s\tremaining: 13s\n",
      "55:\tlearn: 0.4371183\ttotal: 1.13s\tremaining: 13s\n",
      "56:\tlearn: 0.4351502\ttotal: 1.15s\tremaining: 13s\n",
      "57:\tlearn: 0.4334105\ttotal: 1.17s\tremaining: 13s\n",
      "58:\tlearn: 0.4319921\ttotal: 1.19s\tremaining: 12.9s\n",
      "59:\tlearn: 0.4301745\ttotal: 1.21s\tremaining: 12.9s\n",
      "60:\tlearn: 0.4282997\ttotal: 1.23s\tremaining: 12.9s\n",
      "61:\tlearn: 0.4264672\ttotal: 1.25s\tremaining: 12.9s\n",
      "62:\tlearn: 0.4247810\ttotal: 1.27s\tremaining: 12.9s\n",
      "63:\tlearn: 0.4230131\ttotal: 1.29s\tremaining: 12.9s\n",
      "64:\tlearn: 0.4215550\ttotal: 1.32s\tremaining: 12.9s\n",
      "65:\tlearn: 0.4209423\ttotal: 1.34s\tremaining: 12.8s\n",
      "66:\tlearn: 0.4193489\ttotal: 1.36s\tremaining: 12.8s\n",
      "67:\tlearn: 0.4173687\ttotal: 1.38s\tremaining: 12.8s\n",
      "68:\tlearn: 0.4160311\ttotal: 1.4s\tremaining: 12.8s\n",
      "69:\tlearn: 0.4157172\ttotal: 1.41s\tremaining: 12.7s\n",
      "70:\tlearn: 0.4143948\ttotal: 1.43s\tremaining: 12.7s\n",
      "71:\tlearn: 0.4131721\ttotal: 1.45s\tremaining: 12.7s\n",
      "72:\tlearn: 0.4121311\ttotal: 1.47s\tremaining: 12.7s\n",
      "73:\tlearn: 0.4106643\ttotal: 1.5s\tremaining: 12.7s\n",
      "74:\tlearn: 0.4094933\ttotal: 1.51s\tremaining: 12.6s\n",
      "75:\tlearn: 0.4081835\ttotal: 1.54s\tremaining: 12.6s\n",
      "76:\tlearn: 0.4070571\ttotal: 1.56s\tremaining: 12.6s\n",
      "77:\tlearn: 0.4054422\ttotal: 1.58s\tremaining: 12.6s\n",
      "78:\tlearn: 0.4045970\ttotal: 1.6s\tremaining: 12.6s\n",
      "79:\tlearn: 0.4038112\ttotal: 1.62s\tremaining: 12.5s\n",
      "80:\tlearn: 0.4031468\ttotal: 1.64s\tremaining: 12.5s\n",
      "81:\tlearn: 0.4016390\ttotal: 1.66s\tremaining: 12.5s\n",
      "82:\tlearn: 0.4005474\ttotal: 1.68s\tremaining: 12.5s\n",
      "83:\tlearn: 0.3992154\ttotal: 1.7s\tremaining: 12.5s\n",
      "84:\tlearn: 0.3983202\ttotal: 1.72s\tremaining: 12.5s\n",
      "85:\tlearn: 0.3971441\ttotal: 1.74s\tremaining: 12.4s\n",
      "86:\tlearn: 0.3959294\ttotal: 1.77s\tremaining: 12.5s\n",
      "87:\tlearn: 0.3953383\ttotal: 1.79s\tremaining: 12.5s\n",
      "88:\tlearn: 0.3944571\ttotal: 1.81s\tremaining: 12.5s\n",
      "89:\tlearn: 0.3933723\ttotal: 1.83s\tremaining: 12.4s\n",
      "90:\tlearn: 0.3922869\ttotal: 1.85s\tremaining: 12.4s\n",
      "91:\tlearn: 0.3912388\ttotal: 1.88s\tremaining: 12.4s\n",
      "92:\tlearn: 0.3904405\ttotal: 1.9s\tremaining: 12.4s\n",
      "93:\tlearn: 0.3894914\ttotal: 1.92s\tremaining: 12.4s\n",
      "94:\tlearn: 0.3887312\ttotal: 1.94s\tremaining: 12.4s\n",
      "95:\tlearn: 0.3880020\ttotal: 1.97s\tremaining: 12.4s\n",
      "96:\tlearn: 0.3873226\ttotal: 1.99s\tremaining: 12.4s\n",
      "97:\tlearn: 0.3865139\ttotal: 2.01s\tremaining: 12.3s\n",
      "98:\tlearn: 0.3860001\ttotal: 2.03s\tremaining: 12.3s\n",
      "99:\tlearn: 0.3853420\ttotal: 2.05s\tremaining: 12.3s\n",
      "100:\tlearn: 0.3852542\ttotal: 2.06s\tremaining: 12.2s\n",
      "101:\tlearn: 0.3841689\ttotal: 2.08s\tremaining: 12.2s\n",
      "102:\tlearn: 0.3832384\ttotal: 2.1s\tremaining: 12.2s\n",
      "103:\tlearn: 0.3822327\ttotal: 2.12s\tremaining: 12.1s\n",
      "104:\tlearn: 0.3814190\ttotal: 2.14s\tremaining: 12.1s\n",
      "105:\tlearn: 0.3807832\ttotal: 2.16s\tremaining: 12.1s\n",
      "106:\tlearn: 0.3800543\ttotal: 2.18s\tremaining: 12.1s\n",
      "107:\tlearn: 0.3794795\ttotal: 2.2s\tremaining: 12.1s\n",
      "108:\tlearn: 0.3792319\ttotal: 2.21s\tremaining: 12s\n",
      "109:\tlearn: 0.3784959\ttotal: 2.23s\tremaining: 12s\n",
      "110:\tlearn: 0.3775230\ttotal: 2.25s\tremaining: 12s\n",
      "111:\tlearn: 0.3768544\ttotal: 2.27s\tremaining: 11.9s\n",
      "112:\tlearn: 0.3763324\ttotal: 2.29s\tremaining: 11.9s\n",
      "113:\tlearn: 0.3755076\ttotal: 2.31s\tremaining: 11.9s\n",
      "114:\tlearn: 0.3743961\ttotal: 2.34s\tremaining: 11.9s\n",
      "115:\tlearn: 0.3736989\ttotal: 2.36s\tremaining: 11.9s\n",
      "116:\tlearn: 0.3729410\ttotal: 2.38s\tremaining: 11.8s\n",
      "117:\tlearn: 0.3720272\ttotal: 2.4s\tremaining: 11.8s\n",
      "118:\tlearn: 0.3708750\ttotal: 2.42s\tremaining: 11.8s\n",
      "119:\tlearn: 0.3700144\ttotal: 2.44s\tremaining: 11.8s\n",
      "120:\tlearn: 0.3688217\ttotal: 2.46s\tremaining: 11.8s\n",
      "121:\tlearn: 0.3680040\ttotal: 2.49s\tremaining: 11.8s\n",
      "122:\tlearn: 0.3674756\ttotal: 2.51s\tremaining: 11.8s\n",
      "123:\tlearn: 0.3666580\ttotal: 2.53s\tremaining: 11.7s\n",
      "124:\tlearn: 0.3660233\ttotal: 2.55s\tremaining: 11.7s\n",
      "125:\tlearn: 0.3658902\ttotal: 2.56s\tremaining: 11.6s\n",
      "126:\tlearn: 0.3650212\ttotal: 2.58s\tremaining: 11.6s\n",
      "127:\tlearn: 0.3642019\ttotal: 2.6s\tremaining: 11.6s\n",
      "128:\tlearn: 0.3633858\ttotal: 2.62s\tremaining: 11.6s\n",
      "129:\tlearn: 0.3627867\ttotal: 2.64s\tremaining: 11.6s\n",
      "130:\tlearn: 0.3619598\ttotal: 2.67s\tremaining: 11.6s\n",
      "131:\tlearn: 0.3615422\ttotal: 2.69s\tremaining: 11.6s\n",
      "132:\tlearn: 0.3611305\ttotal: 2.71s\tremaining: 11.5s\n",
      "133:\tlearn: 0.3605781\ttotal: 2.73s\tremaining: 11.5s\n",
      "134:\tlearn: 0.3600792\ttotal: 2.74s\tremaining: 11.5s\n",
      "135:\tlearn: 0.3595196\ttotal: 2.77s\tremaining: 11.5s\n",
      "136:\tlearn: 0.3588624\ttotal: 2.79s\tremaining: 11.4s\n",
      "137:\tlearn: 0.3579409\ttotal: 2.81s\tremaining: 11.4s\n",
      "138:\tlearn: 0.3574457\ttotal: 2.83s\tremaining: 11.4s\n",
      "139:\tlearn: 0.3572061\ttotal: 2.84s\tremaining: 11.4s\n",
      "140:\tlearn: 0.3564365\ttotal: 2.86s\tremaining: 11.3s\n",
      "141:\tlearn: 0.3555597\ttotal: 2.88s\tremaining: 11.3s\n",
      "142:\tlearn: 0.3548862\ttotal: 2.9s\tremaining: 11.3s\n",
      "143:\tlearn: 0.3541686\ttotal: 2.93s\tremaining: 11.3s\n",
      "144:\tlearn: 0.3531761\ttotal: 2.95s\tremaining: 11.3s\n",
      "145:\tlearn: 0.3523967\ttotal: 2.97s\tremaining: 11.3s\n",
      "146:\tlearn: 0.3519960\ttotal: 2.99s\tremaining: 11.2s\n",
      "147:\tlearn: 0.3513224\ttotal: 3.01s\tremaining: 11.2s\n",
      "148:\tlearn: 0.3506882\ttotal: 3.03s\tremaining: 11.2s\n",
      "149:\tlearn: 0.3500971\ttotal: 3.05s\tremaining: 11.2s\n",
      "150:\tlearn: 0.3494356\ttotal: 3.07s\tremaining: 11.2s\n",
      "151:\tlearn: 0.3492216\ttotal: 3.09s\tremaining: 11.1s\n",
      "152:\tlearn: 0.3488484\ttotal: 3.11s\tremaining: 11.1s\n",
      "153:\tlearn: 0.3483423\ttotal: 3.13s\tremaining: 11.1s\n",
      "154:\tlearn: 0.3480373\ttotal: 3.15s\tremaining: 11.1s\n",
      "155:\tlearn: 0.3475074\ttotal: 3.17s\tremaining: 11.1s\n",
      "156:\tlearn: 0.3468224\ttotal: 3.19s\tremaining: 11s\n",
      "157:\tlearn: 0.3462777\ttotal: 3.21s\tremaining: 11s\n",
      "158:\tlearn: 0.3458735\ttotal: 3.23s\tremaining: 11s\n",
      "159:\tlearn: 0.3451841\ttotal: 3.25s\tremaining: 11s\n",
      "160:\tlearn: 0.3445872\ttotal: 3.27s\tremaining: 11s\n",
      "161:\tlearn: 0.3438784\ttotal: 3.3s\tremaining: 10.9s\n",
      "162:\tlearn: 0.3432306\ttotal: 3.32s\tremaining: 10.9s\n",
      "163:\tlearn: 0.3425415\ttotal: 3.34s\tremaining: 10.9s\n",
      "164:\tlearn: 0.3421475\ttotal: 3.36s\tremaining: 10.9s\n",
      "165:\tlearn: 0.3411737\ttotal: 3.38s\tremaining: 10.9s\n",
      "166:\tlearn: 0.3407231\ttotal: 3.4s\tremaining: 10.8s\n",
      "167:\tlearn: 0.3403558\ttotal: 3.42s\tremaining: 10.8s\n",
      "168:\tlearn: 0.3397956\ttotal: 3.44s\tremaining: 10.8s\n",
      "169:\tlearn: 0.3390059\ttotal: 3.47s\tremaining: 10.8s\n",
      "170:\tlearn: 0.3385683\ttotal: 3.49s\tremaining: 10.8s\n",
      "171:\tlearn: 0.3381693\ttotal: 3.51s\tremaining: 10.8s\n",
      "172:\tlearn: 0.3375769\ttotal: 3.53s\tremaining: 10.8s\n",
      "173:\tlearn: 0.3369291\ttotal: 3.55s\tremaining: 10.7s\n",
      "174:\tlearn: 0.3363549\ttotal: 3.57s\tremaining: 10.7s\n",
      "175:\tlearn: 0.3356575\ttotal: 3.59s\tremaining: 10.7s\n",
      "176:\tlearn: 0.3349511\ttotal: 3.61s\tremaining: 10.7s\n",
      "177:\tlearn: 0.3343712\ttotal: 3.63s\tremaining: 10.7s\n",
      "178:\tlearn: 0.3337527\ttotal: 3.65s\tremaining: 10.6s\n",
      "179:\tlearn: 0.3332925\ttotal: 3.67s\tremaining: 10.6s\n",
      "180:\tlearn: 0.3327225\ttotal: 3.69s\tremaining: 10.6s\n",
      "181:\tlearn: 0.3321908\ttotal: 3.71s\tremaining: 10.6s\n",
      "182:\tlearn: 0.3316912\ttotal: 3.73s\tremaining: 10.6s\n",
      "183:\tlearn: 0.3312367\ttotal: 3.75s\tremaining: 10.5s\n",
      "184:\tlearn: 0.3308258\ttotal: 3.77s\tremaining: 10.5s\n",
      "185:\tlearn: 0.3301343\ttotal: 3.79s\tremaining: 10.5s\n",
      "186:\tlearn: 0.3295998\ttotal: 3.82s\tremaining: 10.5s\n",
      "187:\tlearn: 0.3290227\ttotal: 3.84s\tremaining: 10.4s\n",
      "188:\tlearn: 0.3285680\ttotal: 3.86s\tremaining: 10.4s\n",
      "189:\tlearn: 0.3279446\ttotal: 3.88s\tremaining: 10.4s\n",
      "190:\tlearn: 0.3272612\ttotal: 3.9s\tremaining: 10.4s\n",
      "191:\tlearn: 0.3265829\ttotal: 3.92s\tremaining: 10.4s\n",
      "192:\tlearn: 0.3261109\ttotal: 3.94s\tremaining: 10.4s\n",
      "193:\tlearn: 0.3257570\ttotal: 3.96s\tremaining: 10.3s\n",
      "194:\tlearn: 0.3251629\ttotal: 3.98s\tremaining: 10.3s\n",
      "195:\tlearn: 0.3246862\ttotal: 4s\tremaining: 10.3s\n",
      "196:\tlearn: 0.3240725\ttotal: 4.03s\tremaining: 10.3s\n",
      "197:\tlearn: 0.3237515\ttotal: 4.05s\tremaining: 10.3s\n",
      "198:\tlearn: 0.3231303\ttotal: 4.07s\tremaining: 10.2s\n",
      "199:\tlearn: 0.3224783\ttotal: 4.09s\tremaining: 10.2s\n",
      "200:\tlearn: 0.3218551\ttotal: 4.11s\tremaining: 10.2s\n",
      "201:\tlearn: 0.3214629\ttotal: 4.13s\tremaining: 10.2s\n",
      "202:\tlearn: 0.3213278\ttotal: 4.15s\tremaining: 10.2s\n",
      "203:\tlearn: 0.3210263\ttotal: 4.17s\tremaining: 10.1s\n",
      "204:\tlearn: 0.3205016\ttotal: 4.19s\tremaining: 10.1s\n",
      "205:\tlearn: 0.3199405\ttotal: 4.21s\tremaining: 10.1s\n",
      "206:\tlearn: 0.3196148\ttotal: 4.23s\tremaining: 10.1s\n",
      "207:\tlearn: 0.3189228\ttotal: 4.25s\tremaining: 10.1s\n",
      "208:\tlearn: 0.3185884\ttotal: 4.27s\tremaining: 10s\n",
      "209:\tlearn: 0.3182350\ttotal: 4.29s\tremaining: 10s\n",
      "210:\tlearn: 0.3178078\ttotal: 4.31s\tremaining: 9.99s\n",
      "211:\tlearn: 0.3174100\ttotal: 4.33s\tremaining: 9.97s\n",
      "212:\tlearn: 0.3170361\ttotal: 4.35s\tremaining: 9.95s\n",
      "213:\tlearn: 0.3167351\ttotal: 4.37s\tremaining: 9.93s\n",
      "214:\tlearn: 0.3166918\ttotal: 4.38s\tremaining: 9.89s\n",
      "215:\tlearn: 0.3160684\ttotal: 4.41s\tremaining: 9.87s\n",
      "216:\tlearn: 0.3157118\ttotal: 4.43s\tremaining: 9.86s\n",
      "217:\tlearn: 0.3155204\ttotal: 4.45s\tremaining: 9.84s\n",
      "218:\tlearn: 0.3151437\ttotal: 4.47s\tremaining: 9.82s\n",
      "219:\tlearn: 0.3147795\ttotal: 4.49s\tremaining: 9.79s\n",
      "220:\tlearn: 0.3140821\ttotal: 4.51s\tremaining: 9.78s\n",
      "221:\tlearn: 0.3136535\ttotal: 4.53s\tremaining: 9.76s\n",
      "222:\tlearn: 0.3132143\ttotal: 4.55s\tremaining: 9.73s\n",
      "223:\tlearn: 0.3128391\ttotal: 4.57s\tremaining: 9.72s\n",
      "224:\tlearn: 0.3122839\ttotal: 4.59s\tremaining: 9.7s\n",
      "225:\tlearn: 0.3119832\ttotal: 4.61s\tremaining: 9.68s\n",
      "226:\tlearn: 0.3116542\ttotal: 4.63s\tremaining: 9.65s\n",
      "227:\tlearn: 0.3113189\ttotal: 4.65s\tremaining: 9.63s\n",
      "228:\tlearn: 0.3108889\ttotal: 4.67s\tremaining: 9.61s\n",
      "229:\tlearn: 0.3102260\ttotal: 4.7s\tremaining: 9.59s\n",
      "230:\tlearn: 0.3096730\ttotal: 4.71s\tremaining: 9.57s\n",
      "231:\tlearn: 0.3092204\ttotal: 4.74s\tremaining: 9.55s\n",
      "232:\tlearn: 0.3087691\ttotal: 4.76s\tremaining: 9.53s\n",
      "233:\tlearn: 0.3081593\ttotal: 4.78s\tremaining: 9.51s\n",
      "234:\tlearn: 0.3075384\ttotal: 4.8s\tremaining: 9.49s\n",
      "235:\tlearn: 0.3070918\ttotal: 4.82s\tremaining: 9.47s\n",
      "236:\tlearn: 0.3067364\ttotal: 4.84s\tremaining: 9.45s\n",
      "237:\tlearn: 0.3064450\ttotal: 4.86s\tremaining: 9.43s\n",
      "238:\tlearn: 0.3061906\ttotal: 4.88s\tremaining: 9.41s\n",
      "239:\tlearn: 0.3059107\ttotal: 4.9s\tremaining: 9.39s\n",
      "240:\tlearn: 0.3054872\ttotal: 4.92s\tremaining: 9.38s\n",
      "241:\tlearn: 0.3051222\ttotal: 4.95s\tremaining: 9.36s\n",
      "242:\tlearn: 0.3046679\ttotal: 4.97s\tremaining: 9.35s\n",
      "243:\tlearn: 0.3042721\ttotal: 4.99s\tremaining: 9.32s\n",
      "244:\tlearn: 0.3037289\ttotal: 5.01s\tremaining: 9.3s\n",
      "245:\tlearn: 0.3035717\ttotal: 5.03s\tremaining: 9.29s\n",
      "246:\tlearn: 0.3029426\ttotal: 5.05s\tremaining: 9.27s\n",
      "247:\tlearn: 0.3025982\ttotal: 5.07s\tremaining: 9.24s\n",
      "248:\tlearn: 0.3021883\ttotal: 5.09s\tremaining: 9.22s\n",
      "249:\tlearn: 0.3017127\ttotal: 5.11s\tremaining: 9.21s\n",
      "250:\tlearn: 0.3012833\ttotal: 5.13s\tremaining: 9.19s\n",
      "251:\tlearn: 0.3011301\ttotal: 5.15s\tremaining: 9.16s\n",
      "252:\tlearn: 0.3008935\ttotal: 5.17s\tremaining: 9.14s\n",
      "253:\tlearn: 0.3003929\ttotal: 5.2s\tremaining: 9.12s\n",
      "254:\tlearn: 0.3001352\ttotal: 5.21s\tremaining: 9.1s\n",
      "255:\tlearn: 0.2998718\ttotal: 5.24s\tremaining: 9.08s\n",
      "256:\tlearn: 0.2994976\ttotal: 5.26s\tremaining: 9.06s\n",
      "257:\tlearn: 0.2992193\ttotal: 5.28s\tremaining: 9.04s\n",
      "258:\tlearn: 0.2990074\ttotal: 5.3s\tremaining: 9.02s\n",
      "259:\tlearn: 0.2986365\ttotal: 5.32s\tremaining: 9s\n",
      "260:\tlearn: 0.2980705\ttotal: 5.34s\tremaining: 8.98s\n",
      "261:\tlearn: 0.2976873\ttotal: 5.36s\tremaining: 8.96s\n",
      "262:\tlearn: 0.2972797\ttotal: 5.39s\tremaining: 8.96s\n",
      "263:\tlearn: 0.2971009\ttotal: 5.42s\tremaining: 8.96s\n",
      "264:\tlearn: 0.2967137\ttotal: 5.47s\tremaining: 8.98s\n",
      "265:\tlearn: 0.2962568\ttotal: 5.5s\tremaining: 8.98s\n",
      "266:\tlearn: 0.2957045\ttotal: 5.52s\tremaining: 8.96s\n",
      "267:\tlearn: 0.2951399\ttotal: 5.55s\tremaining: 8.94s\n",
      "268:\tlearn: 0.2946061\ttotal: 5.57s\tremaining: 8.92s\n",
      "269:\tlearn: 0.2942271\ttotal: 5.59s\tremaining: 8.9s\n",
      "270:\tlearn: 0.2939599\ttotal: 5.61s\tremaining: 8.88s\n",
      "271:\tlearn: 0.2935514\ttotal: 5.63s\tremaining: 8.86s\n",
      "272:\tlearn: 0.2930985\ttotal: 5.65s\tremaining: 8.84s\n",
      "273:\tlearn: 0.2928919\ttotal: 5.67s\tremaining: 8.82s\n",
      "274:\tlearn: 0.2926447\ttotal: 5.69s\tremaining: 8.8s\n",
      "275:\tlearn: 0.2919852\ttotal: 5.71s\tremaining: 8.78s\n",
      "276:\tlearn: 0.2914605\ttotal: 5.73s\tremaining: 8.76s\n",
      "277:\tlearn: 0.2909466\ttotal: 5.75s\tremaining: 8.73s\n",
      "278:\tlearn: 0.2907514\ttotal: 5.77s\tremaining: 8.71s\n",
      "279:\tlearn: 0.2901906\ttotal: 5.79s\tremaining: 8.69s\n",
      "280:\tlearn: 0.2898684\ttotal: 5.82s\tremaining: 8.67s\n",
      "281:\tlearn: 0.2898398\ttotal: 5.83s\tremaining: 8.63s\n",
      "282:\tlearn: 0.2894949\ttotal: 5.84s\tremaining: 8.61s\n",
      "283:\tlearn: 0.2891201\ttotal: 5.87s\tremaining: 8.59s\n",
      "284:\tlearn: 0.2891042\ttotal: 5.88s\tremaining: 8.56s\n",
      "285:\tlearn: 0.2887798\ttotal: 5.9s\tremaining: 8.54s\n",
      "286:\tlearn: 0.2884489\ttotal: 5.92s\tremaining: 8.52s\n",
      "287:\tlearn: 0.2882195\ttotal: 5.94s\tremaining: 8.5s\n",
      "288:\tlearn: 0.2877188\ttotal: 5.96s\tremaining: 8.48s\n",
      "289:\tlearn: 0.2873619\ttotal: 5.98s\tremaining: 8.46s\n",
      "290:\tlearn: 0.2868761\ttotal: 6s\tremaining: 8.44s\n",
      "291:\tlearn: 0.2866451\ttotal: 6.02s\tremaining: 8.42s\n",
      "292:\tlearn: 0.2863487\ttotal: 6.04s\tremaining: 8.39s\n",
      "293:\tlearn: 0.2857801\ttotal: 6.06s\tremaining: 8.38s\n",
      "294:\tlearn: 0.2853211\ttotal: 6.09s\tremaining: 8.36s\n",
      "295:\tlearn: 0.2849742\ttotal: 6.11s\tremaining: 8.33s\n",
      "296:\tlearn: 0.2846024\ttotal: 6.13s\tremaining: 8.31s\n",
      "297:\tlearn: 0.2843060\ttotal: 6.15s\tremaining: 8.29s\n",
      "298:\tlearn: 0.2838506\ttotal: 6.17s\tremaining: 8.27s\n",
      "299:\tlearn: 0.2834748\ttotal: 6.19s\tremaining: 8.25s\n",
      "300:\tlearn: 0.2831739\ttotal: 6.21s\tremaining: 8.23s\n",
      "301:\tlearn: 0.2829557\ttotal: 6.23s\tremaining: 8.21s\n",
      "302:\tlearn: 0.2823486\ttotal: 6.25s\tremaining: 8.19s\n",
      "303:\tlearn: 0.2817923\ttotal: 6.27s\tremaining: 8.17s\n",
      "304:\tlearn: 0.2815593\ttotal: 6.29s\tremaining: 8.15s\n",
      "305:\tlearn: 0.2810686\ttotal: 6.31s\tremaining: 8.13s\n",
      "306:\tlearn: 0.2804452\ttotal: 6.33s\tremaining: 8.11s\n",
      "307:\tlearn: 0.2799196\ttotal: 6.36s\tremaining: 8.09s\n",
      "308:\tlearn: 0.2794443\ttotal: 6.38s\tremaining: 8.07s\n",
      "309:\tlearn: 0.2791096\ttotal: 6.4s\tremaining: 8.05s\n",
      "310:\tlearn: 0.2788478\ttotal: 6.42s\tremaining: 8.03s\n",
      "311:\tlearn: 0.2784257\ttotal: 6.45s\tremaining: 8.02s\n",
      "312:\tlearn: 0.2777062\ttotal: 6.47s\tremaining: 8s\n",
      "313:\tlearn: 0.2774476\ttotal: 6.49s\tremaining: 7.97s\n",
      "314:\tlearn: 0.2771272\ttotal: 6.51s\tremaining: 7.95s\n",
      "315:\tlearn: 0.2768045\ttotal: 6.53s\tremaining: 7.93s\n",
      "316:\tlearn: 0.2764584\ttotal: 6.55s\tremaining: 7.91s\n",
      "317:\tlearn: 0.2762640\ttotal: 6.57s\tremaining: 7.89s\n",
      "318:\tlearn: 0.2759735\ttotal: 6.59s\tremaining: 7.87s\n",
      "319:\tlearn: 0.2757162\ttotal: 6.61s\tremaining: 7.85s\n",
      "320:\tlearn: 0.2752553\ttotal: 6.63s\tremaining: 7.83s\n",
      "321:\tlearn: 0.2749530\ttotal: 6.65s\tremaining: 7.81s\n",
      "322:\tlearn: 0.2745689\ttotal: 6.67s\tremaining: 7.79s\n",
      "323:\tlearn: 0.2742203\ttotal: 6.69s\tremaining: 7.77s\n",
      "324:\tlearn: 0.2738336\ttotal: 6.71s\tremaining: 7.75s\n",
      "325:\tlearn: 0.2733241\ttotal: 6.73s\tremaining: 7.72s\n",
      "326:\tlearn: 0.2730766\ttotal: 6.75s\tremaining: 7.71s\n",
      "327:\tlearn: 0.2725789\ttotal: 6.78s\tremaining: 7.68s\n",
      "328:\tlearn: 0.2720185\ttotal: 6.8s\tremaining: 7.66s\n",
      "329:\tlearn: 0.2717242\ttotal: 6.82s\tremaining: 7.64s\n",
      "330:\tlearn: 0.2714135\ttotal: 6.84s\tremaining: 7.62s\n",
      "331:\tlearn: 0.2710606\ttotal: 6.86s\tremaining: 7.6s\n",
      "332:\tlearn: 0.2706799\ttotal: 6.88s\tremaining: 7.58s\n",
      "333:\tlearn: 0.2701441\ttotal: 6.9s\tremaining: 7.56s\n",
      "334:\tlearn: 0.2697569\ttotal: 6.92s\tremaining: 7.54s\n",
      "335:\tlearn: 0.2692521\ttotal: 6.95s\tremaining: 7.52s\n",
      "336:\tlearn: 0.2688770\ttotal: 6.96s\tremaining: 7.5s\n",
      "337:\tlearn: 0.2685480\ttotal: 6.99s\tremaining: 7.48s\n",
      "338:\tlearn: 0.2682872\ttotal: 7.01s\tremaining: 7.46s\n",
      "339:\tlearn: 0.2679577\ttotal: 7.03s\tremaining: 7.44s\n",
      "340:\tlearn: 0.2672199\ttotal: 7.05s\tremaining: 7.42s\n",
      "341:\tlearn: 0.2668291\ttotal: 7.07s\tremaining: 7.4s\n",
      "342:\tlearn: 0.2665211\ttotal: 7.09s\tremaining: 7.38s\n",
      "343:\tlearn: 0.2661456\ttotal: 7.11s\tremaining: 7.36s\n",
      "344:\tlearn: 0.2657055\ttotal: 7.13s\tremaining: 7.34s\n",
      "345:\tlearn: 0.2652395\ttotal: 7.15s\tremaining: 7.32s\n",
      "346:\tlearn: 0.2648586\ttotal: 7.17s\tremaining: 7.29s\n",
      "347:\tlearn: 0.2645665\ttotal: 7.19s\tremaining: 7.27s\n",
      "348:\tlearn: 0.2642543\ttotal: 7.21s\tremaining: 7.25s\n",
      "349:\tlearn: 0.2638287\ttotal: 7.23s\tremaining: 7.23s\n",
      "350:\tlearn: 0.2637068\ttotal: 7.25s\tremaining: 7.21s\n",
      "351:\tlearn: 0.2632868\ttotal: 7.27s\tremaining: 7.19s\n",
      "352:\tlearn: 0.2630557\ttotal: 7.29s\tremaining: 7.17s\n",
      "353:\tlearn: 0.2626619\ttotal: 7.31s\tremaining: 7.15s\n",
      "354:\tlearn: 0.2620569\ttotal: 7.33s\tremaining: 7.13s\n",
      "355:\tlearn: 0.2617538\ttotal: 7.36s\tremaining: 7.11s\n",
      "356:\tlearn: 0.2614125\ttotal: 7.38s\tremaining: 7.09s\n",
      "357:\tlearn: 0.2609903\ttotal: 7.4s\tremaining: 7.07s\n",
      "358:\tlearn: 0.2604866\ttotal: 7.42s\tremaining: 7.05s\n",
      "359:\tlearn: 0.2602176\ttotal: 7.44s\tremaining: 7.03s\n",
      "360:\tlearn: 0.2597904\ttotal: 7.46s\tremaining: 7.01s\n",
      "361:\tlearn: 0.2596184\ttotal: 7.48s\tremaining: 6.99s\n",
      "362:\tlearn: 0.2593440\ttotal: 7.5s\tremaining: 6.96s\n",
      "363:\tlearn: 0.2588928\ttotal: 7.52s\tremaining: 6.95s\n",
      "364:\tlearn: 0.2586078\ttotal: 7.54s\tremaining: 6.92s\n",
      "365:\tlearn: 0.2582699\ttotal: 7.57s\tremaining: 6.9s\n",
      "366:\tlearn: 0.2579917\ttotal: 7.58s\tremaining: 6.88s\n",
      "367:\tlearn: 0.2576847\ttotal: 7.61s\tremaining: 6.86s\n",
      "368:\tlearn: 0.2573559\ttotal: 7.63s\tremaining: 6.84s\n",
      "369:\tlearn: 0.2568549\ttotal: 7.65s\tremaining: 6.82s\n",
      "370:\tlearn: 0.2565502\ttotal: 7.67s\tremaining: 6.8s\n",
      "371:\tlearn: 0.2562748\ttotal: 7.69s\tremaining: 6.78s\n",
      "372:\tlearn: 0.2559831\ttotal: 7.71s\tremaining: 6.76s\n",
      "373:\tlearn: 0.2556588\ttotal: 7.73s\tremaining: 6.74s\n",
      "374:\tlearn: 0.2553029\ttotal: 7.75s\tremaining: 6.71s\n",
      "375:\tlearn: 0.2548565\ttotal: 7.77s\tremaining: 6.7s\n",
      "376:\tlearn: 0.2543385\ttotal: 7.79s\tremaining: 6.67s\n",
      "377:\tlearn: 0.2540832\ttotal: 7.81s\tremaining: 6.65s\n",
      "378:\tlearn: 0.2536854\ttotal: 7.83s\tremaining: 6.63s\n",
      "379:\tlearn: 0.2532071\ttotal: 7.85s\tremaining: 6.61s\n",
      "380:\tlearn: 0.2530509\ttotal: 7.87s\tremaining: 6.59s\n",
      "381:\tlearn: 0.2528184\ttotal: 7.89s\tremaining: 6.57s\n",
      "382:\tlearn: 0.2525095\ttotal: 7.92s\tremaining: 6.55s\n",
      "383:\tlearn: 0.2521403\ttotal: 7.94s\tremaining: 6.53s\n",
      "384:\tlearn: 0.2519239\ttotal: 7.96s\tremaining: 6.51s\n",
      "385:\tlearn: 0.2515934\ttotal: 7.98s\tremaining: 6.49s\n",
      "386:\tlearn: 0.2511796\ttotal: 8s\tremaining: 6.47s\n",
      "387:\tlearn: 0.2509049\ttotal: 8.02s\tremaining: 6.45s\n",
      "388:\tlearn: 0.2507150\ttotal: 8.04s\tremaining: 6.43s\n",
      "389:\tlearn: 0.2503035\ttotal: 8.06s\tremaining: 6.41s\n",
      "390:\tlearn: 0.2499441\ttotal: 8.09s\tremaining: 6.39s\n",
      "391:\tlearn: 0.2496269\ttotal: 8.11s\tremaining: 6.37s\n",
      "392:\tlearn: 0.2493736\ttotal: 8.13s\tremaining: 6.35s\n",
      "393:\tlearn: 0.2491835\ttotal: 8.15s\tremaining: 6.33s\n",
      "394:\tlearn: 0.2487913\ttotal: 8.17s\tremaining: 6.31s\n",
      "395:\tlearn: 0.2484766\ttotal: 8.19s\tremaining: 6.29s\n",
      "396:\tlearn: 0.2480583\ttotal: 8.21s\tremaining: 6.26s\n",
      "397:\tlearn: 0.2476616\ttotal: 8.23s\tremaining: 6.24s\n",
      "398:\tlearn: 0.2473943\ttotal: 8.25s\tremaining: 6.22s\n",
      "399:\tlearn: 0.2472314\ttotal: 8.27s\tremaining: 6.2s\n",
      "400:\tlearn: 0.2472128\ttotal: 8.28s\tremaining: 6.17s\n",
      "401:\tlearn: 0.2468088\ttotal: 8.3s\tremaining: 6.16s\n",
      "402:\tlearn: 0.2465681\ttotal: 8.32s\tremaining: 6.13s\n",
      "403:\tlearn: 0.2462040\ttotal: 8.34s\tremaining: 6.11s\n",
      "404:\tlearn: 0.2458957\ttotal: 8.37s\tremaining: 6.09s\n",
      "405:\tlearn: 0.2457062\ttotal: 8.39s\tremaining: 6.07s\n",
      "406:\tlearn: 0.2453128\ttotal: 8.41s\tremaining: 6.05s\n",
      "407:\tlearn: 0.2450963\ttotal: 8.43s\tremaining: 6.03s\n",
      "408:\tlearn: 0.2448601\ttotal: 8.45s\tremaining: 6.01s\n",
      "409:\tlearn: 0.2444358\ttotal: 8.47s\tremaining: 5.99s\n",
      "410:\tlearn: 0.2441408\ttotal: 8.49s\tremaining: 5.97s\n",
      "411:\tlearn: 0.2438721\ttotal: 8.51s\tremaining: 5.95s\n",
      "412:\tlearn: 0.2436294\ttotal: 8.53s\tremaining: 5.93s\n",
      "413:\tlearn: 0.2433653\ttotal: 8.55s\tremaining: 5.91s\n",
      "414:\tlearn: 0.2429988\ttotal: 8.57s\tremaining: 5.89s\n",
      "415:\tlearn: 0.2424399\ttotal: 8.6s\tremaining: 5.87s\n",
      "416:\tlearn: 0.2422715\ttotal: 8.62s\tremaining: 5.85s\n",
      "417:\tlearn: 0.2419569\ttotal: 8.64s\tremaining: 5.83s\n",
      "418:\tlearn: 0.2416873\ttotal: 8.66s\tremaining: 5.8s\n",
      "419:\tlearn: 0.2415364\ttotal: 8.68s\tremaining: 5.78s\n",
      "420:\tlearn: 0.2411470\ttotal: 8.7s\tremaining: 5.76s\n",
      "421:\tlearn: 0.2409714\ttotal: 8.72s\tremaining: 5.74s\n",
      "422:\tlearn: 0.2407578\ttotal: 8.74s\tremaining: 5.72s\n",
      "423:\tlearn: 0.2404005\ttotal: 8.76s\tremaining: 5.7s\n",
      "424:\tlearn: 0.2402271\ttotal: 8.78s\tremaining: 5.68s\n",
      "425:\tlearn: 0.2399755\ttotal: 8.8s\tremaining: 5.66s\n",
      "426:\tlearn: 0.2396399\ttotal: 8.82s\tremaining: 5.64s\n",
      "427:\tlearn: 0.2392690\ttotal: 8.84s\tremaining: 5.62s\n",
      "428:\tlearn: 0.2390631\ttotal: 8.86s\tremaining: 5.6s\n",
      "429:\tlearn: 0.2388283\ttotal: 8.88s\tremaining: 5.58s\n",
      "430:\tlearn: 0.2385503\ttotal: 8.9s\tremaining: 5.56s\n",
      "431:\tlearn: 0.2383457\ttotal: 8.92s\tremaining: 5.54s\n",
      "432:\tlearn: 0.2380269\ttotal: 8.95s\tremaining: 5.52s\n",
      "433:\tlearn: 0.2377136\ttotal: 8.97s\tremaining: 5.5s\n",
      "434:\tlearn: 0.2376899\ttotal: 8.98s\tremaining: 5.47s\n",
      "435:\tlearn: 0.2373402\ttotal: 9s\tremaining: 5.45s\n",
      "436:\tlearn: 0.2372123\ttotal: 9.01s\tremaining: 5.42s\n",
      "437:\tlearn: 0.2367687\ttotal: 9.03s\tremaining: 5.4s\n",
      "438:\tlearn: 0.2365768\ttotal: 9.05s\tremaining: 5.38s\n",
      "439:\tlearn: 0.2362075\ttotal: 9.07s\tremaining: 5.36s\n",
      "440:\tlearn: 0.2357582\ttotal: 9.09s\tremaining: 5.34s\n",
      "441:\tlearn: 0.2355768\ttotal: 9.11s\tremaining: 5.32s\n",
      "442:\tlearn: 0.2354370\ttotal: 9.13s\tremaining: 5.3s\n",
      "443:\tlearn: 0.2351321\ttotal: 9.16s\tremaining: 5.28s\n",
      "444:\tlearn: 0.2348352\ttotal: 9.19s\tremaining: 5.26s\n",
      "445:\tlearn: 0.2345136\ttotal: 9.21s\tremaining: 5.24s\n",
      "446:\tlearn: 0.2339513\ttotal: 9.23s\tremaining: 5.22s\n",
      "447:\tlearn: 0.2335591\ttotal: 9.25s\tremaining: 5.2s\n",
      "448:\tlearn: 0.2333521\ttotal: 9.27s\tremaining: 5.18s\n",
      "449:\tlearn: 0.2331356\ttotal: 9.29s\tremaining: 5.16s\n",
      "450:\tlearn: 0.2329648\ttotal: 9.31s\tremaining: 5.14s\n",
      "451:\tlearn: 0.2327848\ttotal: 9.33s\tremaining: 5.12s\n",
      "452:\tlearn: 0.2325172\ttotal: 9.35s\tremaining: 5.1s\n",
      "453:\tlearn: 0.2324123\ttotal: 9.37s\tremaining: 5.08s\n",
      "454:\tlearn: 0.2319780\ttotal: 9.39s\tremaining: 5.06s\n",
      "455:\tlearn: 0.2317788\ttotal: 9.42s\tremaining: 5.04s\n",
      "456:\tlearn: 0.2314188\ttotal: 9.44s\tremaining: 5.02s\n",
      "457:\tlearn: 0.2312739\ttotal: 9.46s\tremaining: 5s\n",
      "458:\tlearn: 0.2310287\ttotal: 9.48s\tremaining: 4.98s\n",
      "459:\tlearn: 0.2307244\ttotal: 9.51s\tremaining: 4.96s\n",
      "460:\tlearn: 0.2305058\ttotal: 9.53s\tremaining: 4.94s\n",
      "461:\tlearn: 0.2303453\ttotal: 9.54s\tremaining: 4.92s\n",
      "462:\tlearn: 0.2298313\ttotal: 9.57s\tremaining: 4.9s\n",
      "463:\tlearn: 0.2297381\ttotal: 9.59s\tremaining: 4.88s\n",
      "464:\tlearn: 0.2294097\ttotal: 9.61s\tremaining: 4.86s\n",
      "465:\tlearn: 0.2291715\ttotal: 9.63s\tremaining: 4.83s\n",
      "466:\tlearn: 0.2289452\ttotal: 9.65s\tremaining: 4.81s\n",
      "467:\tlearn: 0.2285659\ttotal: 9.67s\tremaining: 4.79s\n",
      "468:\tlearn: 0.2281014\ttotal: 9.69s\tremaining: 4.77s\n",
      "469:\tlearn: 0.2278582\ttotal: 9.71s\tremaining: 4.75s\n",
      "470:\tlearn: 0.2276096\ttotal: 9.73s\tremaining: 4.73s\n",
      "471:\tlearn: 0.2271515\ttotal: 9.75s\tremaining: 4.71s\n",
      "472:\tlearn: 0.2265001\ttotal: 9.77s\tremaining: 4.69s\n",
      "473:\tlearn: 0.2262928\ttotal: 9.79s\tremaining: 4.67s\n",
      "474:\tlearn: 0.2258014\ttotal: 9.81s\tremaining: 4.65s\n",
      "475:\tlearn: 0.2255981\ttotal: 9.83s\tremaining: 4.63s\n",
      "476:\tlearn: 0.2252130\ttotal: 9.85s\tremaining: 4.61s\n",
      "477:\tlearn: 0.2248972\ttotal: 9.88s\tremaining: 4.59s\n",
      "478:\tlearn: 0.2246538\ttotal: 9.9s\tremaining: 4.57s\n",
      "479:\tlearn: 0.2243450\ttotal: 9.92s\tremaining: 4.55s\n",
      "480:\tlearn: 0.2240803\ttotal: 9.94s\tremaining: 4.53s\n",
      "481:\tlearn: 0.2238317\ttotal: 9.96s\tremaining: 4.5s\n",
      "482:\tlearn: 0.2236400\ttotal: 9.98s\tremaining: 4.48s\n",
      "483:\tlearn: 0.2234162\ttotal: 10s\tremaining: 4.46s\n",
      "484:\tlearn: 0.2230641\ttotal: 10s\tremaining: 4.44s\n",
      "485:\tlearn: 0.2228135\ttotal: 10s\tremaining: 4.42s\n",
      "486:\tlearn: 0.2226313\ttotal: 10.1s\tremaining: 4.4s\n",
      "487:\tlearn: 0.2222475\ttotal: 10.1s\tremaining: 4.38s\n",
      "488:\tlearn: 0.2219358\ttotal: 10.1s\tremaining: 4.36s\n",
      "489:\tlearn: 0.2216895\ttotal: 10.1s\tremaining: 4.34s\n",
      "490:\tlearn: 0.2212500\ttotal: 10.1s\tremaining: 4.32s\n",
      "491:\tlearn: 0.2210348\ttotal: 10.2s\tremaining: 4.3s\n",
      "492:\tlearn: 0.2205539\ttotal: 10.2s\tremaining: 4.28s\n",
      "493:\tlearn: 0.2202782\ttotal: 10.2s\tremaining: 4.26s\n",
      "494:\tlearn: 0.2199353\ttotal: 10.2s\tremaining: 4.24s\n",
      "495:\tlearn: 0.2194372\ttotal: 10.2s\tremaining: 4.21s\n",
      "496:\tlearn: 0.2189438\ttotal: 10.3s\tremaining: 4.2s\n",
      "497:\tlearn: 0.2187537\ttotal: 10.3s\tremaining: 4.17s\n",
      "498:\tlearn: 0.2185529\ttotal: 10.3s\tremaining: 4.15s\n",
      "499:\tlearn: 0.2183539\ttotal: 10.3s\tremaining: 4.13s\n",
      "500:\tlearn: 0.2179967\ttotal: 10.4s\tremaining: 4.11s\n",
      "501:\tlearn: 0.2175934\ttotal: 10.4s\tremaining: 4.09s\n",
      "502:\tlearn: 0.2172623\ttotal: 10.4s\tremaining: 4.07s\n",
      "503:\tlearn: 0.2169867\ttotal: 10.4s\tremaining: 4.05s\n",
      "504:\tlearn: 0.2166977\ttotal: 10.4s\tremaining: 4.03s\n",
      "505:\tlearn: 0.2163758\ttotal: 10.5s\tremaining: 4.01s\n",
      "506:\tlearn: 0.2160177\ttotal: 10.5s\tremaining: 3.99s\n",
      "507:\tlearn: 0.2158019\ttotal: 10.5s\tremaining: 3.97s\n",
      "508:\tlearn: 0.2156683\ttotal: 10.5s\tremaining: 3.95s\n",
      "509:\tlearn: 0.2152769\ttotal: 10.5s\tremaining: 3.93s\n",
      "510:\tlearn: 0.2150025\ttotal: 10.6s\tremaining: 3.91s\n",
      "511:\tlearn: 0.2147025\ttotal: 10.6s\tremaining: 3.89s\n",
      "512:\tlearn: 0.2144131\ttotal: 10.6s\tremaining: 3.87s\n",
      "513:\tlearn: 0.2139308\ttotal: 10.6s\tremaining: 3.85s\n",
      "514:\tlearn: 0.2137686\ttotal: 10.6s\tremaining: 3.82s\n",
      "515:\tlearn: 0.2133419\ttotal: 10.7s\tremaining: 3.8s\n",
      "516:\tlearn: 0.2131357\ttotal: 10.7s\tremaining: 3.78s\n",
      "517:\tlearn: 0.2128093\ttotal: 10.7s\tremaining: 3.76s\n",
      "518:\tlearn: 0.2126197\ttotal: 10.7s\tremaining: 3.74s\n",
      "519:\tlearn: 0.2123560\ttotal: 10.7s\tremaining: 3.72s\n",
      "520:\tlearn: 0.2122550\ttotal: 10.8s\tremaining: 3.7s\n",
      "521:\tlearn: 0.2120664\ttotal: 10.8s\tremaining: 3.68s\n",
      "522:\tlearn: 0.2117657\ttotal: 10.8s\tremaining: 3.66s\n",
      "523:\tlearn: 0.2115624\ttotal: 10.8s\tremaining: 3.64s\n",
      "524:\tlearn: 0.2111925\ttotal: 10.8s\tremaining: 3.62s\n",
      "525:\tlearn: 0.2109066\ttotal: 10.9s\tremaining: 3.6s\n",
      "526:\tlearn: 0.2107902\ttotal: 10.9s\tremaining: 3.58s\n",
      "527:\tlearn: 0.2105439\ttotal: 10.9s\tremaining: 3.56s\n",
      "528:\tlearn: 0.2102039\ttotal: 10.9s\tremaining: 3.54s\n",
      "529:\tlearn: 0.2098699\ttotal: 11s\tremaining: 3.52s\n",
      "530:\tlearn: 0.2097199\ttotal: 11s\tremaining: 3.49s\n",
      "531:\tlearn: 0.2095170\ttotal: 11s\tremaining: 3.47s\n",
      "532:\tlearn: 0.2092941\ttotal: 11s\tremaining: 3.45s\n",
      "533:\tlearn: 0.2090367\ttotal: 11s\tremaining: 3.43s\n",
      "534:\tlearn: 0.2087957\ttotal: 11.1s\tremaining: 3.41s\n",
      "535:\tlearn: 0.2085463\ttotal: 11.1s\tremaining: 3.39s\n",
      "536:\tlearn: 0.2082949\ttotal: 11.1s\tremaining: 3.37s\n",
      "537:\tlearn: 0.2077381\ttotal: 11.1s\tremaining: 3.35s\n",
      "538:\tlearn: 0.2074574\ttotal: 11.1s\tremaining: 3.33s\n",
      "539:\tlearn: 0.2071355\ttotal: 11.2s\tremaining: 3.31s\n",
      "540:\tlearn: 0.2069304\ttotal: 11.2s\tremaining: 3.29s\n",
      "541:\tlearn: 0.2067191\ttotal: 11.2s\tremaining: 3.27s\n",
      "542:\tlearn: 0.2064456\ttotal: 11.2s\tremaining: 3.25s\n",
      "543:\tlearn: 0.2063350\ttotal: 11.2s\tremaining: 3.22s\n",
      "544:\tlearn: 0.2058841\ttotal: 11.3s\tremaining: 3.2s\n",
      "545:\tlearn: 0.2054647\ttotal: 11.3s\tremaining: 3.18s\n",
      "546:\tlearn: 0.2050703\ttotal: 11.3s\tremaining: 3.16s\n",
      "547:\tlearn: 0.2046718\ttotal: 11.3s\tremaining: 3.14s\n",
      "548:\tlearn: 0.2042137\ttotal: 11.3s\tremaining: 3.12s\n",
      "549:\tlearn: 0.2039390\ttotal: 11.4s\tremaining: 3.1s\n",
      "550:\tlearn: 0.2035056\ttotal: 11.4s\tremaining: 3.08s\n",
      "551:\tlearn: 0.2031619\ttotal: 11.4s\tremaining: 3.06s\n",
      "552:\tlearn: 0.2029121\ttotal: 11.4s\tremaining: 3.04s\n",
      "553:\tlearn: 0.2025152\ttotal: 11.5s\tremaining: 3.02s\n",
      "554:\tlearn: 0.2021961\ttotal: 11.5s\tremaining: 3s\n",
      "555:\tlearn: 0.2020298\ttotal: 11.5s\tremaining: 2.98s\n",
      "556:\tlearn: 0.2014377\ttotal: 11.5s\tremaining: 2.96s\n",
      "557:\tlearn: 0.2011958\ttotal: 11.5s\tremaining: 2.94s\n",
      "558:\tlearn: 0.2009412\ttotal: 11.6s\tremaining: 2.92s\n",
      "559:\tlearn: 0.2005199\ttotal: 11.6s\tremaining: 2.89s\n",
      "560:\tlearn: 0.2003482\ttotal: 11.6s\tremaining: 2.87s\n",
      "561:\tlearn: 0.1999642\ttotal: 11.6s\tremaining: 2.85s\n",
      "562:\tlearn: 0.1996860\ttotal: 11.6s\tremaining: 2.83s\n",
      "563:\tlearn: 0.1994435\ttotal: 11.7s\tremaining: 2.81s\n",
      "564:\tlearn: 0.1992297\ttotal: 11.7s\tremaining: 2.79s\n",
      "565:\tlearn: 0.1988994\ttotal: 11.7s\tremaining: 2.77s\n",
      "566:\tlearn: 0.1984542\ttotal: 11.7s\tremaining: 2.75s\n",
      "567:\tlearn: 0.1981565\ttotal: 11.7s\tremaining: 2.73s\n",
      "568:\tlearn: 0.1977925\ttotal: 11.8s\tremaining: 2.71s\n",
      "569:\tlearn: 0.1975952\ttotal: 11.8s\tremaining: 2.69s\n",
      "570:\tlearn: 0.1974440\ttotal: 11.8s\tremaining: 2.67s\n",
      "571:\tlearn: 0.1971740\ttotal: 11.8s\tremaining: 2.65s\n",
      "572:\tlearn: 0.1968789\ttotal: 11.8s\tremaining: 2.63s\n",
      "573:\tlearn: 0.1965643\ttotal: 11.9s\tremaining: 2.6s\n",
      "574:\tlearn: 0.1961826\ttotal: 11.9s\tremaining: 2.58s\n",
      "575:\tlearn: 0.1958640\ttotal: 11.9s\tremaining: 2.56s\n",
      "576:\tlearn: 0.1955483\ttotal: 11.9s\tremaining: 2.54s\n",
      "577:\tlearn: 0.1952868\ttotal: 12s\tremaining: 2.52s\n",
      "578:\tlearn: 0.1951296\ttotal: 12s\tremaining: 2.5s\n",
      "579:\tlearn: 0.1948904\ttotal: 12s\tremaining: 2.48s\n",
      "580:\tlearn: 0.1946010\ttotal: 12s\tremaining: 2.46s\n",
      "581:\tlearn: 0.1943449\ttotal: 12s\tremaining: 2.44s\n",
      "582:\tlearn: 0.1941127\ttotal: 12.1s\tremaining: 2.42s\n",
      "583:\tlearn: 0.1938357\ttotal: 12.1s\tremaining: 2.4s\n",
      "584:\tlearn: 0.1935135\ttotal: 12.1s\tremaining: 2.38s\n",
      "585:\tlearn: 0.1933098\ttotal: 12.1s\tremaining: 2.36s\n",
      "586:\tlearn: 0.1930918\ttotal: 12.1s\tremaining: 2.34s\n",
      "587:\tlearn: 0.1926614\ttotal: 12.2s\tremaining: 2.31s\n",
      "588:\tlearn: 0.1923346\ttotal: 12.2s\tremaining: 2.29s\n",
      "589:\tlearn: 0.1920641\ttotal: 12.2s\tremaining: 2.27s\n",
      "590:\tlearn: 0.1919163\ttotal: 12.2s\tremaining: 2.25s\n",
      "591:\tlearn: 0.1916071\ttotal: 12.2s\tremaining: 2.23s\n",
      "592:\tlearn: 0.1912195\ttotal: 12.3s\tremaining: 2.21s\n",
      "593:\tlearn: 0.1909493\ttotal: 12.3s\tremaining: 2.19s\n",
      "594:\tlearn: 0.1906955\ttotal: 12.3s\tremaining: 2.17s\n",
      "595:\tlearn: 0.1904997\ttotal: 12.3s\tremaining: 2.15s\n",
      "596:\tlearn: 0.1903141\ttotal: 12.3s\tremaining: 2.13s\n",
      "597:\tlearn: 0.1901675\ttotal: 12.4s\tremaining: 2.11s\n",
      "598:\tlearn: 0.1898138\ttotal: 12.4s\tremaining: 2.09s\n",
      "599:\tlearn: 0.1896109\ttotal: 12.4s\tremaining: 2.07s\n",
      "600:\tlearn: 0.1893577\ttotal: 12.4s\tremaining: 2.05s\n",
      "601:\tlearn: 0.1890602\ttotal: 12.5s\tremaining: 2.03s\n",
      "602:\tlearn: 0.1886968\ttotal: 12.5s\tremaining: 2.01s\n",
      "603:\tlearn: 0.1885641\ttotal: 12.5s\tremaining: 1.99s\n",
      "604:\tlearn: 0.1884832\ttotal: 12.5s\tremaining: 1.96s\n",
      "605:\tlearn: 0.1881313\ttotal: 12.5s\tremaining: 1.94s\n",
      "606:\tlearn: 0.1878361\ttotal: 12.6s\tremaining: 1.92s\n",
      "607:\tlearn: 0.1875912\ttotal: 12.6s\tremaining: 1.9s\n",
      "608:\tlearn: 0.1872981\ttotal: 12.6s\tremaining: 1.88s\n",
      "609:\tlearn: 0.1870510\ttotal: 12.6s\tremaining: 1.86s\n",
      "610:\tlearn: 0.1868249\ttotal: 12.6s\tremaining: 1.84s\n",
      "611:\tlearn: 0.1866455\ttotal: 12.7s\tremaining: 1.82s\n",
      "612:\tlearn: 0.1864149\ttotal: 12.7s\tremaining: 1.8s\n",
      "613:\tlearn: 0.1861215\ttotal: 12.7s\tremaining: 1.78s\n",
      "614:\tlearn: 0.1859750\ttotal: 12.7s\tremaining: 1.76s\n",
      "615:\tlearn: 0.1856410\ttotal: 12.7s\tremaining: 1.74s\n",
      "616:\tlearn: 0.1854990\ttotal: 12.8s\tremaining: 1.72s\n",
      "617:\tlearn: 0.1852388\ttotal: 12.8s\tremaining: 1.7s\n",
      "618:\tlearn: 0.1850928\ttotal: 12.8s\tremaining: 1.67s\n",
      "619:\tlearn: 0.1848382\ttotal: 12.8s\tremaining: 1.65s\n",
      "620:\tlearn: 0.1846439\ttotal: 12.8s\tremaining: 1.63s\n",
      "621:\tlearn: 0.1843596\ttotal: 12.9s\tremaining: 1.61s\n",
      "622:\tlearn: 0.1841980\ttotal: 12.9s\tremaining: 1.59s\n",
      "623:\tlearn: 0.1838884\ttotal: 12.9s\tremaining: 1.57s\n",
      "624:\tlearn: 0.1835031\ttotal: 12.9s\tremaining: 1.55s\n",
      "625:\tlearn: 0.1832639\ttotal: 12.9s\tremaining: 1.53s\n",
      "626:\tlearn: 0.1830625\ttotal: 13s\tremaining: 1.51s\n",
      "627:\tlearn: 0.1827416\ttotal: 13s\tremaining: 1.49s\n",
      "628:\tlearn: 0.1824286\ttotal: 13s\tremaining: 1.47s\n",
      "629:\tlearn: 0.1823075\ttotal: 13s\tremaining: 1.45s\n",
      "630:\tlearn: 0.1820213\ttotal: 13s\tremaining: 1.43s\n",
      "631:\tlearn: 0.1819120\ttotal: 13.1s\tremaining: 1.41s\n",
      "632:\tlearn: 0.1815678\ttotal: 13.1s\tremaining: 1.39s\n",
      "633:\tlearn: 0.1813979\ttotal: 13.1s\tremaining: 1.36s\n",
      "634:\tlearn: 0.1811235\ttotal: 13.1s\tremaining: 1.34s\n",
      "635:\tlearn: 0.1808103\ttotal: 13.2s\tremaining: 1.32s\n",
      "636:\tlearn: 0.1805056\ttotal: 13.2s\tremaining: 1.3s\n",
      "637:\tlearn: 0.1802638\ttotal: 13.2s\tremaining: 1.28s\n",
      "638:\tlearn: 0.1801379\ttotal: 13.2s\tremaining: 1.26s\n",
      "639:\tlearn: 0.1799873\ttotal: 13.2s\tremaining: 1.24s\n",
      "640:\tlearn: 0.1797624\ttotal: 13.3s\tremaining: 1.22s\n",
      "641:\tlearn: 0.1794322\ttotal: 13.3s\tremaining: 1.2s\n",
      "642:\tlearn: 0.1790279\ttotal: 13.3s\tremaining: 1.18s\n",
      "643:\tlearn: 0.1787533\ttotal: 13.3s\tremaining: 1.16s\n",
      "644:\tlearn: 0.1784517\ttotal: 13.3s\tremaining: 1.14s\n",
      "645:\tlearn: 0.1783261\ttotal: 13.4s\tremaining: 1.12s\n",
      "646:\tlearn: 0.1780576\ttotal: 13.4s\tremaining: 1.09s\n",
      "647:\tlearn: 0.1779151\ttotal: 13.4s\tremaining: 1.07s\n",
      "648:\tlearn: 0.1777019\ttotal: 13.4s\tremaining: 1.05s\n",
      "649:\tlearn: 0.1774955\ttotal: 13.4s\tremaining: 1.03s\n",
      "650:\tlearn: 0.1772804\ttotal: 13.5s\tremaining: 1.01s\n",
      "651:\tlearn: 0.1771014\ttotal: 13.5s\tremaining: 993ms\n",
      "652:\tlearn: 0.1769228\ttotal: 13.5s\tremaining: 972ms\n",
      "653:\tlearn: 0.1767949\ttotal: 13.5s\tremaining: 951ms\n",
      "654:\tlearn: 0.1766099\ttotal: 13.5s\tremaining: 931ms\n",
      "655:\tlearn: 0.1763046\ttotal: 13.6s\tremaining: 910ms\n",
      "656:\tlearn: 0.1760933\ttotal: 13.6s\tremaining: 890ms\n",
      "657:\tlearn: 0.1759290\ttotal: 13.6s\tremaining: 869ms\n",
      "658:\tlearn: 0.1757282\ttotal: 13.6s\tremaining: 848ms\n",
      "659:\tlearn: 0.1755962\ttotal: 13.7s\tremaining: 828ms\n",
      "660:\tlearn: 0.1754064\ttotal: 13.7s\tremaining: 807ms\n",
      "661:\tlearn: 0.1750847\ttotal: 13.7s\tremaining: 786ms\n",
      "662:\tlearn: 0.1747748\ttotal: 13.7s\tremaining: 765ms\n",
      "663:\tlearn: 0.1746680\ttotal: 13.7s\tremaining: 745ms\n",
      "664:\tlearn: 0.1744579\ttotal: 13.8s\tremaining: 724ms\n",
      "665:\tlearn: 0.1739894\ttotal: 13.8s\tremaining: 703ms\n",
      "666:\tlearn: 0.1736023\ttotal: 13.8s\tremaining: 683ms\n",
      "667:\tlearn: 0.1735129\ttotal: 13.8s\tremaining: 662ms\n",
      "668:\tlearn: 0.1731768\ttotal: 13.8s\tremaining: 641ms\n",
      "669:\tlearn: 0.1729104\ttotal: 13.9s\tremaining: 621ms\n",
      "670:\tlearn: 0.1726944\ttotal: 13.9s\tremaining: 600ms\n",
      "671:\tlearn: 0.1724632\ttotal: 13.9s\tremaining: 580ms\n",
      "672:\tlearn: 0.1723379\ttotal: 13.9s\tremaining: 559ms\n",
      "673:\tlearn: 0.1720440\ttotal: 13.9s\tremaining: 538ms\n",
      "674:\tlearn: 0.1718350\ttotal: 14s\tremaining: 517ms\n",
      "675:\tlearn: 0.1717108\ttotal: 14s\tremaining: 497ms\n",
      "676:\tlearn: 0.1714737\ttotal: 14s\tremaining: 476ms\n",
      "677:\tlearn: 0.1710452\ttotal: 14s\tremaining: 455ms\n",
      "678:\tlearn: 0.1708387\ttotal: 14.1s\tremaining: 435ms\n",
      "679:\tlearn: 0.1705721\ttotal: 14.1s\tremaining: 414ms\n",
      "680:\tlearn: 0.1702875\ttotal: 14.1s\tremaining: 393ms\n",
      "681:\tlearn: 0.1701077\ttotal: 14.1s\tremaining: 373ms\n",
      "682:\tlearn: 0.1698148\ttotal: 14.1s\tremaining: 352ms\n",
      "683:\tlearn: 0.1695651\ttotal: 14.2s\tremaining: 331ms\n",
      "684:\tlearn: 0.1693513\ttotal: 14.2s\tremaining: 310ms\n",
      "685:\tlearn: 0.1690492\ttotal: 14.2s\tremaining: 290ms\n",
      "686:\tlearn: 0.1689012\ttotal: 14.2s\tremaining: 269ms\n",
      "687:\tlearn: 0.1686179\ttotal: 14.2s\tremaining: 248ms\n",
      "688:\tlearn: 0.1684367\ttotal: 14.3s\tremaining: 228ms\n",
      "689:\tlearn: 0.1680564\ttotal: 14.3s\tremaining: 207ms\n",
      "690:\tlearn: 0.1678294\ttotal: 14.3s\tremaining: 186ms\n",
      "691:\tlearn: 0.1676272\ttotal: 14.3s\tremaining: 166ms\n",
      "692:\tlearn: 0.1673201\ttotal: 14.3s\tremaining: 145ms\n",
      "693:\tlearn: 0.1671301\ttotal: 14.4s\tremaining: 124ms\n",
      "694:\tlearn: 0.1669440\ttotal: 14.4s\tremaining: 103ms\n",
      "695:\tlearn: 0.1666811\ttotal: 14.4s\tremaining: 82.8ms\n",
      "696:\tlearn: 0.1664196\ttotal: 14.4s\tremaining: 62.1ms\n",
      "697:\tlearn: 0.1661419\ttotal: 14.4s\tremaining: 41.4ms\n",
      "698:\tlearn: 0.1659203\ttotal: 14.5s\tremaining: 20.7ms\n",
      "699:\tlearn: 0.1657353\ttotal: 14.5s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'results f1: 0.7638949402835452'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97     16821\n",
      "           1       0.90      0.90      0.90      4544\n",
      "\n",
      "    accuracy                           0.96     21365\n",
      "   macro avg       0.94      0.93      0.93     21365\n",
      "weighted avg       0.96      0.96      0.96     21365\n",
      "\n",
      "auc: 0.9341490644344634\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display_cv(best_model,cleaned_data , y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy on Test Set:  0.858814352574103\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(x_test)\n",
    "final_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Final Accuracy on Test Set: \", final_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8484269614308676"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "f1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1Qdzbejqt4ypSvL-h8WFMmQFEFZB2GKId",
     "timestamp": 1716377771632
    },
    {
     "file_id": "1ER4NDAWpuwaZ43Dn9vYxd_vapYEDeczF",
     "timestamp": 1652728119372
    },
    {
     "file_id": "1InS6-7UZYc8qRPKGhEBkGv8nMQ3dl3Qq",
     "timestamp": 1631545645387
    },
    {
     "file_id": "1Pp88aji8w35O-WJbctcsHfinGqUhoT1c",
     "timestamp": 1622488006439
    },
    {
     "file_id": "1PNmd4hys3w1ZYkMSzqYL7fVV3v72Chxv",
     "timestamp": 1614187967149
    },
    {
     "file_id": "1Nv7GmhY_xL7txEJ0nNKNP1WmMiXEHA5U",
     "timestamp": 1613739709908
    },
    {
     "file_id": "https://github.com/stepthom/NLP_course/blob/main/document_classification/kiva_classification_simple.ipynb",
     "timestamp": 1613482590973
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
